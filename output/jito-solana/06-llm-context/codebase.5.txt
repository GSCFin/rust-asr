This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.buildkite/
  hooks/
    post-checkout
    post-command
    pre-command
  scripts/
    build-stable.sh
    build-stable.test.sh
    common.sh
    common.test.sh
    func-assert-eq.sh
    test-all.sh
    trigger-github-actions-windows-build.sh
  pipeline-upload.sh
  solana-private.sh
.config/
  nextest.toml
.github/
  ISSUE_TEMPLATE/
    0-community.md
    1-core-contributor.md
    2-feature-gate.yml
  scripts/
    add-team-to-ghsa.sh
    check-changelog.sh
    downstream-project-spl-common.sh
    downstream-project-spl-install-deps.sh
    install-all-deps.sh
    install-openssl.sh
    install-proto.sh
    purge-ubuntu-runner.sh
  workflows/
    add-team-to-ghsa.yml
    benchmark.yml
    cargo.yml
    changelog-label.yml
    client-targets.yml
    crate-check.yml
    dependabot-pr.yml
    docs.yml
    downstream-project-anchor.yml
    downstream-project-spl-nightly.yml
    downstream-project-spl.yml
    error-reporting.yml
    label-actions.yml
    publish-windows-tarball.yml
    rebase.yaml
    release.yml
    verify-packets.yml
  CODEOWNERS
  dependabot.yml
  label-actions.yml
  PULL_REQUEST_TEMPLATE.md
  RELEASE_TEMPLATE.md
account-decoder/
  src/
    lib.rs
    parse_account_data.rs
    parse_address_lookup_table.rs
    parse_bpf_loader.rs
    parse_config.rs
    parse_nonce.rs
    parse_stake.rs
    parse_sysvar.rs
    parse_token_extension.rs
    parse_token.rs
    parse_vote.rs
    validator_info.rs
  Cargo.toml
account-decoder-client-types/
  src/
    lib.rs
    token.rs
  Cargo.toml
accounts-cluster-bench/
  src/
    main.rs
  .gitignore
  Cargo.toml
accounts-db/
  benches/
    accounts_index.rs
    accounts.rs
    bench_accounts_file.rs
    bench_hashing.rs
    bench_lock_accounts.rs
    bench_serde.rs
    read_only_accounts_cache.rs
    utils.rs
  src/
    account_storage/
      stored_account_info.rs
    accounts_db/
      accounts_db_config.rs
      geyser_plugin_utils.rs
      stats.rs
      tests.rs
    accounts_index/
      account_map_entry.rs
      accounts_index_storage.rs
      bucket_map_holder.rs
      in_mem_accounts_index.rs
      iter.rs
      roots_tracker.rs
      secondary.rs
      stats.rs
    append_vec/
      meta.rs
      test_utils.rs
    rolling_bit_field/
      iterators.rs
    tiered_storage/
      byte_block.rs
      error.rs
      file.rs
      footer.rs
      hot.rs
      index.rs
      meta.rs
      mmap_utils.rs
      owners.rs
      readable.rs
      test_utils.rs
    account_info.rs
    account_locks.rs
    account_storage_reader.rs
    account_storage.rs
    accounts_cache.rs
    accounts_db.rs
    accounts_file.rs
    accounts_hash.rs
    accounts_index.rs
    accounts_update_notifier_interface.rs
    accounts.rs
    active_stats.rs
    ancestors.rs
    ancient_append_vecs.rs
    append_vec.rs
    blockhash_queue.rs
    contains.rs
    is_loadable.rs
    is_zero_lamport.rs
    lib.rs
    obsolete_accounts.rs
    partitioned_rewards.rs
    pubkey_bins.rs
    read_only_accounts_cache.rs
    rolling_bit_field.rs
    sorted_storages.rs
    stake_rewards.rs
    storable_accounts.rs
    tiered_storage.rs
    utils.rs
    waitable_condvar.rs
  store-histogram/
    src/
      main.rs
    Cargo.toml
  store-tool/
    src/
      main.rs
    Cargo.toml
  tests/
    read_only_accounts_cache.rs
  Cargo.toml
bam-banking-bench/
  src/
    main.rs
    mock_bam_server.rs
  .gitignore
  Cargo.toml
bam-local-cluster/
  examples/
    example_config.toml
  src/
    cluster_manager.rs
    config.rs
    lib.rs
    main.rs
  Cargo.toml
  README.md
banking-bench/
  src/
    main.rs
  .gitignore
  Cargo.toml
banking-stage-ingress-types/
  src/
    lib.rs
  Cargo.toml
banks-client/
  src/
    error.rs
    lib.rs
  Cargo.toml
banks-interface/
  src/
    lib.rs
  Cargo.toml
banks-server/
  src/
    banks_server.rs
    lib.rs
  Cargo.toml
bench-streamer/
  src/
    main.rs
  .gitignore
  Cargo.toml
bench-tps/
  src/
    bench.rs
    cli.rs
    keypairs.rs
    lib.rs
    log_transaction_service.rs
    main.rs
    perf_utils.rs
    rpc_with_retry_utils.rs
    send_batch.rs
  tests/
    fixtures/
      spl_instruction_padding.so
    bench_tps.rs
  .gitignore
  Cargo.toml
bench-vote/
  src/
    main.rs
  Cargo.toml
bloom/
  benches/
    bloom.rs
  src/
    bloom.rs
    lib.rs
  Cargo.toml
bucket_map/
  src/
    bucket_api.rs
    bucket_item.rs
    bucket_map.rs
    bucket_stats.rs
    bucket_storage.rs
    bucket.rs
    index_entry.rs
    lib.rs
    restart.rs
  tests/
    bucket_map.rs
  Cargo.toml
builtins/
  src/
    core_bpf_migration.rs
    lib.rs
    prototype.rs
  Cargo.toml
builtins-default-costs/
  src/
    lib.rs
  Cargo.toml
bundle/
  src/
    lib.rs
  Cargo.toml
cargo-registry/
  src/
    client.rs
    crate_handler.rs
    main.rs
    response_builder.rs
    sparse_index.rs
  Cargo.toml
ci/
  bench/
    common.sh
    part1.sh
    part2.sh
  common/
    limit-threads.sh
    shared-functions.sh
  coverage/
    common.sh
    part-1.sh
    part-2.sh
    part-3.sh
  docker/
    build.sh
    Dockerfile
    env.sh
    README.md
  downstream-projects/
    common.sh
    func-openbook-dex.sh
    func-spl.sh
    run-all.sh
    run-openbook-dex.sh
    run-spl.sh
  semver_bash/
    LICENSE
    README.md
    semver_test.sh
    semver.sh
  stable/
    common.sh
    run-all.sh
    run-local-cluster-partially.sh
    run-localnet.sh
    run-partition.sh
  xtask/
    src/
      commands/
        bump_version.rs
        hello.rs
      commands.rs
      common.rs
      main.rs
    Cargo.toml
  _
  .gitignore
  buildkite-pipeline.sh
  buildkite-secondary.yml
  buildkite-solana-private.sh
  channel_restriction.sh
  channel-info.sh
  check-channel-version.sh
  check-crates.sh
  check-install-all.sh
  crate-version.sh
  do-audit.sh
  docker-run-default-image.sh
  docker-run.sh
  env.sh
  format-url.sh
  hoover.sh
  intercept.sh
  localnet-sanity.sh
  nits.sh
  order-crates-for-publishing.py
  platform-tools-info.sh
  publish-crate.sh
  publish-installer.sh
  publish-metrics-dashboard.sh
  publish-tarball.sh
  run-local.sh
  run-sanity.sh
  rust-version.sh
  shellcheck.sh
  test-checks.sh
  test-coverage.sh
  test-dev-context-only-utils.sh
  test-downstream-builds.sh
  test-frozen-abi.sh
  test-miri.sh
  test-sanity.sh
  test-shuttle.sh
  test-stable.sh
  test-verify-packets-gossip.sh
  test.sh
  upload-benchmark.sh
  upload-ci-artifact.sh
  upload-github-release-asset.sh
clap-utils/
  src/
    compute_budget.rs
    compute_unit_price.rs
    fee_payer.rs
    input_parsers.rs
    input_validators.rs
    keypair.rs
    lib.rs
    memo.rs
    nonce.rs
    offline.rs
  Cargo.toml
clap-v3-utils/
  src/
    input_parsers/
      mod.rs
      signer.rs
    keygen/
      derivation_path.rs
      mnemonic.rs
      mod.rs
    compute_budget.rs
    fee_payer.rs
    input_validators.rs
    keypair.rs
    lib.rs
    memo.rs
    nonce.rs
    offline.rs
  Cargo.toml
cli/
  src/
    address_lookup_table.rs
    checks.rs
    clap_app.rs
    cli.rs
    cluster_query.rs
    compute_budget.rs
    feature.rs
    inflation.rs
    lib.rs
    main.rs
    memo.rs
    nonce.rs
    program_v4.rs
    program.rs
    spend_utils.rs
    stake.rs
    test_utils.rs
    validator_info.rs
    vote.rs
    wallet.rs
  tests/
    fixtures/
      alt_bn128.so
      build.sh
      noop_large.so
      noop.so
    address_lookup_table.rs
    cluster_query.rs
    nonce.rs
    program.rs
    request_airdrop.rs
    stake.rs
    transfer.rs
    validator_info.rs
    vote.rs
  .gitignore
  Cargo.toml
cli-config/
  src/
    config_input.rs
    config.rs
    lib.rs
  Cargo.toml
cli-output/
  src/
    cli_output.rs
    cli_version.rs
    display.rs
    lib.rs
  Cargo.toml
client/
  src/
    nonblocking/
      mod.rs
      tpu_client.rs
    connection_cache.rs
    lib.rs
    send_and_confirm_transactions_in_parallel.rs
    tpu_client.rs
    transaction_executor.rs
  .gitignore
  Cargo.toml
client-test/
  tests/
    client.rs
    send_and_confirm_transactions_in_parallel.rs
  .gitignore
  Cargo.toml
compute-budget/
  src/
    compute_budget_limits.rs
    compute_budget.rs
    lib.rs
  Cargo.toml
compute-budget-instruction/
  benches/
    process_compute_budget_instructions.rs
  src/
    builtin_programs_filter.rs
    compute_budget_instruction_details.rs
    compute_budget_program_id_filter.rs
    instructions_processor.rs
    lib.rs
  Cargo.toml
connection-cache/
  src/
    nonblocking/
      client_connection.rs
      mod.rs
    client_connection.rs
    connection_cache_stats.rs
    connection_cache.rs
    lib.rs
  Cargo.toml
core/
  benches/
    banking_stage.rs
    banking_trace.rs
    consensus.rs
    consumer.rs
    gen_keys.rs
    proto_to_packet.rs
    receive_and_buffer_utils.rs
    receive_and_buffer.rs
    scheduler.rs
    shredder.rs
    sigverify_stage.rs
  src/
    banking_stage/
      transaction_scheduler/
        bam_receive_and_buffer.rs
        bam_scheduler.rs
        bam_utils.rs
        batch_id_generator.rs
        greedy_scheduler.rs
        in_flight_tracker.rs
        mod.rs
        prio_graph_scheduler.rs
        receive_and_buffer.rs
        scheduler_common.rs
        scheduler_controller.rs
        scheduler_error.rs
        scheduler_metrics.rs
        scheduler.rs
        transaction_priority_id.rs
        transaction_state_container.rs
        transaction_state.rs
      committer.rs
      consume_worker.rs
      consumer.rs
      decision_maker.rs
      latest_validator_vote_packet.rs
      leader_slot_metrics.rs
      leader_slot_timing_metrics.rs
      progress_tracker.rs
      qos_service.rs
      read_write_account_set.rs
      scheduler_messages.rs
      tpu_to_pack.rs
      unified_scheduler.rs
      vote_packet_receiver.rs
      vote_storage.rs
      vote_worker.rs
    block_creation_loop/
      stats.rs
    bundle_stage/
      bundle_account_locker.rs
      bundle_consumer.rs
      bundle_packet_deserializer.rs
      bundle_stage_leader_metrics.rs
      bundle_storage.rs
    cluster_slots_service/
      cluster_slots.rs
      slot_supporters.rs
    consensus/
      fork_choice.rs
      heaviest_subtree_fork_choice.rs
      latest_validator_votes_for_frozen_banks.rs
      progress_map.rs
      tower_storage.rs
      tower_vote_state.rs
      tower1_14_11.rs
      tower1_7_14.rs
      tree_diff.rs
      vote_stake_tracker.rs
    forwarding_stage/
      packet_container.rs
    proxy/
      auth.rs
      block_engine_stage.rs
      fetch_stage_manager.rs
      mod.rs
      relayer_stage.rs
    repair/
      ancestor_hashes_service.rs
      cluster_slot_state_verifier.rs
      duplicate_repair_status.rs
      malicious_repair_handler.rs
      mod.rs
      outstanding_requests.rs
      packet_threshold.rs
      quic_endpoint.rs
      repair_generic_traversal.rs
      repair_handler.rs
      repair_response.rs
      repair_service.rs
      repair_weight.rs
      repair_weighted_traversal.rs
      request_response.rs
      result.rs
      serve_repair_service.rs
      serve_repair.rs
      standard_repair_handler.rs
    snapshot_packager_service/
      snapshot_gossip_manager.rs
    tip_manager/
      tip_distribution.rs
      tip_payment.rs
    admin_rpc_post_init.rs
    bam_connection.rs
    bam_dependencies.rs
    bam_manager.rs
    banking_simulation.rs
    banking_stage.rs
    banking_trace.rs
    block_creation_loop.rs
    bundle_sigverify_stage.rs
    bundle_stage.rs
    bundle.rs
    cluster_info_vote_listener.rs
    cluster_slots_service.rs
    commitment_service.rs
    completed_data_sets_service.rs
    consensus.rs
    cost_update_service.rs
    drop_bank_service.rs
    fetch_stage.rs
    forwarding_stage.rs
    gen_keys.rs
    lib.rs
    mock_alpenglow_consensus.rs
    next_leader.rs
    optimistic_confirmation_verifier.rs
    packet_bundle.rs
    replay_stage.rs
    resource_limits.rs
    result.rs
    sample_performance_service.rs
    scheduler_bindings_server.rs
    shred_fetch_stage.rs
    sigverify_stage.rs
    sigverify.rs
    snapshot_packager_service.rs
    staked_nodes_updater_service.rs
    stats_reporter_service.rs
    system_monitor_service.rs
    tip_manager.rs
    tpu_entry_notifier.rs
    tpu.rs
    tvu.rs
    unfrozen_gossip_verified_vote_hashes.rs
    validator.rs
    vortexor_receiver_adapter.rs
    vote_simulator.rs
    voting_service.rs
    warm_quic_cache_service.rs
    window_service.rs
  tests/
    bam_connection.rs
    fork-selection.rs
    scheduler_cost_adjustment.rs
    snapshots.rs
    unified_scheduler.rs
  .gitignore
  Cargo.toml
cost-model/
  benches/
    cost_model.rs
    cost_tracker.rs
  src/
    block_cost_limits.rs
    cost_model.rs
    cost_tracker_post_analysis.rs
    cost_tracker.rs
    lib.rs
    transaction_cost.rs
  Cargo.toml
curves/
  curve25519/
    src/
      curve_syscall_traits.rs
      edwards.rs
      errors.rs
      lib.rs
      ristretto.rs
      scalar.rs
    .gitignore
    Cargo.toml
dev/
  Dockerfile
dev-bins/
  .config/
    nextest.toml
  Cargo.toml
docker-solana/
  .gitignore
  build.sh
  Dockerfile
  README.md
docs/
  art/
    fork-generation.bob
    forks-pruned.bob
    forks-pruned2.bob
    forks.bob
    passive-staking-callflow.msc
    retransmit_stage.bob
    runtime.bob
    sdk-tools.bob
    spv-bank-hash.bob
    spv-block-merkle.bob
    tpu.bob
    transaction.bob
    tvu.bob
    validator-proposal.bob
    validator.bob
  components/
    Card.jsx
    HomeCtaLinks.jsx
  src/
    cli/
      examples/
        _category_.json
        choose-a-cluster.md
        delegate-stake.md
        deploy-a-program.md
        durable-nonce.md
        offline-signing.md
        sign-offchain-message.md
        test-validator.md
        transfer-tokens.md
      wallets/
        hardware/
          _category_.json
          index.md
          ledger.md
        _category_.json
        file-system.md
        index.md
        paper.md
      .usage.md.header
      index.md
      install.md
      intro.md
    clusters/
      available.md
      benchmark.md
      index.md
      metrics.md
      testnet.md
    consensus/
      commitments.md
      fork-generation.md
      leader-rotation.md
      managing-forks.md
      stake-delegation-and-rewards.md
      synchronization.md
      turbine-block-propagation.md
      vote-signing.md
    css/
      custom.css
    implemented-proposals/
      ed_overview/
        ed_validation_client_economics/
          ed_vce_overview.md
          ed_vce_state_validation_protocol_based_rewards.md
          ed_vce_state_validation_transaction_fees.md
          ed_vce_validation_stake_delegation.md
        ed_economic_sustainability.md
        ed_mvp.md
        ed_overview.md
        ed_references.md
        ed_storage_rent_economics.md
      abi-management.md
      bank-timestamp-correction.md
      commitment.md
      durable-tx-nonces.md
      epoch_accounts_hash.md
      index.md
      installer.md
      instruction_introspection.md
      leader-leader-transition.md
      leader-validator-transition.md
      persistent-account-storage.md
      readonly-accounts.md
      reliable-vote-transmission.md
      rent.md
      repair-service.md
      rpc-transaction-history.md
      snapshot-verification.md
      staking-rewards.md
      testing-programs.md
      tower-bft.md
      transaction-fees.md
      validator-timestamp-oracle.md
    operations/
      best-practices/
        _category_.json
        general.md
        monitoring.md
        security.md
      guides/
        _category_.json
        restart-cluster.md
        validator-failover.md
        validator-info.md
        validator-monitor.md
        validator-stake.md
        validator-start.md
        validator-troubleshoot.md
        vote-accounts.md
      _category_.json
      index.md
      prerequisites.md
      requirements.md
      setup-a-validator.md
      setup-an-rpc-node.md
      validator-or-rpc-node.md
    pages/
      styles.module.css
    proposals/
      accepted-design-proposals.md
      accounts-db-replication.md
      bankless-leader.md
      block-confirmation.md
      cluster-test-framework.md
      comprehensive-compute-fees.md
      embedding-move.md
      fee_transaction_priority.md
      handle-duplicate-block.md
      interchain-transaction-verification.md
      ledger-replication-to-implement.md
      log_data.md
      off-chain-message-signing.md
      optimistic_confirmation.md
      optimistic-confirmation-and-slashing.md
      optimistic-transaction-propagation-signal.md
      partitioned-inflationary-rewards-distribution.md
      program-instruction-macro.md
      return-data.md
      rip-curl.md
      simple-payment-and-state-verification.md
      slashing.md
      snapshot-verification.md
      tick-verification.md
      timely-vote-credits.md
      validator-proposal.md
      versioned-transactions.md
      vote-signing-to-implement.md
    runtime/
      zk-docs/
        ciphertext_ciphertext_equality.pdf
        ciphertext_commitment_equality.pdf
        ciphertext_validity.pdf
        percentage_with_cap.pdf
        pubkey_proof.pdf
        twisted_elgamal.pdf
        zero_proof.pdf
      programs.md
      sysvars.md
      zk-elgamal-proof.md
    theme/
      Footer/
        index.js
        styles.module.css
    validator/
      anatomy.md
      blockstore.md
      geyser.md
      gossip.md
      runtime.md
      tpu.md
      tvu.md
    architecture.md
    backwards-compatibility.md
    faq.md
    index.mdx
    proposals.md
    what-is-a-validator.md
    what-is-an-rpc-node.md
  static/
    img/
      favicon.ico
    katex/
      contrib/
        auto-render.js
        auto-render.min.js
        auto-render.mjs
        copy-tex.css
        copy-tex.js
        copy-tex.min.css
        copy-tex.min.js
        copy-tex.mjs
        mathtex-script-type.js
        mathtex-script-type.min.js
        mathtex-script-type.mjs
        mhchem.js
        mhchem.min.js
        mhchem.mjs
        render-a11y-string.js
        render-a11y-string.min.js
        render-a11y-string.mjs
      fonts/
        KaTeX_AMS-Regular.ttf
        KaTeX_AMS-Regular.woff
        KaTeX_AMS-Regular.woff2
        KaTeX_Caligraphic-Bold.ttf
        KaTeX_Caligraphic-Bold.woff
        KaTeX_Caligraphic-Bold.woff2
        KaTeX_Caligraphic-Regular.ttf
        KaTeX_Caligraphic-Regular.woff
        KaTeX_Caligraphic-Regular.woff2
        KaTeX_Fraktur-Bold.ttf
        KaTeX_Fraktur-Bold.woff
        KaTeX_Fraktur-Bold.woff2
        KaTeX_Fraktur-Regular.ttf
        KaTeX_Fraktur-Regular.woff
        KaTeX_Fraktur-Regular.woff2
        KaTeX_Main-Bold.ttf
        KaTeX_Main-Bold.woff
        KaTeX_Main-Bold.woff2
        KaTeX_Main-BoldItalic.ttf
        KaTeX_Main-BoldItalic.woff
        KaTeX_Main-BoldItalic.woff2
        KaTeX_Main-Italic.ttf
        KaTeX_Main-Italic.woff
        KaTeX_Main-Italic.woff2
        KaTeX_Main-Regular.ttf
        KaTeX_Main-Regular.woff
        KaTeX_Main-Regular.woff2
        KaTeX_Math-BoldItalic.ttf
        KaTeX_Math-BoldItalic.woff
        KaTeX_Math-BoldItalic.woff2
        KaTeX_Math-Italic.ttf
        KaTeX_Math-Italic.woff
        KaTeX_Math-Italic.woff2
        KaTeX_SansSerif-Bold.ttf
        KaTeX_SansSerif-Bold.woff
        KaTeX_SansSerif-Bold.woff2
        KaTeX_SansSerif-Italic.ttf
        KaTeX_SansSerif-Italic.woff
        KaTeX_SansSerif-Italic.woff2
        KaTeX_SansSerif-Regular.ttf
        KaTeX_SansSerif-Regular.woff
        KaTeX_SansSerif-Regular.woff2
        KaTeX_Script-Regular.ttf
        KaTeX_Script-Regular.woff
        KaTeX_Script-Regular.woff2
        KaTeX_Size1-Regular.ttf
        KaTeX_Size1-Regular.woff
        KaTeX_Size1-Regular.woff2
        KaTeX_Size2-Regular.ttf
        KaTeX_Size2-Regular.woff
        KaTeX_Size2-Regular.woff2
        KaTeX_Size3-Regular.ttf
        KaTeX_Size3-Regular.woff
        KaTeX_Size3-Regular.woff2
        KaTeX_Size4-Regular.ttf
        KaTeX_Size4-Regular.woff
        KaTeX_Size4-Regular.woff2
        KaTeX_Typewriter-Regular.ttf
        KaTeX_Typewriter-Regular.woff
        KaTeX_Typewriter-Regular.woff2
      katex.css
      katex.js
      katex.min.css
      katex.min.js
      katex.mjs
      README.md
    .nojekyll
  .eslintignore
  .eslintrc
  .gitignore
  .prettierignore
  .prettierrc.json
  babel.config.js
  build-cli-usage.sh
  build.sh
  convert-ascii-to-svg.sh
  deploy.sh
  docusaurus.config.js
  offline-cmd-md-links.sh
  package.json
  README.md
  set-solana-release-tag.sh
  sidebars.js
dos/
  src/
    cli.rs
    lib.rs
    main.rs
  Cargo.toml
download-utils/
  src/
    lib.rs
  Cargo.toml
entry/
  benches/
    entry_sigverify.rs
  src/
    entry.rs
    lib.rs
    poh.rs
    wincode.rs
  Cargo.toml
faucet/
  src/
    bin/
      faucet.rs
    faucet_mock.rs
    faucet.rs
    lib.rs
  tests/
    local-faucet.rs
  .gitignore
  Cargo.toml
feature-set/
  src/
    lib.rs
  Cargo.toml
fee/
  src/
    lib.rs
  Cargo.toml
fs/
  src/
    io_uring/
      dir_remover.rs
      file_creator.rs
      memory.rs
      mod.rs
      sequential_file_reader.rs
    buffered_reader.rs
    dirs.rs
    file_io.rs
    lib.rs
  Cargo.toml
genesis/
  src/
    address_generator.rs
    genesis_accounts.rs
    lib.rs
    main.rs
    stakes.rs
    unlocks.rs
  .gitignore
  Cargo.toml
  README.md
genesis-utils/
  src/
    lib.rs
    open.rs
  Cargo.toml
geyser-plugin-interface/
  src/
    geyser_plugin_interface.rs
    lib.rs
  Cargo.toml
  README.md
geyser-plugin-manager/
  src/
    accounts_update_notifier.rs
    block_metadata_notifier_interface.rs
    block_metadata_notifier.rs
    entry_notifier.rs
    geyser_plugin_manager.rs
    geyser_plugin_service.rs
    lib.rs
    slot_status_notifier.rs
    slot_status_observer.rs
    transaction_notifier.rs
  Cargo.toml
gossip/
  benches/
    crds_gossip_pull.rs
    crds_shards.rs
    crds.rs
    weighted_shuffle.rs
  src/
    cluster_info_metrics.rs
    cluster_info.rs
    contact_info.rs
    crds_data.rs
    crds_entry.rs
    crds_filter.rs
    crds_gossip_error.rs
    crds_gossip_pull.rs
    crds_gossip_push.rs
    crds_gossip.rs
    crds_shards.rs
    crds_value.rs
    crds.rs
    deprecated.rs
    duplicate_shred_handler.rs
    duplicate_shred_listener.rs
    duplicate_shred.rs
    epoch_slots.rs
    epoch_specs.rs
    gossip_error.rs
    gossip_service.rs
    legacy_contact_info.rs
    lib.rs
    node.rs
    ping_pong.rs
    protocol.rs
    push_active_set.rs
    received_cache.rs
    restart_crds_values.rs
    tlv.rs
    weighted_shuffle.rs
    wire_format_tests.rs
  tests/
    crds_gossip.rs
    gossip.rs
  .gitignore
  Cargo.toml
gossip-bin/
  src/
    main.rs
  Cargo.toml
install/
  src/
    bin/
      agave-install-init.rs
    build_env.rs
    command.rs
    config.rs
    defaults.rs
    lib.rs
    main.rs
    stop_process.rs
    update_manifest.rs
  .gitignore
  agave-install-init.sh
  build.rs
  Cargo.toml
  install-help.sh
io-uring/
  src/
    lib.rs
    ring.rs
    slab.rs
  Cargo.toml
jito-protos/
  src/
    lib.rs
  build.rs
  Cargo.toml
keygen/
  src/
    keygen.rs
  .gitignore
  Cargo.toml
lattice-hash/
  benches/
    bench_lt_hash.rs
  src/
    lib.rs
    lt_hash.rs
  Cargo.toml
ledger/
  benches/
    blockstore.rs
    make_shreds_from_entries.rs
    protobuf.rs
  proptest-regressions/
    blockstore_meta.txt
  src/
    blockstore/
      blockstore_purge.rs
      column.rs
      error.rs
    leader_schedule/
      identity_keyed.rs
      vote_keyed.rs
    shred/
      common.rs
      merkle_tree.rs
      merkle.rs
      payload.rs
      shred_code.rs
      shred_data.rs
      stats.rs
      traits.rs
      wire.rs
    ancestor_iterator.rs
    bank_forks_utils.rs
    bigtable_delete.rs
    bigtable_upload_service.rs
    bigtable_upload.rs
    bit_vec.rs
    block_error.rs
    blockstore_cleanup_service.rs
    blockstore_db.rs
    blockstore_meta.rs
    blockstore_metric_report_service.rs
    blockstore_metrics.rs
    blockstore_options.rs
    blockstore_processor.rs
    blockstore.rs
    entry_notifier_interface.rs
    entry_notifier_service.rs
    genesis_utils.rs
    leader_schedule_cache.rs
    leader_schedule_utils.rs
    leader_schedule.rs
    lib.rs
    next_slots_iterator.rs
    rooted_slot_iterator.rs
    shred.rs
    shredder.rs
    sigverify_shreds.rs
    slot_stats.rs
    staking_utils.rs
    token_balances.rs
    transaction_address_lookup_table_scanner.rs
    transaction_balances.rs
    use_snapshot_archives_at_startup.rs
    wire_format_tests.rs
  tests/
    blockstore.rs
    shred.rs
  .gitignore
  Cargo.toml
ledger-tool/
  src/
    args.rs
    bigtable.rs
    blockstore.rs
    error.rs
    ledger_path.rs
    ledger_utils.rs
    main.rs
    output.rs
    program.rs
  tests/
    basic.rs
  .gitignore
  Cargo.toml
local-cluster/
  src/
    cluster_tests.rs
    cluster.rs
    integration_tests.rs
    lib.rs
    local_cluster_snapshot_utils.rs
    local_cluster.rs
    validator_configs.rs
  tests/
    local_cluster.rs
  .gitignore
  Cargo.toml
logger/
  src/
    lib.rs
  Cargo.toml
measure/
  src/
    lib.rs
    macros.rs
    measure.rs
  .gitignore
  Cargo.toml
merkle-tree/
  src/
    lib.rs
    merkle_tree.rs
  .gitignore
  Cargo.toml
metrics/
  benches/
    metrics.rs
  scripts/
    grafana-provisioning/
      dashboards/
        cluster-monitor.json
        dashboard.yml
    .gitignore
    adjust-dashboard-for-channel.py
    enable.sh
    grafana.ini
    influxdb.conf
    README.md
    start.sh
    status.sh
    stop.sh
    test.sh
  src/
    counter.rs
    datapoint.rs
    lib.rs
    metrics.rs
  .gitignore
  Cargo.toml
  README.md
multinode-demo/
  bench-tps.sh
  bootstrap-validator.sh
  common.sh
  delegate-stake.sh
  faucet.sh
  setup-from-mainnet-beta.sh
  setup-from-testnet.sh
  setup.sh
  validator-x.sh
  validator.sh
net/
  remote/
    cleanup.sh
    README.md
    remote-client.sh
    remote-deploy-update.sh
    remote-node-wait-init.sh
    remote-node.sh
    remote-sanity.sh
  scripts/
    azure-provider.sh
    colo_nodes
    colo-node-onacquire.sh
    colo-node-onfree.sh
    colo-provider.sh
    colo-utils.sh
    create-solana-user.sh
    disable-background-upgrades.sh
    ec2-provider.sh
    ec2-security-group-config.json
    gce-provider.sh
    gce-self-destruct.sh
    install-ag.sh
    install-at.sh
    install-certbot.sh
    install-docker.sh
    install-earlyoom.sh
    install-iftop.sh
    install-jq.sh
    install-libssl.sh
    install-perf.sh
    install-rsync.sh
    localtime.sh
    mount-additional-disk.sh
    network-config.sh
    remove-docker-interface.sh
    rsync-retry.sh
  .gitignore
  common.sh
  gce.sh
  init-metrics.sh
  net.sh
  scp.sh
  ssh.sh
net-utils/
  benches/
    token_bucket.rs
  src/
    ip_echo_client.rs
    ip_echo_server.rs
    lib.rs
    multihomed_sockets.rs
    socket_addr_space.rs
    sockets.rs
    token_bucket.rs
    tooling_for_tests.rs
  .gitignore
  Cargo.toml
notifier/
  src/
    lib.rs
  .gitignore
  Cargo.toml
perf/
  benches/
    dedup.rs
    discard.rs
    recycler.rs
    reset.rs
    shrink.rs
    sigverify.rs
  src/
    data_budget.rs
    deduper.rs
    discard.rs
    lib.rs
    packet.rs
    perf_libs.rs
    recycled_vec.rs
    recycler_cache.rs
    recycler.rs
    sigverify.rs
    test_tx.rs
    thread.rs
  build.rs
  Cargo.toml
platform-tools-sdk/
  cargo-build-sbf/
    src/
      main.rs
      post_processing.rs
      toolchain.rs
      utils.rs
    tests/
      crates/
        fail/
          src/
            lib.rs
          Cargo.toml
        noop/
          src/
            lib.rs
          Cargo.toml
        package-metadata/
          src/
            lib.rs
          Cargo.toml
        workspace-metadata/
          src/
            lib.rs
          Cargo.toml
      crates.rs
    .gitignore
    Cargo.toml
  cargo-test-sbf/
    src/
      main.rs
    Cargo.toml
  gen-headers/
    src/
      main.rs
    Cargo.toml
  sbf/
    c/
      inc/
        sol/
          inc/
            alt_bn128_compression.inc
            alt_bn128.inc
            assert.inc
            big_mod_exp.inc
            blake3.inc
            compute_units.inc
            cpi.inc
            keccak.inc
            last_restart_slot.inc
            log.inc
            poseidon.inc
            pubkey.inc
            return_data.inc
            secp256k1.inc
            sha.inc
          alt_bn128_compression.h
          alt_bn128.h
          assert.h
          big_mod_exp.h
          blake3.h
          compute_units.h
          constants.h
          cpi.h
          deserialize_deprecated.h
          deserialize.h
          entrypoint.h
          keccak.h
          last_restart_slot.h
          log.h
          poseidon.h
          pubkey.h
          return_data.h
          secp256k1.h
          sha.h
          string.h
          types.h
        sys/
          param.h
        deserialize_deprecated.h
        solana_sdk.h
        stdio.h
        stdlib.h
        string.h
        wchar.h
      README.md
      sbf.ld
      sbf.mk
    scripts/
      dump.sh
      install.sh
      objcopy.sh
      package.sh
      strip.sh
    .gitignore
    env.sh
poh/
  benches/
    poh_verify.rs
    poh.rs
    transaction_recorder.rs
  src/
    lib.rs
    poh_controller.rs
    poh_recorder.rs
    poh_service.rs
    record_channels.rs
    transaction_recorder.rs
  .gitignore
  Cargo.toml
poh-bench/
  src/
    main.rs
  Cargo.toml
poseidon/
  src/
    legacy.rs
    lib.rs
  Cargo.toml
precompiles/
  benches/
    ed25519_instructions.rs
    secp256k1_instructions.rs
    secp256r1_instructions.rs
  src/
    ed25519.rs
    lib.rs
    secp256k1.rs
    secp256r1.rs
  Cargo.toml
program-binaries/
  src/
    programs/
      core_bpf_address_lookup_table-3.0.0.so
      core_bpf_config-3.0.0.so
      core_bpf_feature_gate-0.0.1.so
      core_bpf_stake-1.0.1.so
      spl_associated_token_account-1.1.1.so
      spl_memo-1.0.0.so
      spl_memo-3.0.0.so
      spl_token_2022-8.0.0.so
      spl_token-3.5.0.so
      spl-jito_tip_distribution-0.1.10.so
      spl-jito_tip_distribution-0.1.4.so
      spl-jito_tip_distribution-0.1.7.so
      spl-jito_tip_payment-0.1.10.so
      spl-jito_tip_payment-0.1.4.so
      spl-jito_tip_payment-0.1.7.so
    lib.rs
  Cargo.toml
program-runtime/
  src/
    cpi.rs
    execution_budget.rs
    invoke_context.rs
    lib.rs
    loaded_programs.rs
    mem_pool.rs
    memory.rs
    serialization.rs
    stable_log.rs
    sysvar_cache.rs
  Cargo.toml
program-test/
  src/
    lib.rs
  tests/
    fixtures/
      noop_program.so
    bpf.rs
    builtins.rs
    compute_units.rs
    core_bpf.rs
    cpi.rs
    fuzz.rs
    genesis_accounts.rs
    lamports.rs
    panic.rs
    realloc.rs
    return_data.rs
    setup.rs
    spl.rs
    sysvar_last_restart_slot.rs
    sysvar.rs
    warp.rs
  Cargo.toml
programs/
  bpf_loader/
    benches/
      bpf_loader_upgradeable.rs
      serialization.rs
    src/
      lib.rs
    test_elfs/
      out/
        noop_aligned.so
        noop_unaligned.so
        sbpfv0_verifier_err.so
        sbpfv3_return_err.so
        sbpfv3_return_ok.so
      src/
        noop_aligned/
          noop_aligned.c
        noop_unaligned/
          noop_unaligned.c
      makefile
    Cargo.toml
  bpf-loader-tests/
    tests/
      common.rs
      extend_program_ix.rs
    Cargo.toml
    noop.so
  compute-budget/
    src/
      lib.rs
    Cargo.toml
  compute-budget-bench/
    benches/
      compute_budget.rs
    Cargo.toml
  ed25519-tests/
    tests/
      process_transaction.rs
    Cargo.toml
  loader-v4/
    src/
      lib.rs
    Cargo.toml
  sbf/
    benches/
      bpf_loader.rs
    c/
      src/
        alloc/
          alloc.c
        alt_bn128/
          alt_bn128.c
        alt_bn128_compression/
          alt_bn128.c
        bench_alu/
          bench_alu.c
          test_bench_alu.c
        big_mod_exp/
          big_mod_exp.c
        deprecated_loader/
          deprecated_loader.c
        dup_accounts/
          dup_accounts.c
        error_handling/
          error_handling.c
        float/
          float.c
        invoke/
          invoke.c
        invoked/
          instruction.h
          invoked.c
        log_data/
          log_data.c
        move_funds/
          move_funds.c
        multiple_static/
          multiple_static.c
        noop/
          noop.c
        noop++/
          noop++.cc
        panic/
          panic.c
        poseidon/
          poseidon.c
        read_program/
          read_program.c
        relative_call/
          relative_call.c
        remaining_compute_units/
          remaining_compute_units.c
        return_data/
          return_data.c
        sanity/
          sanity.c
        sanity++/
          sanity++.cc
        sbf_to_sbf/
          entrypoint.c
          helper.c
          helper.h
        secp256k1_recover/
          secp256k1_recover.c
        ser/
          ser.c
        sha/
          sha.c
        stdlib/
          stdlib.c
        struct_pass/
          struct_pass.c
        struct_ret/
          struct_ret.c
        tuner/
          tuner.c
        tuner-variable-iterations/
          tuner-variable-iterations.c
      .gitignore
    rust/
      128bit/
        src/
          lib.rs
        Cargo.toml
      128bit_dep/
        src/
          lib.rs
        Cargo.toml
      account_mem/
        src/
          lib.rs
        Cargo.toml
      account_mem_deprecated/
        src/
          lib.rs
        Cargo.toml
      alloc/
        src/
          lib.rs
        Cargo.toml
      alt_bn128/
        src/
          lib.rs
        Cargo.toml
      alt_bn128_compression/
        src/
          lib.rs
        Cargo.toml
      big_mod_exp/
        src/
          lib.rs
        Cargo.toml
      call_args/
        src/
          lib.rs
        Cargo.toml
      call_depth/
        src/
          lib.rs
        Cargo.toml
      caller_access/
        src/
          lib.rs
        Cargo.toml
      curve25519/
        src/
          lib.rs
        Cargo.toml
      custom_heap/
        src/
          lib.rs
        Cargo.toml
      dep_crate/
        src/
          lib.rs
        Cargo.toml
      deprecated_loader/
        src/
          lib.rs
        Cargo.toml
      divide_by_zero/
        src/
          lib.rs
        Cargo.toml
      dup_accounts/
        src/
          lib.rs
        Cargo.toml
      error_handling/
        src/
          lib.rs
        Cargo.toml
      external_spend/
        src/
          lib.rs
        Cargo.toml
      get_minimum_delegation/
        src/
          lib.rs
        Cargo.toml
      inner_instruction_alignment_check/
        src/
          lib.rs
        Cargo.toml
      instruction_introspection/
        src/
          lib.rs
        Cargo.toml
      invoke/
        src/
          lib.rs
        Cargo.toml
      invoke_and_error/
        src/
          lib.rs
        Cargo.toml
      invoke_and_ok/
        src/
          lib.rs
        Cargo.toml
      invoke_and_return/
        src/
          lib.rs
        Cargo.toml
      invoke_dep/
        src/
          lib.rs
        Cargo.toml
      invoked/
        src/
          lib.rs
        Cargo.toml
      invoked_dep/
        src/
          lib.rs
        Cargo.toml
      iter/
        src/
          lib.rs
        Cargo.toml
      log_data/
        src/
          lib.rs
        Cargo.toml
      many_args/
        src/
          helper.rs
          lib.rs
        Cargo.toml
      many_args_dep/
        src/
          lib.rs
        Cargo.toml
      mem/
        src/
          lib.rs
        Cargo.toml
      mem_dep/
        src/
          lib.rs
        Cargo.toml
      membuiltins/
        src/
          lib.rs
        Cargo.toml
      noop/
        src/
          lib.rs
        Cargo.toml
      panic/
        src/
          lib.rs
        Cargo.toml
      param_passing/
        src/
          lib.rs
        Cargo.toml
      param_passing_dep/
        src/
          lib.rs
        Cargo.toml
      poseidon/
        src/
          lib.rs
        Cargo.toml
      r2_instruction_data_pointer/
        src/
          lib.rs
        Cargo.toml
      rand/
        src/
          lib.rs
        Cargo.toml
      realloc/
        src/
          lib.rs
        Cargo.toml
      realloc_dep/
        src/
          lib.rs
        Cargo.toml
      realloc_invoke/
        src/
          lib.rs
        Cargo.toml
      realloc_invoke_dep/
        src/
          lib.rs
        Cargo.toml
      remaining_compute_units/
        src/
          lib.rs
        Cargo.toml
      ro_account_modify/
        src/
          lib.rs
        Cargo.toml
      ro_modify/
        src/
          lib.rs
        Cargo.toml
      sanity/
        src/
          lib.rs
        Cargo.toml
      secp256k1_recover/
        src/
          lib.rs
        Cargo.toml
      sha/
        src/
          lib.rs
        Cargo.toml
      sibling_inner_instructions/
        src/
          lib.rs
        Cargo.toml
      sibling_instructions/
        src/
          lib.rs
        Cargo.toml
      simulation/
        src/
          lib.rs
        Cargo.toml
      spoof1/
        src/
          lib.rs
        Cargo.toml
      spoof1_system/
        src/
          lib.rs
        Cargo.toml
      syscall-get-epoch-stake/
        src/
          lib.rs
        Cargo.toml
      sysvar/
        src/
          lib.rs
        Cargo.toml
      upgradeable/
        src/
          lib.rs
        Cargo.toml
      upgraded/
        src/
          lib.rs
        Cargo.toml
    tests/
      programs.rs
      simulation.rs
      syscall_get_epoch_stake.rs
      sysvar.rs
    .gitignore
    Cargo.toml
    Makefile
  system/
    benches/
      system.rs
    src/
      lib.rs
      system_instruction.rs
      system_processor.rs
    Cargo.toml
  vote/
    benches/
      process_vote.rs
      vote_instructions.rs
    src/
      vote_state/
        handler.rs
        mod.rs
      lib.rs
      vote_processor.rs
    Cargo.toml
  zk-elgamal-proof/
    benches/
      verify_proofs.rs
    src/
      lib.rs
    Cargo.toml
  zk-elgamal-proof-tests/
    tests/
      process_transaction.rs
    Cargo.toml
  zk-token-proof/
    benches/
      verify_proofs.rs
    src/
      lib.rs
    Cargo.toml
pubsub-client/
  src/
    nonblocking/
      mod.rs
      pubsub_client.rs
    lib.rs
    pubsub_client.rs
  Cargo.toml
quic-client/
  src/
    nonblocking/
      mod.rs
      quic_client.rs
    lib.rs
    quic_client.rs
  tests/
    quic_client.rs
  Cargo.toml
rayon-threadlimit/
  src/
    lib.rs
  .gitignore
  Cargo.toml
rbpf-cli/
  src/
    main.rs
  Cargo.toml
remote-wallet/
  src/
    ledger_error.rs
    ledger.rs
    lib.rs
    locator.rs
    remote_keypair.rs
    remote_wallet.rs
  Cargo.toml
  README.md
reserved-account-keys/
  src/
    lib.rs
  Cargo.toml
rpc/
  src/
    rpc/
      account_resolver.rs
    cluster_tpu_info.rs
    filter.rs
    lib.rs
    max_slots.rs
    optimistically_confirmed_bank_tracker.rs
    parsed_token_accounts.rs
    rpc_cache.rs
    rpc_completed_slots_service.rs
    rpc_health.rs
    rpc_pubsub_service.rs
    rpc_pubsub.rs
    rpc_service.rs
    rpc_subscription_tracker.rs
    rpc_subscriptions.rs
    rpc.rs
    slot_status_notifier.rs
    transaction_notifier_interface.rs
    transaction_status_service.rs
  .gitignore
  Cargo.toml
rpc-client/
  src/
    nonblocking/
      mod.rs
      rpc_client.rs
    http_sender.rs
    lib.rs
    mock_sender.rs
    rpc_client.rs
    rpc_sender.rs
    spinner.rs
  Cargo.toml
rpc-client-api/
  src/
    bundles.rs
    client_error.rs
    custom_error.rs
    lib.rs
    response.rs
  Cargo.toml
rpc-client-nonce-utils/
  src/
    nonblocking/
      blockhash_query.rs
      mod.rs
    blockhash_query.rs
    lib.rs
  Cargo.toml
rpc-client-types/
  src/
    config.rs
    error_object.rs
    filter.rs
    lib.rs
    request.rs
    response.rs
  Cargo.toml
rpc-test/
  tests/
    nonblocking.rs
    rpc.rs
  .gitignore
  Cargo.toml
runtime/
  benches/
    accounts.rs
    prioritization_fee_cache.rs
    status_cache.rs
  src/
    accounts_background_service/
      pending_snapshot_packages.rs
      stats.rs
    bank/
      builtins/
        core_bpf_migration/
          error.rs
          mod.rs
          source_buffer.rs
          target_bpf_v2.rs
          target_builtin.rs
          target_core_bpf.rs
        mod.rs
      partitioned_epoch_rewards/
        calculation.rs
        distribution.rs
        epoch_rewards_hasher.rs
        mod.rs
        sysvar.rs
      accounts_lt_hash.rs
      address_lookup_table.rs
      bank_hash_details.rs
      check_transactions.rs
      fee_distribution.rs
      metrics.rs
      recent_blockhashes_account.rs
      serde_snapshot.rs
      sysvar_cache.rs
      tests.rs
    inflation_rewards/
      mod.rs
      points.rs
    serde_snapshot/
      obsolete_accounts.rs
      status_cache.rs
      storage.rs
      tests.rs
      types.rs
      utils.rs
    snapshot_package/
      compare.rs
    snapshot_utils/
      snapshot_storage_rebuilder.rs
    stakes/
      serde_stakes.rs
    account_saver.rs
    accounts_background_service.rs
    bank_client.rs
    bank_forks.rs
    bank_hash_cache.rs
    bank_utils.rs
    bank.rs
    commitment.rs
    dependency_tracker.rs
    epoch_stakes.rs
    genesis_utils.rs
    installed_scheduler_pool.rs
    lib.rs
    loader_utils.rs
    non_circulating_supply.rs
    prioritization_fee_cache.rs
    prioritization_fee.rs
    read_optimized_dashmap.rs
    rent_collector.rs
    runtime_config.rs
    serde_snapshot.rs
    snapshot_bank_utils.rs
    snapshot_controller.rs
    snapshot_minimizer.rs
    snapshot_package.rs
    snapshot_utils.rs
    stake_account.rs
    stake_history.rs
    stake_utils.rs
    stake_weighted_timestamp.rs
    stakes.rs
    static_ids.rs
    status_cache.rs
    transaction_batch.rs
    vote_sender_types.rs
  .gitignore
  Cargo.toml
runtime-transaction/
  benches/
    get_signature_details.rs
  src/
    runtime_transaction/
      sdk_transactions.rs
      transaction_view.rs
    instruction_data_len.rs
    instruction_meta.rs
    lib.rs
    runtime_transaction.rs
    signature_details.rs
    transaction_meta.rs
    transaction_with_meta.rs
  Cargo.toml
scheduler-bindings/
  src/
    lib.rs
  Cargo.toml
scheduling-utils/
  src/
    handshake/
      client.rs
      mod.rs
      server.rs
      shared.rs
      tests.rs
    error.rs
    lib.rs
    pubkeys_ptr.rs
    responses_region.rs
    thread_aware_account_locks.rs
    transaction_ptr.rs
  Cargo.toml
scripts/
  agave-build-lists.sh
  agave-install-deploy.sh
  agave-install-update-manifest-keypair.sh
  build-agave-xdp-ebpf.sh
  build-downstream-anchor-projects.sh
  cargo-clippy-nightly.sh
  cargo-clippy.sh
  cargo-for-all-lock-files.sh
  cargo-install-all.sh
  check-dev-context-only-utils.sh
  configure-metrics.sh
  confirm-cargo-version-numbers-before-bump.sh
  coverage.sh
  create-release-tarball.sh
  elf-hash-symbol.sh
  fd-monitor.sh
  generate-target-triple.sh
  iftop.sh
  increment-cargo-version.sh
  metrics-write-datapoint.sh
  net-shaper.sh
  net-stats.sh
  oom-monitor.sh
  oom-score-adj.sh
  patch-crates.sh
  patch-spl-crates-for-anchor.sh
  perf-plot.py
  perf-stats.py
  read-cargo-variable.sh
  reserve-cratesio-package-name.sh
  run.sh
  sed-i-all-rs-files-for-rust-analyzer.sh
  spl-token-cli-version.sh
  system-stats.sh
  ulimit-n.sh
  wallet-sanity.sh
sdk/
  README.md
send-transaction-service/
  src/
    lib.rs
    send_transaction_service_stats.rs
    send_transaction_service.rs
    test_utils.rs
    tpu_info.rs
    transaction_client.rs
  Cargo.toml
snapshots/
  src/
    archive_format.rs
    archive.rs
    error.rs
    hardened_unpack.rs
    kind.rs
    lib.rs
    paths.rs
    snapshot_archive_info.rs
    snapshot_config.rs
    snapshot_hash.rs
    snapshot_interval.rs
    snapshot_version.rs
    unarchive.rs
  Cargo.toml
stake-accounts/
  src/
    arg_parser.rs
    args.rs
    main.rs
    stake_accounts.rs
  Cargo.toml
storage-bigtable/
  build-proto/
    src/
      main.rs
    .gitignore
    build.sh
    Cargo.toml
    README.md
  proto/
    google.api.rs
    google.bigtable.v2.rs
    google.protobuf.rs
    google.rpc.rs
  src/
    access_token.rs
    bigtable.rs
    compression.rs
    lib.rs
    pki-goog-roots.pem
    root_ca_certificate.rs
  Cargo.toml
  init-bigtable.sh
  README.md
storage-proto/
  proto/
    confirmed_block.proto
    entries.proto
    transaction_by_addr.proto
  src/
    convert.rs
    lib.rs
  build.rs
  Cargo.toml
  README.md
streamer/
  examples/
    swqos.rs
  src/
    nonblocking/
      connection_rate_limiter.rs
      mod.rs
      qos.rs
      quic.rs
      recvmmsg.rs
      sendmmsg.rs
      simple_qos.rs
      stream_throttle.rs
      swqos.rs
      testing_utilities.rs
    evicting_sender.rs
    lib.rs
    msghdr.rs
    packet.rs
    quic.rs
    recvmmsg.rs
    sendmmsg.rs
    streamer.rs
  tests/
    recvmmsg.rs
  Cargo.toml
svm/
  doc/
    diagrams/
      context.svg
      context.tex
    spec.md
  src/
    account_loader.rs
    account_overrides.rs
    lib.rs
    message_processor.rs
    nonce_info.rs
    program_loader.rs
    rent_calculator.rs
    rollback_accounts.rs
    transaction_account_state_info.rs
    transaction_balances.rs
    transaction_commit_result.rs
    transaction_error_metrics.rs
    transaction_execution_result.rs
    transaction_processing_callback.rs
    transaction_processing_result.rs
    transaction_processor.rs
  tests/
    example-programs/
      clock-sysvar/
        src/
          lib.rs
        Cargo.toml
        clock_sysvar_program.so
      hello-solana/
        src/
          lib.rs
        Cargo.toml
        hello_solana_program.so
      simple-transfer/
        src/
          lib.rs
        Cargo.toml
        simple_transfer_program.so
      transfer-from-account/
        src/
          lib.rs
        Cargo.toml
        transfer_from_account_program.so
      write-to-account/
        src/
          lib.rs
        Cargo.toml
        write_to_account_program.so
    concurrent_tests.rs
    integration_test.rs
    mock_bank.rs
  Cargo.toml
svm-callback/
  src/
    lib.rs
  Cargo.toml
svm-feature-set/
  src/
    lib.rs
  Cargo.toml
svm-log-collector/
  src/
    lib.rs
  Cargo.toml
svm-measure/
  src/
    lib.rs
    macros.rs
    measure.rs
  Cargo.toml
svm-rent-calculator/
  src/
    lib.rs
    rent_state.rs
    svm_rent_calculator.rs
  Cargo.toml
svm-test-harness/
  bin/
    test_exec_instr.rs
  src/
    fixture/
      account_state.rs
      error.rs
      feature_set.rs
      instr_context.rs
      instr_effects.rs
      mod.rs
    file.rs
    fuzz.rs
    instr.rs
    lib.rs
    program_cache.rs
    sysvar_cache.rs
  .gitignore
  build.rs
  Cargo.toml
  Makefile
svm-timings/
  src/
    lib.rs
  Cargo.toml
svm-transaction/
  src/
    svm_message/
      sanitized_message.rs
      sanitized_transaction.rs
    svm_transaction/
      sanitized_transaction.rs
    instruction.rs
    lib.rs
    message_address_table_lookup.rs
    svm_message.rs
    svm_transaction.rs
    tests.rs
  Cargo.toml
svm-type-overrides/
  src/
    lib.rs
  Cargo.toml
syscalls/
  gen-syscall-list/
    src/
      main.rs
    build.rs
    Cargo.toml
  src/
    cpi.rs
    lib.rs
    logging.rs
    mem_ops.rs
    sysvar.rs
  Cargo.toml
test-validator/
  src/
    lib.rs
  Cargo.toml
thread-manager/
  examples/
    common/
      mod.rs
    core_contention_basics.rs
    core_contention_contending_set.toml
    core_contention_dedicated_set.toml
    core_contention_sweep.rs
  src/
    lib.rs
    native_thread_runtime.rs
    policy.rs
    rayon_runtime.rs
    tokio_runtime.rs
  Cargo.toml
  README.md
tls-utils/
  src/
    config.rs
    crypto_provider.rs
    lib.rs
    quic_client_certificate.rs
    skip_client_verification.rs
    skip_server_verification.rs
    tls_certificates.rs
  Cargo.toml
  README
tokens/
  src/
    arg_parser.rs
    args.rs
    commands.rs
    db.rs
    lib.rs
    main.rs
    spl_token.rs
    stake.rs
    token_display.rs
  tests/
    commands.rs
  .gitignore
  Cargo.toml
  README.md
tps-client/
  src/
    bank_client.rs
    lib.rs
    rpc_client.rs
    tpu_client.rs
    utils.rs
  Cargo.toml
tpu-client/
  src/
    nonblocking/
      mod.rs
      tpu_client.rs
    lib.rs
    tpu_client.rs
  .gitignore
  Cargo.toml
tpu-client-next/
  src/
    node_address_service/
      leader_tpu_cache_service.rs
      recent_leader_slots.rs
      slot_event.rs
      slot_receiver.rs
      slot_update_service.rs
    quic_networking/
      error.rs
    client_builder.rs
    connection_worker.rs
    connection_workers_scheduler.rs
    leader_updater.rs
    lib.rs
    logging.rs
    metrics.rs
    node_address_service.rs
    quic_networking.rs
    send_transaction_stats.rs
    transaction_batch.rs
    websocket_node_address_service.rs
    workers_cache.rs
  tests/
    connection_workers_scheduler_test.rs
  Cargo.toml
transaction-context/
  src/
    instruction_accounts.rs
    instruction.rs
    lib.rs
    transaction_accounts.rs
    vm_slice.rs
  Cargo.toml
transaction-dos/
  src/
    main.rs
  .gitignore
  Cargo.toml
transaction-metrics-tracker/
  src/
    lib.rs
  Cargo.toml
transaction-status/
  benches/
    extract_memos.rs
  src/
    parse_token/
      extension/
        confidential_mint_burn.rs
        confidential_transfer_fee.rs
        confidential_transfer.rs
        cpi_guard.rs
        default_account_state.rs
        group_member_pointer.rs
        group_pointer.rs
        interest_bearing_mint.rs
        memo_transfer.rs
        metadata_pointer.rs
        mint_close_authority.rs
        mod.rs
        pausable.rs
        permanent_delegate.rs
        reallocate.rs
        scaled_ui_amount.rs
        token_group.rs
        token_metadata.rs
        transfer_fee.rs
        transfer_hook.rs
    extract_memos.rs
    lib.rs
    parse_accounts.rs
    parse_address_lookup_table.rs
    parse_associated_token.rs
    parse_bpf_loader.rs
    parse_instruction.rs
    parse_stake.rs
    parse_system.rs
    parse_token.rs
    parse_vote.rs
    token_balances.rs
  Cargo.toml
transaction-status-client-types/
  src/
    lib.rs
    option_serializer.rs
  Cargo.toml
transaction-view/
  benches/
    bytes.rs
    transaction_view.rs
  src/
    address_table_lookup_frame.rs
    bytes.rs
    instructions_frame.rs
    lib.rs
    message_header_frame.rs
    resolved_transaction_view.rs
    result.rs
    sanitize.rs
    signature_frame.rs
    static_account_keys_frame.rs
    transaction_data.rs
    transaction_frame.rs
    transaction_version.rs
    transaction_view.rs
  Cargo.toml
turbine/
  benches/
    cluster_info.rs
    cluster_nodes.rs
  src/
    broadcast_stage/
      broadcast_duplicates_run.rs
      broadcast_fake_shreds_run.rs
      broadcast_metrics.rs
      broadcast_utils.rs
      fail_entry_verification_broadcast_run.rs
      standard_broadcast_run.rs
    addr_cache.rs
    broadcast_stage.rs
    cluster_nodes.rs
    lib.rs
    quic_endpoint.rs
    retransmit_stage.rs
    sigverify_shreds.rs
    xdp.rs
  Cargo.toml
udp-client/
  src/
    nonblocking/
      mod.rs
      udp_client.rs
    lib.rs
    udp_client.rs
  Cargo.toml
unified-scheduler-logic/
  src/
    lib.rs
  Cargo.toml
unified-scheduler-pool/
  src/
    lib.rs
    sleepless_testing.rs
  Cargo.toml
validator/
  src/
    bin/
      solana-test-validator.rs
    cli/
      thread_args.rs
    commands/
      authorized_voter/
        mod.rs
      bam/
        mod.rs
      block_engine/
        mod.rs
      contact_info/
        mod.rs
      exit/
        mod.rs
      manage_block_production/
        mod.rs
      monitor/
        mod.rs
      plugin/
        mod.rs
      relayer/
        mod.rs
      repair_shred_from_peer/
        mod.rs
      repair_whitelist/
        mod.rs
      run/
        args/
          account_secondary_indexes.rs
          blockstore_options.rs
          json_rpc_config.rs
          pub_sub_config.rs
          rpc_bigtable_config.rs
          rpc_bootstrap_config.rs
          send_transaction_config.rs
        args.rs
        execute.rs
        mod.rs
      set_identity/
        mod.rs
      set_log_filter/
        mod.rs
      set_public_address/
        mod.rs
      shred/
        mod.rs
      staked_nodes_overrides/
        mod.rs
      wait_for_restart_window/
        mod.rs
      mod.rs
    admin_rpc_service.rs
    bootstrap.rs
    cli.rs
    dashboard.rs
    lib.rs
    main.rs
  tests/
    cli.rs
  .gitignore
  Cargo.toml
  solana-test-validator
verified-packet-receiver/
  src/
    lib.rs
    receiver.rs
  Cargo.toml
  Readme.md
version/
  src/
    legacy.rs
    lib.rs
  .gitignore
  build.rs
  Cargo.toml
vortexor/
  src/
    cli.rs
    lib.rs
    main.rs
    rpc_load_balancer.rs
    sender.rs
    stake_updater.rs
    vortexor.rs
  tests/
    vortexor.rs
  Cargo.toml
  README.md
vote/
  benches/
    vote_account.rs
  src/
    vote_state_view/
      field_frames.rs
      frame_v1_14_11.rs
      frame_v3.rs
      frame_v4.rs
      list_view.rs
    lib.rs
    vote_account.rs
    vote_parser.rs
    vote_state_view.rs
    vote_transaction.rs
  Cargo.toml
votor/
  src/
    consensus_pool/
      certificate_builder.rs
      parent_ready_tracker.rs
      slot_stake_counters.rs
      stats.rs
      vote_pool.rs
    consensus_pool_service/
      stats.rs
    event_handler/
      stats.rs
    timer_manager/
      stats.rs
      timers.rs
    commitment.rs
    common.rs
    consensus_metrics.rs
    consensus_pool_service.rs
    consensus_pool.rs
    event_handler.rs
    event.rs
    lib.rs
    root_utils.rs
    staked_validators_cache.rs
    timer_manager.rs
    vote_history_storage.rs
    vote_history.rs
    voting_service.rs
    voting_utils.rs
    votor.rs
  Cargo.toml
votor-messages/
  src/
    consensus_message.rs
    lib.rs
    vote.rs
  Cargo.toml
watchtower/
  src/
    main.rs
  .gitignore
  Cargo.toml
  README.md
web3.js/
  README.md
wen-restart/
  proto/
    wen_restart.proto
  src/
    heaviest_fork_aggregate.rs
    last_voted_fork_slots_aggregate.rs
    lib.rs
    wen_restart.rs
  build.rs
  Cargo.toml
xdp/
  src/
    device.rs
    lib.rs
    netlink.rs
    packet.rs
    program.rs
    route.rs
    socket.rs
    tx_loop.rs
    umem.rs
  Cargo.toml
xdp-ebpf/
  src/
    bin/
      agave-xdp-prog.rs
    lib.rs
  agave-xdp-prog
  Cargo.toml
  README
zk-keygen/
  README.md
zk-sdk/
  README.md
zk-token-sdk/
  src/
    encryption/
      auth_encryption.rs
      decode_u32_precomputation_for_G.bincode
      discrete_log.rs
      elgamal.rs
      grouped_elgamal.rs
      mod.rs
      pedersen.rs
    instruction/
      batched_grouped_ciphertext_validity/
        handles_2.rs
        handles_3.rs
        mod.rs
      batched_range_proof/
        batched_range_proof_u128.rs
        batched_range_proof_u256.rs
        batched_range_proof_u64.rs
        mod.rs
      grouped_ciphertext_validity/
        handles_2.rs
        handles_3.rs
        mod.rs
      transfer/
        encryption.rs
        mod.rs
        with_fee.rs
        without_fee.rs
      ciphertext_ciphertext_equality.rs
      ciphertext_commitment_equality.rs
      errors.rs
      fee_sigma.rs
      mod.rs
      pubkey_validity.rs
      range_proof.rs
      withdraw.rs
      zero_balance.rs
    range_proof/
      errors.rs
      generators.rs
      inner_product.rs
      mod.rs
      util.rs
    sigma_proofs/
      batched_grouped_ciphertext_validity_proof/
        handles_2.rs
        handles_3.rs
        mod.rs
      grouped_ciphertext_validity_proof/
        handles_2.rs
        handles_3.rs
        mod.rs
      ciphertext_ciphertext_equality_proof.rs
      ciphertext_commitment_equality_proof.rs
      errors.rs
      fee_proof.rs
      mod.rs
      pubkey_proof.rs
      zero_balance_proof.rs
    zk_token_elgamal/
      pod/
        auth_encryption.rs
        elgamal.rs
        grouped_elgamal.rs
        instruction.rs
        mod.rs
        pedersen.rs
        range_proof.rs
        sigma_proofs.rs
      convert.rs
      decryption.rs
      mod.rs
      ops.rs
    errors.rs
    lib.rs
    macros.rs
    transcript.rs
    zk_token_proof_instruction.rs
    zk_token_proof_program.rs
    zk_token_proof_state.rs
  .gitignore
  Cargo.toml
  README.md
.codecov.yml
.dockerignore
.gitignore
.gitmodules
.mergify.yml
bootstrap
cargo
cargo-build-sbf
cargo-test-sbf
Cargo.toml
CHANGELOG.md
clippy.toml
CONTRIBUTING.md
deploy_programs
f
fetch-core-bpf.sh
fetch-perf-libs.sh
fetch-programs.sh
fetch-spl.sh
legal.md
LICENSE
privacy.md
README.md
RELEASE.md
rust-toolchain.toml
rustfmt.toml
s
SECURITY.md
start
start_multi
vercel.json

================================================================
Files
================================================================

================
File: tpu-client-next/src/node_address_service/leader_tpu_cache_service.rs
================
pub struct Config {
⋮----
impl Default for Config {
fn default() -> Self {
⋮----
pub struct LeaderTpuCacheService {
⋮----
pub struct LeaderUpdateReceiver {
⋮----
impl LeaderUpdateReceiver {
pub fn leaders(&self, lookahead_leaders: usize) -> Vec<SocketAddr> {
let NodesTpuInfo { leaders, extend } = self.receiver.borrow().clone();
⋮----
lookahead_leaders.saturating_add(1)
⋮----
extract_send_leaders(&leaders, lookahead_leaders)
⋮----
struct NodesTpuInfo {
⋮----
impl LeaderTpuCacheService {
pub async fn run(
⋮----
let (leader_tpu_map, epoch_info, slot_leaders) = initialize_state(
cluster_info.as_ref(),
slot_receiver.clone(),
⋮----
let current_slot = slot_receiver.slot();
⋮----
adjust_lookahead(current_slot, &slot_leaders, config.lookahead_leaders);
let leaders = leader_sockets(
⋮----
cancel.clone(),
⋮----
Ok((
⋮----
handle: Some(handle),
⋮----
/// Gracefully shutdown the [`LeaderTpuCacheService`].
    pub async fn shutdown(&mut self) -> Result<(), Error> {
⋮----
pub async fn shutdown(&mut self) -> Result<(), Error> {
self.cancel.cancel();
if let Some(handle) = self.handle.take() {
⋮----
Ok(())
⋮----
async fn run_loop(
⋮----
let mut refresh_tpu_interval = interval(config.refresh_nodes_info_every);
⋮----
pub enum Error {
⋮----
pub trait ClusterInfoProvider: Send + Sync {
⋮----
async fn update_leader_info(
⋮----
try_update(
⋮----
if estimated_current_slot.saturating_add(MAX_FANOUT_SLOTS) > slot_leaders.last_slot() {
⋮----
fn leader_sockets(
⋮----
let fanout_slots = (lookahead_leaders as u64).saturating_mul(NUM_CONSECUTIVE_LEADER_SLOTS);
⋮----
(current_slot..current_slot + fanout_slots).step_by(NUM_CONSECUTIVE_LEADER_SLOTS as usize)
⋮----
if let Some(leader) = slot_leaders.slot_leader(leader_slot) {
if let Some(tpu_socket) = leader_tpu_map.get(leader) {
leader_sockets.push(*tpu_socket);
debug!("Pushed leader {leader} TPU socket: {tpu_socket}");
⋮----
debug!("TPU not available for leader {leader}");
⋮----
warn!(
⋮----
async fn initialize_state(
⋮----
if leader_tpu_map.is_none() {
leader_tpu_map = LeaderTpuMap::new(cluster_info).await.ok();
⋮----
if epoch_info.is_none() {
epoch_info = EpochInfo::new(cluster_info, slot_receiver.slot())
⋮----
.ok();
⋮----
if slot_leaders.is_none() {
⋮----
slot_receiver.slot(),
⋮----
if leader_tpu_map.is_some() && epoch_info.is_some() && slot_leaders.is_some() {
return Ok((
leader_tpu_map.take().unwrap(),
epoch_info.take().unwrap(),
slot_leaders.take().unwrap(),
⋮----
let elapsed = iteration_start.elapsed();
⋮----
Err(Error::InitializationFailed)
⋮----
fn adjust_lookahead(slot: Slot, slot_leaders: &SlotLeaders, lookahead_leaders: u8) -> u8 {
⋮----
.is_leader_last_consecutive_slot(slot)
.unwrap_or(true)
⋮----
async fn try_update<F, Fut, T>(
⋮----
match make_call().await {
⋮----
debug!("{label} updated successfully");
⋮----
*num_failures = num_failures.saturating_add(1);
warn!("Failed to update {label}: {e} ({num_failures} consecutive failures)",);
⋮----
error!("Max consecutive failures for {label}, giving up.");
Err(e)
⋮----
struct LeaderTpuMap {
⋮----
impl LeaderTpuMap {
async fn new(cluster_info: &impl ClusterInfoProvider) -> Result<Self, Error> {
let leader_tpu_map = cluster_info.tpu_socket_map().await?;
Ok(Self { leader_tpu_map })
⋮----
fn get(&self, leader: &Pubkey) -> Option<&SocketAddr> {
self.leader_tpu_map.get(leader)
⋮----
struct SlotLeaders {
⋮----
impl SlotLeaders {
async fn new(
⋮----
Ok(Self {
⋮----
leaders: cluster_info.slot_leaders(first_slot, slots_limit).await?,
⋮----
fn last_slot(&self) -> Slot {
self.first_slot + self.leaders.len().saturating_sub(1) as u64
⋮----
fn slot_leader(&self, slot: Slot) -> Option<&Pubkey> {
slot.checked_sub(self.first_slot)
.and_then(|index| self.leaders.get(index as usize))
⋮----
fn is_leader_last_consecutive_slot(&self, slot: Slot) -> Option<bool> {
slot.checked_sub(self.first_slot).and_then(|index| {
⋮----
if index + 1 < self.leaders.len() {
Some(self.leaders[index] != self.leaders[index + 1])
⋮----
struct EpochInfo {
⋮----
impl EpochInfo {
async fn new(cluster_info: &impl ClusterInfoProvider, first_slot: Slot) -> Result<Self, Error> {
let (slots_in_epoch, last_slot_in_epoch) = cluster_info.epoch_info(first_slot).await?;
⋮----
impl ClusterInfoProvider for RpcClient {
async fn initial_slot(&self) -> Result<Slot, Error> {
self.get_slot_with_commitment(CommitmentConfig::processed())
⋮----
.map_err(Error::RpcError)
⋮----
async fn tpu_socket_map(&self) -> Result<HashMap<Pubkey, SocketAddr>, Error> {
let cluster_nodes = self.get_cluster_nodes().await.map_err(Error::RpcError)?;
Ok(extract_cluster_tpu_sockets(cluster_nodes))
⋮----
async fn epoch_info(&self, first_slot: Slot) -> Result<(Slot, Slot), Error> {
let epoch_schedule = self.get_epoch_schedule().await.map_err(Error::RpcError)?;
let epoch = epoch_schedule.get_epoch(first_slot);
let slots_in_epoch = epoch_schedule.get_slots_in_epoch(epoch);
let last_slot_in_epoch = epoch_schedule.get_last_slot_in_epoch(epoch);
debug!(
⋮----
Ok((slots_in_epoch, last_slot_in_epoch))
⋮----
async fn slot_leaders(&self, first_slot: Slot, slots_limit: u64) -> Result<Vec<Pubkey>, Error> {
let max_slots_to_fetch = (2 * MAX_FANOUT_SLOTS).min(slots_limit);
let slot_leaders = self.get_slot_leaders(first_slot, max_slots_to_fetch).await;
debug!("Fetched slot leaders from slot {first_slot} for {slots_limit}. ");
slot_leaders.map_err(Error::RpcError)
⋮----
fn extract_cluster_tpu_sockets(
⋮----
.into_iter()
.filter_map(|contact_info| {
let pubkey = Pubkey::from_str(&contact_info.pubkey).ok()?;
⋮----
contact_info.tpu_quic.or_else(|| {
⋮----
let port = socket.port().checked_add(QUIC_PORT_OFFSET)?;
socket.set_port(port);
Some(socket)
⋮----
Some((pubkey, socket))
⋮----
.collect()

================
File: tpu-client-next/src/node_address_service/recent_leader_slots.rs
================
pub struct RecentLeaderSlots(VecDeque<SlotEvent>);
impl RecentLeaderSlots {
pub fn new() -> Self {
Self(VecDeque::with_capacity(RECENT_LEADER_SLOTS_CAPACITY))
⋮----
impl Default for RecentLeaderSlots {
fn default() -> Self {
⋮----
pub fn record(&mut self, slot_event: SlotEvent) {
while self.0.len() > RECENT_LEADER_SLOTS_CAPACITY.saturating_sub(1) {
self.0.pop_front();
⋮----
self.0.push_back(slot_event);
⋮----
pub fn estimate_current_slot(&self) -> Slot {
let mut recent_slots: Vec<SlotEvent> = self.0.iter().cloned().collect();
assert!(
⋮----
recent_slots.sort_by(|a, b| {
a.slot()
.cmp(&b.slot())
.then_with(|| b.is_start().cmp(&a.is_start()))
⋮----
let max_index = recent_slots.len() - 1;
⋮----
let median_recent_slot = recent_slots[median_index].slot();
⋮----
.iter()
.rposition(|e| e.slot() <= max_reasonable_current_slot)
.expect("no reasonable slot");
⋮----
if slot_event.is_start() {
slot_event.slot()
⋮----
slot_event.slot().saturating_add(1)
⋮----
mod tests {
⋮----
fn from(recent_slots: Vec<Slot>) -> Self {
use std::collections::VecDeque;
assert!(!recent_slots.is_empty());
let mut events = VecDeque::with_capacity(recent_slots.len());
⋮----
events.push_back(SlotEvent::Start(slot));
events.push_back(SlotEvent::End(slot));
⋮----
Self(events)
⋮----
fn test_recent_leader_slots() {
let mut recent_slots: Vec<Slot> = (1..=12).collect();
assert_eq!(
⋮----
recent_slots.reverse();
⋮----
recent_slots.record(SlotEvent::Start(13));
assert_eq!(recent_slots.estimate_current_slot(), 13);
recent_slots.record(SlotEvent::Start(14));
assert_eq!(recent_slots.estimate_current_slot(), 14);
recent_slots.record(SlotEvent::Start(15));
assert_eq!(recent_slots.estimate_current_slot(), 15);

================
File: tpu-client-next/src/node_address_service/slot_event.rs
================
use solana_clock::Slot;
⋮----
pub enum SlotEvent {
⋮----
impl SlotEvent {
pub fn slot(&self) -> Slot {
⋮----
pub fn is_start(&self) -> bool {
matches!(self, SlotEvent::Start(_))

================
File: tpu-client-next/src/node_address_service/slot_receiver.rs
================
pub struct SlotReceiver(watch::Receiver<Slot>);
impl SlotReceiver {
pub fn new(receiver: watch::Receiver<Slot>) -> Self {
Self(receiver)
⋮----
pub fn slot(&self) -> Slot {
*self.0.borrow()
⋮----
pub async fn changed(&mut self) -> Result<(), SlotReceiverError> {
⋮----
.changed()
⋮----
.map_err(|_| SlotReceiverError::ChannelClosed)
⋮----
pub enum SlotReceiverError {

================
File: tpu-client-next/src/node_address_service/slot_update_service.rs
================
pub struct SlotUpdateService {
⋮----
impl SlotUpdateService {
pub fn run(
⋮----
let cancel_clone = cancel.clone();
⋮----
let mut slot_update_stream = pin!(slot_update_stream);
⋮----
Ok(())
⋮----
Ok((
⋮----
handle: Some(handle),
⋮----
pub async fn shutdown(&mut self) -> Result<(), Error> {
self.cancel.cancel();
if let Some(handle) = self.handle.take() {
⋮----
pub enum Error {

================
File: tpu-client-next/src/quic_networking/error.rs
================
pub struct IoErrorWithPartialEq(pub io::Error);
impl PartialEq for IoErrorWithPartialEq {
fn eq(&self, other: &Self) -> bool {
let formatted_self = format!("{self:?}");
let formatted_other = format!("{other:?}");
⋮----
fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
self.0.fmt(f)
⋮----
fn from(err: io::Error) -> Self {
IoErrorWithPartialEq(err)
⋮----
pub enum QuicError {

================
File: tpu-client-next/src/client_builder.rs
================
pub struct TransactionSender(mpsc::Sender<TransactionBatch>);
pub struct Client {
⋮----
pub struct ClientBuilder {
⋮----
impl ClientBuilder {
pub fn new(leader_updater: Box<dyn LeaderUpdater>) -> Self {
⋮----
pub fn runtime_handle(mut self, handle: runtime::Handle) -> Self {
self.runtime_handle = Some(handle);
⋮----
pub fn bind_socket(mut self, bind_socket: UdpSocket) -> Self {
self.bind_target = Some(BindTarget::Socket(bind_socket));
⋮----
pub fn leader_send_fanout(mut self, fanout: usize) -> Self {
⋮----
pub fn identity<'a>(mut self, identity: impl Into<Option<&'a Keypair>>) -> Self {
self.identity = identity.into().map(StakeIdentity::new);
⋮----
pub fn max_cache_size(mut self, num_connections: usize) -> Self {
⋮----
pub fn cancel_token(mut self, cancel: CancellationToken) -> Self {
self.cancel_scheduler = cancel.child_token();
self.cancel_reporter = cancel.child_token();
⋮----
pub fn worker_channel_size(mut self, size: usize) -> Self {
⋮----
pub fn sender_channel_size(mut self, size: usize) -> Self {
⋮----
pub fn max_reconnect_attempts(mut self, attempts: usize) -> Self {
⋮----
pub fn metric_reporter<F, Fut>(mut self, f: F) -> Self
⋮----
self.report_fn = Some(Box::new(move |stats, cancel| Box::pin(f(stats, cancel))));
⋮----
pub fn build<Broadcaster>(self) -> Result<(TransactionSender, Client), ClientBuilderError>
⋮----
let bind = self.bind_target.ok_or(ClientBuilderError::Misconfigured)?;
⋮----
// We open connection to one more leader in advance, which time-wise means ~1.6s
⋮----
connect: self.leader_send_fanout.saturating_add(1),
⋮----
self.cancel_scheduler.clone(),
⋮----
.unwrap_or_else(tokio::runtime::Handle::current);
⋮----
let stats = scheduler.get_stats();
let cancel = self.cancel_reporter.clone();
let handle = runtime_handle.spawn(report_fn(stats, self.cancel_reporter));
Some(CancellableHandle { handle, cancel })
⋮----
runtime_handle.spawn(scheduler.run_with_broadcaster::<Broadcaster>(config));
⋮----
Ok((TransactionSender(sender), client))
⋮----
pub type ReportFn = Box<
⋮----
impl TransactionSender {
pub async fn send_transactions_in_batch<T>(
⋮----
.send(TransactionBatch::new(wire_transactions))
⋮----
.map_err(ClientError::SendError)
⋮----
pub fn try_send_transactions_in_batch<T>(
⋮----
.try_send(TransactionBatch::new(wire_transactions))
.map_err(ClientError::TrySendError)
⋮----
impl Client {
pub fn update_identity(&self, identity: &Keypair) -> Result<(), ClientError> {
⋮----
.send(Some(stake_identity))
.map_err(|_| ClientError::FailedToUpdateIdentity)
⋮----
pub async fn shutdown(self) -> Result<(), ClientError> {
self.scheduler_handle.shutdown().await??;
⋮----
reporter_handle.shutdown().await?;
⋮----
drop(self.update_certificate_sender);
Ok(())
⋮----
pub enum ClientBuilderError {
⋮----
pub enum ClientError {
⋮----
struct CancellableHandle<T> {
⋮----
pub async fn shutdown(self) -> Result<T, JoinError> {
self.cancel.cancel();

================
File: tpu-client-next/src/connection_worker.rs
================
enum ConnectionState {
⋮----
impl Drop for ConnectionState {
fn drop(&mut self) {
⋮----
debug!(
⋮----
connection.close(0u32.into(), b"done");
⋮----
pub(crate) struct ConnectionWorker {
⋮----
impl ConnectionWorker {
pub fn new(
⋮----
cancel: cancel.clone(),
⋮----
pub async fn run(&mut self) {
let cancel = self.cancel.clone();
⋮----
self.create_connection(0).await;
⋮----
error!(
⋮----
sleep(RETRY_SLEEP_INTERVAL).await;
self.reconnect(*num_reconnects).await;
⋮----
cancel.cancel();
⋮----
fn handle_connection_closed(&mut self, close_reason: ConnectionError) {
⋮----
debug!("Connection to {} closed locally", self.peer);
⋮----
warn!("Connection to {} timed out", self.peer);
⋮----
warn!("Connection to {} reset", self.peer);
⋮----
warn!(
⋮----
error!("Connection to {} failed: version mismatch", self.peer);
⋮----
record_error(close_reason.clone().into(), &self.send_txs_stats);
⋮----
async fn send_transactions(&mut self, connection: Connection, transactions: TransactionBatch) {
let now = timestamp();
⋮----
&& now.saturating_sub(transactions.timestamp()) > MAX_PROCESSING_AGE_MS
⋮----
debug!("Drop outdated transaction batch for peer: {}", self.peer);
⋮----
for data in transactions.into_iter() {
if connection.close_reason().is_some() {
debug!("Connection closed during transaction batch sending");
⋮----
let result = send_data_over_stream(&connection, &data).await;
⋮----
trace!(
⋮----
record_error(error, &self.send_txs_stats);
⋮----
.fetch_add(1, Ordering::Relaxed);
⋮----
measure_send.stop();
⋮----
async fn create_connection(&mut self, retries_attempt: usize) {
let server_name = socket_addr_to_quic_server_name(self.peer);
let connecting = self.endpoint.connect(self.peer, &server_name);
⋮----
let res = timeout(self.handshake_timeout, connecting).await;
measure_connection.stop();
⋮----
warn!("Connection error {}: {}", self.peer, err);
record_error(err.into(), &self.send_txs_stats);
self.connection = ConnectionState::Retry(retries_attempt.saturating_add(1));
⋮----
record_error(QuicError::HandshakeTimeout, &self.send_txs_stats);
⋮----
record_error(connecting_error.clone().into(), &self.send_txs_stats);
⋮----
async fn reconnect(&mut self, num_reconnects: usize) {
⋮----
self.create_connection(num_reconnects).await;

================
File: tpu-client-next/src/connection_workers_scheduler.rs
================
pub type TransactionReceiver = mpsc::Receiver<TransactionBatch>;
pub struct ConnectionWorkersScheduler {
⋮----
pub enum ConnectionWorkersSchedulerError {
⋮----
pub struct Fanout {
⋮----
pub struct ConnectionWorkersSchedulerConfig {
⋮----
pub enum BindTarget {
⋮----
pub struct StakeIdentity(QuicClientCertificate);
impl StakeIdentity {
pub fn new(keypair: &Keypair) -> Self {
Self(QuicClientCertificate::new(Some(keypair)))
⋮----
pub fn as_certificate(&self) -> &QuicClientCertificate {
⋮----
fn from(identity: StakeIdentity) -> Self {
⋮----
pub trait WorkersBroadcaster {
⋮----
impl ConnectionWorkersScheduler {
pub fn new(
⋮----
pub fn get_stats(&self) -> Arc<SendTransactionStats> {
self.stats.clone()
⋮----
pub async fn run(
⋮----
pub async fn run_with_broadcaster<Broadcaster: WorkersBroadcaster>(
⋮----
let mut endpoint = setup_endpoint(bind, stake_identity)?;
debug!("Client endpoint bind address: {:?}", endpoint.local_addr());
let mut workers = WorkersCache::new(num_connections, cancel.clone());
⋮----
let connect_leaders = leader_updater.next_leaders(leaders_fanout.connect);
let send_leaders = extract_send_leaders(&connect_leaders, leaders_fanout.send);
⋮----
if let Some(evicted_worker) = workers.ensure_worker(
⋮----
stats.clone(),
⋮----
shutdown_worker(evicted_worker);
⋮----
last_error = Some(error);
⋮----
workers.shutdown().await;
endpoint.close(0u32.into(), b"Closing connection");
leader_updater.stop().await;
⋮----
return Err(error);
⋮----
Ok(stats)
⋮----
pub fn setup_endpoint(
⋮----
let client_config = build_client_config(stake_identity.as_ref());
let endpoint = create_client_endpoint(bind, client_config)?;
Ok(endpoint)
⋮----
fn build_client_config(stake_identity: Option<&StakeIdentity>) -> ClientConfig {
⋮----
Some(identity) => identity.as_certificate(),
⋮----
create_client_config(client_certificate)
⋮----
pub struct NonblockingBroadcaster;
⋮----
impl WorkersBroadcaster for NonblockingBroadcaster {
async fn send_to_workers(
⋮----
workers.try_send_transactions_to_address(new_leader, transaction_batch.clone());
⋮----
debug!("Failed to send transactions to {new_leader:?}, worker send error: {err}.");
⋮----
if let Some(pop_worker) = workers.pop(*new_leader) {
shutdown_worker(pop_worker)
⋮----
Ok(())
⋮----
pub fn extract_send_leaders(leaders: &[SocketAddr], send_fanout: usize) -> Vec<SocketAddr> {
let send_count = send_fanout.min(leaders.len());
remove_duplicates(&leaders[..send_count])
⋮----
fn remove_duplicates(input: &[SocketAddr]) -> Vec<SocketAddr> {
let mut res = Vec::with_capacity(input.len());
⋮----
if !res.contains(address) {
res.push(*address);

================
File: tpu-client-next/src/leader_updater.rs
================
pub trait LeaderUpdater: Send {
⋮----
pub struct LeaderUpdaterError;
⋮----
fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
write!(f, "Leader updater encountered an error")
⋮----
write!(f, "LeaderUpdaterError")
⋮----
pub async fn create_leader_updater(
⋮----
return Ok(Box::new(PinnedLeaderUpdater {
address: vec![pinned_address],
⋮----
LeaderTpuService::new(rpc_client, &websocket_url, Protocol::QUIC, exit.clone())
⋮----
.map_err(|error| {
error!("Failed to create a LeaderTpuService: {error}");
⋮----
Ok(Box::new(LeaderUpdaterService {
⋮----
struct LeaderUpdaterService {
⋮----
impl LeaderUpdater for LeaderUpdaterService {
fn next_leaders(&mut self, lookahead_leaders: usize) -> Vec<SocketAddr> {
⋮----
(lookahead_leaders as u64).saturating_mul(NUM_CONSECUTIVE_LEADER_SLOTS);
self.leader_tpu_service.leader_tpu_sockets(lookahead_slots)
⋮----
async fn stop(&mut self) {
self.exit.store(true, Ordering::Relaxed);
self.leader_tpu_service.join().await;
⋮----
struct PinnedLeaderUpdater {
⋮----
impl LeaderUpdater for PinnedLeaderUpdater {
fn next_leaders(&mut self, _lookahead_leaders: usize) -> Vec<SocketAddr> {
self.address.clone()
⋮----
async fn stop(&mut self) {}

================
File: tpu-client-next/src/lib.rs
================
pub mod client_builder;
pub(crate) mod connection_worker;
pub mod connection_workers_scheduler;
pub mod send_transaction_stats;
pub mod workers_cache;
⋮----
pub(crate) mod quic_networking;
pub(crate) use crate::quic_networking::QuicError;
pub mod leader_updater;
pub mod transaction_batch;
⋮----
pub mod metrics;
pub(crate) mod logging;
pub mod node_address_service;
⋮----
pub mod websocket_node_address_service;

================
File: tpu-client-next/src/logging.rs
================
compile_error!("Either 'log' or 'tracing' feature must be enabled");
⋮----
compile_error!("'log' and 'tracing' features are mutually exclusive");
⋮----
mod tests {
⋮----
fn test_logging_macros_available() {
debug!("Test debug message");
error!("Test error message");
info!("Test info message");
warn!("Test warn message");

================
File: tpu-client-next/src/metrics.rs
================
impl SendTransactionStats {
⋮----
pub async fn report_to_influxdb(
⋮----
let mut interval = interval(reporting_interval);
let stats = self.clone();
⋮----
select! {

================
File: tpu-client-next/src/node_address_service.rs
================
pub mod leader_tpu_cache_service;
pub mod recent_leader_slots;
pub mod slot_event;
pub mod slot_receiver;
pub mod slot_update_service;
⋮----
pub struct NodeAddressService {
⋮----
impl NodeAddressService {
pub async fn run(
⋮----
.initial_slot()
⋮----
.map_err(NodeAddressServiceError::from)?;
⋮----
SlotUpdateService::run(initial_slot, slot_update_stream, cancel.clone())?;
⋮----
slot_receiver.clone(),
⋮----
Ok(Self {
⋮----
pub async fn shutdown(&mut self) -> Result<(), NodeAddressServiceError> {
let (slot_update_service_res, leader_cache_service_res) = join!(
⋮----
Ok(())
⋮----
pub fn estimated_current_slot(&self) -> Slot {
self.slot_receiver.slot()
⋮----
impl LeaderUpdater for NodeAddressService {
fn next_leaders(&mut self, lookahead_leaders: usize) -> Vec<SocketAddr> {
self.leaders_receiver.leaders(lookahead_leaders)
⋮----
async fn stop(&mut self) {
if let Err(e) = self.shutdown().await {
error!("Failed to shutdown NodeAddressService: {e}");
⋮----
pub enum NodeAddressServiceError {

================
File: tpu-client-next/src/quic_networking.rs
================
pub mod error;
⋮----
pub(crate) fn create_client_config(client_certificate: &QuicClientCertificate) -> ClientConfig {
let mut crypto = tls_client_config_builder()
.with_client_auth_cert(
vec![client_certificate.certificate.clone()],
client_certificate.key.clone_key(),
⋮----
.expect("Failed to set QUIC client certificates");
⋮----
crypto.alpn_protocols = vec![ALPN_TPU_PROTOCOL_ID.to_vec()];
⋮----
let timeout = IdleTimeout::try_from(QUIC_MAX_TIMEOUT).unwrap();
res.max_idle_timeout(Some(timeout));
res.keep_alive_interval(Some(QUIC_KEEP_ALIVE));
res.send_fairness(QUIC_SEND_FAIRNESS);
⋮----
let mut config = ClientConfig::new(Arc::new(QuicClientConfig::try_from(crypto).unwrap()));
config.transport_config(Arc::new(transport_config));
⋮----
pub(crate) fn create_client_endpoint(
⋮----
Endpoint::client(bind_addr).map_err(IoErrorWithPartialEq::from)?
⋮----
let runtime = default_runtime()
.ok_or_else(|| std::io::Error::other("no async runtime found"))
.map_err(IoErrorWithPartialEq::from)?;
⋮----
.map_err(IoErrorWithPartialEq::from)?
⋮----
endpoint.set_default_client_config(client_config);
Ok(endpoint)
⋮----
pub(crate) async fn send_data_over_stream(
⋮----
let mut send_stream = connection.open_uni().await?;
send_stream.write_all(data).await.map_err(QuicError::from)?;
Ok(())

================
File: tpu-client-next/src/send_transaction_stats.rs
================
pub struct SendTransactionStats {
⋮----
pub fn record_error(err: QuicError, stats: &SendTransactionStats) {
⋮----
stats.connect_error_other.fetch_add(1, Ordering::Relaxed);
⋮----
.fetch_add(1, Ordering::Relaxed);
⋮----
stats.connection_error_reset.fetch_add(1, Ordering::Relaxed);
⋮----
stats.write_error_stopped.fetch_add(1, Ordering::Relaxed);
⋮----
macro_rules! display_send_transaction_stats_body {
⋮----
fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
display_send_transaction_stats_body!(
⋮----
macro_rules! define_non_atomic_struct_for {
⋮----
define_non_atomic_struct_for!(

================
File: tpu-client-next/src/transaction_batch.rs
================
pub struct TransactionBatch {
⋮----
type WiredTransaction = Bytes;
impl IntoIterator for TransactionBatch {
type Item = Bytes;
type IntoIter = std::vec::IntoIter<Self::Item>;
fn into_iter(self) -> Self::IntoIter {
self.wired_transactions.into_iter()
⋮----
impl TransactionBatch {
pub fn new<T>(wired_transactions: Vec<T>) -> Self
⋮----
.into_iter()
.map(|v| Bytes::from_owner(v))
.collect();
⋮----
timestamp: timestamp(),
⋮----
pub fn timestamp(&self) -> u64 {

================
File: tpu-client-next/src/websocket_node_address_service.rs
================
pub struct WebsocketNodeAddressService {
⋮----
impl WebsocketNodeAddressService {
pub async fn run(
⋮----
websocket_slot_event_stream(websocket_url);
⋮----
Ok(Self {
⋮----
ws_task_handle: Some(ws_task_handle),
⋮----
pub async fn shutdown(&mut self) -> Result<(), Error> {
self.service.shutdown().await?;
if let Some(handle) = self.ws_task_handle.take() {
⋮----
Ok(())
⋮----
pub fn current_slot(&self) -> Slot {
self.service.estimated_current_slot()
⋮----
impl LeaderUpdater for WebsocketNodeAddressService {
fn next_leaders(&mut self, lookahead_leaders: usize) -> Vec<SocketAddr> {
self.service.next_leaders(lookahead_leaders)
⋮----
async fn stop(&mut self) {
if let Err(e) = self.shutdown().await {
error!("Failed to shutdown WebsocketNodeAddressService: {e}");
⋮----
pub enum Error {
⋮----
fn websocket_slot_event_stream(
⋮----
let (mut notifications, unsubscribe) = pubsub_client.slot_updates_subscribe().await?;
while let Some(event) = notifications.next().await {
let Some(event) = map_websocket_update_to_slot_event(event) else {
⋮----
let Err(send_error) = tx.send_timeout(event, SEND_TIMEOUT).await else {
⋮----
info!("Slot event receiver dropped, exiting websocket slot event stream.");
⋮----
info!(
⋮----
drop(notifications);
unsubscribe().await;
pubsub_client.shutdown().await?;
⋮----
fn map_websocket_update_to_slot_event(update: SlotUpdate) -> Option<SlotEvent> {
⋮----
SlotUpdate::FirstShredReceived { slot, .. } => Some(SlotEvent::Start(slot)),
SlotUpdate::Completed { slot, .. } => Some(SlotEvent::End(slot)),

================
File: tpu-client-next/src/workers_cache.rs
================
pub struct WorkerInfo {
⋮----
impl WorkerInfo {
pub fn new(
⋮----
fn try_send_transactions(&self, txs_batch: TransactionBatch) -> Result<(), WorkersCacheError> {
self.sender.try_send(txs_batch).map_err(|err| match err {
⋮----
Ok(())
⋮----
async fn send_transactions(
⋮----
.send(txs_batch)
⋮----
.map_err(|_| WorkersCacheError::ReceiverDropped)?;
⋮----
async fn shutdown(self) -> Result<(), WorkersCacheError> {
self.cancel.cancel();
drop(self.sender);
⋮----
.map_err(|_| WorkersCacheError::TaskJoinFailure)?;
⋮----
fn is_active(&self) -> bool {
!(self.cancel.is_cancelled() || self.sender.is_closed())
⋮----
pub fn spawn_worker(
⋮----
let endpoint = endpoint.clone();
⋮----
worker.run().await;
⋮----
pub struct WorkersCache {
⋮----
pub enum WorkersCacheError {
⋮----
impl WorkersCache {
pub fn new(capacity: usize, cancel: CancellationToken) -> Self {
⋮----
pub fn contains(&self, peer: &SocketAddr) -> bool {
self.workers.contains(peer)
⋮----
pub fn push(&mut self, leader: SocketAddr, peer_worker: WorkerInfo) -> Option<ShutdownWorker> {
if let Some((leader, popped_worker)) = self.workers.push(leader, peer_worker) {
return Some(ShutdownWorker {
⋮----
pub fn pop(&mut self, leader: SocketAddr) -> Option<ShutdownWorker> {
if let Some(popped_worker) = self.workers.pop(&leader) {
⋮----
pub fn ensure_worker(
⋮----
if let Some(worker) = self.workers.peek(&peer) {
if worker.is_active() {
⋮----
trace!("No active worker for peer {peer}, respawning.");
let worker = spawn_worker(
⋮----
self.push(peer, worker)
⋮----
pub fn try_send_transactions_to_address(
⋮----
if cancel.is_cancelled() {
return Err(WorkersCacheError::ShutdownError);
⋮----
let current_worker = workers.get(peer).ok_or(WorkersCacheError::WorkerNotFound)?;
let send_res = current_worker.try_send_transactions(txs_batch);
⋮----
debug!(
⋮----
if let Some(current_worker) = workers.pop(peer) {
shutdown_worker(ShutdownWorker {
⋮----
pub async fn send_transactions_to_address(
⋮----
let send_res = current_worker.send_transactions(txs_batch).await;
⋮----
.run_until_cancelled(body)
⋮----
.unwrap_or(Err(WorkersCacheError::ShutdownError))
⋮----
pub(crate) fn flush(&mut self) {
while let Some((peer, current_worker)) = self.workers.pop_lru() {
⋮----
pub async fn shutdown(&mut self) {
⋮----
tasks.spawn(shutdown_worker.shutdown());
⋮----
while let Some(res) = tasks.join_next().await {
⋮----
debug!("A shutdown task failed: {err}");
⋮----
pub struct ShutdownWorker {
⋮----
impl ShutdownWorker {
pub(crate) fn leader(&self) -> SocketAddr {
⋮----
pub(crate) async fn shutdown(self) -> Result<(), WorkersCacheError> {
self.worker.shutdown().await
⋮----
pub fn shutdown_worker(worker: ShutdownWorker) {
⋮----
let leader = worker.leader();
let res = worker.shutdown().await;
⋮----
debug!("Error while shutting down worker for {leader}: {err}");
⋮----
mod tests {
⋮----
fn create_test_endpoint() -> Endpoint {
let socket = bind_to_localhost_unique().unwrap();
let client_config = create_client_config(&QuicClientCertificate::new(None));
create_client_endpoint(BindTarget::Socket(socket), client_config).unwrap()
⋮----
async fn test_worker_stopped_after_failed_connect() {
let endpoint = create_test_endpoint();
let port_range = unique_port_range_for_tests(2);
let peer: SocketAddr = SocketAddr::new(Ipv4Addr::LOCALHOST.into(), port_range.start);
⋮----
let worker_info = spawn_worker(
⋮----
stats.clone(),
⋮----
timeout(TEST_MAX_TIME, worker_info.handle)
⋮----
.unwrap_or_else(|_| panic!("Should stop in less than {TEST_MAX_TIME:?}."))
.expect("Worker task should finish successfully.");
assert_eq!(
⋮----
async fn test_worker_shutdown() {
⋮----
timeout(TEST_MAX_TIME, worker_info.shutdown())
⋮----
async fn test_worker_removed_after_exit() {
⋮----
let mut cache = WorkersCache::new(10, cancel.clone());
⋮----
assert!(cache.push(peer, worker).is_none());
let worker_info = cache.workers.peek(&peer).unwrap();
⋮----
while !worker_info.sender.is_closed() {
if start.elapsed() > TEST_MAX_TIME {
panic!("Sender did not close in {TEST_MAX_TIME:?}");
⋮----
sleep(Duration::from_millis(500)).await;
⋮----
assert!(!worker_info.is_active(), "Worker should be inactive");
⋮----
.try_send_transactions_to_address(&peer, TransactionBatch::new(vec![vec![0u8; 1]]));
assert_eq!(result, Err(WorkersCacheError::ReceiverDropped));
assert!(
⋮----
cancel.cancel();
cache.shutdown().await;

================
File: tpu-client-next/tests/connection_workers_scheduler_test.rs
================
use solana_tpu_client_next::leader_updater::create_leader_updater;
⋮----
fn test_config(stake_identity: Option<Keypair>) -> ConnectionWorkersSchedulerConfig {
⋮----
unique_port_range_for_tests(1).start,
⋮----
stake_identity: stake_identity.map(|identity| StakeIdentity::new(&identity)),
⋮----
async fn setup_connection_worker_scheduler(
⋮----
json_rpc_url.to_string(),
⋮----
let config = test_config(stake_identity);
// Setup sending txs
⋮----
let leader_updater = create_leader_updater(rpc_client, websocket_url, Some(tpu_address))
⋮----
.expect("Leader updates was successfully created");
⋮----
cancel.clone(),
⋮----
let scheduler = tokio::spawn(scheduler.run(config));
⋮----
async fn join_scheduler(
⋮----
.unwrap()
.expect("Scheduler should stop successfully.");
scheduler_stats.read_and_reset()
⋮----
struct SpawnTxGenerator {
⋮----
/// Generates `num_tx_batches` batches of transactions, each holding a single transaction of
/// `tx_size` bytes.
⋮----
/// `tx_size` bytes.
///
⋮----
///
/// It will not close the returned `tx_receiver` until `tx_sender_shutdown` is invoked.  Otherwise,
⋮----
/// It will not close the returned `tx_receiver` until `tx_sender_shutdown` is invoked.  Otherwise,
/// there is a race condition, that exists between the last transaction being scheduled for delivery
⋮----
/// there is a race condition, that exists between the last transaction being scheduled for delivery
/// and the server connection being closed.
⋮----
/// and the server connection being closed.
fn spawn_tx_sender(
⋮----
fn spawn_tx_sender(
⋮----
.try_into()
.expect("`num_tx_batches` fits into u32 for all the tests");
let (tx_sender, tx_receiver) = channel(1);
⋮----
let tx_sender = tx_sender.clone();
⋮----
let txs = vec![vec![i as u8; tx_size]; 1];
⋮----
.send(TransactionBatch::new(txs))
⋮----
.expect("Receiver should not close their side");
// Pretend the client runs at the specified TPS.
⋮----
.saturating_mul(i)
.saturating_sub(start.elapsed());
if !sleep_time.is_zero() {
sleep(sleep_time).await;
⋮----
// It is OK if the receiver has disconnected.
let _ = done_sender.send(());
⋮----
let cancel = cancel.clone();
⋮----
cancel.cancel();
// This makes sure that the sender exists up until the shutdown is invoked.
drop(tx_sender);
sender.await.unwrap();
⋮----
async fn test_basic_transactions_sending() {
⋮----
} = setup_quic_server(
⋮----
// Pretend that we are running at ~100 TPS.
⋮----
} = spawn_tx_sender(tx_size, expected_num_txs, Duration::from_millis(10));
⋮----
setup_connection_worker_scheduler(server_address, tx_receiver, None).await;
// dropping sender will not lead to stop the scheduler.
drop(update_identity_sender);
// Check results
⋮----
let elapsed = now.elapsed();
assert!(
⋮----
let Ok(packets) = receiver.try_recv() else {
sleep(Duration::from_millis(10)).await;
⋮----
actual_num_packets += packets.len();
for p in packets.iter() {
let packet_id = p.data(0).expect("Data should not be lost by server.");
received_data.push(*packet_id);
assert_eq!(p.meta().size, 1);
⋮----
received_data.sort_unstable();
for i in 1..received_data.len() {
assert_eq!(received_data[i - 1] + 1, received_data[i]);
⋮----
// Stop sending
⋮----
let stats = join_scheduler(scheduler_handle).await;
assert_eq!(stats.successfully_sent, expected_num_txs as u64,);
// Stop server
⋮----
server_handle.await.unwrap();
⋮----
async fn count_received_packets_for(
⋮----
let mut num_packets_received = Saturating(0usize);
while now.elapsed() < receive_duration {
if let Ok(packets) = receiver.try_recv() {
num_packets_received += packets.len();
⋮----
assert_eq!(p.meta().size, expected_tx_size);
⋮----
sleep(Duration::from_millis(100)).await;
⋮----
// Check that client can create connection even if the first several attempts were unsuccessful.
⋮----
async fn test_connection_denied_until_allowed() {
⋮----
// To prevent server from accepting a new connection, we
// set max_connections_per_peer == 1
⋮----
// If we create a blocking connection and try to create connections to send TXs,
// the new connections will be immediately closed.
// Since client is not retrying sending failed transactions, this leads to the packets loss.
let blocking_connection = make_client_endpoint(&server_address, None).await;
⋮----
} = spawn_tx_sender(tx_size, num_tx_batches, time_per_tx);
⋮----
let received_num_packets = count_received_packets_for(
receiver.clone(),
⋮----
assert_eq!(
⋮----
// drop blocking connection, allow packets to get in now
drop(blocking_connection);
⋮----
count_received_packets_for(receiver, tx_size, time_per_tx * num_tx_batches as u32 / 2)
⋮----
// Wait for the exchange to finish.
⋮----
// Expect at least some errors.
⋮----
// Exit server
⋮----
// Check that if the client connection has been pruned, client manages to
// reestablish it. With more packets, we can observe the impact of pruning
// even with proactive detection.
⋮----
async fn test_connection_pruned_and_reopened() {
⋮----
} = spawn_tx_sender(tx_size, expected_num_txs, Duration::from_millis(100));
⋮----
sleep(Duration::from_millis(400)).await;
let _connection_to_prune_client = make_client_endpoint(&server_address, None).await;
⋮----
let actual_num_packets = count_received_packets_for(receiver, tx_size, TEST_MAX_TIME).await;
assert!(actual_num_packets < expected_num_txs);
⋮----
// Proactive detection catches pruning immediately, expect multiple retries.
⋮----
/// Check that client creates staked connection. To do that prohibit unstaked
/// connection and verify that all the txs has been received.
⋮----
/// connection and verify that all the txs has been received.
#[tokio::test]
async fn test_staked_connection() {
⋮----
let stakes = HashMap::from([(stake_identity.pubkey(), 100_000)]);
⋮----
Some(staked_nodes),
⋮----
// Must use at least the number of endpoints (10) because
// `max_staked_connections` and `max_unstaked_connections` are
// cumulative for all the endpoints.
⋮----
setup_connection_worker_scheduler(server_address, tx_receiver, Some(stake_identity)).await;
⋮----
assert_eq!(actual_num_packets, expected_num_txs);
⋮----
// Check that if client sends transactions at a reasonably high rate that is
// higher than what the server accepts, nevertheless all the transactions are
// delivered and there are no errors on the client side.
⋮----
async fn test_connection_throttling() {
⋮----
// Send at 1000 TPS - x10 more than the throttling interval of 10ms used in other tests allows.
⋮----
} = spawn_tx_sender(tx_size, expected_num_txs, Duration::from_millis(1));
⋮----
count_received_packets_for(receiver, tx_size, Duration::from_secs(1)).await;
⋮----
// Check that when the host cannot be reached, the client exits gracefully.
⋮----
async fn test_no_host() {
// A "black hole" address for the TPU.
⋮----
// Setup sending side.
⋮----
} = spawn_tx_sender(tx_size, max_send_attempts, Duration::from_millis(10));
⋮----
// Wait for all the transactions to be sent, and some extra time for the delivery to be
// attempted.
tx_sender_done.await.unwrap();
⋮----
// Wait for the generator to finish.
⋮----
// For each transaction, we will check if worker exists and active. In this
// case, worker will never be active because when failed creating
// connection, we stop it. So scheduler will `max_send_attempts` try to
// create worker and fail each time.
⋮----
// Check that when the client is rate-limited by server, we update counters
// accordingly. To implement it we:
// * set the connection limit per minute to 1
// * create a dummy connection to reach the limit and immediately close it
// * set up client which will try to create a new connection which it will be
// rate-limited. This test doesn't check what happens when the rate-limiting
⋮----
async fn test_rate_limiting() {
⋮----
let connection_to_reach_limit = make_client_endpoint(&server_address, None).await;
drop(connection_to_reach_limit);
⋮----
assert_eq!(actual_num_packets, 0);
⋮----
scheduler_cancel.cancel();
⋮----
async fn test_rate_limiting_establish_connection() {
⋮----
} = spawn_tx_sender(tx_size, expected_num_txs, Duration::from_millis(1000));
⋮----
count_received_packets_for(receiver, tx_size, Duration::from_secs(70)).await;
⋮----
let mut stats = join_scheduler(scheduler_handle).await;
⋮----
assert_eq!(stats, SendTransactionStatsNonAtomic::default());
⋮----
async fn test_update_identity() {
⋮----
} = spawn_tx_sender(tx_size, num_txs, Duration::from_millis(50));
⋮----
setup_connection_worker_scheduler(
⋮----
.send(Some(StakeIdentity::new(&stake_identity)))
.unwrap();
⋮----
assert!(actual_num_packets > 0);
⋮----
assert!(stats.successfully_sent > 0);
⋮----
async fn test_proactive_connection_close_detection() {
⋮----
let (tx_sender, tx_receiver) = channel(10);
⋮----
.send(TransactionBatch::new(vec![vec![1u8; tx_size]]))
⋮----
.expect("Send first batch");
⋮----
while !first_packet_received && start.elapsed() < Duration::from_secs(1) {
⋮----
if !packets.is_empty() {
⋮----
assert!(first_packet_received, "First packet should be received");
⋮----
.send(TransactionBatch::new(vec![vec![2u8; tx_size]]))
⋮----
.expect("Send second batch");
⋮----
.send(TransactionBatch::new(vec![vec![3u8; tx_size]]))
⋮----
.expect("Send third batch");
⋮----
async fn test_client_builder() {
⋮----
let _drop_guard = cancel.clone().drop_guard();
⋮----
let port_range = localhost_port_range_for_tests();
let socket = bind_to(IpAddr::V4(Ipv4Addr::LOCALHOST), port_range.0)
.expect("Should be able to open UdpSocket for tests.");
⋮----
let leader_updater = create_leader_updater(rpc_client, websocket_url, Some(server_address))
⋮----
.cancel_token(cancel.child_token())
.bind_socket(socket)
.leader_send_fanout(1)
.identity(None)
.max_cache_size(1)
.worker_channel_size(100)
.metric_reporter({
let successfully_sent = successfully_sent.clone();
⋮----
let mut interval = interval(Duration::from_millis(10));
⋮----
.run_until_cancelled(async {
⋮----
interval.tick().await;
let view = stats.read_and_reset();
successfully_sent.fetch_add(view.successfully_sent, Ordering::Relaxed);
⋮----
.expect("Client should be built successfully.");
⋮----
let txs = vec![vec![0_u8; tx_size]; 1];
⋮----
.send_transactions_in_batch(txs.clone())
⋮----
.expect("Client should accept the transaction batch");
⋮----
.try_send_transactions_in_batch(txs.clone())
⋮----
.shutdown()
⋮----
.expect("Client should shutdown successfully.");

================
File: tpu-client-next/Cargo.toml
================
[package]
name = "solana-tpu-client-next"
description = "Client code to send transaction to TPU."
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
default = ["log"]
agave-unstable-api = []
log = ["dep:log"]
metrics = ["dep:solana-metrics"]
tracing = ["dep:tracing"]
websocket-node-address-service = ["dep:solana-pubsub-client", "dep:tokio-stream"]

[dependencies]
async-trait = { workspace = true }
futures = { workspace = true }
futures-util = { workspace = true }
log = { workspace = true, optional = true }
lru = { workspace = true }
quinn = { workspace = true }
rustls = { workspace = true }
solana-clock = { workspace = true }
solana-commitment-config = { workspace = true }
solana-connection-cache = { workspace = true }
solana-epoch-schedule = { workspace = true }
solana-keypair = { workspace = true }
solana-measure = { workspace = true }
solana-metrics = { workspace = true, optional = true }
solana-pubkey = { workspace = true }
solana-pubsub-client = { workspace = true, optional = true }
solana-quic-definitions = { workspace = true }
solana-rpc-client = { workspace = true }
solana-rpc-client-api = { workspace = true }
solana-streamer = { workspace = true }
solana-time-utils = { workspace = true }
solana-tls-utils = { workspace = true }
solana-tpu-client = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
tokio-stream = { workspace = true, optional = true }
tokio-util = { workspace = true }
tracing = { workspace = true, optional = true }

[dev-dependencies]
crossbeam-channel = { workspace = true }
futures = { workspace = true }
serde_json = { workspace = true }
solana-cli-config = { workspace = true }
solana-commitment-config = { workspace = true }
solana-net-utils = { workspace = true }
solana-pubkey = { workspace = true }
solana-signer = { workspace = true }
solana-streamer = { workspace = true, features = ["dev-context-only-utils"] }
solana-tpu-client-next = { path = ".", features = ["agave-unstable-api", "websocket-node-address-service"] }

================
File: transaction-context/src/instruction_accounts.rs
================
pub struct InstructionAccount {
⋮----
impl InstructionAccount {
pub fn new(
⋮----
pub fn is_signer(&self) -> bool {
⋮----
pub fn is_writable(&self) -> bool {
⋮----
pub fn set_is_signer(&mut self, value: bool) {
⋮----
pub fn set_is_writable(&mut self, value: bool) {
⋮----
pub struct BorrowedInstructionAccount<'a, 'ix_data> {
⋮----
/// Returns the index of this account (transaction wide)
    #[inline]
pub fn get_index_in_transaction(&self) -> IndexOfAccount {
⋮----
/// Returns the public key of this account (transaction wide)
    #[inline]
pub fn get_key(&self) -> &Pubkey {
⋮----
.get_key_of_account_at_index(self.instruction_account.index_in_transaction)
.unwrap()
⋮----
/// Returns the owner of this account (transaction wide)
    #[inline]
pub fn get_owner(&self) -> &Pubkey {
self.account.owner()
⋮----
/// Assignes the owner of this account (transaction wide)
    #[cfg(not(target_os = "solana"))]
pub fn set_owner(&mut self, pubkey: &[u8]) -> Result<(), InstructionError> {
// Only the owner can assign a new owner
if !self.is_owned_by_current_program() {
return Err(InstructionError::ModifiedProgramId);
⋮----
// and only if the account is writable
if !self.is_writable() {
⋮----
// and only if the data is zero-initialized or empty
if !is_zeroed(self.get_data()) {
⋮----
// don't touch the account if the owner does not change
if self.get_owner().to_bytes() == pubkey {
return Ok(());
⋮----
self.touch()?;
self.account.copy_into_owner_from_slice(pubkey);
Ok(())
⋮----
pub fn get_lamports(&self) -> u64 {
self.account.lamports()
⋮----
pub fn set_lamports(&mut self, lamports: u64) -> Result<(), InstructionError> {
if !self.is_owned_by_current_program() && lamports < self.get_lamports() {
return Err(InstructionError::ExternalAccountLamportSpend);
⋮----
return Err(InstructionError::ReadonlyLamportChange);
⋮----
let old_lamports = self.get_lamports();
⋮----
let lamports_balance = (lamports as i128).saturating_sub(old_lamports as i128);
⋮----
.add_lamports_delta(lamports_balance)?;
⋮----
self.account.set_lamports(lamports);
⋮----
pub fn checked_add_lamports(&mut self, lamports: u64) -> Result<(), InstructionError> {
self.set_lamports(
self.get_lamports()
.checked_add(lamports)
.ok_or(InstructionError::ArithmeticOverflow)?,
⋮----
pub fn checked_sub_lamports(&mut self, lamports: u64) -> Result<(), InstructionError> {
⋮----
.checked_sub(lamports)
⋮----
pub fn get_data(&self) -> &[u8] {
self.account.data()
⋮----
pub fn get_data_mut(&mut self) -> Result<&mut [u8], InstructionError> {
self.can_data_be_changed()?;
⋮----
self.make_data_mut();
Ok(self.account.data_as_mut_slice())
⋮----
pub fn set_data_from_slice(&mut self, data: &[u8]) -> Result<(), InstructionError> {
self.can_data_be_resized(data.len())?;
⋮----
self.update_accounts_resize_delta(data.len())?;
self.account.set_data_from_slice(data);
⋮----
pub fn set_data_length(&mut self, new_length: usize) -> Result<(), InstructionError> {
self.can_data_be_resized(new_length)?;
if self.get_data().len() == new_length {
⋮----
self.update_accounts_resize_delta(new_length)?;
self.account.resize(new_length, 0);
⋮----
pub fn extend_from_slice(&mut self, data: &[u8]) -> Result<(), InstructionError> {
let new_len = self.get_data().len().saturating_add(data.len());
self.can_data_be_resized(new_len)?;
if data.is_empty() {
⋮----
self.update_accounts_resize_delta(new_len)?;
⋮----
self.account.extend_from_slice(data);
⋮----
pub fn is_shared(&self) -> bool {
self.account.is_shared()
⋮----
fn make_data_mut(&mut self) {
if self.account.is_shared() {
⋮----
.reserve(MAX_ACCOUNT_DATA_GROWTH_PER_INSTRUCTION);
⋮----
pub fn get_state<T: serde::de::DeserializeOwned>(&self) -> Result<T, InstructionError> {
bincode::deserialize(self.account.data()).map_err(|_| InstructionError::InvalidAccountData)
⋮----
pub fn set_state<T: serde::Serialize>(&mut self, state: &T) -> Result<(), InstructionError> {
let data = self.get_data_mut()?;
⋮----
bincode::serialized_size(state).map_err(|_| InstructionError::GenericError)?;
if serialized_size > data.len() as u64 {
return Err(InstructionError::AccountDataTooSmall);
⋮----
bincode::serialize_into(&mut *data, state).map_err(|_| InstructionError::GenericError)?;
⋮----
pub fn is_rent_exempt_at_data_length(&self, data_length: usize) -> bool {
⋮----
.is_exempt(self.get_lamports(), data_length)
⋮----
pub fn is_executable(&self) -> bool {
⋮----
self.account.executable()
⋮----
pub fn set_executable(&mut self, is_executable: bool) -> Result<(), InstructionError> {
⋮----
.is_exempt(self.get_lamports(), self.get_data().len())
⋮----
return Err(InstructionError::ExecutableAccountNotRentExempt);
⋮----
return Err(InstructionError::ExecutableModified);
⋮----
if self.is_executable() == is_executable {
⋮----
self.account.set_executable(is_executable);
⋮----
pub fn get_rent_epoch(&self) -> u64 {
self.account.rent_epoch()
⋮----
self.instruction_account.is_signer()
⋮----
self.instruction_account.is_writable()
⋮----
pub fn is_owned_by_current_program(&self) -> bool {
⋮----
.get_key_of_account_at_index(self.index_in_transaction_of_instruction_program)
.map(|program_key| program_key == self.get_owner())
.unwrap_or_default()
⋮----
pub fn can_data_be_changed(&self) -> Result<(), InstructionError> {
⋮----
return Err(InstructionError::ReadonlyDataModified);
⋮----
return Err(InstructionError::ExternalAccountDataModified);
⋮----
pub fn can_data_be_resized(&self, new_len: usize) -> Result<(), InstructionError> {
let old_len = self.get_data().len();
if new_len != old_len && !self.is_owned_by_current_program() {
return Err(InstructionError::AccountDataSizeChanged);
⋮----
.can_data_be_resized(old_len, new_len)?;
self.can_data_be_changed()
⋮----
fn touch(&self) -> Result<(), InstructionError> {
⋮----
.touch(self.instruction_account.index_in_transaction)
⋮----
fn update_accounts_resize_delta(&mut self, new_len: usize) -> Result<(), InstructionError> {
⋮----
.update_accounts_resize_delta(self.get_data().len(), new_len)
⋮----
fn is_zeroed(buf: &[u8]) -> bool {
⋮----
let mut chunks = buf.chunks_exact(ZEROS_LEN);
⋮----
chunks.all(|chunk| chunk == &ZEROS[..])
&& chunks.remainder() == &ZEROS[..chunks.remainder().len()]

================
File: transaction-context/src/instruction.rs
================
pub struct InstructionFrame<'ix_data> {
⋮----
/// This is an account deduplication map that maps index_in_transaction to index_in_instruction
    /// Usage: dedup_map[index_in_transaction] = index_in_instruction
⋮----
/// Usage: dedup_map[index_in_transaction] = index_in_instruction
    /// This is a vector of u8s to save memory, since many entries may be unused.
⋮----
/// This is a vector of u8s to save memory, since many entries may be unused.
    pub(crate) dedup_map: Vec<u16>,
⋮----
pub struct InstructionContext<'a, 'ix_data> {
⋮----
pub fn get_index_in_trace(&self) -> usize {
⋮----
pub fn get_stack_height(&self) -> usize {
self.nesting_level.saturating_add(1)
⋮----
pub fn get_number_of_instruction_accounts(&self) -> IndexOfAccount {
self.instruction_accounts.len() as IndexOfAccount
⋮----
pub fn check_number_of_instruction_accounts(
⋮----
if self.get_number_of_instruction_accounts() < expected_at_least {
Err(InstructionError::MissingAccount)
⋮----
Ok(())
⋮----
pub fn get_instruction_data(&self) -> &[u8] {
⋮----
pub fn get_index_of_program_account_in_transaction(
⋮----
Ok(self.program_account_index_in_tx)
⋮----
pub fn get_index_of_instruction_account_in_transaction(
⋮----
Ok(self
⋮----
.get(instruction_account_index as usize)
.ok_or(InstructionError::MissingAccount)?
⋮----
pub fn get_index_of_account_in_instruction(
⋮----
.get(index_in_transaction as usize)
.and_then(|idx| {
if *idx as usize >= self.instruction_accounts.len() {
⋮----
Some(*idx as IndexOfAccount)
⋮----
.ok_or(InstructionError::MissingAccount)
⋮----
pub fn is_instruction_account_duplicate(
⋮----
self.get_index_of_instruction_account_in_transaction(instruction_account_index)?;
⋮----
self.get_index_of_account_in_instruction(index_in_transaction)?;
Ok(
⋮----
Some(first_instruction_account_index)
⋮----
pub fn get_program_key(&self) -> Result<&'a Pubkey, InstructionError> {
self.get_index_of_program_account_in_transaction()
.and_then(|index_in_transaction| {
⋮----
.get_key_of_account_at_index(index_in_transaction)
⋮----
/// Get the owner of the program account of this instruction
    pub fn get_program_owner(&self) -> Result<Pubkey, InstructionError> {
⋮----
pub fn get_program_owner(&self) -> Result<Pubkey, InstructionError> {
⋮----
.try_borrow(index_in_transaction)
⋮----
.map(|acc| *acc.owner())
⋮----
/// Gets an instruction account of this Instruction
    pub fn try_borrow_instruction_account(
⋮----
pub fn try_borrow_instruction_account(
⋮----
.get(index_in_instruction as usize)
.ok_or(InstructionError::MissingAccount)?;
⋮----
.try_borrow_mut(instruction_account.index_in_transaction)?;
Ok(BorrowedInstructionAccount {
⋮----
/// Returns whether an instruction account is a signer
    pub fn is_instruction_account_signer(
⋮----
pub fn is_instruction_account_signer(
⋮----
.is_signer())
⋮----
/// Returns whether an instruction account is writable
    pub fn is_instruction_account_writable(
⋮----
pub fn is_instruction_account_writable(
⋮----
.is_writable())
⋮----
/// Calculates the set of all keys of signer instruction accounts in this Instruction
    pub fn get_signers(&self) -> Result<HashSet<Pubkey>, InstructionError> {
⋮----
pub fn get_signers(&self) -> Result<HashSet<Pubkey>, InstructionError> {
⋮----
for instruction_account in self.instruction_accounts.iter() {
if instruction_account.is_signer() {
result.insert(
⋮----
.get_key_of_account_at_index(instruction_account.index_in_transaction)?,
⋮----
Ok(result)
⋮----
pub fn instruction_accounts(&self) -> &[InstructionAccount] {
⋮----
pub fn get_key_of_instruction_account(
⋮----
self.get_index_of_instruction_account_in_transaction(index_in_instruction)
.and_then(|idx| self.transaction_context.get_key_of_account_at_index(idx))

================
File: transaction-context/src/lib.rs
================
pub mod instruction;
pub mod instruction_accounts;
pub mod transaction_accounts;
pub mod vm_slice;
⋮----
pub type IndexOfAccount = u16;
⋮----
pub struct TransactionContext<'ix_data> {
⋮----
pub fn new(
⋮----
instruction_trace: vec![InstructionFrame::default()],
⋮----
pub fn set_top_level_instruction_index(&mut self, top_level_instruction_index: usize) {
⋮----
pub fn deconstruct_without_keys(self) -> Result<Vec<AccountSharedData>, InstructionError> {
if !self.instruction_stack.is_empty() {
return Err(InstructionError::CallDepth);
⋮----
.expect("transaction_context.accounts has unexpected outstanding refs")
.deconstruct_into_account_shared_data();
Ok(accounts)
⋮----
pub fn accounts(&self) -> &Rc<TransactionAccounts> {
⋮----
pub fn get_number_of_accounts(&self) -> IndexOfAccount {
self.accounts.len() as IndexOfAccount
⋮----
pub fn get_key_of_account_at_index(
⋮----
.account_key(index_in_transaction)
.ok_or(InstructionError::MissingAccount)
⋮----
pub fn find_index_of_account(&self, pubkey: &Pubkey) -> Option<IndexOfAccount> {
⋮----
.account_keys_iter()
.position(|key| key == pubkey)
.map(|index| index as IndexOfAccount)
⋮----
pub fn get_instruction_trace_capacity(&self) -> usize {
⋮----
pub fn get_instruction_trace_length(&self) -> usize {
self.instruction_trace.len().saturating_sub(1)
⋮----
pub fn get_instruction_context_at_index_in_trace(
⋮----
.get(index_in_trace)
.ok_or(InstructionError::CallDepth)?;
Ok(InstructionContext {
⋮----
pub fn get_instruction_context_at_nesting_level(
⋮----
.get(nesting_level)
⋮----
let instruction_context = self.get_instruction_context_at_index_in_trace(index_in_trace)?;
debug_assert_eq!(instruction_context.nesting_level, nesting_level);
Ok(instruction_context)
⋮----
pub fn get_instruction_stack_capacity(&self) -> usize {
⋮----
pub fn get_instruction_stack_height(&self) -> usize {
self.instruction_stack.len()
⋮----
pub fn get_current_instruction_context(
⋮----
.get_instruction_stack_height()
.checked_sub(1)
⋮----
self.get_instruction_context_at_nesting_level(level)
⋮----
pub fn get_next_instruction_context(
⋮----
.len()
⋮----
self.get_instruction_context_at_index_in_trace(index_in_trace)
⋮----
pub fn configure_next_instruction(
⋮----
debug_assert_eq!(deduplication_map.len(), MAX_ACCOUNTS_PER_TRANSACTION);
⋮----
.last_mut()
⋮----
Ok(())
⋮----
/// A version of `configure_next_instruction` to help creating the deduplication map in tests
    pub fn configure_next_instruction_for_tests(
⋮----
pub fn configure_next_instruction_for_tests(
⋮----
debug_assert!(instruction_accounts.len() <= u16::MAX as usize);
let mut dedup_map = vec![u16::MAX; MAX_ACCOUNTS_PER_TRANSACTION];
for (idx, account) in instruction_accounts.iter().enumerate() {
⋮----
.get_mut(account.index_in_transaction as usize)
.unwrap();
⋮----
self.configure_next_instruction(
⋮----
/// Pushes the next instruction
    #[cfg(not(target_os = "solana"))]
pub fn push(&mut self) -> Result<(), InstructionError> {
let nesting_level = self.get_instruction_stack_height();
if !self.instruction_stack.is_empty() && self.accounts.get_lamports_delta() != 0 {
return Err(InstructionError::UnbalancedInstruction);
⋮----
let index_in_trace = self.get_instruction_trace_length();
⋮----
return Err(InstructionError::MaxInstructionTraceLengthExceeded);
⋮----
self.instruction_trace.push(InstructionFrame::default());
⋮----
self.instruction_stack.push(index_in_trace);
if let Some(index_in_transaction) = self.find_index_of_account(&instructions::id()) {
let mut mut_account_ref = self.accounts.try_borrow_mut(index_in_transaction)?;
if mut_account_ref.owner() != &solana_sdk_ids::sysvar::id() {
return Err(InstructionError::InvalidAccountOwner);
⋮----
mut_account_ref.data_as_mut_slice(),
⋮----
/// Pops the current instruction
    #[cfg(not(target_os = "solana"))]
pub fn pop(&mut self) -> Result<(), InstructionError> {
if self.instruction_stack.is_empty() {
⋮----
// Verify (before we pop) that the total sum of all lamports in this instruction did not change
⋮----
self.get_current_instruction_context()
.and_then(|instruction_context| {
// Verify all executable accounts have no outstanding refs
⋮----
.try_borrow_mut(
instruction_context.get_index_of_program_account_in_transaction()?,
⋮----
.map_err(|err| {
⋮----
Ok(self.accounts.get_lamports_delta() != 0)
⋮----
// Always pop, even if we `detected_an_unbalanced_instruction`
self.instruction_stack.pop();
⋮----
self.top_level_instruction_index = self.top_level_instruction_index.saturating_add(1);
⋮----
Err(InstructionError::UnbalancedInstruction)
⋮----
/// Gets the return data of the current instruction or any above
    pub fn get_return_data(&self) -> (&Pubkey, &[u8]) {
⋮----
pub fn get_return_data(&self) -> (&Pubkey, &[u8]) {
⋮----
/// Set the return data of the current instruction
    pub fn set_return_data(
⋮----
pub fn set_return_data(
⋮----
/// Returns a new account data write access handler
    pub fn access_violation_handler(
⋮----
pub fn access_violation_handler(
⋮----
// This region is not a writable account.
⋮----
vm_addr.saturating_add(len).saturating_sub(region.vm_addr) as usize;
⋮----
// Requested access goes further than the account region.
⋮----
// The four calls below can't really fail. If they fail because of a bug,
let Ok(mut account) = accounts.try_borrow_mut(index_in_transaction) else {
debug_assert!(false);
⋮----
if accounts.touch(index_in_transaction).is_err() {
⋮----
.saturating_sub(accounts.resize_delta())
.max(0) as usize;
⋮----
let old_len = account.data().len();
⋮----
.min(MAX_ACCOUNT_DATA_LEN as usize)
.min(old_len.saturating_add(remaining_allowed_growth));
debug_assert!(accounts.can_data_be_resized(old_len, new_len).is_ok());
⋮----
.update_accounts_resize_delta(old_len, new_len)
.is_err()
⋮----
account.resize(new_len, 0);
⋮----
region.host_addr = account.data_as_mut_slice().as_mut_ptr() as u64;
⋮----
pub fn take_instruction_trace(&mut self) -> Vec<InstructionFrame<'_>> {
// The last frame is a placeholder for the next instruction to be executed, so it
// is empty.
self.instruction_trace.pop();
⋮----
/// Return data at the end of a transaction
#[cfg_attr(feature = "serde", derive(serde::Deserialize, serde::Serialize))]
⋮----
pub struct TransactionReturnData {
⋮----
/// Everything that needs to be recorded from a TransactionContext after execution
#[cfg(not(target_os = "solana"))]
pub struct ExecutionRecord {
⋮----
/// Used by the bank in the runtime to write back the processed accounts and recorded instructions
#[cfg(not(target_os = "solana"))]
⋮----
fn from(context: TransactionContext) -> Self {
⋮----
.take();
⋮----
.iter()
.fold(0usize, |accumulator, was_touched| {
accumulator.saturating_add(was_touched.get() as usize)
⋮----
mod tests {
⋮----
fn test_instructions_sysvar_store_index_checked() {
⋮----
vec![
⋮----
let rent_exempt_lamports = Rent::default().minimum_balance(correct_space);
⋮----
assert_eq!(
⋮----
assert_eq!(build_transaction_context(account).push(), Ok(()),);
⋮----
fn test_invalid_native_loader_index() {
⋮----
vec![(
⋮----
.configure_next_instruction_for_tests(
⋮----
vec![InstructionAccount::new(0, false, false)],
vec![],
⋮----
let instruction_context = transaction_context.get_next_instruction_context().unwrap();
let result = instruction_context.get_index_of_program_account_in_transaction();
assert_eq!(result, Err(InstructionError::MissingAccount));
let result = instruction_context.get_program_key();
⋮----
let result = instruction_context.get_program_owner();
assert_eq!(result.err(), Some(InstructionError::MissingAccount));

================
File: transaction-context/src/transaction_accounts.rs
================
use qualifier_attr::qualifiers;
⋮----
struct AccountSharedFields {
⋮----
struct AccountPrivateFields {
⋮----
impl AccountPrivateFields {
fn payload_len(&self) -> usize {
self.payload.len()
⋮----
pub struct TransactionAccountView<'a> {
⋮----
impl ReadableAccount for TransactionAccountView<'_> {
fn lamports(&self) -> u64 {
⋮----
fn data(&self) -> &[u8] {
self.private_fields.payload.as_slice()
⋮----
fn owner(&self) -> &Pubkey {
⋮----
fn executable(&self) -> bool {
⋮----
fn rent_epoch(&self) -> u64 {
⋮----
fn eq(&self, other: &AccountSharedData) -> bool {
other.lamports() == self.lamports()
&& other.data() == self.data()
&& other.owner() == self.owner()
&& other.executable() == self.executable()
&& other.rent_epoch() == self.rent_epoch()
⋮----
pub struct TransactionAccountViewMut<'a> {
⋮----
fn data_mut(&mut self) -> &mut Vec<u8> {
⋮----
pub(crate) fn resize(&mut self, new_len: usize, value: u8) {
self.data_mut().resize(new_len, value);
// SAFETY: We are synchronizing the lengths.
⋮----
self.abi_account.payload.set_len(new_len as u64);
⋮----
pub(crate) fn set_data_from_slice(&mut self, new_data: &[u8]) {
// If the buffer isn't shared, we're going to memcpy in place.
⋮----
self.private_fields.payload = Arc::new(new_data.to_vec());
⋮----
self.abi_account.payload.set_len(new_data.len() as u64);
⋮----
let new_len = new_data.len();
data.reserve(new_len.saturating_sub(data.len()));
⋮----
data.set_len(0);
ptr::copy_nonoverlapping(new_data.as_ptr(), data.as_mut_ptr(), new_len);
data.set_len(new_len);
⋮----
pub(crate) fn extend_from_slice(&mut self, data: &[u8]) {
self.data_mut().extend_from_slice(data);
⋮----
.set_len(self.private_fields.payload_len() as u64);
⋮----
pub(crate) fn reserve(&mut self, additional: usize) {
⋮----
data.reserve(additional)
⋮----
Vec::with_capacity(self.private_fields.payload_len().saturating_add(additional));
data.extend_from_slice(self.private_fields.payload.as_slice());
⋮----
pub(crate) fn is_shared(&self) -> bool {
⋮----
impl ReadableAccount for TransactionAccountViewMut<'_> {
⋮----
impl WritableAccount for TransactionAccountViewMut<'_> {
fn set_lamports(&mut self, lamports: u64) {
⋮----
fn data_as_mut_slice(&mut self) -> &mut [u8] {
Arc::make_mut(&mut self.private_fields.payload).as_mut_slice()
⋮----
fn set_owner(&mut self, owner: Pubkey) {
⋮----
fn copy_into_owner_from_slice(&mut self, source: &[u8]) {
self.abi_account.owner.as_mut().copy_from_slice(source);
⋮----
fn set_executable(&mut self, executable: bool) {
⋮----
fn set_rent_epoch(&mut self, epoch: u64) {
⋮----
fn create(
⋮----
panic!("It is not possible to create a TransactionAccountMutView");
⋮----
pub type KeyedAccountSharedData = (Pubkey, AccountSharedData);
pub(crate) type DeconstructedTransactionAccounts =
⋮----
pub struct TransactionAccounts {
⋮----
impl TransactionAccounts {
⋮----
pub(crate) fn new(accounts: Vec<KeyedAccountSharedData>) -> TransactionAccounts {
let touched_flags = vec![Cell::new(false); accounts.len()].into_boxed_slice();
let borrow_counters = vec![BorrowCounter::default(); accounts.len()].into_boxed_slice();
⋮----
.into_iter()
.enumerate()
.map(|(idx, item)| {
⋮----
owner: *item.1.owner(),
lamports: item.1.lamports(),
⋮----
.saturating_add(GUEST_REGION_SIZE.saturating_mul(idx as u64)),
item.1.data().len() as u64,
⋮----
rent_epoch: item.1.rent_epoch(),
executable: item.1.executable(),
payload: item.1.data_clone(),
⋮----
shared_account_fields: UnsafeCell::new(shared_accounts.into_boxed_slice()),
private_account_fields: UnsafeCell::new(private_fields.into_boxed_slice()),
⋮----
pub(crate) fn len(&self) -> usize {
⋮----
(&(*self.shared_account_fields.get())).len()
⋮----
pub fn touch(&self, index: IndexOfAccount) -> Result<(), InstructionError> {
⋮----
.get(index as usize)
.ok_or(InstructionError::MissingAccount)?
.set(true);
Ok(())
⋮----
pub(crate) fn update_accounts_resize_delta(
⋮----
let accounts_resize_delta = self.resize_delta.get();
self.resize_delta.set(
accounts_resize_delta.saturating_add((new_len as i64).saturating_sub(old_len as i64)),
⋮----
pub(crate) fn can_data_be_resized(
⋮----
return Err(InstructionError::InvalidRealloc);
⋮----
let length_delta = (new_len as i64).saturating_sub(old_len as i64);
if self.resize_delta.get().saturating_add(length_delta)
⋮----
return Err(InstructionError::MaxAccountsDataAllocationsExceeded);
⋮----
pub(crate) fn try_borrow_mut(
⋮----
.ok_or(InstructionError::MissingAccount)?;
borrow_counter.try_borrow_mut()?;
// See previous RUST UPGRADE NOTE in this file
⋮----
// SAFETY: The borrow counter guarantees this is the only mutable borrow of this account.
// The unwrap is safe because accounts.len() == borrow_counters.len(), so the missing
// account error should have been returned above.
⋮----
(&mut (*self.shared_account_fields.get()))
.get_mut(index as usize)
.unwrap()
⋮----
(&mut (*self.private_account_fields.get()))
⋮----
Ok(AccountRefMut {
⋮----
pub fn try_borrow(&self, index: IndexOfAccount) -> Result<AccountRef<'_>, InstructionError> {
⋮----
borrow_counter.try_borrow()?;
⋮----
(&(*self.shared_account_fields.get()))
⋮----
(&(*self.private_account_fields.get()))
⋮----
Ok(AccountRef {
⋮----
pub(crate) fn add_lamports_delta(&self, balance: i128) -> Result<(), InstructionError> {
let delta = self.lamports_delta.get();
self.lamports_delta.set(
⋮----
.checked_add(balance)
.ok_or(InstructionError::ArithmeticOverflow)?,
⋮----
pub(crate) fn get_lamports_delta(&self) -> i128 {
self.lamports_delta.get()
⋮----
fn deconstruct_into_keyed_account_shared_data(&mut self) -> Vec<KeyedAccountSharedData> {
⋮----
.get_mut()
⋮----
.zip(&mut *self.private_account_fields.get_mut())
.map(|(shared_fields, private_fields)| {
⋮----
private_fields.payload.clone(),
⋮----
.collect()
⋮----
pub(crate) fn deconstruct_into_account_shared_data(&mut self) -> Vec<AccountSharedData> {
⋮----
pub(crate) fn take(mut self) -> DeconstructedTransactionAccounts {
let shared_data = self.deconstruct_into_keyed_account_shared_data();
⋮----
pub fn resize_delta(&self) -> i64 {
self.resize_delta.get()
⋮----
pub(crate) fn account_key(&self, index: IndexOfAccount) -> Option<&Pubkey> {
⋮----
.map(|acc| &acc.key)
⋮----
pub(crate) fn account_keys_iter(&self) -> impl Iterator<Item = &Pubkey> {
⋮----
(*self.shared_account_fields.get())
.iter()
.map(|item| &item.key)
⋮----
struct BorrowCounter {
⋮----
impl BorrowCounter {
⋮----
fn is_writing(&self) -> bool {
self.counter.get() < 0
⋮----
fn is_reading(&self) -> bool {
self.counter.get() > 0
⋮----
fn try_borrow(&self) -> Result<(), InstructionError> {
if self.is_writing() {
return Err(InstructionError::AccountBorrowFailed);
⋮----
if let Some(counter) = self.counter.get().checked_add(1) {
self.counter.set(counter);
return Ok(());
⋮----
Err(InstructionError::AccountBorrowFailed)
⋮----
fn try_borrow_mut(&self) -> Result<(), InstructionError> {
if self.is_writing() || self.is_reading() {
⋮----
self.counter.set(self.counter.get().saturating_sub(1));
⋮----
fn release_borrow(&self) {
⋮----
fn release_borrow_mut(&self) {
self.counter.set(self.counter.get().saturating_add(1));
⋮----
pub struct AccountRef<'a> {
⋮----
impl Drop for AccountRef<'_> {
fn drop(&mut self) {
self.borrow_counter.release_borrow();
⋮----
impl<'a> Deref for AccountRef<'a> {
type Target = TransactionAccountView<'a>;
fn deref(&self) -> &Self::Target {
⋮----
pub struct AccountRefMut<'a> {
⋮----
impl Drop for AccountRefMut<'_> {
⋮----
.set_len(self.account.private_fields.payload_len() as u64);
⋮----
self.borrow_counter.release_borrow_mut();
⋮----
impl<'a> Deref for AccountRefMut<'a> {
type Target = TransactionAccountViewMut<'a>;
⋮----
impl DerefMut for AccountRefMut<'_> {
fn deref_mut(&mut self) -> &mut Self::Target {
⋮----
mod tests {
⋮----
fn test_missing_account() {
let accounts = vec![
⋮----
let res = tx_accounts.try_borrow(3);
assert_eq!(res.err(), Some(InstructionError::MissingAccount));
let res = tx_accounts.try_borrow_mut(3);
⋮----
fn test_invalid_borrow() {
⋮----
let acc_1 = tx_accounts.try_borrow(0);
assert!(acc_1.is_ok());
let acc_2 = tx_accounts.try_borrow(1);
assert!(acc_2.is_ok());
let acc_1_new = tx_accounts.try_borrow(0);
assert!(acc_1_new.is_ok());
assert_eq!(acc_1.unwrap().account, acc_1_new.unwrap().account);
⋮----
let acc_1 = tx_accounts.try_borrow_mut(0);
⋮----
let acc_2 = tx_accounts.try_borrow_mut(1);
⋮----
let acc_1_new = tx_accounts.try_borrow_mut(0);
assert_eq!(acc_1_new.err(), Some(InstructionError::AccountBorrowFailed));
⋮----
fn too_many_borrows() {
⋮----
let acc = tx_accounts.try_borrow(1);
⋮----
assert!(acc.is_ok());
borrows.push(acc.unwrap());
⋮----
assert_eq!(acc.err(), Some(InstructionError::AccountBorrowFailed));

================
File: transaction-context/src/vm_slice.rs
================
use std::marker::PhantomData;
⋮----
pub struct VmSlice<T> {
⋮----
pub fn new(ptr: u64, len: u64) -> Self {
⋮----
pub fn ptr(&self) -> u64 {
⋮----
pub fn len(&self) -> u64 {
⋮----
pub fn is_empty(&self) -> bool {
⋮----
pub unsafe fn set_len(&mut self, new_len: u64) {

================
File: transaction-context/Cargo.toml
================
[package]
name = "solana-transaction-context"
description = "Solana data shared between program runtime and built-in programs as well as SBF programs."
documentation = "https://docs.rs/solana-transaction-context"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]
all-features = true
rustdoc-args = ["--cfg=docsrs"]

[features]
agave-unstable-api = []
bincode = ["dep:bincode", "serde", "solana-account/bincode"]
dev-context-only-utils = ["bincode", "solana-account/dev-context-only-utils", "dep:qualifier_attr"]
serde = ["serde/derive"]

[dependencies]
qualifier_attr = { workspace = true, optional = true }
serde = { workspace = true, optional = true }
solana-account = { workspace = true }
solana-instruction = { workspace = true, features = ["std"] }
solana-instructions-sysvar = { workspace = true }
solana-pubkey = { workspace = true }
solana-sbpf = { workspace = true }

[target.'cfg(not(target_os = "solana"))'.dependencies]
bincode = { workspace = true, optional = true }
solana-rent = { workspace = true }
solana-sdk-ids = { workspace = true }
solana-signature = { workspace = true, optional = true }

[dev-dependencies]
solana-account-info = { workspace = true }
solana-program-entrypoint = { workspace = true }
solana-system-interface = { workspace = true }
solana-transaction-context = { path = ".", features = [
    "agave-unstable-api",
    "dev-context-only-utils",
] }
static_assertions = { workspace = true }

[lints]
workspace = true

================
File: transaction-dos/src/main.rs
================
pub fn airdrop_lamports(
⋮----
let starting_balance = client.get_balance(&id.pubkey()).unwrap_or(0);
info!("starting balance {starting_balance}");
⋮----
info!(
⋮----
let blockhash = client.get_latest_blockhash().unwrap();
match request_airdrop_transaction(faucet_addr, &id.pubkey(), airdrop_amount, blockhash) {
⋮----
let result = client.send_and_confirm_transaction(&transaction);
if result.is_ok() {
⋮----
panic!(
⋮----
let current_balance = client.get_balance(&id.pubkey()).unwrap_or_else(|e| {
panic!("airdrop error {e}");
⋮----
info!("current balance {current_balance}...");
⋮----
fn make_create_message(
⋮----
let instructions = vec![system_instruction::create_account(
⋮----
Message::new(&instructions, Some(&keypair.pubkey()))
⋮----
fn make_dos_message(
⋮----
.map(|_| {
let data = [num_program_iterations, rng().random_range(0..255)];
Instruction::new_with_bytes(program_id, &data, account_metas.to_vec())
⋮----
.collect();
⋮----
async fn run_transactions_dos(
⋮----
assert!(num_instructions > 0);
⋮----
info!("Targeting {entrypoint_addr}");
let space = maybe_space.unwrap_or(1000);
let min_balance = maybe_lamports.unwrap_or_else(|| {
⋮----
.get_minimum_balance_for_rent_exemption(space as usize)
.expect("min balance")
⋮----
assert!(min_balance > 0);
let account_groups = maybe_account_groups.unwrap_or(1);
assert!(account_keypairs.len().is_multiple_of(account_groups));
let account_group_size = account_keypairs.len() / account_groups;
let program_account = client.get_account(&program_id);
let mut blockhash = client.get_latest_blockhash().expect("blockhash");
⋮----
vec![AccountMeta::new(Pubkey::new_unique(), true)],
⋮----
.get_fee_for_message(&message)
.expect("get_fee_for_message");
let account_space_fees = min_balance * account_keypairs.len() as u64;
let program_fees = if program_account.is_ok() {
⋮----
client.get_minimum_balance_for_rent_exemption(2400).unwrap()
⋮----
account_keypairs.len() as u64 * fee + iterations as u64 * batch_size as u64 * fee;
⋮----
if program_account.is_err() {
⋮----
.expect("If the program doesn't exist, need to provide program keypair to deploy");
⋮----
config.signers = vec![payer_keypairs[0], &program_keypair];
⋮----
program_location: Some(program_location),
⋮----
program_signer_index: Some(1),
⋮----
process_command(&config).await.expect("deploy didn't pass");
⋮----
info!("Found program account. Skipping deploy..");
assert!(program_account.unwrap().executable);
⋮----
.iter()
.map(|keypair| client.get_balance(&keypair.pubkey()).unwrap_or(0))
⋮----
info!("Starting balance(s): {balances:?}");
⋮----
.map(|kp| AccountMeta::new(kp.pubkey(), false))
⋮----
if latest_blockhash.elapsed().as_secs() > 10 {
blockhash = client.get_latest_blockhash().expect("blockhash");
⋮----
for (i, balance) in balances.iter_mut().enumerate() {
if *balance < lamports || last_balance.elapsed().as_secs() > 2 {
if let Ok(b) = client.get_balance(&payer_keypairs[i].pubkey()) {
⋮----
info!("Balance {balance} is less than needed: {lamports}, doing aidrop...");
if !airdrop_lamports(
⋮----
warn!("failed airdrop, exiting");
⋮----
let mut accounts_to_create = vec![];
⋮----
if let Ok(account) = client.get_account(&kp.pubkey()) {
if account.data.len() as u64 != space {
⋮----
accounts_to_create.push(kp);
⋮----
if !accounts_to_create.is_empty() {
info!("creating accounts {}", accounts_to_create.len());
⋮----
.par_iter()
.enumerate()
.map(|(i, keypair)| {
let message = make_create_message(
payer_keypairs[i % payer_keypairs.len()],
⋮----
vec![payer_keypairs[i % payer_keypairs.len()], keypair];
⋮----
let mut new_ids = executor.push_transactions(txs);
warn!("sent account creation {}", new_ids.len());
⋮----
let cleared = executor.drain_cleared();
new_ids.retain(|x| !cleared.contains(x));
if new_ids.is_empty() {
⋮----
if start.elapsed().as_secs() > 60 {
info!("Some creation failed");
⋮----
sleep(Duration::from_millis(500));
⋮----
let account = client.get_account(&kp.pubkey()).unwrap();
info!("{} => {:?}", kp.pubkey(), account);
assert!(account.data.len() as u64 == space);
⋮----
info!("All accounts created.");
⋮----
info!("creating new batch of size: {batch_size}");
let chunk_size = batch_size / payer_keypairs.len();
for (i, keypair) in payer_keypairs.iter().enumerate() {
⋮----
.into_par_iter()
.map(|x| {
let message = make_dos_message(
⋮----
let signers: Vec<&Keypair> = vec![keypair];
⋮----
if !tested_size.load(Ordering::Relaxed) {
let ser_size = bincode::serialized_size(&tx).unwrap();
assert!(ser_size < PACKET_DATA_SIZE as u64, "{}", ser_size);
tested_size.store(true, Ordering::Relaxed);
⋮----
balances[i] = balances[i].saturating_sub(fee * txs.len() as u64);
info!("txs: {}", txs.len());
let new_ids = executor.push_transactions(txs);
info!("ids: {}", new_ids.len());
tx_sent_count += new_ids.len();
total_dos_messages_sent += num_instructions * new_ids.len();
⋮----
let _ = executor.drain_cleared();
⋮----
if last_log.elapsed().as_secs() > 3 {
⋮----
if executor.num_outstanding() >= batch_size {
sleep(Duration::from_millis(batch_sleep_ms));
⋮----
executor.close();
⋮----
async fn main() {
⋮----
let matches = App::new(crate_name!())
.about(crate_description!())
.version(solana_version::version!())
.arg(
⋮----
.long("entrypoint")
.takes_value(true)
.value_name("HOST:PORT")
.help("RPC entrypoint address. Usually <ip>:8899"),
⋮----
.long("faucet")
⋮----
.help("Faucet entrypoint address. Usually <ip>:9900"),
⋮----
.long("space")
⋮----
.value_name("BYTES")
.help("Size of accounts to create"),
⋮----
.long("lamports")
⋮----
.value_name("LAMPORTS")
.help("How many lamports to fund each account"),
⋮----
.long("payer")
⋮----
.multiple(true)
.value_name("FILE")
.help("One or more payer keypairs to fund account creation."),
⋮----
.long("account")
⋮----
.help(
⋮----
.long("account_groups")
⋮----
.value_name("NUM")
.help("Number of groups of accounts to split the accounts into"),
⋮----
.long("batch-size")
⋮----
.help("Number of transactions to send per batch"),
⋮----
.long("num-instructions")
⋮----
.help("Number of accounts to create on each transaction"),
⋮----
.long("num-program-iterations")
⋮----
.help("Number of iterations in the smart contract"),
⋮----
.long("iterations")
⋮----
.help("Number of iterations to make"),
⋮----
.long("batch-sleep-ms")
⋮----
.long("check-gossip")
.help("Just use entrypoint address directly"),
⋮----
.long("shred-version")
⋮----
.value_name("VERSION")
.requires("check_gossip")
.help("The shred version to use for node discovery"),
⋮----
.long("just-calculate-fees")
.help("Just print the necessary fees and exit"),
⋮----
.long("program-id")
⋮----
.required(true)
.help("program_id address to initialize account"),
⋮----
.get_matches();
let skip_gossip = !matches.is_present("check_gossip");
⋮----
if let Some(addr) = matches.value_of("entrypoint") {
entrypoint_addr = solana_net_utils::parse_host_port(addr).unwrap_or_else(|e| {
eprintln!("failed to parse entrypoint address: {e}");
exit(1)
⋮----
if let Ok(version) = value_t!(matches, "shred_version", u16) {
Some(version)
⋮----
Some(
solana_net_utils::get_cluster_shred_version(&entrypoint_addr).unwrap_or_else(
⋮----
eprintln!("Failed to get shred version: {err}");
exit(1);
⋮----
let just_calculate_fees = matches.is_present("just_calculate_fees");
⋮----
if let Some(addr) = matches.value_of("faucet_addr") {
faucet_addr = solana_net_utils::parse_host_port(addr).unwrap_or_else(|e| {
⋮----
let space = value_t!(matches, "space", u64).ok();
let lamports = value_t!(matches, "lamports", u64).ok();
let batch_size = value_t!(matches, "batch_size", usize).unwrap_or(4);
let iterations = value_t!(matches, "iterations", usize).unwrap_or(10);
let num_program_iterations = value_t!(matches, "num_program_iterations", usize).unwrap_or(10);
let num_instructions = value_t!(matches, "num_instructions", usize).unwrap_or(1);
⋮----
eprintln!("bad num_instructions: {num_instructions}");
⋮----
let batch_sleep_ms = value_t!(matches, "batch_sleep_ms", u64).unwrap_or(500);
let program_id = pubkey_of(&matches, "program_id").unwrap();
let payer_keypairs: Vec<_> = values_t_or_exit!(matches, "payer", String)
⋮----
.map(|keypair_string| {
read_keypair_file(keypair_string)
.unwrap_or_else(|_| panic!("bad keypair {keypair_string:?}"))
⋮----
let account_keypairs: Vec<_> = values_t_or_exit!(matches, "account", String)
⋮----
let account_groups = value_t!(matches, "account_groups", usize).ok();
let payer_keypair_refs: Vec<&Keypair> = payer_keypairs.iter().collect();
let account_keypair_refs: Vec<&Keypair> = account_keypairs.iter().collect();
⋮----
info!("Finding cluster entry: {entrypoint_addr:?}");
let (gossip_nodes, _validators) = discover_peers(
⋮----
&vec![entrypoint_addr],
⋮----
shred_version.unwrap(),
⋮----
.unwrap_or_else(|err| {
eprintln!("Failed to discover {entrypoint_addr} node: {err:?}");
⋮----
info!("done found {} nodes", gossip_nodes.len());
gossip_nodes[0].rpc().unwrap()
⋮----
info!("Using {entrypoint_addr:?} as the RPC address");
⋮----
run_transactions_dos(
⋮----
pub mod test {
⋮----
fn test_tx_size() {
⋮----
.map(|_| AccountMeta::new(Pubkey::new_unique(), false))
⋮----
let signers: Vec<&Keypair> = vec![&keypair];
⋮----
let size = bincode::serialized_size(&tx).unwrap();
info!("size:{size}");
assert!(size < PACKET_DATA_SIZE as u64);
⋮----
async fn test_transaction_dos() {
⋮----
node_stakes: vec![100; num_nodes],
validator_configs: make_identical_validator_configs(&validator_config, num_nodes),
⋮----
let maybe_space = Some(10_000_000);
⋮----
let maybe_lamports = Some(10);
let maybe_account_groups = Some(1);
⋮----
let account_keypairs: Vec<_> = (0..num_accounts).map(|_| Keypair::new()).collect();
let account_keypair_refs: Vec<_> = account_keypairs.iter().collect();
⋮----
cluster.entry_point_info.rpc().unwrap(),
⋮----
program_keypair.pubkey(),
Some((
⋮----
format!(
⋮----
start.stop();
info!("{start}");

================
File: transaction-dos/.gitignore
================
/target/
/farf/

================
File: transaction-dos/Cargo.toml
================
[package]
name = "solana-transaction-dos"
publish = false
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
agave-unstable-api = []
dev-context-only-utils = []

[dependencies]
agave-logger = { workspace = true }
bincode = { workspace = true }
clap = { workspace = true }
log = { workspace = true }
rand = { workspace = true }
rayon = { workspace = true }
solana-clap-utils = { workspace = true }
solana-cli = { workspace = true }
solana-client = { workspace = true }
solana-commitment-config = { workspace = true }
solana-faucet = { workspace = true }
solana-gossip = { workspace = true }
solana-instruction = { workspace = true }
solana-keypair = { workspace = true }
solana-measure = { workspace = true }
solana-message = { workspace = true }
solana-net-utils = { workspace = true }
solana-packet = { workspace = true }
solana-pubkey = { workspace = true }
solana-rpc-client = { workspace = true }
solana-runtime = { workspace = true }
solana-signer = { workspace = true }
solana-system-interface = { workspace = true }
solana-transaction = { workspace = true }
solana-transaction-status = { workspace = true }
solana-version = { workspace = true }
tokio = { workspace = true }

[dev-dependencies]
solana-core = { workspace = true, features = ["dev-context-only-utils"] }
solana-hash = { workspace = true }
solana-local-cluster = { workspace = true, features = ["dev-context-only-utils"] }
solana-poh-config = { workspace = true }
solana-runtime = { workspace = true, features = ["dev-context-only-utils"] }

================
File: transaction-metrics-tracker/src/lib.rs
================
std::sync::LazyLock::new(|| rand::rng().random_range(0..4096));
pub fn should_track_transaction(signature: &[u8; SIGNATURE_BYTES]) -> bool {
⋮----
trace!("Matching txn: {match_portion:016b} {:016b}", *TXN_MASK);
⋮----
pub fn signature_if_should_track_packet(
⋮----
let signature = get_signature_from_packet(packet)?;
Ok(should_track_transaction(signature).then_some(signature))
⋮----
pub fn get_signature_from_packet(
⋮----
.data(..)
.and_then(|bytes| decode_shortu16_len(bytes).ok())
.ok_or(PacketError::InvalidShortVec)?;
⋮----
return Err(PacketError::InvalidSignatureLen);
⋮----
.data(sig_start..sig_start.saturating_add(SIGNATURE_BYTES))
.ok_or(PacketError::InvalidSignatureLen)?;
⋮----
.try_into()
.map_err(|_| PacketError::InvalidSignatureLen)?;
Ok(signature)
⋮----
mod tests {
⋮----
fn test_get_signature_from_packet() {
⋮----
let sig = get_signature_from_packet(&packet);
assert_eq!(sig, Err(PacketError::InvalidShortVec));
⋮----
let packet = BytesPacket::from_data(None, tx.clone()).unwrap();
⋮----
assert!(sig.is_ok());
let mut data = bincode::serialize(&tx).unwrap();
⋮----
assert_eq!(sig, Err(PacketError::InvalidSignatureLen));
⋮----
fn test_should_track_transaction() {
⋮----
let track = should_track_transaction(&sig);
assert_eq!(track, *TXN_MASK == 0);
⋮----
let random_number: u8 = rng.random_range(0..=15);
⋮----
assert!(track);
⋮----
fn test_signature_if_should_track_packet() {
⋮----
let sig = signature_if_should_track_packet(&packet);
⋮----
let packet = BytesPacket::from_data(None, tx).unwrap();
⋮----
assert_eq!(Ok(None), sig);
⋮----
let sig2 = signature_if_should_track_packet(&packet);
⋮----
assert!(sig.is_some());
⋮----
Err(_) => panic!("Expected to get a matching signature!"),

================
File: transaction-metrics-tracker/Cargo.toml
================
[package]
name = "solana-transaction-metrics-tracker"
description = "Solana transaction metrics tracker"
documentation = "https://docs.rs/solana-transaction-metrics-tracker"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
agave-unstable-api = []

[dependencies]
base64 = { workspace = true }
bincode = { workspace = true }
# Update this borsh dependency to the workspace version once
log = { workspace = true }
rand = { workspace = true }
solana-packet = { workspace = true }
solana-perf = { workspace = true }
solana-short-vec = { workspace = true }
solana-signature = { workspace = true }

[dev-dependencies]
solana-hash = { workspace = true }
solana-keypair = { workspace = true }
solana-packet = { workspace = true, features = ["dev-context-only-utils"] }
solana-perf = { workspace = true, features = ["dev-context-only-utils"] }
solana-pubkey = { workspace = true, features = ["rand"] }
solana-system-transaction = { workspace = true }

================
File: transaction-status/benches/extract_memos.rs
================
fn bench_extract_memos(b: &mut Bencher) {
let mut account_keys: Vec<Pubkey> = (0..64).map(|_| Pubkey::new_unique()).collect();
⋮----
.map(|i| CompiledInstruction {
⋮----
accounts: vec![],
data: memo.as_bytes().to_vec(),
⋮----
.collect();
⋮----
b.iter(|| message.extract_memos());
⋮----
benchmark_group!(benches, bench_extract_memos);
benchmark_main!(benches);

================
File: transaction-status/src/parse_token/extension/confidential_mint_burn.rs
================
pub(in crate::parse_token) fn parse_confidential_mint_burn_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let value = json!({
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeConfidentialMintBurnMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
instruction_type: "updateConfidentialMintBurnDecryptableSupply".to_string(),
⋮----
check_num_token_accounts(account_indexes, 3)?;
⋮----
map.insert(
"proofAccount".to_string(),
json!(account_keys[account_indexes[1] as usize].to_string()),
⋮----
"instructionsSysvar".to_string(),
⋮----
instruction_type: "rotateConfidentialMintBurnSupplyElGamalPubkey".to_string(),
⋮----
let mint_data: MintInstructionData = *decode_instruction_data(instruction_data)
.map_err(|_| {
⋮----
if offset < account_indexes.len() - 1
⋮----
json!(account_keys[account_indexes[offset] as usize].to_string()),
⋮----
if offset < account_indexes.len() - 1 {
⋮----
label.to_string(),
⋮----
instruction_type: "confidentialMint".to_string(),
⋮----
let burn_data: BurnInstructionData = *decode_instruction_data(instruction_data)
⋮----
instruction_type: "confidentialBurn".to_string(),
⋮----
instruction_type: "applyPendingBurn".to_string(),
⋮----
mod test {
⋮----
fn check_no_panic(mut instruction: Instruction) {
⋮----
instruction.accounts = vec![account_meta.clone(); i];
let message = Message::new(&[instruction.clone()], None);
⋮----
let _ = parse_token(
⋮----
fn test_initialize() {
let instruction = initialize_mint(
⋮----
.unwrap();
check_no_panic(instruction);
⋮----
fn test_update() {
let instruction = update_decryptable_supply(
⋮----
fn test_rotate() {
⋮----
NonZero::new(1).unwrap(),
⋮----
let instructions = rotate_supply_elgamal_pubkey(
⋮----
check_no_panic(instructions[0].clone());
⋮----
fn test_mint() {
⋮----
NonZero::new(2).unwrap(),
⋮----
NonZero::new(3).unwrap(),
⋮----
let instructions = confidential_mint_with_split_proofs(
⋮----
fn test_burn() {
⋮----
let instructions = confidential_burn_with_split_proofs(

================
File: transaction-status/src/parse_token/extension/confidential_transfer_fee.rs
================
pub(in crate::parse_token) fn parse_confidential_transfer_fee_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("authority".to_string(), json!(authority.to_string()));
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeConfidentialTransferFeeConfig".to_string(),
⋮----
check_num_token_accounts(account_indexes, 4)?;
⋮----
map.insert(
"proofContextStateAccount".to_string(),
json!(account_keys[account_indexes[2] as usize].to_string()),
⋮----
"instructionsSysvar".to_string(),
⋮----
if account_indexes.len() > 4 {
⋮----
"recordAccount".to_string(),
json!(account_keys[account_indexes[3] as usize].to_string()),
⋮----
parse_signers(
⋮----
instruction_type: "withdrawWithheldConfidentialTransferTokensFromMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 4 + num_token_accounts as usize)?;
⋮----
.len()
.saturating_sub(num_token_accounts as usize);
⋮----
"proofAccount".to_string(),
⋮----
let mut source_accounts: Vec<String> = vec![];
for i in account_indexes[first_source_account_index..].iter() {
source_accounts.push(account_keys[*i as usize].to_string());
⋮----
map.insert("sourceAccounts".to_string(), json!(source_accounts));
⋮----
.to_string(),
⋮----
for i in account_indexes.iter().skip(1) {
⋮----
instruction_type: "harvestWithheldConfidentialTransferTokensToMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
instruction_type: "enableConfidentialTransferFeeHarvestToMint".to_string(),
⋮----
instruction_type: "disableConfidentialTransferFeeHarvestToMint".to_string(),
⋮----
mod test {
⋮----
fn check_no_panic(mut instruction: Instruction) {
⋮----
instruction.accounts = vec![account_meta.clone(); i];
let message = Message::new(&[instruction.clone()], None);
⋮----
let _ = parse_token(
⋮----
fn test_withdraw_from_accounts() {
⋮----
NonZero::new(1).unwrap(),
⋮----
let instruction = inner_withdraw_withheld_tokens_from_accounts(
⋮----
.unwrap();
check_no_panic(instruction);
⋮----
fn test_withdraw_from_mint() {
⋮----
let instruction = inner_withdraw_withheld_tokens_from_mint(

================
File: transaction-status/src/parse_token/extension/confidential_transfer.rs
================
pub(in crate::parse_token) fn parse_confidential_transfer_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("authority".to_string(), json!(authority.to_string()));
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeConfidentialTransferMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
let update_mint_data: UpdateMintData = *decode_instruction_data(instruction_data)
.map_err(|_| {
⋮----
let value = json!({
⋮----
instruction_type: "updateConfidentialTransferMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 4)?;
⋮----
.into();
⋮----
map.insert(
"proofContextStateAccount".to_string(),
json!(account_keys[account_indexes[2] as usize].to_string()),
⋮----
"instructionsSysvar".to_string(),
⋮----
if account_indexes.len() > 4 {
⋮----
"recordAccount".to_string(),
json!(account_keys[account_indexes[3] as usize].to_string()),
⋮----
parse_signers(
⋮----
instruction_type: "configureConfidentialTransferAccount".to_string(),
⋮----
check_num_token_accounts(account_indexes, 3)?;
⋮----
instruction_type: "approveConfidentialTransferAccount".to_string(),
info: json!({
⋮----
json!(account_keys[account_indexes[1] as usize].to_string()),
⋮----
if account_indexes.len() > 3 {
⋮----
instruction_type: "emptyConfidentialTransferAccount".to_string(),
⋮----
let deposit_data: DepositInstructionData = *decode_instruction_data(instruction_data)
⋮----
let amount: u64 = deposit_data.amount.into();
⋮----
instruction_type: "depositConfidentialTransfer".to_string(),
⋮----
check_num_token_accounts(account_indexes, 5)?;
⋮----
let amount: u64 = withdrawal_data.amount.into();
⋮----
if offset < account_indexes.len() - 1
⋮----
json!(account_keys[account_indexes[offset] as usize].to_string()),
⋮----
if offset < account_indexes.len() - 1 {
⋮----
label.to_string(),
⋮----
instruction_type: "withdrawConfidentialTransfer".to_string(),
⋮----
let transfer_data: TransferInstructionData = *decode_instruction_data(instruction_data)
⋮----
instruction_type: "confidentialTransfer".to_string(),
⋮----
instruction_type: "confidentialTransferWithFee".to_string(),
⋮----
instruction_type: "applyPendingConfidentialTransferBalance".to_string(),
⋮----
instruction_type: "enableConfidentialTransferConfidentialCredits".to_string(),
⋮----
instruction_type: "disableConfidentialTransferConfidentialCredits".to_string(),
⋮----
instruction_type: "enableConfidentialTransferNonConfidentialCredits".to_string(),
⋮----
instruction_type: "disableConfidentialTransferNonConfidentialCredits".to_string(),
⋮----
instruction_type: "configureConfidentialAccountWithRegistry".to_string(),
⋮----
mod test {
⋮----
fn check_no_panic(mut instruction: Instruction) {
⋮----
instruction.accounts = vec![account_meta.clone(); i];
let message = Message::new(&[instruction.clone()], None);
⋮----
let _ = parse_token(
⋮----
fn test_initialize() {
let instruction = initialize_mint(
⋮----
Some(Pubkey::new_unique()),
⋮----
.unwrap();
check_no_panic(instruction);
⋮----
fn test_approve() {
let instruction = approve_account(
⋮----
fn test_update() {
let instruction = update_mint(
⋮----
fn test_configure() {
⋮----
NonZero::new(1).unwrap(),
⋮----
let instruction = inner_configure_account(
⋮----
fn test_empty_account() {
⋮----
let instruction = inner_empty_account(
⋮----
fn test_withdraw() {
⋮----
NonZero::new(3).unwrap(),
⋮----
let instruction = inner_withdraw(
⋮----
fn test_transfer() {
⋮----
NonZero::new(2).unwrap(),
⋮----
let instruction = inner_transfer(
⋮----
fn test_transfer_with_fee() {
⋮----
NonZero::new(4).unwrap(),
⋮----
NonZero::new(5).unwrap(),
⋮----
let instruction = inner_transfer_with_fee(

================
File: transaction-status/src/parse_token/extension/cpi_guard.rs
================
pub(in crate::parse_token) fn parse_cpi_guard_instruction(
⋮----
check_num_token_accounts(account_indexes, 2)?;
let instruction_type_str = match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
Ok(ParsedInstructionEnum {
instruction_type: format!("{instruction_type_str}CpiGuard"),
⋮----
mod test {
⋮----
fn test_parse_cpi_guard_instruction() {
⋮----
let enable_cpi_guard_ix = enable_cpi_guard(
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
let enable_cpi_guard_ix = disable_cpi_guard(

================
File: transaction-status/src/parse_token/extension/default_account_state.rs
================
pub(in crate::parse_token) fn parse_default_account_state_instruction(
⋮----
let (default_account_state_instruction, account_state) = decode_instruction(instruction_data)
.map_err(|_| {
⋮----
check_num_token_accounts(account_indexes, 1)?;
Ok(ParsedInstructionEnum {
instruction_type: format!("initialize{instruction_type}"),
info: json!({
⋮----
check_num_token_accounts(account_indexes, 2)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
instruction_type: format!("update{instruction_type}"),
⋮----
mod test {
⋮----
fn test_parse_default_account_state_instruction() {
⋮----
let init_default_account_state_ix = initialize_default_account_state(
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
let update_default_account_state_ix = update_default_account_state(

================
File: transaction-status/src/parse_token/extension/group_member_pointer.rs
================
pub(in crate::parse_token) fn parse_group_member_pointer_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
} = *decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("authority".to_string(), json!(authority.to_string()));
⋮----
map.insert(
"memberAddress".to_string(),
json!(member_address.to_string()),
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeGroupMemberPointer".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
parse_signers(
⋮----
instruction_type: "updateGroupMemberPointer".to_string(),
⋮----
mod test {
⋮----
fn test_parse_group_member_pointer_instruction() {
⋮----
let init_ix = initialize(
⋮----
Some(authority),
Some(member_address),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
initialize(&spl_token_2022_interface::id(), &mint_pubkey, None, None).unwrap();
⋮----
let update_ix = update(

================
File: transaction-status/src/parse_token/extension/group_pointer.rs
================
pub(in crate::parse_token) fn parse_group_pointer_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
} = *decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("authority".to_string(), json!(authority.to_string()));
⋮----
map.insert("groupAddress".to_string(), json!(group_address.to_string()));
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeGroupPointer".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
parse_signers(
⋮----
instruction_type: "updateGroupPointer".to_string(),
⋮----
mod test {
⋮----
fn test_parse_group_pointer_instruction() {
⋮----
let init_ix = initialize(
⋮----
Some(authority),
Some(group_address),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
initialize(&spl_token_2022_interface::id(), &mint_pubkey, None, None).unwrap();
⋮----
let update_ix = update(

================
File: transaction-status/src/parse_token/extension/interest_bearing_mint.rs
================
pub(in crate::parse_token) fn parse_interest_bearing_mint_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
} = *decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let rate_authority: Option<Pubkey> = rate_authority.into();
Ok(ParsedInstructionEnum {
instruction_type: "initializeInterestBearingConfig".to_string(),
info: json!({
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
instruction_type: "updateInterestBearingConfigRate".to_string(),

================
File: transaction-status/src/parse_token/extension/memo_transfer.rs
================
pub(in crate::parse_token) fn parse_memo_transfer_instruction(
⋮----
check_num_token_accounts(account_indexes, 2)?;
let instruction_type_str = match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
Ok(ParsedInstructionEnum {
instruction_type: format!("{instruction_type_str}RequiredMemoTransfers"),
⋮----
mod test {
⋮----
fn test_parse_memo_transfer_instruction() {
⋮----
let enable_memo_transfers_ix = enable_required_transfer_memos(
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
let enable_memo_transfers_ix = disable_required_transfer_memos(

================
File: transaction-status/src/parse_token/extension/metadata_pointer.rs
================
pub(in crate::parse_token) fn parse_metadata_pointer_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
} = *decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("authority".to_string(), json!(authority.to_string()));
⋮----
map.insert(
"metadataAddress".to_string(),
json!(metadata_address.to_string()),
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeMetadataPointer".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
parse_signers(
⋮----
instruction_type: "updateMetadataPointer".to_string(),
⋮----
mod test {
⋮----
fn test_parse_metadata_pointer_instruction() {
⋮----
let init_ix = initialize(
⋮----
Some(authority),
Some(metadata_address),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
initialize(&spl_token_2022_interface::id(), &mint_pubkey, None, None).unwrap();
⋮----
let update_ix = update(

================
File: transaction-status/src/parse_token/extension/mint_close_authority.rs
================
pub(in crate::parse_token) fn parse_initialize_mint_close_authority_instruction(
⋮----
check_num_token_accounts(account_indexes, 1)?;
Ok(ParsedInstructionEnum {
instruction_type: "initializeMintCloseAuthority".to_string(),
info: json!({
⋮----
mod test {
⋮----
fn test_parse_initialize_mint_close_authority_instruction() {
⋮----
let mint_close_authority_ix = initialize_mint_close_authority(
⋮----
Some(&close_authority),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
initialize_mint_close_authority(&spl_token_2022_interface::id(), &mint_pubkey, None)

================
File: transaction-status/src/parse_token/extension/mod.rs
================
pub(super) mod confidential_mint_burn;
pub(super) mod confidential_transfer;
pub(super) mod confidential_transfer_fee;
pub(super) mod cpi_guard;
pub(super) mod default_account_state;
pub(super) mod group_member_pointer;
pub(super) mod group_pointer;
pub(super) mod interest_bearing_mint;
pub(super) mod memo_transfer;
pub(super) mod metadata_pointer;
pub(super) mod mint_close_authority;
pub(super) mod pausable;
pub(super) mod permanent_delegate;
pub(super) mod reallocate;
pub(super) mod scaled_ui_amount;
pub(super) mod token_group;
pub(super) mod token_metadata;
pub(super) mod transfer_fee;
pub(super) mod transfer_hook;

================
File: transaction-status/src/parse_token/extension/pausable.rs
================
pub(in crate::parse_token) fn parse_pausable_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
*decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let authority: Option<Pubkey> = authority.into();
Ok(ParsedInstructionEnum {
instruction_type: "initializePausableConfig".to_string(),
info: json!({
⋮----
check_num_token_accounts(account_indexes, 2)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
instruction_type: "pause".to_string(),
⋮----
instruction_type: "resume".to_string(),

================
File: transaction-status/src/parse_token/extension/permanent_delegate.rs
================
pub(in crate::parse_token) fn parse_initialize_permanent_delegate_instruction(
⋮----
check_num_token_accounts(account_indexes, 1)?;
Ok(ParsedInstructionEnum {
instruction_type: "initializePermanentDelegate".to_string(),
info: json!({
⋮----
mod test {
⋮----
fn test_parse_initialize_permanent_delegate_instruction() {
⋮----
initialize_permanent_delegate(&spl_token_2022_interface::id(), &mint_pubkey, &delegate)
.unwrap();
⋮----
assert_eq!(

================
File: transaction-status/src/parse_token/extension/reallocate.rs
================
pub(in crate::parse_token) fn parse_reallocate_instruction(
⋮----
check_num_token_accounts(account_indexes, 4)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "reallocate".to_string(),
⋮----
mod test {
⋮----
fn test_parse_reallocate_instruction() {
⋮----
let extension_types = vec![
⋮----
let reallocate_ix = reallocate(
⋮----
.unwrap();
⋮----
assert_eq!(

================
File: transaction-status/src/parse_token/extension/scaled_ui_amount.rs
================
pub(in crate::parse_token) fn parse_scaled_ui_amount_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
} = *decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let authority: Option<Pubkey> = authority.into();
Ok(ParsedInstructionEnum {
instruction_type: "initializeScaledUiAmountConfig".to_string(),
info: json!({
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
parse_signers(
⋮----
instruction_type: "updateMultiplier".to_string(),

================
File: transaction-status/src/parse_token/extension/token_group.rs
================
pub(in crate::parse_token) fn parse_token_group_instruction(
⋮----
check_num_token_accounts(account_indexes, 3)?;
⋮----
let value = json!({
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeTokenGroup".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
instruction_type: "updateTokenGroupMaxSize".to_string(),
⋮----
instruction_type: "updateTokenGroupAuthority".to_string(),
⋮----
check_num_token_accounts(account_indexes, 5)?;
⋮----
instruction_type: "initializeTokenGroupMember".to_string(),
⋮----
mod test {
⋮----
fn test_parse_token_group_instruction() {
⋮----
Some(group_update_authority),
⋮----
assert_eq!(
⋮----
Some(new_authority),

================
File: transaction-status/src/parse_token/extension/token_metadata.rs
================
fn token_metadata_field_to_string(field: &Field) -> String {
⋮----
Field::Name => "name".to_string(),
Field::Symbol => "symbol".to_string(),
Field::Uri => "uri".to_string(),
Field::Key(key) => key.clone(),
⋮----
pub(in crate::parse_token) fn parse_token_metadata_instruction(
⋮----
check_num_token_accounts(account_indexes, 4)?;
⋮----
let value = json!({
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeTokenMetadata".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
instruction_type: "updateTokenMetadataField".to_string(),
⋮----
instruction_type: "removeTokenMetadataKey".to_string(),
⋮----
instruction_type: "updateTokenMetadataAuthority".to_string(),
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("start".to_string(), json!(start));
⋮----
map.insert("end".to_string(), json!(end));
⋮----
instruction_type: "emitTokenMetadata".to_string(),
⋮----
mod test {
⋮----
fn test_parse_token_metadata_instruction() {
⋮----
let name = "Mega Token".to_string();
let symbol = "MEGA".to_string();
let uri = "https://mega.com".to_string();
⋮----
name.clone(),
symbol.clone(),
uri.clone(),
⋮----
assert_eq!(
⋮----
"https://ultra-mega.com".to_string(),
⋮----
spl_token_metadata_interface::state::Field::Key("new_field".to_string()),
"new_value".to_string(),
⋮----
"new_field".to_string(),
⋮----
Some(new_authority).try_into().unwrap(),
⋮----
Option::<Pubkey>::None.try_into().unwrap(),
⋮----
Some(1),
Some(2),

================
File: transaction-status/src/parse_token/extension/transfer_fee.rs
================
pub(in crate::parse_token) fn parse_transfer_fee_instruction(
⋮----
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?;
⋮----
check_num_token_accounts(account_indexes, 1)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert(
"transferFeeConfigAuthority".to_string(),
json!(transfer_fee_config_authority.to_string()),
⋮----
"withdrawWithheldAuthority".to_string(),
json!(withdraw_withheld_authority.to_string()),
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeTransferFeeConfig".to_string(),
⋮----
check_num_token_accounts(account_indexes, 4)?;
⋮----
parse_signers(
⋮----
instruction_type: "transferCheckedWithFee".to_string(),
⋮----
check_num_token_accounts(account_indexes, 3)?;
⋮----
instruction_type: "withdrawWithheldTokensFromMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 3 + num_token_accounts as usize)?;
⋮----
let mut source_accounts: Vec<String> = vec![];
⋮----
.len()
.saturating_sub(num_token_accounts as usize);
for i in account_indexes[first_source_account_index..].iter() {
source_accounts.push(account_keys[*i as usize].to_string());
⋮----
map.insert("sourceAccounts".to_string(), json!(source_accounts));
⋮----
instruction_type: "withdrawWithheldTokensFromAccounts".to_string(),
⋮----
for i in account_indexes.iter().skip(1) {
⋮----
instruction_type: "harvestWithheldTokensToMint".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
⋮----
instruction_type: "setTransferFee".to_string(),
⋮----
mod test {
⋮----
fn test_parse_transfer_fee_instruction() {
⋮----
let init_transfer_fee_config_ix = initialize_transfer_fee_config(
⋮----
Some(&transfer_fee_config_authority),
Some(&withdraw_withheld_authority),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
let transfer_checked_with_fee_ix = transfer_checked_with_fee(
⋮----
let withdraw_withheld_tokens_from_mint_ix = withdraw_withheld_tokens_from_mint(
⋮----
let withdraw_withheld_tokens_from_accounts_ix = withdraw_withheld_tokens_from_accounts(
⋮----
let harvest_withheld_tokens_to_mint_ix = harvest_withheld_tokens_to_mint(
⋮----
let set_transfer_fee_ix = set_transfer_fee(

================
File: transaction-status/src/parse_token/extension/transfer_hook.rs
================
pub(in crate::parse_token) fn parse_transfer_hook_instruction(
⋮----
match decode_instruction_type(instruction_data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_token_accounts(account_indexes, 1)?;
⋮----
} = *decode_instruction_data(instruction_data).map_err(|_| {
⋮----
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert("authority".to_string(), json!(authority.to_string()));
⋮----
map.insert("programId".to_string(), json!(program_id.to_string()));
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeTransferHook".to_string(),
⋮----
check_num_token_accounts(account_indexes, 2)?;
let UpdateInstructionData { program_id } = *decode_instruction_data(instruction_data)
.map_err(|_| {
⋮----
parse_signers(
⋮----
instruction_type: "updateTransferHook".to_string(),
⋮----
mod test {
⋮----
fn test_parse_transfer_hook_instruction() {
⋮----
let init_ix = initialize(
⋮----
Some(authority),
Some(program_id),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
initialize(&spl_token_2022_interface::id(), &mint_pubkey, None, None).unwrap();
⋮----
let update_ix = update(

================
File: transaction-status/src/extract_memos.rs
================
pub fn extract_and_fmt_memos<T: ExtractMemos>(message: &T) -> Option<String> {
let memos = message.extract_memos();
if memos.is_empty() {
⋮----
Some(memos.join("; "))
⋮----
fn extract_and_fmt_memo_data(data: &[u8]) -> String {
let memo_len = data.len();
let parsed_memo = parse_memo_data(data).unwrap_or_else(|_| "(unparseable)".to_string());
format!("[{memo_len}] {parsed_memo}")
⋮----
pub trait ExtractMemos {
⋮----
impl ExtractMemos for Message {
fn extract_memos(&self) -> Vec<String> {
extract_memos_inner(
⋮----
impl ExtractMemos for SanitizedMessage {
⋮----
extract_memos_inner(&self.account_keys(), self.instructions())
⋮----
impl ExtractMemos for VersionedTransactionWithStatusMeta {
⋮----
&self.account_keys(),
self.transaction.message.instructions(),
⋮----
enum KeyType<'a> {
⋮----
fn extract_memos_inner(
⋮----
let mut account_keys: Vec<KeyType> = account_keys.iter().map(KeyType::Unknown).collect();
⋮----
.iter()
.filter_map(|ix| {
⋮----
let key_type = account_keys.get(index)?;
⋮----
KeyType::MemoProgram => Some(&ix.data),
⋮----
Some(&ix.data)
⋮----
Some(extract_and_fmt_memo_data(memo_data))
⋮----
.collect()
⋮----
mod test {
⋮----
fn test_extract_memos_inner() {
⋮----
let expected_memos = vec![
⋮----
let memo_instructions = vec![
⋮----
let static_keys = vec![
⋮----
assert_eq!(

================
File: transaction-status/src/lib.rs
================
pub mod extract_memos;
pub mod parse_accounts;
pub mod parse_address_lookup_table;
pub mod parse_associated_token;
pub mod parse_bpf_loader;
pub mod parse_instruction;
pub mod parse_stake;
pub mod parse_system;
pub mod parse_token;
pub mod parse_vote;
pub mod token_balances;
pub struct BlockEncodingOptions {
⋮----
pub trait Encodable {
⋮----
pub trait EncodableWithMeta {
⋮----
trait JsonAccounts {
⋮----
fn make_ui_partially_decoded_instruction(
⋮----
program_id: account_keys[instruction.program_id_index as usize].to_string(),
⋮----
.iter()
.map(|&i| account_keys[i as usize].to_string())
.collect(),
data: bs58::encode(instruction.data.clone()).into_string(),
⋮----
pub fn parse_ui_instruction(
⋮----
if let Ok(parsed_instruction) = parse(program_id, instruction, account_keys, stack_height) {
⋮----
make_ui_partially_decoded_instruction(instruction, account_keys, stack_height),
⋮----
pub fn map_inner_instructions(
⋮----
.into_iter()
.enumerate()
.map(|(index, instructions)| InnerInstructions {
⋮----
.map(|info| InnerInstruction {
stack_height: Some(u32::from(info.stack_height)),
⋮----
.filter(|i| !i.instructions.is_empty())
⋮----
pub fn parse_ui_inner_instructions(
⋮----
.map(
⋮----
}| { parse_ui_instruction(ix, account_keys, *stack_height) },
⋮----
fn build_simple_ui_transaction_status_meta(
⋮----
err: meta.status.clone().map_err(Into::into).err(),
status: meta.status.map_err(Into::into),
⋮----
.map(|balance| balance.into_iter().map(Into::into).collect())
.into(),
⋮----
meta.rewards.into()
⋮----
fn parse_ui_transaction_status_meta(
⋮----
let account_keys = AccountKeys::new(static_keys, Some(&meta.loaded_addresses));
⋮----
.map(|ixs| {
ixs.into_iter()
.map(|ix| parse_ui_inner_instructions(ix, &account_keys))
.collect()
⋮----
log_messages: meta.log_messages.into(),
⋮----
rewards: if show_rewards { meta.rewards } else { None }.into(),
⋮----
meta.return_data.map(|return_data| return_data.into()),
⋮----
pub struct RewardsAndNumPartitions {
⋮----
pub enum ConvertBlockError {
⋮----
pub struct ConfirmedBlock {
⋮----
pub struct VersionedConfirmedBlock {
⋮----
fn from(block: VersionedConfirmedBlock) -> Self {
⋮----
.map(TransactionWithStatusMeta::Complete)
⋮----
type Error = ConvertBlockError;
fn try_from(block: ConfirmedBlock) -> Result<Self, Self::Error> {
let expected_transaction_count = block.transactions.len();
⋮----
.filter_map(|tx| match tx {
⋮----
TransactionWithStatusMeta::Complete(tx) => Some(tx),
⋮----
.collect();
if txs.len() != expected_transaction_count {
return Err(ConvertBlockError::TransactionsMissing(
⋮----
txs.len(),
⋮----
Ok(Self {
⋮----
impl ConfirmedBlock {
pub fn encode_with_options(
⋮----
Some(
⋮----
.map(|tx_with_meta| {
tx_with_meta.encode(
⋮----
.map(|tx_with_meta| tx_with_meta.transaction_signature().to_string())
⋮----
tx_with_meta.build_json_accounts(
⋮----
Ok(UiConfirmedBlock {
⋮----
Some(self.rewards)
⋮----
pub struct VersionedConfirmedBlockWithEntries {
⋮----
pub struct EntrySummary {
⋮----
pub enum TransactionWithStatusMeta {
⋮----
pub struct VersionedTransactionWithStatusMeta {
⋮----
impl TransactionWithStatusMeta {
pub fn get_status_meta(&self) -> Option<TransactionStatusMeta> {
⋮----
Self::Complete(tx_with_meta) => Some(tx_with_meta.meta.clone()),
⋮----
pub fn get_transaction(&self) -> VersionedTransaction {
⋮----
Self::MissingMetadata(transaction) => VersionedTransaction::from(transaction.clone()),
Self::Complete(tx_with_meta) => tx_with_meta.transaction.clone(),
⋮----
pub fn transaction_signature(&self) -> &Signature {
⋮----
pub fn encode(
⋮----
Self::MissingMetadata(ref transaction) => Ok(EncodedTransactionWithStatusMeta {
⋮----
transaction: transaction.encode(encoding),
⋮----
tx_with_meta.encode(encoding, max_supported_transaction_version, show_rewards)
⋮----
pub fn account_keys(&self) -> AccountKeys<'_> {
⋮----
Self::Complete(tx_with_meta) => tx_with_meta.account_keys(),
⋮----
fn build_json_accounts(
⋮----
transaction: transaction.build_json_accounts(),
⋮----
tx_with_meta.build_json_accounts(max_supported_transaction_version, show_rewards)
⋮----
impl VersionedTransactionWithStatusMeta {
fn validate_version(
⋮----
self.transaction.version(),
⋮----
// Set to none because old clients can't handle this field
(None, TransactionVersion::LEGACY) => Ok(None),
⋮----
Err(EncodeError::UnsupportedTransactionVersion(version))
⋮----
(Some(_), TransactionVersion::LEGACY) => Ok(Some(TransactionVersion::LEGACY)),
⋮----
Ok(Some(TransactionVersion::Number(version)))
⋮----
let version = self.validate_version(max_supported_transaction_version)?;
Ok(EncodedTransactionWithStatusMeta {
transaction: self.transaction.encode_with_meta(encoding, &self.meta),
meta: Some(match encoding {
UiTransactionEncoding::JsonParsed => parse_ui_transaction_status_meta(
⋮----
self.transaction.message.static_account_keys(),
⋮----
Some(&self.meta.loaded_addresses),
⋮----
VersionedMessage::Legacy(message) => parse_legacy_message_accounts(message),
⋮----
parse_v0_message_accounts(&loaded_message)
⋮----
.map(ToString::to_string)
⋮----
meta: Some(build_simple_ui_transaction_status_meta(
⋮----
pub struct ConfirmedTransactionWithStatusMeta {
⋮----
pub struct VersionedConfirmedTransactionWithStatusMeta {
⋮----
impl ConfirmedTransactionWithStatusMeta {
⋮----
Ok(EncodedConfirmedTransactionWithStatusMeta {
⋮----
transaction: self.tx_with_meta.encode(
⋮----
self.tx_with_meta.get_transaction()
⋮----
impl EncodableWithMeta for VersionedTransaction {
type Encoded = EncodedTransaction;
fn encode_with_meta(
⋮----
bs58::encode(bincode::serialize(self).unwrap()).into_string(),
⋮----
BASE64_STANDARD.encode(bincode::serialize(self).unwrap()),
⋮----
UiTransactionEncoding::Json => self.json_encode(),
⋮----
signatures: self.signatures.iter().map(ToString::to_string).collect(),
⋮----
message.encode(UiTransactionEncoding::JsonParsed)
⋮----
message.encode_with_meta(UiTransactionEncoding::JsonParsed, meta)
⋮----
fn json_encode(&self) -> Self::Encoded {
⋮----
VersionedMessage::Legacy(message) => message.encode(UiTransactionEncoding::Json),
VersionedMessage::V0(message) => message.json_encode(),
⋮----
impl Encodable for VersionedTransaction {
⋮----
fn encode(&self, encoding: UiTransactionEncoding) -> Self::Encoded {
⋮----
impl Encodable for Transaction {
⋮----
message: self.message.encode(encoding),
⋮----
impl JsonAccounts for Transaction {
⋮----
fn build_json_accounts(&self) -> Self::Encoded {
⋮----
account_keys: parse_legacy_message_accounts(&self.message),
⋮----
impl Encodable for Message {
type Encoded = UiMessage;
⋮----
account_keys: parse_legacy_message_accounts(self),
recent_blockhash: self.recent_blockhash.to_string(),
⋮----
.map(|instruction| {
parse_ui_instruction(
⋮----
Some(TRANSACTION_LEVEL_STACK_HEIGHT as u32),
⋮----
account_keys: self.account_keys.iter().map(ToString::to_string).collect(),
⋮----
.map(|ix| {
UiCompiledInstruction::from(ix, Some(TRANSACTION_LEVEL_STACK_HEIGHT as u32))
⋮----
impl Encodable for v0::Message {
⋮----
account_keys: parse_v0_message_accounts(&loaded_message),
⋮----
impl EncodableWithMeta for v0::Message {
⋮----
let account_keys = AccountKeys::new(&self.account_keys, Some(&meta.loaded_addresses));
⋮----
address_table_lookups: Some(
self.address_table_lookups.iter().map(Into::into).collect(),
⋮----
self.json_encode()
⋮----
// A serialized `Vec<TransactionByAddrInfo>` is stored in the `tx-by-addr` table.  The row keys are
// the one's compliment of the slot so that rows may be listed in reverse order
⋮----
pub struct TransactionByAddrInfo {
⋮----
mod test {
⋮----
fn test_ui_transaction_status_meta_ctors_serialization() {
⋮----
status: Ok(()),
⋮----
pre_balances: vec![1, 2, 3],
post_balances: vec![4, 5, 6],
⋮----
writable: vec![],
readonly: vec![],
⋮----
.unwrap();
let ui_meta_from: UiTransactionStatusMeta = meta.clone().into();
assert_eq!(
⋮----
let ui_meta_parse_with_rewards = parse_ui_transaction_status_meta(meta.clone(), &[], true);
⋮----
let ui_meta_parse_no_rewards = parse_ui_transaction_status_meta(meta, &[], false);

================
File: transaction-status/src/parse_accounts.rs
================
pub fn parse_legacy_message_accounts(message: &Message) -> Vec<ParsedAccount> {
⋮----
let mut accounts: Vec<ParsedAccount> = vec![];
for (i, account_key) in message.account_keys.iter().enumerate() {
accounts.push(ParsedAccount {
pubkey: account_key.to_string(),
writable: message.is_maybe_writable(i, Some(&reserved_account_keys)),
signer: message.is_signer(i),
source: Some(ParsedAccountSource::Transaction),
⋮----
pub fn parse_v0_message_accounts(message: &LoadedMessage) -> Vec<ParsedAccount> {
⋮----
for (i, account_key) in message.account_keys().iter().enumerate() {
let source = if i < message.static_account_keys().len() {
⋮----
writable: message.is_writable(i),
⋮----
source: Some(source),
⋮----
mod test {
⋮----
fn test_parse_legacy_message_accounts() {
⋮----
account_keys: vec![pubkey0, pubkey1, pubkey2, pubkey3],
⋮----
assert_eq!(
⋮----
fn test_parse_v0_message_accounts() {
⋮----
writable: vec![pubkey4],
readonly: vec![pubkey5],

================
File: transaction-status/src/parse_address_lookup_table.rs
================
pub fn parse_address_lookup_table(
⋮----
let address_lookup_table_instruction: ProgramInstruction = deserialize(&instruction.data)
.map_err(|_| {
⋮----
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
check_num_address_lookup_table_accounts(&instruction.accounts, 4)?;
Ok(ParsedInstructionEnum {
instruction_type: "createLookupTable".to_string(),
info: json!({
⋮----
check_num_address_lookup_table_accounts(&instruction.accounts, 2)?;
⋮----
instruction_type: "freezeLookupTable".to_string(),
⋮----
.into_iter()
.map(|address| address.to_string())
.collect();
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
if instruction.accounts.len() >= 4 {
map.insert(
"payerAccount".to_string(),
json!(account_keys[instruction.accounts[2] as usize].to_string()),
⋮----
"systemProgram".to_string(),
json!(account_keys[instruction.accounts[3] as usize].to_string()),
⋮----
instruction_type: "extendLookupTable".to_string(),
⋮----
instruction_type: "deactivateLookupTable".to_string(),
⋮----
check_num_address_lookup_table_accounts(&instruction.accounts, 3)?;
⋮----
instruction_type: "closeLookupTable".to_string(),
⋮----
fn check_num_address_lookup_table_accounts(
⋮----
check_num_accounts(accounts, num, ParsableProgram::AddressLookupTable)
⋮----
mod test {
⋮----
fn test_parse_create_address_lookup_table_ix() {
⋮----
let authority = Pubkey::from_str("HkxY6vXdrKzoCQLmdJ3cYo9534FdZQxzBNWTyrJzzqJM").unwrap();
⋮----
assert_eq!(
⋮----
assert!(parse_address_lookup_table(
⋮----
let keys = message.account_keys.clone();
message.instructions[0].accounts.pop();
⋮----
fn test_parse_freeze_lookup_table_ix() {
⋮----
fn test_parse_extend_lookup_table_ix() {
⋮----
let no_addresses = vec![];
⋮----
let some_addresses = vec![address0, address1];
⋮----
Some(from_pubkey),
⋮----
fn test_parse_deactivate_lookup_table_ix() {
⋮----
fn test_parse_close_lookup_table_ix() {

================
File: transaction-status/src/parse_associated_token.rs
================
pub fn parse_associated_token(
⋮----
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
let ata_instruction = if instruction.data.is_empty() {
⋮----
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplToken))?
⋮----
check_num_associated_token_accounts(&instruction.accounts, 6)?;
Ok(ParsedInstructionEnum {
instruction_type: "create".to_string(),
info: json!({
⋮----
instruction_type: "createIdempotent".to_string(),
⋮----
check_num_associated_token_accounts(&instruction.accounts, 7)?;
⋮----
instruction_type: "recoverNested".to_string(),
⋮----
fn check_num_associated_token_accounts(
⋮----
check_num_accounts(accounts, num, ParsableProgram::SplAssociatedTokenAccount)
⋮----
mod test {
⋮----
fn test_parse_create_deprecated() {
⋮----
let associated_account_address = get_associated_token_address(&wallet_address, &mint);
⋮----
create_associated_token_account(&funder, &wallet_address, &mint, &token_program_id);
create_ix.data = vec![];
⋮----
.push(AccountMeta::new_readonly(sysvar::rent::id(), false));
⋮----
assert_eq!(
⋮----
.iter()
.position(|index| message.account_keys[*index as usize] == sysvar::rent::id())
.unwrap();
compiled_instruction.accounts.remove(rent_account_index);
⋮----
compiled_instruction.accounts.pop();
assert!(parse_associated_token(
⋮----
fn test_parse_create() {
⋮----
get_associated_token_address_with_program_id(&wallet_address, &mint, &token_program_id);
⋮----
fn test_parse_create_idempotent() {
⋮----
let create_ix = create_associated_token_account_idempotent(
⋮----
fn test_parse_recover_nested() {
⋮----
let owner_associated_account_address = get_associated_token_address_with_program_id(
⋮----
let nested_associated_account_address = get_associated_token_address_with_program_id(
⋮----
let destination_associated_account_address = get_associated_token_address_with_program_id(
⋮----
let recover_ix = recover_nested(

================
File: transaction-status/src/parse_bpf_loader.rs
================
pub fn parse_bpf_loader(
⋮----
let bpf_loader_instruction: LoaderInstruction = deserialize(&instruction.data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::BpfLoader))?;
if instruction.accounts.is_empty() || instruction.accounts[0] as usize >= account_keys.len() {
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
check_num_bpf_loader_accounts(&instruction.accounts, 1)?;
Ok(ParsedInstructionEnum {
instruction_type: "write".to_string(),
info: json!({
⋮----
check_num_bpf_loader_accounts(&instruction.accounts, 2)?;
⋮----
instruction_type: "finalize".to_string(),
⋮----
pub fn parse_bpf_upgradeable_loader(
⋮----
deserialize(&instruction.data).map_err(|_| {
⋮----
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
check_num_bpf_upgradeable_loader_accounts(&instruction.accounts, 1)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
if instruction.accounts.len() > 1 {
map.insert(
"authority".to_string(),
json!(account_keys[instruction.accounts[1] as usize].to_string()),
⋮----
instruction_type: "initializeBuffer".to_string(),
⋮----
check_num_bpf_upgradeable_loader_accounts(&instruction.accounts, 2)?;
⋮----
check_num_bpf_upgradeable_loader_accounts(&instruction.accounts, 8)?;
⋮----
instruction_type: "deployWithMaxDataLen".to_string(),
⋮----
check_num_bpf_upgradeable_loader_accounts(&instruction.accounts, 7)?;
⋮----
instruction_type: "upgrade".to_string(),
⋮----
instruction_type: "setAuthority".to_string(),
⋮----
check_num_bpf_upgradeable_loader_accounts(&instruction.accounts, 3)?;
⋮----
instruction_type: "setAuthorityChecked".to_string(),
⋮----
instruction_type: "close".to_string(),
⋮----
instruction_type: "extendProgram".to_string(),
⋮----
instruction_type: "migrate".to_string(),
⋮----
instruction_type: "extendProgramChecked".to_string(),
⋮----
fn check_num_bpf_loader_accounts(accounts: &[u8], num: usize) -> Result<(), ParseInstructionError> {
check_num_accounts(accounts, num, ParsableProgram::BpfLoader)
⋮----
fn check_num_bpf_upgradeable_loader_accounts(
⋮----
check_num_accounts(accounts, num, ParsableProgram::BpfUpgradeableLoader)
⋮----
mod test {
⋮----
fn test_parse_bpf_loader_instructions() {
⋮----
let bytes = vec![8; 99];
⋮----
let account_keys = vec![fee_payer, account_pubkey];
let missing_account_keys = vec![account_pubkey];
⋮----
solana_loader_v2_interface::write(&account_pubkey, &program_id, offset, bytes.clone());
let mut message = Message::new(&[instruction], Some(&fee_payer));
assert_eq!(
⋮----
assert!(parse_bpf_loader(
⋮----
message.instructions[0].accounts.pop();
⋮----
accounts: vec![1, 2],
data: vec![2, 0, 0, 0],
⋮----
accounts: vec![],
data: vec![1, 0, 0, 0],
⋮----
fn test_parse_bpf_upgradeable_loader_create_buffer_ix() {
⋮----
.unwrap();
⋮----
assert!(parse_bpf_upgradeable_loader(
⋮----
let keys = message.account_keys.clone();
message.instructions[1].accounts.pop();
⋮----
fn test_parse_bpf_upgradeable_loader_write_ix() {
⋮----
bytes.clone(),
⋮----
fn test_parse_bpf_upgradeable_loader_deploy_ix() {
⋮----
&[program_address.as_ref()],
⋮----
fn test_parse_bpf_upgradeable_loader_upgrade_ix() {
⋮----
fn test_parse_bpf_upgradeable_loader_set_buffer_authority_ix() {
⋮----
fn test_parse_bpf_upgradeable_loader_set_buffer_authority_checked_ix() {
⋮----
fn test_parse_bpf_upgradeable_loader_set_upgrade_authority_ix() {
⋮----
Some(&new_authority_address),
⋮----
fn test_parse_bpf_upgradeable_loader_set_upgrade_authority_checked_ix() {
⋮----
fn test_parse_bpf_upgradeable_loader_close_buffer_ix() {
⋮----
fn test_parse_bpf_upgradeable_loader_close_program_ix() {
⋮----
Some(&authority_address),
Some(&program_address),

================
File: transaction-status/src/parse_instruction.rs
================
pub use solana_transaction_status_client_types::ParsedInstruction;
⋮----
.into_iter()
.chain(
spl_token_ids()
⋮----
.map(|spl_token_id| (spl_token_id, ParsableProgram::SplToken)),
⋮----
.collect()
⋮----
pub enum ParseInstructionError {
⋮----
pub struct ParsedInstructionEnum {
⋮----
pub enum ParsableProgram {
⋮----
pub fn parse(
⋮----
.get(program_id)
.ok_or(ParseInstructionError::ProgramNotParsable)?;
⋮----
serde_json::to_value(parse_address_lookup_table(instruction, account_keys)?)?
⋮----
serde_json::to_value(parse_associated_token(instruction, account_keys)?)?
⋮----
ParsableProgram::SplMemo => parse_memo(instruction)?,
ParsableProgram::SplToken => serde_json::to_value(parse_token(instruction, account_keys)?)?,
⋮----
serde_json::to_value(parse_bpf_loader(instruction, account_keys)?)?
⋮----
serde_json::to_value(parse_bpf_upgradeable_loader(instruction, account_keys)?)?
⋮----
ParsableProgram::Stake => serde_json::to_value(parse_stake(instruction, account_keys)?)?,
ParsableProgram::System => serde_json::to_value(parse_system(instruction, account_keys)?)?,
ParsableProgram::Vote => serde_json::to_value(parse_vote(instruction, account_keys)?)?,
⋮----
Ok(ParsedInstruction {
program: format!("{program_name:?}").to_kebab_case(),
program_id: program_id.to_string(),
⋮----
fn parse_memo(instruction: &CompiledInstruction) -> Result<Value, ParseInstructionError> {
parse_memo_data(&instruction.data)
.map(Value::String)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::SplMemo))
⋮----
pub fn parse_memo_data(data: &[u8]) -> Result<String, Utf8Error> {
from_utf8(data).map(|s| s.to_string())
⋮----
pub(crate) fn check_num_accounts(
⋮----
if accounts.len() < num {
Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
Ok(())
⋮----
mod test {
⋮----
fn test_parse() {
⋮----
accounts: vec![],
data: vec![240, 159, 166, 150],
⋮----
assert_eq!(
⋮----
assert!(parse(&non_parsable_program_id, &memo_instruction, &no_keys, None).is_err());
⋮----
fn test_parse_memo() {
let good_memo = "good memo".to_string();
⋮----
let bad_memo = vec![128u8];
assert!(std::str::from_utf8(&bad_memo).is_err());
assert!(parse_memo(&CompiledInstruction {

================
File: transaction-status/src/parse_stake.rs
================
pub fn parse_stake(
⋮----
let stake_instruction: StakeInstruction = deserialize(&instruction.data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::Stake))?;
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
check_num_stake_accounts(&instruction.accounts, 2)?;
let authorized = json!({
⋮----
let lockup = json!({
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initialize".to_string(),
info: json!({
⋮----
check_num_stake_accounts(&instruction.accounts, 3)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
if instruction.accounts.len() >= 4 {
map.insert(
"custodian".to_string(),
json!(account_keys[instruction.accounts[3] as usize].to_string()),
⋮----
instruction_type: "authorize".to_string(),
⋮----
check_num_stake_accounts(&instruction.accounts, 6)?;
⋮----
instruction_type: "delegate".to_string(),
⋮----
instruction_type: "split".to_string(),
⋮----
check_num_stake_accounts(&instruction.accounts, 5)?;
⋮----
if instruction.accounts.len() >= 6 {
⋮----
json!(account_keys[instruction.accounts[5] as usize].to_string()),
⋮----
instruction_type: "withdraw".to_string(),
⋮----
instruction_type: "deactivate".to_string(),
⋮----
lockup_map.insert("unixTimestamp".to_string(), json!(timestamp));
⋮----
lockup_map.insert("epoch".to_string(), json!(epoch));
⋮----
lockup_map.insert("custodian".to_string(), json!(custodian.to_string()));
⋮----
instruction_type: "setLockup".to_string(),
⋮----
instruction_type: "merge".to_string(),
⋮----
if instruction.accounts.len() >= 3 {
⋮----
"clockSysvar".to_string(),
json!(account_keys[instruction.accounts[2] as usize].to_string()),
⋮----
instruction_type: "authorizeWithSeed".to_string(),
⋮----
check_num_stake_accounts(&instruction.accounts, 4)?;
⋮----
instruction_type: "initializeChecked".to_string(),
⋮----
if instruction.accounts.len() >= 5 {
⋮----
json!(account_keys[instruction.accounts[4] as usize].to_string()),
⋮----
instruction_type: "authorizeChecked".to_string(),
⋮----
instruction_type: "authorizeCheckedWithSeed".to_string(),
⋮----
lockup_map.insert(
⋮----
instruction_type: "setLockupChecked".to_string(),
⋮----
StakeInstruction::GetMinimumDelegation => Ok(ParsedInstructionEnum {
instruction_type: "getMinimumDelegation".to_string(),
⋮----
instruction_type: "deactivateDelinquent".to_string(),
⋮----
instruction_type: "redelegate".to_string(),
⋮----
instruction_type: "moveStake".to_string(),
⋮----
instruction_type: "moveLamports".to_string(),
⋮----
fn check_num_stake_accounts(accounts: &[u8], num: usize) -> Result<(), ParseInstructionError> {
check_num_accounts(accounts, num, ParsableProgram::Stake)
⋮----
mod test {
⋮----
fn test_parse_stake_initialize_ix() {
⋮----
assert_eq!(
⋮----
assert!(parse_stake(
⋮----
let keys = message.account_keys.clone();
message.instructions[0].accounts.pop();
assert!(parse_stake(&message.instructions[0], &AccountKeys::new(&keys, None)).is_err());
⋮----
fn test_parse_stake_authorize_ix() {
⋮----
Some(&custodian_pubkey),
⋮----
fn test_parse_stake_delegate_ix() {
⋮----
fn test_parse_stake_split_ix() {
⋮----
fn test_parse_stake_withdraw_ix() {
⋮----
fn test_parse_stake_deactivate_stake_ix() {
⋮----
fn test_parse_stake_merge_ix() {
⋮----
fn test_parse_stake_authorize_with_seed_ix() {
⋮----
seed.to_string(),
⋮----
fn test_parse_stake_set_lockup() {
let keys: Vec<Pubkey> = repeat_with(Pubkey::new_unique).take(3).collect();
⋮----
unix_timestamp: Some(unix_timestamp),
⋮----
epoch: Some(epoch),
⋮----
custodian: Some(custodian),
⋮----
custodian: Some(keys[1]),
⋮----
fn test_parse_stake_create_account_checked_ix() {
⋮----
fn test_parse_stake_authorize_checked_ix() {
⋮----
fn test_parse_stake_authorize_checked_with_seed_ix() {
⋮----
fn test_parse_stake_move_ix() {
⋮----
type InstructionFn = fn(&Pubkey, &Pubkey, &Pubkey, u64) -> Instruction;
let test_vectors: Vec<(InstructionFn, String)> = vec![
⋮----
let instruction = mk_ixn(

================
File: transaction-status/src/parse_system.rs
================
pub fn parse_system(
⋮----
let system_instruction: SystemInstruction = deserialize(&instruction.data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::System))?;
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
check_num_system_accounts(&instruction.accounts, 2)?;
Ok(ParsedInstructionEnum {
instruction_type: "createAccount".to_string(),
info: json!({
⋮----
check_num_system_accounts(&instruction.accounts, 1)?;
⋮----
instruction_type: "assign".to_string(),
⋮----
instruction_type: "transfer".to_string(),
⋮----
instruction_type: "createAccountWithSeed".to_string(),
⋮----
check_num_system_accounts(&instruction.accounts, 3)?;
⋮----
instruction_type: "advanceNonce".to_string(),
⋮----
check_num_system_accounts(&instruction.accounts, 5)?;
⋮----
instruction_type: "withdrawFromNonce".to_string(),
⋮----
instruction_type: "initializeNonce".to_string(),
⋮----
instruction_type: "authorizeNonce".to_string(),
⋮----
instruction_type: "upgradeNonce".to_string(),
⋮----
instruction_type: "allocate".to_string(),
⋮----
instruction_type: "allocateWithSeed".to_string(),
⋮----
instruction_type: "assignWithSeed".to_string(),
⋮----
instruction_type: "transferWithSeed".to_string(),
⋮----
fn check_num_system_accounts(accounts: &[u8], num: usize) -> Result<(), ParseInstructionError> {
check_num_accounts(accounts, num, ParsableProgram::System)
⋮----
mod test {
⋮----
fn test_parse_system_create_account_ix() {
⋮----
assert_eq!(
⋮----
assert!(parse_system(
⋮----
let keys = message.account_keys.clone();
message.instructions[0].accounts.pop();
assert!(parse_system(&message.instructions[0], &AccountKeys::new(&keys, None)).is_err());
⋮----
fn test_parse_system_assign_ix() {
⋮----
assert!(parse_system(&message.instructions[0], &AccountKeys::new(&[], None)).is_err());
⋮----
fn test_parse_system_transfer_ix() {
⋮----
fn test_parse_system_create_account_with_seed_ix() {
⋮----
fn test_parse_system_allocate_ix() {
⋮----
fn test_parse_system_allocate_with_seed_ix() {
⋮----
fn test_parse_system_assign_with_seed_ix() {
⋮----
fn test_parse_system_transfer_with_seed_ix() {
⋮----
seed.to_string(),
⋮----
fn test_parse_system_advance_nonce_account_ix() {
⋮----
fn test_parse_system_withdraw_nonce_account_ix() {
⋮----
fn test_parse_system_initialize_nonce_ix() {
⋮----
fn test_parse_system_authorize_nonce_account_ix() {

================
File: transaction-status/src/parse_token.rs
================
mod extension;
pub fn parse_token(
⋮----
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
check_num_token_accounts(&instruction.accounts, 2)?;
let mut value = json!({
⋮----
let map = value.as_object_mut().unwrap();
⋮----
map.insert(
"freezeAuthority".to_string(),
json!(freeze_authority.to_string()),
⋮----
Ok(ParsedInstructionEnum {
instruction_type: "initializeMint".to_string(),
⋮----
check_num_token_accounts(&instruction.accounts, 1)?;
⋮----
instruction_type: "initializeMint2".to_string(),
⋮----
check_num_token_accounts(&instruction.accounts, 4)?;
⋮----
instruction_type: "initializeAccount".to_string(),
info: json!({
⋮----
check_num_token_accounts(&instruction.accounts, 3)?;
⋮----
instruction_type: "initializeAccount2".to_string(),
⋮----
instruction_type: "initializeAccount3".to_string(),
⋮----
let mut signers: Vec<String> = vec![];
for i in instruction.accounts[2..].iter() {
signers.push(account_keys[*i as usize].to_string());
⋮----
instruction_type: "initializeMultisig".to_string(),
⋮----
for i in instruction.accounts[1..].iter() {
⋮----
instruction_type: "initializeMultisig2".to_string(),
⋮----
parse_signers(
⋮----
instruction_type: "transfer".to_string(),
⋮----
instruction_type: "approve".to_string(),
⋮----
instruction_type: "revoke".to_string(),
⋮----
instruction_type: "setAuthority".to_string(),
⋮----
instruction_type: "mintTo".to_string(),
⋮----
instruction_type: "burn".to_string(),
⋮----
instruction_type: "closeAccount".to_string(),
⋮----
instruction_type: "freezeAccount".to_string(),
⋮----
instruction_type: "thawAccount".to_string(),
⋮----
instruction_type: "transferChecked".to_string(),
⋮----
instruction_type: "approveChecked".to_string(),
⋮----
instruction_type: "mintToChecked".to_string(),
⋮----
instruction_type: "burnChecked".to_string(),
⋮----
instruction_type: "syncNative".to_string(),
⋮----
if !extension_types.is_empty() {
⋮----
"extensionTypes".to_string(),
json!(extension_types
⋮----
instruction_type: "getAccountDataSize".to_string(),
⋮----
instruction_type: "initializeImmutableOwner".to_string(),
⋮----
instruction_type: "amountToUiAmount".to_string(),
⋮----
instruction_type: "uiAmountToAmount".to_string(),
⋮----
parse_initialize_mint_close_authority_instruction(
⋮----
TokenInstruction::TransferFeeExtension => parse_transfer_fee_instruction(
⋮----
parse_confidential_transfer_instruction(
⋮----
if instruction.data.len() <= 2 {
return Err(ParseInstructionError::InstructionNotParsable(
⋮----
parse_default_account_state_instruction(
⋮----
parse_reallocate_instruction(extension_types, &instruction.accounts, account_keys)
⋮----
if instruction.data.len() < 2 {
⋮----
parse_memo_transfer_instruction(
⋮----
instruction_type: "createNativeMint".to_string(),
⋮----
instruction_type: "initializeNonTransferableMint".to_string(),
⋮----
parse_interest_bearing_mint_instruction(
⋮----
parse_cpi_guard_instruction(
⋮----
parse_initialize_permanent_delegate_instruction(
⋮----
parse_transfer_hook_instruction(
⋮----
parse_confidential_transfer_fee_instruction(
⋮----
instruction_type: "withdrawExcessLamports".to_string(),
⋮----
parse_metadata_pointer_instruction(
⋮----
parse_group_pointer_instruction(
⋮----
parse_group_member_pointer_instruction(
⋮----
parse_confidential_mint_burn_instruction(
⋮----
TokenInstruction::ScaledUiAmountExtension => parse_scaled_ui_amount_instruction(
⋮----
TokenInstruction::PausableExtension => parse_pausable_instruction(
⋮----
parse_token_group_instruction(
⋮----
parse_token_metadata_instruction(
⋮----
Err(ParseInstructionError::InstructionNotParsable(
⋮----
pub enum UiAuthorityType {
⋮----
fn from(authority_type: AuthorityType) -> Self {
⋮----
pub enum UiExtensionType {
⋮----
fn from(extension_type: ExtensionType) -> Self {
⋮----
fn parse_signers(
⋮----
if accounts.len() > last_nonsigner_index + 1 {
⋮----
for i in accounts[last_nonsigner_index + 1..].iter() {
⋮----
multisig_field_name.to_string(),
json!(account_keys[accounts[last_nonsigner_index] as usize].to_string()),
⋮----
map.insert("signers".to_string(), json!(signers));
⋮----
owner_field_name.to_string(),
⋮----
fn check_num_token_accounts(accounts: &[u8], num: usize) -> Result<(), ParseInstructionError> {
check_num_accounts(accounts, num, ParsableProgram::SplToken)
⋮----
fn map_coption_pubkey(pubkey: COption<Pubkey>) -> Option<String> {
⋮----
COption::Some(pubkey) => Some(pubkey.to_string()),
⋮----
mod test {
⋮----
fn test_parse_token(program_id: &Pubkey) {
⋮----
let initialize_mint_ix = initialize_mint(
⋮----
Some(&freeze_authority),
⋮----
.unwrap();
⋮----
assert_eq!(
⋮----
initialize_mint(program_id, &mint_pubkey, &mint_authority, None, 2).unwrap();
⋮----
let initialize_mint_ix = initialize_mint2(
⋮----
initialize_account(program_id, &account_pubkey, &mint_pubkey, &owner).unwrap();
⋮----
initialize_account2(program_id, &account_pubkey, &mint_pubkey, &owner).unwrap();
⋮----
initialize_account3(program_id, &account_pubkey, &mint_pubkey, &owner).unwrap();
⋮----
let initialize_multisig_ix = initialize_multisig(
⋮----
let initialize_multisig_ix = initialize_multisig2(
⋮----
transfer(program_id, &account_pubkey, &recipient, &owner, &[], 42).unwrap();
⋮----
let transfer_ix = transfer(
⋮----
let approve_ix = approve(program_id, &account_pubkey, &recipient, &owner, &[], 42).unwrap();
⋮----
let approve_ix = approve(
⋮----
let revoke_ix = revoke(program_id, &account_pubkey, &owner, &[]).unwrap();
⋮----
let set_authority_ix = set_authority(
⋮----
Some(&new_freeze_authority),
⋮----
let mint_to_ix = mint_to(
⋮----
let burn_ix = burn(program_id, &account_pubkey, &mint_pubkey, &owner, &[], 42).unwrap();
⋮----
close_account(program_id, &account_pubkey, &recipient, &owner, &[]).unwrap();
⋮----
let freeze_account_ix = freeze_account(
⋮----
let thaw_account_ix = thaw_account(
⋮----
let transfer_ix = transfer_checked(
⋮----
let approve_ix = approve_checked(
⋮----
let mint_to_ix = mint_to_checked(
⋮----
let burn_ix = burn_checked(
⋮----
let sync_native_ix = sync_native(program_id, &account_pubkey).unwrap();
⋮----
initialize_immutable_owner(program_id, &account_pubkey).unwrap();
⋮----
let get_account_data_size_ix = get_account_data_size(
⋮----
let amount_to_ui_amount_ix = amount_to_ui_amount(program_id, &mint_pubkey, 4242).unwrap();
⋮----
ui_amount_to_amount(program_id, &mint_pubkey, "42.42").unwrap();
⋮----
fn test_parse_token_v3() {
test_parse_token(&spl_token_interface::id());
⋮----
fn test_parse_token_2022() {
test_parse_token(&spl_token_2022_interface::id());
⋮----
fn test_create_native_mint() {
⋮----
create_native_mint(&spl_token_2022_interface::id(), &payer).unwrap();
⋮----
fn test_token_ix_not_enough_keys(program_id: &Pubkey) {
let keys: Vec<Pubkey> = repeat_with(solana_pubkey::new_rand).take(10).collect();
⋮----
initialize_mint(program_id, &keys[0], &keys[1], Some(&keys[2]), 2).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys[0..1], None)).is_err());
⋮----
compiled_instruction.accounts[0..compiled_instruction.accounts.len() - 1].to_vec();
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys, None)).is_err());
let initialize_mint_ix = initialize_mint(program_id, &keys[0], &keys[1], None, 2).unwrap();
⋮----
initialize_mint2(program_id, &keys[0], &keys[1], Some(&keys[2]), 2).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys[0..0], None)).is_err());
⋮----
initialize_account(program_id, &keys[0], &keys[1], &keys[2]).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys[0..3], None)).is_err());
⋮----
initialize_account2(program_id, &keys[0], &keys[1], &keys[3]).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys[0..2], None)).is_err());
⋮----
initialize_account3(program_id, &keys[0], &keys[1], &keys[2]).unwrap();
⋮----
initialize_multisig(program_id, &keys[0], &[&keys[1], &keys[2], &keys[3]], 2).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys[0..4], None)).is_err());
⋮----
compiled_instruction.accounts[0..compiled_instruction.accounts.len() - 3].to_vec();
⋮----
initialize_multisig2(program_id, &keys[0], &[&keys[1], &keys[2], &keys[3]], 2).unwrap();
⋮----
let transfer_ix = transfer(program_id, &keys[1], &keys[2], &keys[0], &[], 42).unwrap();
⋮----
let approve_ix = approve(program_id, &keys[1], &keys[2], &keys[0], &[], 42).unwrap();
⋮----
let revoke_ix = revoke(program_id, &keys[1], &keys[0], &[]).unwrap();
⋮----
Some(&keys[2]),
⋮----
let mint_to_ix = mint_to(program_id, &keys[1], &keys[2], &keys[0], &[], 42).unwrap();
⋮----
let burn_ix = burn(program_id, &keys[1], &keys[2], &keys[0], &[], 42).unwrap();
⋮----
close_account(program_id, &keys[1], &keys[2], &keys[0], &[]).unwrap();
⋮----
freeze_account(program_id, &keys[1], &keys[2], &keys[0], &[]).unwrap();
⋮----
let thaw_account_ix = thaw_account(program_id, &keys[1], &keys[2], &keys[0], &[]).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&keys[0..5], None)).is_err());
⋮----
mint_to_checked(program_id, &keys[1], &keys[2], &keys[0], &[], 42, 2).unwrap();
⋮----
let burn_ix = burn_checked(program_id, &keys[1], &keys[2], &keys[0], &[], 42, 2).unwrap();
⋮----
let sync_native_ix = sync_native(program_id, &keys[0]).unwrap();
⋮----
assert!(parse_token(compiled_instruction, &AccountKeys::new(&[], None)).is_err());
⋮----
let init_immutable_owner_ix = initialize_immutable_owner(program_id, &keys[0]).unwrap();
⋮----
let get_account_data_size_ix = get_account_data_size(program_id, &keys[0], &[]).unwrap();
⋮----
let amount_to_ui_amount_ix = amount_to_ui_amount(program_id, &keys[0], 4242).unwrap();
⋮----
let ui_amount_to_amount_ix = ui_amount_to_amount(program_id, &keys[0], "42.42").unwrap();
⋮----
fn test_not_enough_keys_token_v3() {
test_token_ix_not_enough_keys(&spl_token_interface::id());
⋮----
fn test_not_enough_keys_token_2022() {
test_token_ix_not_enough_keys(&spl_token_2022_interface::id());

================
File: transaction-status/src/parse_vote.rs
================
pub fn parse_vote(
⋮----
let vote_instruction: VoteInstruction = deserialize(&instruction.data)
.map_err(|_| ParseInstructionError::InstructionNotParsable(ParsableProgram::Vote))?;
match instruction.accounts.iter().max() {
Some(index) if (*index as usize) < account_keys.len() => {}
⋮----
return Err(ParseInstructionError::InstructionKeyMismatch(
⋮----
check_num_vote_accounts(&instruction.accounts, 4)?;
Ok(ParsedInstructionEnum {
instruction_type: "initialize".to_string(),
info: json!({
⋮----
check_num_vote_accounts(&instruction.accounts, 3)?;
⋮----
instruction_type: "authorize".to_string(),
⋮----
instruction_type: "authorizeWithSeed".to_string(),
⋮----
instruction_type: "authorizeCheckedWithSeed".to_string(),
⋮----
let vote = json!({
⋮----
instruction_type: "vote".to_string(),
⋮----
check_num_vote_accounts(&instruction.accounts, 2)?;
let vote_state_update = json!({
⋮----
instruction_type: "updatevotestate".to_string(),
⋮----
instruction_type: "updatevotestateswitch".to_string(),
⋮----
instruction_type: "compactupdatevotestate".to_string(),
⋮----
instruction_type: "compactupdatevotestateswitch".to_string(),
⋮----
let tower_sync = json!({
⋮----
instruction_type: "towersync".to_string(),
⋮----
instruction_type: "towersyncswitch".to_string(),
⋮----
instruction_type: "withdraw".to_string(),
⋮----
instruction_type: "updateValidatorIdentity".to_string(),
⋮----
instruction_type: "updateCommission".to_string(),
⋮----
instruction_type: "voteSwitch".to_string(),
⋮----
instruction_type: "authorizeChecked".to_string(),
⋮----
fn check_num_vote_accounts(accounts: &[u8], num: usize) -> Result<(), ParseInstructionError> {
check_num_accounts(accounts, num, ParsableProgram::Vote)
⋮----
mod test {
⋮----
fn test_parse_vote_initialize_ix() {
⋮----
assert_eq!(
⋮----
assert!(parse_vote(
⋮----
let keys = message.account_keys.clone();
message.instructions[0].accounts.pop();
assert!(parse_vote(&message.instructions[0], &AccountKeys::new(&keys, None)).is_err());
⋮----
fn test_parse_vote_authorize_ix() {
⋮----
fn test_parse_vote_authorize_with_seed_ix() {
⋮----
fn test_parse_vote_authorize_with_seed_checked_ix() {
⋮----
fn test_parse_vote_ix() {
⋮----
slots: vec![1, 2, 4],
⋮----
timestamp: Some(1_234_567_890),
⋮----
fn test_parse_vote_withdraw_ix() {
⋮----
fn test_parse_vote_update_validator_identity_ix() {
⋮----
fn test_parse_vote_update_commission_ix() {
⋮----
fn test_parse_vote_switch_ix() {
⋮----
fn test_parse_vote_authorized_checked_ix() {
⋮----
fn test_parse_vote_state_update_ix() {
let vote_state_update = VoteStateUpdate::from(vec![(0, 3), (1, 2), (2, 1)]);
⋮----
vote_state_update.clone(),
⋮----
fn test_parse_vote_state_update_switch_ix() {
⋮----
fn test_parse_compact_vote_state_update_ix() {
⋮----
let compact_vote_state_update = vote_state_update.clone();
⋮----
fn test_parse_compact_vote_state_update_switch_ix() {
⋮----
fn test_parse_tower_sync_ix() {
let tower_sync = TowerSync::from(vec![(0, 3), (1, 2), (2, 1)]);
⋮----
tower_sync.clone(),
⋮----
fn test_parse_tower_sync_switch_ix() {

================
File: transaction-status/src/token_balances.rs
================
use crate::TransactionTokenBalance;
pub type TransactionTokenBalances = Vec<Vec<TransactionTokenBalance>>;
⋮----
pub struct TransactionTokenBalancesSet {
⋮----
impl TransactionTokenBalancesSet {
pub fn new(
⋮----
assert_eq!(pre_token_balances.len(), post_token_balances.len());

================
File: transaction-status/Cargo.toml
================
[package]
name = "solana-transaction-status"
description = "Solana transaction status types"
documentation = "https://docs.rs/solana-transaction-status"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
agave-unstable-api = []

[dependencies]
Inflector = { workspace = true }
agave-reserved-account-keys = { workspace = true }
base64 = { workspace = true }
bincode = { workspace = true }
borsh = { workspace = true }
bs58 = { workspace = true }
log = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
solana-account-decoder = { workspace = true }
solana-address-lookup-table-interface = { workspace = true }
solana-clock = { workspace = true }
solana-hash = { workspace = true }
solana-instruction = { workspace = true }
solana-loader-v2-interface = { workspace = true, features = ["bincode"] }
solana-loader-v3-interface = { workspace = true, features = ["bincode"] }
solana-message = { workspace = true }
solana-program-option = { workspace = true }
solana-pubkey = { workspace = true }
solana-reward-info = { workspace = true }
solana-sdk-ids = { workspace = true }
solana-signature = { workspace = true }
solana-stake-interface = { workspace = true }
solana-system-interface = { workspace = true }
solana-transaction = { workspace = true }
solana-transaction-error = { workspace = true }
solana-transaction-status-client-types = { workspace = true }
solana-vote-interface = { workspace = true }
spl-associated-token-account-interface = { workspace = true, features = ["borsh"] }
spl-memo-interface = { workspace = true }
spl-token-2022-interface = { workspace = true }
spl-token-group-interface = { workspace = true }
spl-token-interface = { workspace = true }
spl-token-metadata-interface = { workspace = true }
thiserror = { workspace = true }

[dev-dependencies]
bencher = { workspace = true }
bytemuck = { workspace = true }
solana-pubkey = { workspace = true, features = ["rand"] }
solana-transaction-status = { path = ".", features = ["agave-unstable-api"] }
spl-token-confidential-transfer-proof-extraction = { workspace = true }

[[bench]]
name = "extract_memos"
harness = false

================
File: transaction-status-client-types/src/lib.rs
================
pub mod option_serializer;
⋮----
pub enum TransactionBinaryEncoding {
⋮----
pub enum UiTransactionEncoding {
⋮----
impl UiTransactionEncoding {
pub fn into_binary_encoding(&self) -> Option<TransactionBinaryEncoding> {
⋮----
Self::Binary | Self::Base58 => Some(TransactionBinaryEncoding::Base58),
Self::Base64 => Some(TransactionBinaryEncoding::Base64),
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
let v = serde_json::to_value(self).map_err(|_| fmt::Error)?;
let s = v.as_str().ok_or(fmt::Error)?;
write!(f, "{s}")
⋮----
pub enum TransactionDetails {
⋮----
pub enum EncodeError {
⋮----
pub struct ConfirmedTransactionStatusWithSignature {
⋮----
pub enum TransactionConfirmationStatus {
⋮----
pub struct UiConfirmedBlock {
⋮----
pub struct UiTransaction {
⋮----
pub struct UiParsedMessage {
⋮----
pub struct ParsedAccount {
⋮----
pub enum ParsedAccountSource {
⋮----
pub enum UiMessage {
⋮----
pub enum EncodedTransaction {
⋮----
impl EncodedTransaction {
pub fn decode(&self) -> Option<VersionedTransaction> {
⋮----
.into_vec()
.ok()
.and_then(|bytes| bincode::deserialize(&bytes).ok()),
⋮----
.decode(blob)
⋮----
transaction.filter(|transaction| transaction.sanitize().is_ok())
⋮----
pub struct EncodedTransactionWithStatusMeta {
⋮----
pub struct Reward {
⋮----
pub type Rewards = Vec<Reward>;
⋮----
pub struct UiAddressTableLookup {
⋮----
fn from(lookup: &MessageAddressTableLookup) -> Self {
⋮----
account_key: lookup.account_key.to_string(),
writable_indexes: lookup.writable_indexes.clone(),
readonly_indexes: lookup.readonly_indexes.clone(),
⋮----
pub struct UiTransactionError(TransactionError);
⋮----
fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
self.0.fmt(f)
⋮----
fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
Some(&self.0)
⋮----
fn from(value: TransactionError) -> Self {
UiTransactionError(value)
⋮----
fn from(value: UiTransactionError) -> Self {
⋮----
impl SerializeTrait for UiTransactionError {
fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
⋮----
let mut state = serializer.serialize_tuple_variant(
⋮----
state.serialize_field(outer_instruction_index)?;
state.serialize_field(err)?;
state.end()
⋮----
fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
⋮----
if let Some(obj) = value.as_object() {
if let Some(arr) = obj.get("InstructionError").and_then(|v| v.as_array()) {
⋮----
.first()
.ok_or_else(|| {
⋮----
.as_u64()
⋮----
let instruction_error = arr.get(1).ok_or_else(|| {
⋮----
// Handle SDK version compatibility: if it's a v2-style
let err: InstructionError = if instruction_error.get("BorshIoError").is_some() {
from_value(serde_json::json!("BorshIoError"))
⋮----
from_value(instruction_error.clone())
⋮----
.map_err(|e| DeserializeError::custom(e.to_string()))?;
return Ok(UiTransactionError(TransactionError::InstructionError(
⋮----
let err = TransactionError::deserialize(value).map_err(de::Error::custom)?;
Ok(UiTransactionError(err))
⋮----
pub struct UiTransactionStatusMeta {
⋮----
fn from(meta: TransactionStatusMeta) -> Self {
⋮----
err: meta.status.clone().map_err(Into::into).err(),
status: meta.status.map_err(Into::into),
⋮----
.map(|ixs| ixs.into_iter().map(Into::into).collect())
.into(),
log_messages: meta.log_messages.into(),
⋮----
.map(|balance| balance.into_iter().map(Into::into).collect())
⋮----
rewards: meta.rewards.into(),
loaded_addresses: Some(UiLoadedAddresses::from(&meta.loaded_addresses)).into(),
⋮----
meta.return_data.map(|return_data| return_data.into()),
⋮----
pub struct UiTransactionReturnData {
⋮----
impl Default for UiTransactionReturnData {
fn default() -> Self {
⋮----
fn from(return_data: TransactionReturnData) -> Self {
⋮----
program_id: return_data.program_id.to_string(),
⋮----
BASE64_STANDARD.encode(return_data.data),
⋮----
pub enum UiReturnDataEncoding {
⋮----
pub struct UiLoadedAddresses {
⋮----
fn from(loaded_addresses: &LoadedAddresses) -> Self {
⋮----
.iter()
.map(ToString::to_string)
.collect(),
⋮----
pub struct TransactionTokenBalance {
⋮----
pub struct UiTransactionTokenBalance {
⋮----
fn from(token_balance: TransactionTokenBalance) -> Self {
⋮----
owner: if !token_balance.owner.is_empty() {
⋮----
program_id: if !token_balance.program_id.is_empty() {
⋮----
pub struct UiAccountsList {
⋮----
pub struct UiRawMessage {
⋮----
pub struct UiCompiledInstruction {
⋮----
impl UiCompiledInstruction {
pub fn from(instruction: &CompiledInstruction, stack_height: Option<u32>) -> Self {
⋮----
accounts: instruction.accounts.clone(),
data: bs58::encode(&instruction.data).into_string(),
⋮----
pub enum UiInstruction {
⋮----
pub enum UiParsedInstruction {
⋮----
pub struct UiPartiallyDecodedInstruction {
⋮----
pub struct ParsedInstruction {
⋮----
pub struct UiInnerInstructions {
⋮----
fn from(inner_instructions: InnerInstructions) -> Self {
⋮----
.map(
⋮----
pub struct InnerInstructions {
⋮----
pub struct InnerInstruction {
⋮----
pub struct TransactionStatusMeta {
⋮----
impl Default for TransactionStatusMeta {
⋮----
status: Ok(()),
⋮----
pre_balances: vec![],
post_balances: vec![],
⋮----
pub struct EncodedConfirmedBlock {
⋮----
fn from(block: UiConfirmedBlock) -> Self {
⋮----
transactions: block.transactions.unwrap_or_default(),
rewards: block.rewards.unwrap_or_default(),
⋮----
pub struct EncodedConfirmedTransactionWithStatusMeta {
⋮----
pub struct TransactionStatus {
⋮----
impl TransactionStatus {
pub fn satisfies_commitment(&self, commitment_config: CommitmentConfig) -> bool {
if commitment_config.is_finalized() {
self.confirmations.is_none()
} else if commitment_config.is_confirmed() {
⋮----
self.confirmations.is_some() && self.confirmations.unwrap() > 1
|| self.confirmations.is_none()
⋮----
pub fn confirmation_status(&self) -> TransactionConfirmationStatus {
⋮----
Some(status) => status.clone(),
⋮----
if self.confirmations.is_none() {
⋮----
} else if self.confirmations.unwrap() > 0 {
⋮----
mod test {
⋮----
fn test_decode_invalid_transaction() {
⋮----
.to_string(),
⋮----
assert!(unsanitary_transaction.decode().is_none());
⋮----
fn test_satisfies_commitment() {
⋮----
confirmation_status: Some(TransactionConfirmationStatus::Finalized),
⋮----
assert!(status.satisfies_commitment(CommitmentConfig::finalized()));
assert!(status.satisfies_commitment(CommitmentConfig::confirmed()));
assert!(status.satisfies_commitment(CommitmentConfig::processed()));
⋮----
confirmations: Some(10),
⋮----
confirmation_status: Some(TransactionConfirmationStatus::Confirmed),
⋮----
assert!(!status.satisfies_commitment(CommitmentConfig::finalized()));
⋮----
confirmations: Some(1),
⋮----
confirmation_status: Some(TransactionConfirmationStatus::Processed),
⋮----
assert!(!status.satisfies_commitment(CommitmentConfig::confirmed()));
⋮----
confirmations: Some(0),
⋮----
confirmations: Some(2),
⋮----
fn test_serde_empty_fields() {
fn test_serde<'de, T: serde::Serialize + serde::Deserialize<'de>>(
⋮----
let typed_meta: T = serde_json::from_str(json_input).unwrap();
let reserialized_value = json!(typed_meta);
⋮----
serde_json::from_str(expected_json_output).unwrap();
assert_eq!(reserialized_value, expected_json_output_value);
⋮----
fn test_serialize_ui_transaction_error(
⋮----
let actual_serialization = to_value(UiTransactionError(transaction_error))
.expect("Failed to serialize `UiTransactionError");
assert_eq!(actual_serialization, expected_serialization);
⋮----
fn test_deserialize_ui_transaction_error(
⋮----
.expect("Failed to deserialize `UiTransactionError");
assert_eq!(actual_transaction_error, expected_transaction_error);
⋮----
fn test_deserialize_instruction_error_string_format() {
⋮----
let error_json = to_value(&new_error).unwrap();
⋮----
assert!(matches!(
⋮----
to_value(serde_json::json!({"InstructionError": [0, {"BorshIoError": "Unknown"}]}))
.unwrap();

================
File: transaction-status-client-types/src/option_serializer.rs
================
pub enum OptionSerializer<T> {
⋮----
pub fn none() -> Self {
⋮----
pub fn skip() -> Self {
⋮----
pub fn should_skip(&self) -> bool {
matches!(self, Self::Skip)
⋮----
pub fn or_skip(option: Option<T>) -> Self {
⋮----
pub fn as_ref(&self) -> OptionSerializer<&T> {
⋮----
pub fn as_mut(&mut self) -> OptionSerializer<&mut T> {
⋮----
pub fn is_some(&self) -> bool {
matches!(*self, OptionSerializer::Some(_))
⋮----
pub fn is_none(&self) -> bool {
matches!(*self, OptionSerializer::None)
⋮----
pub fn is_skip(&self) -> bool {
matches!(*self, OptionSerializer::Skip)
⋮----
pub fn expect(self, msg: &str) -> T {
⋮----
_ => panic!("{}", msg),
⋮----
pub fn unwrap(self) -> T {
⋮----
panic!("called `OptionSerializer::unwrap()` on a `None` value")
⋮----
panic!("called `OptionSerializer::unwrap()` on a `Skip` value")
⋮----
pub fn unwrap_or(self, default: T) -> T {
⋮----
pub fn unwrap_or_else<F>(self, f: F) -> T
⋮----
_ => f(),
⋮----
pub fn map<U, F>(self, f: F) -> Option<U>
⋮----
OptionSerializer::Some(x) => Some(f(x)),
⋮----
pub fn map_or<U, F>(self, default: U, f: F) -> U
⋮----
OptionSerializer::Some(t) => f(t),
⋮----
pub fn map_or_else<U, D, F>(self, default: D, f: F) -> U
⋮----
_ => default(),
⋮----
pub fn filter<P>(self, predicate: P) -> Self
⋮----
if predicate(&x) {
⋮----
pub fn ok_or<E>(self, err: E) -> Result<T, E> {
⋮----
OptionSerializer::Some(v) => Ok(v),
_ => Err(err),
⋮----
pub fn ok_or_else<E, F>(self, err: F) -> Result<T, E>
⋮----
_ => Err(err()),
⋮----
fn from(option: Option<T>) -> Self {
⋮----
fn from(option: OptionSerializer<T>) -> Self {
⋮----
impl<T: Serialize> Serialize for OptionSerializer<T> {
fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
⋮----
Self::Some(item) => item.serialize(serializer),
Self::None => serializer.serialize_none(),
Self::Skip => Err(Error::custom("Skip variants should not be serialized")),
⋮----
fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
⋮----
Option::deserialize(deserializer).map(Into::into)

================
File: transaction-status-client-types/Cargo.toml
================
[package]
name = "solana-transaction-status-client-types"
description = "Core RPC client types for solana-transaction-status"
documentation = "https://docs.rs/solana-transaction-status-client-types"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
agave-unstable-api = []

[dependencies]
base64 = { workspace = true }
bincode = { workspace = true }
bs58 = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
solana-account-decoder-client-types = { workspace = true }
solana-commitment-config = { workspace = true }
solana-instruction = { workspace = true }
solana-message = { workspace = true }
solana-pubkey = { workspace = true }
solana-reward-info = { workspace = true, features = ["serde"] }
solana-signature = { workspace = true, default-features = false }
solana-transaction = { workspace = true, features = ["serde"] }
solana-transaction-context = { workspace = true }
solana-transaction-error = { workspace = true, features = ["serde"] }
thiserror = { workspace = true }

[dev-dependencies]
test-case = { workspace = true }

================
File: transaction-view/benches/bytes.rs
================
fn setup() -> Vec<(u16, usize, Vec<u8>)> {
let options = DefaultOptions::new().with_fixint_encoding();
⋮----
let short_u16 = ShortU16(value);
let mut buffer = vec![0u8; 16];
⋮----
.serialized_size(&short_u16)
.expect("Failed to get serialized size");
serialize_into(&mut buffer[..], &short_u16).expect("Serialization failed");
values.push((value, serialized_len as usize, buffer));
⋮----
fn bench_u16_parsing(c: &mut Criterion) {
let values_serialized_lengths_and_buffers = setup();
let mut group = c.benchmark_group("compressed_u16_parsing");
group.throughput(Throughput::Elements(
values_serialized_lengths_and_buffers.len() as u64,
⋮----
group.bench_function("short_u16_decode", |c| {
c.iter(|| {
decode_shortu16_len_iter(&values_serialized_lengths_and_buffers);
⋮----
group.bench_function("read_compressed_u16", |c| {
⋮----
read_compressed_u16_iter(&values_serialized_lengths_and_buffers);
⋮----
group.bench_function("optimized_read_compressed_u16", |c| {
⋮----
optimized_read_compressed_u16_iter(&values_serialized_lengths_and_buffers);
⋮----
fn decode_shortu16_len_iter(values_serialized_lengths_and_buffers: &[(u16, usize, Vec<u8>)]) {
for (value, serialized_len, buffer) in values_serialized_lengths_and_buffers.iter() {
let (read_value, bytes_read) = decode_shortu16_len(black_box(buffer)).unwrap();
assert_eq!(read_value, *value as usize, "Value mismatch for: {value}");
assert_eq!(bytes_read, *serialized_len, "Offset mismatch for: {value}");
⋮----
fn read_compressed_u16_iter(values_serialized_lengths_and_buffers: &[(u16, usize, Vec<u8>)]) {
⋮----
let read_value = read_compressed_u16(black_box(buffer), &mut offset).unwrap();
assert_eq!(read_value, *value, "Value mismatch for: {value}");
assert_eq!(offset, *serialized_len, "Offset mismatch for: {value}");
⋮----
fn optimized_read_compressed_u16_iter(
⋮----
let read_value = optimized_read_compressed_u16(black_box(buffer), &mut offset).unwrap();
⋮----
criterion_group!(benches, bench_u16_parsing);
criterion_main!(benches);

================
File: transaction-view/benches/transaction_view.rs
================
fn serialize_transactions(transactions: Vec<VersionedTransaction>) -> Vec<Vec<u8>> {
⋮----
.into_iter()
.map(|transaction| bincode::serialize(&transaction).unwrap())
.collect()
⋮----
fn bench_transactions_parsing(
⋮----
group.bench_function("VersionedTransaction", |c| {
c.iter(|| {
for bytes in serialized_transactions.iter() {
let _ = bincode::deserialize::<VersionedTransaction>(black_box(bytes)).unwrap();
⋮----
group.bench_function("SanitizedVersionedTransaction", |c| {
⋮----
let tx = bincode::deserialize::<VersionedTransaction>(black_box(bytes)).unwrap();
let _ = SanitizedVersionedTransaction::try_new(tx).unwrap();
⋮----
group.bench_function("TransactionView", |c| {
⋮----
let _ = TransactionView::try_new_unsanitized(black_box(bytes.as_ref())).unwrap();
⋮----
group.bench_function("TransactionView (Sanitized)", |c| {
⋮----
TransactionView::try_new_sanitized(black_box(bytes.as_ref()), true).unwrap();
⋮----
fn minimum_sized_transactions() -> Vec<VersionedTransaction> {
⋮----
.map(|_| {
⋮----
Some(&keypair.pubkey()),
⋮----
.unwrap()
⋮----
fn simple_transfers() -> Vec<VersionedTransaction> {
⋮----
&keypair.pubkey(),
⋮----
fn packed_transfers() -> Vec<VersionedTransaction> {
⋮----
&vec![(to_pubkey, 1); MAX_TRANSFERS_PER_TX],
⋮----
VersionedMessage::Legacy(Message::new(&ixs, Some(&keypair.pubkey()))),
⋮----
fn packed_noops() -> Vec<VersionedTransaction> {
⋮----
.map(|_| Instruction::new_with_bytes(program_id, &[], vec![]));
⋮----
fn packed_atls() -> Vec<VersionedTransaction> {
⋮----
account_keys: vec![keypair.pubkey()],
⋮----
instructions: vec![],
address_table_lookups: Vec::from_iter((0..MAX_ATLS_PER_TRANSACTION).map(
⋮----
writable_indexes: vec![0],
readonly_indexes: vec![],
⋮----
fn bench_parse_min_sized_transactions(c: &mut Criterion) {
let serialized_transactions = serialize_transactions(minimum_sized_transactions());
let mut group = c.benchmark_group("min sized transactions");
group.throughput(Throughput::Elements(serialized_transactions.len() as u64));
bench_transactions_parsing(&mut group, serialized_transactions);
⋮----
fn bench_parse_simple_transfers(c: &mut Criterion) {
let serialized_transactions = serialize_transactions(simple_transfers());
let mut group = c.benchmark_group("simple transfers");
⋮----
fn bench_parse_packed_transfers(c: &mut Criterion) {
let serialized_transactions = serialize_transactions(packed_transfers());
let mut group = c.benchmark_group("packed transfers");
⋮----
fn bench_parse_packed_noops(c: &mut Criterion) {
let serialized_transactions = serialize_transactions(packed_noops());
let mut group = c.benchmark_group("packed noops");
⋮----
fn bench_parse_packed_atls(c: &mut Criterion) {
let serialized_transactions = serialize_transactions(packed_atls());
let mut group = c.benchmark_group("packed atls");
⋮----
criterion_group!(
⋮----
criterion_main!(benches);

================
File: transaction-view/src/address_table_lookup_frame.rs
================
pub(crate) struct AddressTableLookupFrame {
⋮----
impl AddressTableLookupFrame {
⋮----
pub(crate) fn try_new(bytes: &[u8], offset: &mut usize) -> Result<Self> {
const _: () = assert!(MAX_ATLS_PER_PACKET & 0b1000_0000 == 0);
let num_address_table_lookups = read_byte(bytes, offset)?;
⋮----
return Err(TransactionViewError::ParseError);
⋮----
check_remaining(
⋮----
MIN_SIZED_ATL.wrapping_mul(usize::from(num_address_table_lookups)),
⋮----
assert!(u16::MAX as usize * MAX_ATLS_PER_PACKET as usize <= u32::MAX as usize);
⋮----
let num_write_accounts = optimized_read_compressed_u16(bytes, offset)?;
⋮----
total_writable_lookup_accounts.wrapping_add(u32::from(num_write_accounts));
⋮----
let num_read_accounts = optimized_read_compressed_u16(bytes, offset)?;
⋮----
total_readonly_lookup_accounts.wrapping_add(u32::from(num_read_accounts));
⋮----
Ok(Self {
⋮----
.map_err(|_| TransactionViewError::SanitizeError)?,
⋮----
pub struct AddressTableLookupIterator<'a> {
⋮----
impl<'a> Iterator for AddressTableLookupIterator<'a> {
type Item = SVMMessageAddressTableLookup<'a>;
⋮----
fn next(&mut self) -> Option<Self::Item> {
⋮----
self.index = self.index.wrapping_add(1);
// Each ATL has 3 pieces:
// 1. Address (Pubkey)
// 2. write indexes ([u8])
// 3. read indexes ([u8])
// Advance offset for address of the lookup table.
const _: () = assert!(core::mem::align_of::<Pubkey>() == 1, "Pubkey alignment");
// SAFETY:
// - The offset is checked to be valid in the slice.
// - The alignment of Pubkey is 1.
// - `Pubkey` is a byte array, it cannot be improperly initialized.
let account_key = unsafe { read_type::<Pubkey>(self.bytes, &mut self.offset) }.ok()?;
// Read the number of write indexes, and then update the offset.
⋮----
optimized_read_compressed_u16(self.bytes, &mut self.offset).ok()?;
const _: () = assert!(core::mem::align_of::<u8>() == 1, "u8 alignment");
⋮----
// - The offset is checked to be valid in the byte slice.
// - The alignment of u8 is 1.
// - The slice length is checked to be valid.
// - `u8` cannot be improperly initialized.
⋮----
.ok()?;
// Read the number of read indexes, and then update the offset.
⋮----
Some(SVMMessageAddressTableLookup {
⋮----
impl ExactSizeIterator for AddressTableLookupIterator<'_> {
fn len(&self) -> usize {
usize::from(self.num_address_table_lookups.wrapping_sub(self.index))
⋮----
impl Debug for AddressTableLookupIterator<'_> {
fn fmt(&self, f: &mut Formatter) -> core::fmt::Result {
f.debug_list().entries(self.clone()).finish()
⋮----
mod tests {
⋮----
fn test_zero_atls() {
let bytes = bincode::serialize(&ShortVec::<MessageAddressTableLookup>(vec![])).unwrap();
⋮----
let frame = AddressTableLookupFrame::try_new(&bytes, &mut offset).unwrap();
assert_eq!(frame.num_address_table_lookups, 0);
assert_eq!(frame.offset, 1);
assert_eq!(offset, bytes.len());
assert_eq!(frame.total_writable_lookup_accounts, 0);
assert_eq!(frame.total_readonly_lookup_accounts, 0);
⋮----
fn test_length_too_high() {
let mut bytes = bincode::serialize(&ShortVec::<MessageAddressTableLookup>(vec![])).unwrap();
⋮----
assert!(AddressTableLookupFrame::try_new(&bytes, &mut offset).is_err());
⋮----
fn test_single_atl() {
let bytes = bincode::serialize(&ShortVec::<MessageAddressTableLookup>(vec![
⋮----
.unwrap();
⋮----
assert_eq!(frame.num_address_table_lookups, 1);
⋮----
assert_eq!(frame.total_writable_lookup_accounts, 3);
assert_eq!(frame.total_readonly_lookup_accounts, 3);
⋮----
fn test_multiple_atls() {
⋮----
assert_eq!(frame.num_address_table_lookups, 2);
⋮----
assert_eq!(frame.total_writable_lookup_accounts, 6);
assert_eq!(frame.total_readonly_lookup_accounts, 5);
⋮----
fn test_invalid_writable_indexes_vec() {
let mut bytes = bincode::serialize(&ShortVec(vec![MessageAddressTableLookup {
⋮----
fn test_invalid_readonly_indexes_vec() {

================
File: transaction-view/src/bytes.rs
================
pub fn check_remaining(bytes: &[u8], offset: usize, num_bytes: usize) -> Result<()> {
if num_bytes > bytes.len().wrapping_sub(offset) {
Err(TransactionViewError::ParseError)
⋮----
Ok(())
⋮----
pub fn read_byte(bytes: &[u8], offset: &mut usize) -> Result<u8> {
⋮----
.get(*offset)
.copied()
.ok_or(TransactionViewError::ParseError);
*offset = offset.wrapping_add(1);
⋮----
pub unsafe fn unchecked_read_byte(bytes: &[u8], offset: &mut usize) -> u8 {
let value = unsafe { *bytes.get_unchecked(*offset) };
⋮----
pub fn read_compressed_u16(bytes: &[u8], offset: &mut usize) -> Result<u16> {
⋮----
.get(offset.wrapping_add(i))
.ok_or(TransactionViewError::ParseError)?;
⋮----
return Err(TransactionViewError::ParseError);
⋮----
shift = shift.wrapping_add(7);
⋮----
*offset = offset.wrapping_add(i).wrapping_add(1);
return Ok(result);
⋮----
*offset = offset.wrapping_add(3);
Ok(result)
⋮----
pub fn optimized_read_compressed_u16(bytes: &[u8], offset: &mut usize) -> Result<u16> {
⋮----
let byte1 = *bytes.get(*offset).ok_or(TransactionViewError::ParseError)?;
⋮----
.get(offset.wrapping_add(1))
⋮----
*offset = offset.wrapping_add(2);
⋮----
pub fn advance_offset_for_array<T: Sized>(
⋮----
let array_len_bytes = usize::from(num_elements).wrapping_mul(core::mem::size_of::<T>());
check_remaining(bytes, *offset, array_len_bytes)?;
*offset = offset.wrapping_add(array_len_bytes);
⋮----
pub fn advance_offset_for_type<T: Sized>(bytes: &[u8], offset: &mut usize) -> Result<()> {
⋮----
check_remaining(bytes, *offset, type_size)?;
*offset = offset.wrapping_add(type_size);
⋮----
pub unsafe fn read_slice_data<'a, T: Sized>(
⋮----
let current_ptr = unsafe { bytes.as_ptr().add(*offset) };
⋮----
Ok(unsafe { core::slice::from_raw_parts(current_ptr as *const T, usize::from(num_elements)) })
⋮----
/// Return a reference to the next slice of `T` in the buffer,
/// and advancing the offset.
⋮----
/// and advancing the offset.
///
⋮----
///
/// * `bytes` - Slice of bytes to read from.
⋮----
/// * `bytes` - Slice of bytes to read from.
/// * `offset` - Current offset into `bytes`.
⋮----
/// * `offset` - Current offset into `bytes`.
/// * `num_elements` - Number of `T` elements in the slice.
⋮----
/// * `num_elements` - Number of `T` elements in the slice.
///
⋮----
///
/// # Safety
⋮----
/// # Safety
/// 1. `bytes` must be a valid slice of bytes.
⋮----
/// 1. `bytes` must be a valid slice of bytes.
/// 2. `offset` must be a valid offset into `bytes`.
⋮----
/// 2. `offset` must be a valid offset into `bytes`.
/// 3. `bytes + offset` must be properly aligned for `T`.
⋮----
/// 3. `bytes + offset` must be properly aligned for `T`.
/// 4. `T` slice must be validly initialized.
⋮----
/// 4. `T` slice must be validly initialized.
/// 5. The size of `T` is small enough such that a usize will not overflow if
⋮----
/// 5. The size of `T` is small enough such that a usize will not overflow if
///    given the maximum slice size (u16::MAX).
⋮----
///    given the maximum slice size (u16::MAX).
#[inline(always)]
pub unsafe fn unchecked_read_slice_data<'a, T: Sized>(
⋮----
pub unsafe fn read_type<'a, T: Sized>(bytes: &'a [u8], offset: &mut usize) -> Result<&'a T> {
⋮----
Ok(unsafe { &*(current_ptr as *const T) })
⋮----
mod tests {
⋮----
fn test_check_remaining() {
// Empty buffer checks
assert!(check_remaining(&[], 0, 0).is_ok());
assert!(check_remaining(&[], 0, 1).is_err());
// Buffer with data checks
assert!(check_remaining(&[1, 2, 3], 0, 0).is_ok());
assert!(check_remaining(&[1, 2, 3], 0, 1).is_ok());
assert!(check_remaining(&[1, 2, 3], 0, 3).is_ok());
assert!(check_remaining(&[1, 2, 3], 0, 4).is_err());
// Non-zero offset.
assert!(check_remaining(&[1, 2, 3], 1, 0).is_ok());
assert!(check_remaining(&[1, 2, 3], 1, 1).is_ok());
assert!(check_remaining(&[1, 2, 3], 1, 2).is_ok());
assert!(check_remaining(&[1, 2, 3], 1, usize::MAX).is_err());
⋮----
fn test_read_byte() {
⋮----
assert_eq!(read_byte(&bytes, &mut offset), Ok(5));
assert_eq!(offset, 1);
assert_eq!(read_byte(&bytes, &mut offset), Ok(6));
assert_eq!(offset, 2);
assert_eq!(read_byte(&bytes, &mut offset), Ok(7));
assert_eq!(offset, 3);
assert!(read_byte(&bytes, &mut offset).is_err());
⋮----
fn test_read_compressed_u16() {
⋮----
let options = DefaultOptions::new().with_fixint_encoding(); // Ensure fixed-int encoding
// Test all possible u16 values
⋮----
let short_u16 = ShortU16(value);
// Serialize the value into the buffer
serialize_into(&mut buffer[..], &short_u16).expect("Serialization failed");
// Use bincode's size calculation to determine the length of the serialized data
⋮----
.serialized_size(&short_u16)
.expect("Failed to get serialized size");
⋮----
let read_value = read_compressed_u16(&buffer, &mut offset);
assert_eq!(read_value, Ok(value), "Value mismatch for: {value}");
assert_eq!(
⋮----
assert_eq!(Ok(0), read_compressed_u16(&[0; 3], &mut 0));
assert!(read_compressed_u16(&[0xFF, 0xFF, 0x04], &mut 0).is_err());
⋮----
assert!(read_compressed_u16(&[u8::MAX; 1], &mut 0).is_err());
assert!(read_compressed_u16(&[u8::MAX; 2], &mut 0).is_err());
assert!(read_compressed_u16(&[0x81, 0x80, 0x00], &mut 0).is_err());
⋮----
fn test_optimized_read_compressed_u16() {
⋮----
let options = DefaultOptions::new().with_fixint_encoding();
⋮----
let read_value = optimized_read_compressed_u16(&buffer, &mut offset);
⋮----
assert_eq!(Ok(0), optimized_read_compressed_u16(&[0; 3], &mut 0));
assert!(optimized_read_compressed_u16(&[0xFF, 0xFF, 0x04], &mut 0).is_err());
assert!(optimized_read_compressed_u16(&[0xFF, 0x80], &mut 0).is_err());
assert!(optimized_read_compressed_u16(&[u8::MAX; 1], &mut 0).is_err());
assert!(optimized_read_compressed_u16(&[u8::MAX; 2], &mut 0).is_err());
assert!(optimized_read_compressed_u16(&[0x81, 0x00], &mut 0).is_err());
⋮----
fn test_advance_offset_for_array() {
⋮----
struct MyStruct {
⋮----
const _: () = assert!(core::mem::size_of::<MyStruct>() == 2);
⋮----
assert!(advance_offset_for_array::<MyStruct>(&bytes, &mut offset, 1).is_err());
⋮----
assert!(advance_offset_for_array::<MyStruct>(&bytes, &mut offset, 2).is_ok());
assert_eq!(offset, 4);
⋮----
fn test_advance_offset_for_type() {
⋮----
assert!(advance_offset_for_type::<MyStruct>(&bytes, &mut offset).is_err());
⋮----
assert!(advance_offset_for_type::<MyStruct>(&bytes, &mut offset).is_ok());

================
File: transaction-view/src/instructions_frame.rs
================
pub(crate) struct InstructionsFrame {
⋮----
pub(crate) struct InstructionFrame {
⋮----
impl InstructionsFrame {
⋮----
pub(crate) fn try_new(bytes: &[u8], offset: &mut usize) -> Result<Self> {
let num_instructions = optimized_read_compressed_u16(bytes, offset)?;
check_remaining(
⋮----
3usize.wrapping_mul(usize::from(num_instructions)),
⋮----
let _program_id_index = read_byte(bytes, offset)?;
⋮----
let num_accounts = optimized_read_compressed_u16(bytes, offset)?;
let num_accounts_len = offset.wrapping_sub(num_accounts_offset) as u8;
⋮----
let data_len = optimized_read_compressed_u16(bytes, offset)?;
let data_len_len = offset.wrapping_sub(data_len_offset) as u8;
⋮----
frames.push(InstructionFrame {
⋮----
Ok(Self {
⋮----
pub struct InstructionsIterator<'a> {
⋮----
impl<'a> Iterator for InstructionsIterator<'a> {
type Item = SVMInstruction<'a>;
⋮----
fn next(&mut self) -> Option<Self::Item> {
⋮----
self.index = self.index.wrapping_add(1);
let program_id_index = unsafe { unchecked_read_byte(self.bytes, &mut self.offset) };
self.offset = self.offset.wrapping_add(usize::from(num_accounts_len));
const _: () = assert!(core::mem::align_of::<u8>() == 1, "u8 alignment");
⋮----
self.offset = self.offset.wrapping_add(usize::from(data_len_len));
⋮----
Some(SVMInstruction {
⋮----
impl ExactSizeIterator for InstructionsIterator<'_> {
fn len(&self) -> usize {
usize::from(self.num_instructions.wrapping_sub(self.index))
⋮----
impl Debug for InstructionsIterator<'_> {
fn fmt(&self, f: &mut Formatter) -> core::fmt::Result {
f.debug_list().entries(self.clone()).finish()
⋮----
mod tests {
⋮----
fn test_zero_instructions() {
let bytes = bincode::serialize(&ShortVec(Vec::<CompiledInstruction>::new())).unwrap();
⋮----
let instructions_frame = InstructionsFrame::try_new(&bytes, &mut offset).unwrap();
assert_eq!(instructions_frame.num_instructions, 0);
assert_eq!(instructions_frame.offset, 1);
assert_eq!(offset, bytes.len());
⋮----
fn test_num_instructions_too_high() {
let mut bytes = bincode::serialize(&ShortVec(vec![CompiledInstruction {
⋮----
.unwrap();
⋮----
assert!(InstructionsFrame::try_new(&bytes, &mut offset).is_err());
⋮----
fn test_single_instruction() {
let bytes = bincode::serialize(&ShortVec(vec![CompiledInstruction {
⋮----
assert_eq!(instructions_frame.num_instructions, 1);
⋮----
fn test_multiple_instructions() {
let bytes = bincode::serialize(&ShortVec(vec![
⋮----
assert_eq!(instructions_frame.num_instructions, 2);
⋮----
fn test_invalid_instruction_accounts_vec() {
⋮----
fn test_invalid_instruction_data_vec() {

================
File: transaction-view/src/lib.rs
================
pub mod bytes;
⋮----
mod bytes;
mod address_table_lookup_frame;
mod instructions_frame;
mod message_header_frame;
pub mod resolved_transaction_view;
pub mod result;
mod sanitize;
mod signature_frame;
pub mod static_account_keys_frame;
pub mod transaction_data;
mod transaction_frame;
pub mod transaction_version;
pub mod transaction_view;

================
File: transaction-view/src/message_header_frame.rs
================
pub(crate) struct MessageHeaderFrame {
⋮----
impl MessageHeaderFrame {
⋮----
pub(crate) fn try_new(bytes: &[u8], offset: &mut usize) -> Result<Self> {
⋮----
let message_prefix = read_byte(bytes, offset)?;
⋮----
0 => (TransactionVersion::V0, read_byte(bytes, offset)?),
_ => return Err(TransactionViewError::ParseError),
⋮----
let num_readonly_signed_accounts = read_byte(bytes, offset)?;
let num_readonly_unsigned_accounts = read_byte(bytes, offset)?;
Ok(Self {
⋮----
mod tests {
⋮----
fn test_invalid_version() {
⋮----
assert!(MessageHeaderFrame::try_new(&bytes, &mut offset).is_err());
⋮----
fn test_legacy_transaction_missing_header_byte() {
⋮----
fn test_legacy_transaction_valid() {
⋮----
let header = MessageHeaderFrame::try_new(&bytes, &mut offset).unwrap();
assert!(matches!(header.version, TransactionVersion::Legacy));
assert_eq!(header.num_required_signatures, 5);
assert_eq!(header.num_readonly_signed_accounts, 1);
assert_eq!(header.num_readonly_unsigned_accounts, 2);
⋮----
fn test_v0_transaction_missing_header_byte() {
⋮----
fn test_v0_transaction_valid() {
⋮----
assert!(matches!(header.version, TransactionVersion::V0));

================
File: transaction-view/src/resolved_transaction_view.rs
================
pub struct ResolvedTransactionView<D: TransactionData> {
⋮----
impl<D: TransactionData> Deref for ResolvedTransactionView<D> {
type Target = TransactionView<true, D>;
fn deref(&self) -> &Self::Target {
⋮----
pub fn try_new(
⋮----
let resolved_addresses_ref = resolved_addresses.as_ref();
if matches!(view.version(), TransactionVersion::V0) && resolved_addresses_ref.is_none() {
return Err(TransactionViewError::AddressLookupMismatch);
⋮----
if loaded_addresses.writable.len() != usize::from(view.total_writable_lookup_accounts())
|| loaded_addresses.readonly.len()
!= usize::from(view.total_readonly_lookup_accounts())
⋮----
} else if view.total_writable_lookup_accounts() != 0
|| view.total_readonly_lookup_accounts() != 0
⋮----
Ok(Self {
⋮----
fn cache_is_writable(
⋮----
let account_keys = AccountKeys::new(view.static_account_keys(), resolved_addresses);
⋮----
let num_static_account_keys = usize::from(view.num_static_account_keys());
let num_writable_lookup_accounts = usize::from(view.total_writable_lookup_accounts());
let num_signed_accounts = usize::from(view.num_required_signatures());
⋮----
usize::from(view.num_writable_unsigned_static_accounts());
⋮----
usize::from(view.num_writable_signed_static_accounts());
for (index, key) in account_keys.iter().enumerate() {
⋮----
let loaded_address_index = index.wrapping_sub(num_static_account_keys);
⋮----
let unsigned_account_index = index.wrapping_sub(num_signed_accounts);
⋮----
is_writable_cache[index] = is_requested_write && !reserved_account_keys.contains(key);
⋮----
for ix in view.instructions_iter() {
⋮----
&& !*is_upgradable_loader_present.get_or_insert_with(|| {
for key in account_keys.iter() {
⋮----
pub fn loaded_addresses(&self) -> Option<&LoadedAddresses> {
self.resolved_addresses.as_ref()
⋮----
pub fn into_view(self) -> TransactionView<true, D> {
⋮----
impl<D: TransactionData> SVMStaticMessage for ResolvedTransactionView<D> {
fn num_transaction_signatures(&self) -> u64 {
u64::from(self.view.num_required_signatures())
⋮----
fn num_write_locks(&self) -> u64 {
self.view.num_requested_write_locks()
⋮----
fn recent_blockhash(&self) -> &Hash {
self.view.recent_blockhash()
⋮----
fn num_instructions(&self) -> usize {
usize::from(self.view.num_instructions())
⋮----
fn instructions_iter(&self) -> impl Iterator<Item = SVMInstruction<'_>> {
self.view.instructions_iter()
⋮----
fn program_instructions_iter(
⋮----
self.view.program_instructions_iter()
⋮----
fn static_account_keys(&self) -> &[Pubkey] {
self.view.static_account_keys()
⋮----
fn fee_payer(&self) -> &Pubkey {
&self.view.static_account_keys()[0]
⋮----
fn num_lookup_tables(&self) -> usize {
usize::from(self.view.num_address_table_lookups())
⋮----
fn message_address_table_lookups(
⋮----
self.view.address_table_lookup_iter()
⋮----
impl<D: TransactionData> SVMMessage for ResolvedTransactionView<D> {
fn account_keys(&self) -> AccountKeys<'_> {
⋮----
self.view.static_account_keys(),
self.resolved_addresses.as_ref(),
⋮----
fn is_writable(&self, index: usize) -> bool {
self.writable_cache.get(index).copied().unwrap_or(false)
⋮----
fn is_signer(&self, index: usize) -> bool {
index < usize::from(self.view.num_required_signatures())
⋮----
fn is_invoked(&self, key_index: usize) -> bool {
⋮----
.instructions_iter()
.any(|ix| ix.program_id_index == index)
⋮----
impl<D: TransactionData> SVMTransaction for ResolvedTransactionView<D> {
fn signature(&self) -> &Signature {
&self.view.signatures()[0]
⋮----
fn signatures(&self) -> &[Signature] {
self.view.signatures()
⋮----
impl<D: TransactionData> Debug for ResolvedTransactionView<D> {
fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
f.debug_struct("ResolvedTransactionView")
.field("view", &self.view)
.finish()
⋮----
mod tests {
⋮----
fn test_expected_loaded_addresses() {
let static_keys = vec![Pubkey::new_unique(), Pubkey::new_unique()];
⋮----
signatures: vec![Signature::default()],
⋮----
instructions: vec![],
⋮----
address_table_lookups: vec![MessageAddressTableLookup {
⋮----
let bytes = bincode::serialize(&transaction).unwrap();
let view = SanitizedTransactionView::try_new_sanitized(bytes.as_ref(), true).unwrap();
⋮----
assert!(matches!(
⋮----
fn test_unexpected_loaded_addresses() {
⋮----
writable: vec![Pubkey::new_unique()],
readonly: vec![],
⋮----
address_table_lookups: vec![],
⋮----
ResolvedTransactionView::try_new(view, Some(loaded_addresses), &HashSet::default());
⋮----
fn test_mismatched_loaded_address_lengths() {
⋮----
fn test_is_writable() {
⋮----
account_keys: static_keys[..2].to_vec(),
⋮----
let static_keys = vec![sysvar::clock::id(), key0];
⋮----
writable: vec![key1],
readonly: vec![key2],
⋮----
let transaction = create_transaction_with_keys(static_keys, &loaded_addresses);
⋮----
Some(loaded_addresses),
⋮----
.unwrap();
let expected = vec![false, false, true, false];
for (index, expected) in expected.into_iter().enumerate() {
assert_eq!(resolved_view.is_writable(index), expected);
⋮----
let static_keys = vec![system_program::id(), key0];
⋮----
let static_keys = vec![key0, key1];
⋮----
writable: vec![system_program::id()],
⋮----
let expected = vec![true, false, false, false];
⋮----
fn test_demote_writable_program() {
⋮----
writable: vec![key3, key4],
⋮----
instructions: vec![CompiledInstruction {
⋮----
let static_keys = vec![key0, key1, key2];
let transaction = create_transaction_with_static_keys(static_keys, &loaded_addresses);
⋮----
Some(loaded_addresses.clone()),
⋮----
let expected = vec![true, false, true, true, true];
⋮----
let static_keys = vec![key0, key1, bpf_loader_upgradeable::ID];
⋮----
let expected = vec![true, true, true, true, true];
⋮----
writable: vec![key3],
readonly: vec![bpf_loader_upgradeable::ID],
⋮----
let expected = vec![true, true, true, true, false];

================
File: transaction-view/src/result.rs
================
pub enum TransactionViewError {
⋮----
pub type Result<T> = core::result::Result<T, TransactionViewError>;

================
File: transaction-view/src/sanitize.rs
================
pub(crate) fn sanitize(
⋮----
sanitize_signatures(view)?;
sanitize_account_access(view)?;
sanitize_instructions(view, enable_static_instruction_limit)?;
sanitize_address_table_lookups(view)
⋮----
fn sanitize_signatures(view: &UnsanitizedTransactionView<impl TransactionData>) -> Result<()> {
if view.num_signatures() != view.num_required_signatures() {
return Err(TransactionViewError::SanitizeError);
⋮----
if view.num_static_account_keys() < view.num_signatures() {
⋮----
Ok(())
⋮----
fn sanitize_account_access(view: &UnsanitizedTransactionView<impl TransactionData>) -> Result<()> {
if view.num_readonly_unsigned_static_accounts()
⋮----
.num_static_account_keys()
.wrapping_sub(view.num_required_signatures())
⋮----
if view.num_readonly_signed_static_accounts() >= view.num_required_signatures() {
⋮----
if total_number_of_accounts(view) > 256 {
⋮----
fn sanitize_instructions(
⋮----
&& usize::from(view.num_instructions())
⋮----
let max_program_id_index = view.num_static_account_keys().wrapping_sub(1);
let max_account_index = total_number_of_accounts(view).wrapping_sub(1) as u8;
for instruction in view.instructions_iter() {
⋮----
for account_index in instruction.accounts.iter().copied() {
⋮----
fn sanitize_address_table_lookups(
⋮----
for address_table_lookup in view.address_table_lookup_iter() {
if address_table_lookup.writable_indexes.is_empty()
&& address_table_lookup.readonly_indexes.is_empty()
⋮----
fn total_number_of_accounts(view: &UnsanitizedTransactionView<impl TransactionData>) -> u16 {
u16::from(view.num_static_account_keys())
.saturating_add(view.total_writable_lookup_accounts())
.saturating_add(view.total_readonly_lookup_accounts())
⋮----
mod tests {
⋮----
fn create_legacy_transaction(
⋮----
signatures: vec![Signature::default(); num_signatures as usize],
⋮----
fn create_v0_transaction(
⋮----
fn multiple_transfers() -> VersionedTransaction {
⋮----
signatures: vec![Signature::default()],
⋮----
Some(&payer),
⋮----
fn test_sanitize_multiple_transfers() {
let transaction = multiple_transfers();
let data = bincode::serialize(&transaction).unwrap();
let view = TransactionView::try_new_unsanitized(data.as_ref()).unwrap();
assert!(view.sanitize(true).is_ok());
⋮----
fn test_sanitize_signatures() {
⋮----
let transaction = create_legacy_transaction(
⋮----
(0..3).map(|_| Pubkey::new_unique()).collect(),
vec![],
⋮----
assert_eq!(
⋮----
(0..1).map(|_| Pubkey::new_unique()).collect(),
⋮----
let transaction = create_v0_transaction(
⋮----
vec![MessageAddressTableLookup {
⋮----
fn test_sanitize_account_access() {
⋮----
(0..2).map(|_| Pubkey::new_unique()).collect(),
⋮----
vec![
⋮----
fn test_sanitize_instructions() {
⋮----
let account_keys = vec![
⋮----
let valid_instructions = vec![
⋮----
let atls = vec![MessageAddressTableLookup {
⋮----
account_keys.clone(),
valid_instructions.clone(),
⋮----
assert!(sanitize_instructions(&view, true).is_ok());
⋮----
atls.clone(),
⋮----
for instruction_index in 0..valid_instructions.len() {
⋮----
let mut instructions = valid_instructions.clone();
instructions[instruction_index].program_id_index = account_keys.len() as u8;
⋮----
.push(account_keys.len() as u8);
⋮----
atls[0].writable_indexes.len() + atls[0].readonly_indexes.len();
let total_accounts = (account_keys.len() + num_lookup_accounts) as u8;
⋮----
.push(total_accounts);
⋮----
.iter()
.cycle()
.take(65)
.cloned()
.collect();
⋮----
too_many_instructions.clone(),
⋮----
assert!(sanitize_instructions(&view, false).is_ok());
⋮----
fn test_sanitize_address_table_lookups() {
fn create_transaction(empty_index: usize) -> VersionedTransaction {
⋮----
let mut address_table_lookups = vec![
⋮----
address_table_lookups[empty_index].writable_indexes.clear();
create_v0_transaction(
⋮----
vec![payer],
⋮----
let transaction = create_transaction(empty_index);

================
File: transaction-view/src/signature_frame.rs
================
pub(crate) struct SignatureFrame {
⋮----
impl SignatureFrame {
⋮----
pub(crate) fn try_new(bytes: &[u8], offset: &mut usize) -> Result<Self> {
const _: () = assert!(MAX_SIGNATURES_PER_PACKET & 0b1000_0000 == 0);
let num_signatures = read_byte(bytes, offset)?;
⋮----
return Err(TransactionViewError::ParseError);
⋮----
Ok(Self {
⋮----
mod tests {
⋮----
fn test_zero_signatures() {
let bytes = bincode::serialize(&ShortVec(Vec::<Signature>::new())).unwrap();
⋮----
assert!(SignatureFrame::try_new(&bytes, &mut offset).is_err());
⋮----
fn test_one_signature() {
let bytes = bincode::serialize(&ShortVec(vec![Signature::default()])).unwrap();
⋮----
let frame = SignatureFrame::try_new(&bytes, &mut offset).unwrap();
assert_eq!(frame.num_signatures, 1);
assert_eq!(frame.offset, 1);
assert_eq!(offset, 1 + core::mem::size_of::<Signature>());
⋮----
fn test_max_signatures() {
let signatures = vec![Signature::default(); usize::from(MAX_SIGNATURES_PER_PACKET)];
let bytes = bincode::serialize(&ShortVec(signatures)).unwrap();
⋮----
assert_eq!(frame.num_signatures, 12);
⋮----
assert_eq!(offset, 1 + 12 * core::mem::size_of::<Signature>());
⋮----
fn test_non_zero_offset() {
let mut bytes = bincode::serialize(&ShortVec(vec![Signature::default()])).unwrap();
bytes.insert(0, 0);
⋮----
assert_eq!(frame.offset, 2);
assert_eq!(offset, 2 + core::mem::size_of::<Signature>());
⋮----
fn test_too_many_signatures() {
let signatures = vec![Signature::default(); usize::from(MAX_SIGNATURES_PER_PACKET) + 1];
⋮----
fn test_u16_max_signatures() {
let signatures = vec![Signature::default(); u16::MAX as usize];

================
File: transaction-view/src/static_account_keys_frame.rs
================
pub(crate) struct StaticAccountKeysFrame {
⋮----
impl StaticAccountKeysFrame {
⋮----
pub(crate) fn try_new(bytes: &[u8], offset: &mut usize) -> Result<Self> {
const _: () = assert!(MAX_STATIC_ACCOUNTS_PER_PACKET & 0b1000_0000 == 0);
let num_static_accounts = read_byte(bytes, offset)?;
⋮----
return Err(TransactionViewError::ParseError);
⋮----
Ok(Self {
⋮----
mod tests {
⋮----
fn test_zero_accounts() {
let bytes = bincode::serialize(&ShortVec(Vec::<Pubkey>::new())).unwrap();
⋮----
assert!(StaticAccountKeysFrame::try_new(&bytes, &mut offset).is_err());
⋮----
fn test_one_account() {
let bytes = bincode::serialize(&ShortVec(vec![Pubkey::default()])).unwrap();
⋮----
let frame = StaticAccountKeysFrame::try_new(&bytes, &mut offset).unwrap();
assert_eq!(frame.num_static_accounts, 1);
assert_eq!(frame.offset, 1);
assert_eq!(offset, 1 + core::mem::size_of::<Pubkey>());
⋮----
fn test_max_accounts() {
let signatures = vec![Pubkey::default(); usize::from(MAX_STATIC_ACCOUNTS_PER_PACKET)];
let bytes = bincode::serialize(&ShortVec(signatures)).unwrap();
⋮----
assert_eq!(frame.num_static_accounts, 38);
⋮----
assert_eq!(offset, 1 + 38 * core::mem::size_of::<Pubkey>());
⋮----
fn test_too_many_accounts() {
let signatures = vec![Pubkey::default(); usize::from(MAX_STATIC_ACCOUNTS_PER_PACKET) + 1];
⋮----
fn test_u16_max_accounts() {
let signatures = vec![Pubkey::default(); u16::MAX as usize];

================
File: transaction-view/src/transaction_data.rs
================
pub trait TransactionData {
⋮----
impl TransactionData for &[u8] {
⋮----
fn data(&self) -> &[u8] {
⋮----
impl TransactionData for std::sync::Arc<Vec<u8>> {
⋮----
self.as_ref()

================
File: transaction-view/src/transaction_frame.rs
================
pub(crate) struct TransactionFrame {
⋮----
impl TransactionFrame {
pub(crate) fn try_new(bytes: &[u8]) -> Result<Self> {
⋮----
if offset != bytes.len() {
return Err(TransactionViewError::ParseError);
⋮----
Ok(Self {
⋮----
pub(crate) fn num_signatures(&self) -> u8 {
⋮----
pub(crate) fn version(&self) -> TransactionVersion {
⋮----
pub(crate) fn num_required_signatures(&self) -> u8 {
⋮----
pub(crate) fn num_readonly_signed_static_accounts(&self) -> u8 {
⋮----
pub(crate) fn num_readonly_unsigned_static_accounts(&self) -> u8 {
⋮----
pub(crate) fn num_static_account_keys(&self) -> u8 {
⋮----
pub(crate) fn num_instructions(&self) -> u16 {
⋮----
pub(crate) fn num_address_table_lookups(&self) -> u8 {
⋮----
pub(crate) fn total_writable_lookup_accounts(&self) -> u16 {
⋮----
pub(crate) fn total_readonly_lookup_accounts(&self) -> u16 {
⋮----
pub(crate) fn message_offset(&self) -> u16 {
⋮----
pub(crate) unsafe fn signatures<'a>(&self, bytes: &'a [u8]) -> &'a [Signature] {
// Verify at compile time there are no alignment constraints.
const _: () = assert!(
⋮----
// The length of the slice is not greater than isize::MAX.
⋮----
assert!(u8::MAX as usize * core::mem::size_of::<Signature>() <= isize::MAX as usize);
// SAFETY:
// - If this `TransactionFrame` was created from `bytes`:
//     - the pointer is valid for the range and is properly aligned.
// - `num_signatures` has been verified against the bounds if
//   `TransactionFrame` was created successfully.
// - `Signature` are just byte arrays; there is no possibility the
//   `Signature` are not initialized properly.
// - The lifetime of the returned slice is the same as the input
//   `bytes`. This means it will not be mutated or deallocated while
//   holding the slice.
// - The length does not overflow `isize`.
⋮----
bytes.as_ptr().add(usize::from(self.signature.offset)) as *const Signature,
⋮----
/// Return the slice of static account keys in the transaction.
    ///
⋮----
///
    /// # Safety
⋮----
/// # Safety
    ///  - This function must be called with the same `bytes` slice that was
⋮----
///  - This function must be called with the same `bytes` slice that was
    ///    used to create the `TransactionFrame` instance.
⋮----
///    used to create the `TransactionFrame` instance.
    #[inline]
pub(crate) unsafe fn static_account_keys<'a>(&self, bytes: &'a [u8]) -> &'a [Pubkey] {
const _: () = assert!(core::mem::align_of::<Pubkey>() == 1, "Pubkey alignment");
⋮----
assert!(u8::MAX as usize * core::mem::size_of::<Pubkey>() <= isize::MAX as usize);
⋮----
.as_ptr()
.add(usize::from(self.static_account_keys.offset))
⋮----
pub(crate) unsafe fn recent_blockhash<'a>(&self, bytes: &'a [u8]) -> &'a Hash {
⋮----
const _: () = assert!(core::mem::align_of::<Hash>() == 1, "Hash alignment");
⋮----
// - The pointer is correctly aligned (no alignment constraints).
// - `Hash` is just a byte array; there is no possibility the `Hash`
//   is not initialized properly.
// - Aliasing rules are respected because the lifetime of the returned
//   reference is the same as the input/source `bytes`.
⋮----
.add(usize::from(self.recent_blockhash_offset)) as *const Hash)
⋮----
/// Return an iterator over the instructions in the transaction.
    /// # Safety
⋮----
/// # Safety
    /// - This function must be called with the same `bytes` slice that was
⋮----
/// - This function must be called with the same `bytes` slice that was
    ///   used to create the `TransactionFrame` instance.
⋮----
///   used to create the `TransactionFrame` instance.
    #[inline]
pub(crate) unsafe fn instructions_iter<'a>(
⋮----
/// Return an iterator over the address table lookups in the transaction.
    /// # Safety
⋮----
pub(crate) unsafe fn address_table_lookup_iter<'a>(
⋮----
mod tests {
⋮----
fn verify_transaction_view_frame(tx: &VersionedTransaction) {
let bytes = bincode::serialize(tx).unwrap();
let frame = TransactionFrame::try_new(&bytes).unwrap();
assert_eq!(frame.signature.num_signatures, tx.signatures.len() as u8);
assert_eq!(frame.signature.offset as usize, 1);
assert_eq!(
⋮----
fn minimally_sized_transaction() -> VersionedTransaction {
⋮----
signatures: vec![Signature::default()],
⋮----
account_keys: vec![Pubkey::default()],
⋮----
instructions: vec![],
⋮----
fn simple_transfer() -> VersionedTransaction {
⋮----
Some(&payer),
⋮----
fn simple_transfer_v0() -> VersionedTransaction {
⋮----
.unwrap(),
⋮----
fn multiple_transfers() -> VersionedTransaction {
⋮----
fn v0_with_single_lookup() -> VersionedTransaction {
⋮----
addresses: vec![to],
⋮----
fn v0_with_multiple_lookups() -> VersionedTransaction {
⋮----
addresses: vec![to1],
⋮----
addresses: vec![to2],
⋮----
fn test_minimal_sized_transaction() {
verify_transaction_view_frame(&minimally_sized_transaction());
⋮----
fn test_simple_transfer() {
verify_transaction_view_frame(&simple_transfer());
⋮----
fn test_simple_transfer_v0() {
verify_transaction_view_frame(&simple_transfer_v0());
⋮----
fn test_v0_with_lookup() {
verify_transaction_view_frame(&v0_with_single_lookup());
⋮----
fn test_trailing_byte() {
let tx = simple_transfer();
let mut bytes = bincode::serialize(&tx).unwrap();
bytes.push(0);
assert!(TransactionFrame::try_new(&bytes).is_err());
⋮----
fn test_insufficient_bytes() {
⋮----
let bytes = bincode::serialize(&tx).unwrap();
assert!(TransactionFrame::try_new(&bytes[..bytes.len().wrapping_sub(1)]).is_err());
⋮----
fn test_signature_overflow() {
⋮----
fn test_account_key_overflow() {
⋮----
fn test_instructions_overflow() {
⋮----
fn test_alt_overflow() {
let tx = simple_transfer_v0();
let ix_bytes = tx.message.instructions()[0].data.len();
⋮----
fn test_basic_accessors() {
⋮----
assert_eq!(frame.num_signatures(), 1);
assert!(matches!(frame.version(), TransactionVersion::Legacy));
assert_eq!(frame.num_required_signatures(), 1);
assert_eq!(frame.num_readonly_signed_static_accounts(), 0);
assert_eq!(frame.num_readonly_unsigned_static_accounts(), 1);
assert_eq!(frame.num_static_account_keys(), 3);
assert_eq!(frame.num_instructions(), 1);
assert_eq!(frame.num_address_table_lookups(), 0);
⋮----
let signatures = frame.signatures(&bytes);
assert_eq!(signatures, &tx.signatures);
let static_account_keys = frame.static_account_keys(&bytes);
assert_eq!(static_account_keys, tx.message.static_account_keys());
let recent_blockhash = frame.recent_blockhash(&bytes);
assert_eq!(recent_blockhash, tx.message.recent_blockhash());
⋮----
fn test_instructions_iter_empty() {
let tx = minimally_sized_transaction();
⋮----
let mut iter = frame.instructions_iter(&bytes);
assert!(iter.next().is_none());
⋮----
fn test_instructions_iter_single() {
⋮----
let ix = iter.next().unwrap();
assert_eq!(ix.program_id_index, 2);
assert_eq!(ix.accounts, &[0, 1]);
⋮----
fn test_instructions_iter_multiple() {
let tx = multiple_transfers();
⋮----
assert_eq!(ix.program_id_index, 3);
⋮----
assert_eq!(ix.accounts, &[0, 2]);
⋮----
fn test_address_table_lookup_iter_empty() {
⋮----
let mut iter = frame.address_table_lookup_iter(&bytes);
⋮----
fn test_address_table_lookup_iter_single() {
let tx = v0_with_single_lookup();
⋮----
let atls_actual = tx.message.address_table_lookups().unwrap();
⋮----
let lookup = iter.next().unwrap();
assert_eq!(lookup.account_key, &atls_actual[0].account_key);
assert_eq!(lookup.writable_indexes, atls_actual[0].writable_indexes);
assert_eq!(lookup.readonly_indexes, atls_actual[0].readonly_indexes);
⋮----
fn test_address_table_lookup_iter_multiple() {
let tx = v0_with_multiple_lookups();
⋮----
assert_eq!(lookup.account_key, &atls_actual[1].account_key);
assert_eq!(lookup.writable_indexes, atls_actual[1].writable_indexes);
assert_eq!(lookup.readonly_indexes, atls_actual[1].readonly_indexes);

================
File: transaction-view/src/transaction_version.rs
================
pub enum TransactionVersion {

================
File: transaction-view/src/transaction_view.rs
================
pub type UnsanitizedTransactionView<D> = TransactionView<false, D>;
pub type SanitizedTransactionView<D> = TransactionView<true, D>;
pub struct TransactionView<const SANITIZED: bool, D: TransactionData> {
⋮----
pub fn try_new_unsanitized(data: D) -> Result<Self> {
let frame = TransactionFrame::try_new(data.data())?;
Ok(Self { data, frame })
⋮----
pub fn sanitize(
⋮----
sanitize(&self, enable_static_instruction_limit)?;
Ok(SanitizedTransactionView {
⋮----
pub fn try_new_sanitized(data: D, enable_static_instruction_limit: bool) -> Result<Self> {
⋮----
unsanitized_view.sanitize(enable_static_instruction_limit)
⋮----
pub fn num_signatures(&self) -> u8 {
self.frame.num_signatures()
⋮----
pub fn version(&self) -> TransactionVersion {
self.frame.version()
⋮----
pub fn num_required_signatures(&self) -> u8 {
self.frame.num_required_signatures()
⋮----
pub fn num_readonly_signed_static_accounts(&self) -> u8 {
self.frame.num_readonly_signed_static_accounts()
⋮----
pub fn num_readonly_unsigned_static_accounts(&self) -> u8 {
self.frame.num_readonly_unsigned_static_accounts()
⋮----
pub fn num_static_account_keys(&self) -> u8 {
self.frame.num_static_account_keys()
⋮----
pub fn num_instructions(&self) -> u16 {
self.frame.num_instructions()
⋮----
pub fn num_address_table_lookups(&self) -> u8 {
self.frame.num_address_table_lookups()
⋮----
pub fn total_writable_lookup_accounts(&self) -> u16 {
self.frame.total_writable_lookup_accounts()
⋮----
pub fn total_readonly_lookup_accounts(&self) -> u16 {
self.frame.total_readonly_lookup_accounts()
⋮----
pub fn signatures(&self) -> &[Signature] {
let data = self.data();
unsafe { self.frame.signatures(data) }
⋮----
pub fn static_account_keys(&self) -> &[Pubkey] {
⋮----
unsafe { self.frame.static_account_keys(data) }
⋮----
pub fn recent_blockhash(&self) -> &Hash {
⋮----
unsafe { self.frame.recent_blockhash(data) }
⋮----
pub fn instructions_iter(&self) -> InstructionsIterator<'_> {
⋮----
// SAFETY: `frame` was created from `data`.
unsafe { self.frame.instructions_iter(data) }
⋮----
/// Return an iterator over the address table lookups in the transaction.
    #[inline]
pub fn address_table_lookup_iter(&self) -> AddressTableLookupIterator<'_> {
⋮----
unsafe { self.frame.address_table_lookup_iter(data) }
⋮----
pub fn data(&self) -> &[u8] {
self.data.data()
⋮----
pub fn message_data(&self) -> &[u8] {
&self.data()[usize::from(self.frame.message_offset())..]
⋮----
pub fn inner_data(&self) -> &D {
⋮----
pub fn into_inner_data(self) -> D {
⋮----
pub fn program_instructions_iter(
⋮----
self.instructions_iter().map(|ix| {
⋮----
let program_id = &self.static_account_keys()[program_id_index];
⋮----
/// Return the number of unsigned static account keys.
    #[inline]
pub(crate) fn num_static_unsigned_static_accounts(&self) -> u8 {
self.num_static_account_keys()
.wrapping_sub(self.num_required_signatures())
⋮----
/// Return the number of writable unsigned static accounts.
    #[inline]
pub(crate) fn num_writable_unsigned_static_accounts(&self) -> u8 {
self.num_static_unsigned_static_accounts()
.wrapping_sub(self.num_readonly_unsigned_static_accounts())
⋮----
pub(crate) fn num_writable_signed_static_accounts(&self) -> u8 {
self.num_required_signatures()
.wrapping_sub(self.num_readonly_signed_static_accounts())
⋮----
/// Return the total number of accounts in the transactions.
    #[inline]
pub fn total_num_accounts(&self) -> u16 {
u16::from(self.num_static_account_keys())
.wrapping_add(self.total_writable_lookup_accounts())
.wrapping_add(self.total_readonly_lookup_accounts())
⋮----
/// Return the number of requested writable keys.
    #[inline]
pub fn num_requested_write_locks(&self) -> u64 {
⋮----
(self.num_static_account_keys())
⋮----
.wrapping_sub(self.num_readonly_unsigned_static_accounts()),
⋮----
.wrapping_add(self.total_writable_lookup_accounts()),
⋮----
// Manual implementation of `Debug` - avoids bound on `D`.
// Prints nicely formatted struct-ish fields even for the iterator fields.
impl<const SANITIZED: bool, D: TransactionData> Debug for TransactionView<SANITIZED, D> {
fn fmt(&self, f: &mut Formatter<'_>) -> core::fmt::Result {
f.debug_struct("TransactionView")
.field("frame", &self.frame)
.field("signatures", &self.signatures())
.field("static_account_keys", &self.static_account_keys())
.field("recent_blockhash", &self.recent_blockhash())
.field("instructions", &self.instructions_iter())
.field("address_table_lookups", &self.address_table_lookup_iter())
.finish()
⋮----
impl<D: TransactionData> SVMStaticMessage for TransactionView<true, D> {
fn num_transaction_signatures(&self) -> u64 {
self.num_required_signatures() as u64
⋮----
fn num_write_locks(&self) -> u64 {
self.num_requested_write_locks()
⋮----
fn recent_blockhash(&self) -> &Hash {
self.recent_blockhash()
⋮----
fn num_instructions(&self) -> usize {
self.num_instructions() as usize
⋮----
fn instructions_iter(&self) -> impl Iterator<Item = SVMInstruction<'_>> {
self.instructions_iter()
⋮----
fn program_instructions_iter(
⋮----
self.program_instructions_iter()
⋮----
fn static_account_keys(&self) -> &[Pubkey] {
self.static_account_keys()
⋮----
fn fee_payer(&self) -> &Pubkey {
&self.static_account_keys()[0]
⋮----
fn num_lookup_tables(&self) -> usize {
self.num_address_table_lookups() as usize
⋮----
fn message_address_table_lookups(
⋮----
self.address_table_lookup_iter()
⋮----
impl<D: TransactionData> SVMStaticMessage for &TransactionView<true, D> {
⋮----
mod tests {
⋮----
fn verify_transaction_view_frame(tx: &VersionedTransaction) {
let bytes = bincode::serialize(tx).unwrap();
let view = TransactionView::try_new_unsanitized(bytes.as_ref()).unwrap();
assert_eq!(view.num_signatures(), tx.signatures.len() as u8);
assert_eq!(
⋮----
fn multiple_transfers() -> VersionedTransaction {
⋮----
signatures: vec![Signature::default()],
⋮----
Some(&payer),
⋮----
fn test_multiple_transfers() {
verify_transaction_view_frame(&multiple_transfers());

================
File: transaction-view/Cargo.toml
================
[package]
name = "agave-transaction-view"
description = "Agave TranactionView"
documentation = "https://docs.rs/agave-transaction-view"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []
dev-context-only-utils = []

[dependencies]
solana-hash = { workspace = true }
solana-message = { workspace = true }
solana-packet = { workspace = true }
solana-pubkey = { workspace = true }
solana-sdk-ids = { workspace = true }
solana-short-vec = { workspace = true }
solana-signature = { workspace = true }
solana-svm-transaction = { workspace = true }
solana-transaction-context = { workspace = true }

[dev-dependencies]
# See order-crates-for-publishing.py for using this unusual `path = "."`
agave-transaction-view = { path = ".", features = ["agave-unstable-api", "dev-context-only-utils"] }
bincode = { workspace = true }
criterion = { workspace = true }
solana-instruction = { workspace = true }
solana-keypair = { workspace = true }
solana-message = { workspace = true, features = ["serde"] }
solana-signature = { workspace = true, features = ["serde"] }
solana-signer = { workspace = true }
solana-system-interface = { workspace = true, features = ["bincode"] }
solana-transaction = { workspace = true, features = ["bincode"] }

[[bench]]
name = "bytes"
harness = false

[[bench]]
name = "transaction_view"
harness = false

================
File: turbine/benches/cluster_info.rs
================
fn broadcast_shreds_bench(b: &mut Bencher) {
⋮----
let leader_info = Node::new_localhost_with_pubkey(&leader_keypair.pubkey());
⋮----
leader_keypair.clone(),
⋮----
let socket = bind_to_localhost_unique().expect("should bind");
⋮----
let GenesisConfigInfo { genesis_config, .. } = create_genesis_config(10_000);
⋮----
let root_bank = bank_forks.read().unwrap().root_bank();
⋮----
root_bank.slot(),
root_bank.parent_slot(),
⋮----
.unwrap();
let entries = vec![Entry::new(&Hash::default(), 0, vec![])];
let data_shreds = shredder.make_merkle_shreds_from_entries(
⋮----
let shreds: Vec<_> = data_shreds.take(NUM_SHREDS).collect();
⋮----
let contact_info = ContactInfo::new_localhost(&id, timestamp());
cluster_info.insert_info(contact_info);
stakes.insert(id, thread_rng().gen_range(1..NUM_PEERS) as u64);
⋮----
b.iter(move || {
let shreds = shreds.clone();
broadcast_shreds(
⋮----
benchmark_group!(benches, broadcast_shreds_bench);
benchmark_main!(benches);

================
File: turbine/benches/cluster_nodes.rs
================
fn make_cluster_nodes<R: Rng>(
⋮----
let (nodes, stakes, cluster_info) = make_test_cluster(rng, 5_000, unstaked_ratio);
⋮----
fn get_retransmit_peers_deterministic(
⋮----
let shredder = Shredder::new(slot, parent_slot, 0, 0).unwrap();
let shreds = shredder.make_merkle_shreds_from_entries(
⋮----
let _retransmit_peers = cluster_nodes.get_retransmit_addrs(
⋮----
&shred.id(),
⋮----
fn get_retransmit_peers_deterministic_wrapper(
⋮----
let (nodes, cluster_nodes) = make_cluster_nodes(&mut rng, unstaked_ratio, use_cha_cha_8);
let slot_leader = *nodes[1..].choose(&mut rng).unwrap().pubkey();
⋮----
b.iter(|| get_retransmit_peers_deterministic(&cluster_nodes, slot, &slot_leader));
⋮----
fn bench_get_retransmit_peers_deterministic_unstaked_ratio_1_2_20(b: &mut Bencher) {
get_retransmit_peers_deterministic_wrapper(b, Some((1, 2)), false);
⋮----
fn bench_get_retransmit_peers_deterministic_unstaked_ratio_1_32_20(b: &mut Bencher) {
get_retransmit_peers_deterministic_wrapper(b, Some((1, 32)), false);
⋮----
fn bench_get_retransmit_peers_deterministic_unstaked_ratio_1_2_8(b: &mut Bencher) {
get_retransmit_peers_deterministic_wrapper(b, Some((1, 2)), true);
⋮----
fn bench_get_retransmit_peers_deterministic_unstaked_ratio_1_32_8(b: &mut Bencher) {
get_retransmit_peers_deterministic_wrapper(b, Some((1, 32)), true);
⋮----
benchmark_group!(
⋮----
benchmark_main!(benches);

================
File: turbine/src/broadcast_stage/broadcast_duplicates_run.rs
================
pub enum ClusterPartition {
⋮----
pub struct BroadcastDuplicatesConfig {
⋮----
pub(super) struct BroadcastDuplicatesRun {
⋮----
impl BroadcastDuplicatesRun {
pub(super) fn new(shred_version: u16, config: BroadcastDuplicatesConfig) -> Self {
⋮----
impl BroadcastRun for BroadcastDuplicatesRun {
fn run(
⋮----
let bank = receive_results.bank.clone();
⋮----
if bank.slot() != self.current_slot {
⋮----
bank.slot(),
bank.parent_slot(),
⋮----
.unwrap();
⋮----
self.current_slot = bank.slot();
⋮----
if receive_results.entries.is_empty() {
return Ok(());
⋮----
if !entry.transactions.is_empty() {
self.recent_blockhash = Some(*entry.transactions[0].message.recent_blockhash());
⋮----
if last_tick_height == bank.max_tick_height()
&& bank.slot() > MINIMUM_DUPLICATE_SLOT
&& self.num_slots_broadcasted.is_multiple_of(DUPLICATE_RATE)
&& self.recent_blockhash.is_some()
⋮----
let entry_batch_len = receive_results.entries.len();
⋮----
Some(receive_results.entries[entry_batch_len - 2].hash)
⋮----
let original_last_entry = receive_results.entries.pop().unwrap();
assert!(original_last_entry.is_tick());
⋮----
self.recent_blockhash.unwrap(),
⋮----
let new_extra_entry = Entry::new(&prev_entry_hash, 1, vec![extra_tx]);
⋮----
vec![],
⋮----
Some((original_last_entry, vec![new_extra_entry, new_last_entry]))
⋮----
.as_ref()
.map(|(original_last_entry, _)| original_last_entry.hash)
.or_else(|| Some(receive_results.entries.last().unwrap().hash));
⋮----
bank.parent().unwrap().slot(),
(bank.tick_height() % bank.ticks_per_slot()) as u8,
⋮----
.expect("Expected to create a new shredder");
let (data_shreds, coding_shreds) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
last_tick_height == bank.max_tick_height() && last_entries.is_none(),
⋮----
if let Some(shred) = data_shreds.iter().max_by_key(|shred| shred.index()) {
self.chained_merkle_root = shred.merkle_root().unwrap();
⋮----
self.next_shred_index += data_shreds.len() as u32;
if let Some(index) = coding_shreds.iter().map(Shred::index).max() {
⋮----
last_entries.map(|(original_last_entry, duplicate_extra_last_entries)| {
let (original_last_data_shred, _) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
let (partition_last_data_shred, _) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
.iter()
.map(|s| (s.signature(), s.index()))
.collect();
info!(
⋮----
assert_eq!(
⋮----
self.next_shred_index += u32::try_from(original_last_data_shred.len()).unwrap();
⋮----
blockstore_sender.send((data_shreds.clone(), None))?;
⋮----
assert!(data_shreds.iter().all(|shred| shred.slot() == bank.slot()));
socket_sender.send((data_shreds, None))?;
⋮----
let pubkey = keypair.pubkey();
self.original_last_data_shreds.lock().unwrap().extend(
original_last_data_shred.iter().map(|shred| {
assert!(shred.verify(&pubkey));
shred.signature()
⋮----
self.partition_last_data_shreds.lock().unwrap().extend(
partition_last_data_shred.iter().map(|shred| {
info!("adding {} to partition set", shred.signature());
⋮----
blockstore_sender.send((original_last_data_shred.clone(), None))?;
assert!(original_last_data_shred
⋮----
assert!(partition_last_data_shred
⋮----
let _ = duplicate_slot_sender.send(bank.slot());
⋮----
socket_sender.send((original_last_data_shred, None))?;
socket_sender.send((partition_last_data_shred, None))?;
⋮----
Ok(())
⋮----
fn transmit(
⋮----
let (shreds, _) = receiver.recv()?;
if shreds.is_empty() {
⋮----
let slot = shreds.first().unwrap().slot();
assert!(shreds.iter().all(|shred| shred.slot() == slot));
⋮----
let bank_forks = bank_forks.read().unwrap();
(bank_forks.root_bank(), bank_forks.working_bank())
⋮----
let self_pubkey = cluster_info.id();
⋮----
let epoch = root_bank.get_leader_schedule_epoch(slot);
⋮----
.epoch_staked_nodes(epoch)
.unwrap()
⋮----
.filter(|(pubkey, _)| **pubkey != self_pubkey)
.sorted_by_key(|(pubkey, stake)| (**stake, **pubkey))
.take_while(|(_, stake)| {
⋮----
.map(|(pubkey, _)| *pubkey)
.collect()
⋮----
ClusterPartition::Pubkey(pubkeys) => pubkeys.iter().cloned().collect(),
⋮----
.get(slot, &root_bank, &working_bank, cluster_info);
let socket_addr_space = cluster_info.socket_addr_space();
⋮----
.filter_map(|shred| {
let node = cluster_nodes.get_broadcast_peer(&shred.id())?;
if !socket_addr_space.check(&node.tvu(Protocol::UDP)?) {
⋮----
.lock()
⋮----
.remove(shred.signature())
⋮----
if cluster_partition.contains(node.pubkey()) {
⋮----
return Some(
⋮----
.filter_map(|pubkey| {
⋮----
let tvu = cluster_info.lookup_contact_info(pubkey, |node| {
node.tvu(Protocol::UDP)
⋮----
Some((shred.payload(), tvu))
⋮----
.collect(),
⋮----
Some(vec![(shred.payload(), node.tvu(Protocol::UDP)?)])
⋮----
.flatten()
⋮----
panic!("Xdp not supported for duplicate shreds run");
⋮----
batch_send(sock, packets).map_err(|SendPktsError::IoError(err, _)| Error::Io(err))
⋮----
fn record(&mut self, receiver: &RecordReceiver, blockstore: &Blockstore) -> Result<()> {
let (all_shreds, _) = receiver.recv()?;
⋮----
.insert_shreds(all_shreds.to_vec(), None, true)
.expect("Failed to insert shreds in blockstore");

================
File: turbine/src/broadcast_stage/broadcast_fake_shreds_run.rs
================
pub(super) struct BroadcastFakeShredsRun {
⋮----
impl BroadcastFakeShredsRun {
pub(super) fn new(partition: usize, shred_version: u16) -> Self {
⋮----
impl BroadcastRun for BroadcastFakeShredsRun {
fn run(
⋮----
.meta(bank.slot())
.expect("Database error")
.map(|meta| meta.consumed)
.unwrap_or(0) as u32;
let chained_merkle_root = match next_shred_index.checked_sub(1) {
⋮----
bank.slot(),
bank.parent_slot(),
⋮----
.unwrap(),
⋮----
.get_data_shred(bank.slot(), u64::from(index))
.unwrap()
.unwrap();
shred::layout::get_merkle_root(&shred).unwrap()
⋮----
let num_entries = receive_results.entries.len();
⋮----
bank.parent().unwrap().slot(),
(bank.tick_height() % bank.ticks_per_slot()) as u8,
⋮----
.expect("Expected to create a new shredder");
let (data_shreds, coding_shreds) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
last_tick_height == bank.max_tick_height(),
⋮----
self.last_blockhash = bank.parent().unwrap().last_blockhash();
⋮----
.map(|_| Entry::new(&self.last_blockhash, 0, vec![]))
.collect();
let (fake_data_shreds, fake_coding_shreds) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
.iter()
.chain(&fake_coding_shreds)
.map(Shred::index)
.max()
⋮----
if last_tick_height == bank.max_tick_height() {
⋮----
blockstore_sender.send((data_shreds.clone(), None))?;
let slot = bank.slot();
⋮----
let batch_info = Some(batch_info);
assert!(fake_data_shreds.iter().all(|shred| shred.slot() == slot));
assert!(fake_coding_shreds.iter().all(|shred| shred.slot() == slot));
socket_sender.send((Arc::new(fake_data_shreds), batch_info.clone()))?;
socket_sender.send((Arc::new(fake_coding_shreds), batch_info))?;
socket_sender.send((data_shreds, None))?;
socket_sender.send((Arc::new(coding_shreds), None))?;
Ok(())
⋮----
fn transmit(
⋮----
panic!("Xdp not supported for fake shreds");
⋮----
let fake = batch_info.is_some();
let peers = cluster_info.tvu_peers(ContactInfo::clone);
peers.iter().enumerate().for_each(|(i, peer)| {
⋮----
if let Some(addr) = peer.tvu(Protocol::UDP) {
data_shreds.iter().for_each(|b| {
sock.send_to(b.payload(), addr).unwrap();
⋮----
fn record(&mut self, receiver: &RecordReceiver, blockstore: &Blockstore) -> Result<()> {
⋮----
blockstore.insert_shreds(data_shreds.to_vec(), None, true)?;
⋮----
mod tests {
⋮----
fn test_tvu_peers_ordering() {
⋮----
let contact_info = ContactInfo::new_localhost(&keypair.pubkey(), 0);
⋮----
cluster.insert_info(ContactInfo::new_with_socketaddr(
&Keypair::new().pubkey(),
⋮----
let tvu_peers1 = cluster.tvu_peers(ContactInfo::clone);
(0..5).for_each(|_| {
⋮----
.tvu_peers(ContactInfo::clone)
⋮----
.zip(tvu_peers1.iter())
.for_each(|(v1, v2)| {
assert_eq!(v1, v2);

================
File: turbine/src/broadcast_stage/broadcast_metrics.rs
================
pub(crate) trait BroadcastStats {
⋮----
pub(crate) struct BroadcastShredBatchInfo {
⋮----
pub struct TransmitShredsStats {
⋮----
impl BroadcastStats for TransmitShredsStats {
fn update(&mut self, new_stats: &TransmitShredsStats) {
⋮----
fn report_stats(&mut self, slot: Slot, slot_start: Instant, was_interrupted: bool) {
⋮----
datapoint_info!(
⋮----
pub(crate) struct InsertShredsStats {
⋮----
impl BroadcastStats for InsertShredsStats {
fn update(&mut self, new_stats: &InsertShredsStats) {
⋮----
pub(crate) struct BatchCounter<T: BroadcastStats + Default> {
⋮----
pub(crate) fn num_batches(&self) -> usize {
⋮----
pub(crate) struct SlotBroadcastStats<T: BroadcastStats + Default>(HashMap<Slot, BatchCounter<T>>);
⋮----
pub(crate) fn get(&self, slot: Slot) -> Option<&BatchCounter<T>> {
self.0.get(&slot)
⋮----
pub(crate) fn update(&mut self, new_stats: &T, batch_info: &Option<BroadcastShredBatchInfo>) {
⋮----
let slot_batch_counter = self.0.entry(batch_info.slot).or_default();
slot_batch_counter.broadcast_shred_stats.update(new_stats);
⋮----
slot_batch_counter.num_expected_batches = Some(num_expected_batches);
⋮----
slot_batch_counter.broadcast_shred_stats.report_stats(
⋮----
.remove(&batch_info.slot)
.expect("delete should be successful");
⋮----
mod test {
⋮----
struct TestStats {
⋮----
impl BroadcastStats for TestStats {
fn update(&mut self, new_stats: &TestStats) {
⋮----
self.sender.clone_from(&new_stats.sender);
⋮----
fn report_stats(&mut self, slot: Slot, slot_start: Instant, _was_interrupted: bool) {
⋮----
.as_ref()
.unwrap()
.send((self.count, slot, slot_start))
⋮----
fn test_update_broadcast() {
⋮----
slot_broadcast_stats.update(
⋮----
&Some(BroadcastShredBatchInfo {
⋮----
num_expected_batches: Some(2),
⋮----
let slot_0_stats = slot_broadcast_stats.0.get(&0).unwrap();
assert_eq!(slot_0_stats.num_batches, 1);
assert_eq!(slot_0_stats.num_expected_batches.unwrap(), 2);
assert_eq!(slot_0_stats.broadcast_shred_stats.transmit_elapsed, 1);
assert_eq!(slot_0_stats.broadcast_shred_stats.send_quic_elapsed, 2);
assert_eq!(slot_0_stats.broadcast_shred_stats.send_mmsg_elapsed, 3);
assert_eq!(slot_0_stats.broadcast_shred_stats.send_xdp_elapsed, 4);
assert_eq!(slot_0_stats.broadcast_shred_stats.shred_select, 5);
assert_eq!(slot_0_stats.broadcast_shred_stats.num_shreds, 6);
assert_eq!(slot_0_stats.broadcast_shred_stats.total_packets, 7);
assert_eq!(slot_0_stats.broadcast_shred_stats.dropped_packets_udp, 8);
assert_eq!(slot_0_stats.broadcast_shred_stats.dropped_packets_quic, 9);
assert_eq!(slot_0_stats.broadcast_shred_stats.dropped_packets_xdp, 10);
⋮----
assert!(!slot_broadcast_stats.0.contains_key(&0));
⋮----
fn test_update_multi_threaded() {
⋮----
let (sender, receiver) = unbounded();
⋮----
.map(|i| {
let slot_broadcast_stats = slot_broadcast_stats.clone();
let sender = Some(sender.clone());
⋮----
broadcast_batch_info.num_expected_batches = Some(num_threads);
⋮----
.name("test_update_multi_threaded".to_string())
.spawn(move || {
⋮----
.lock()
⋮----
.update(&test_stats, &Some(broadcast_batch_info))
⋮----
.collect();
⋮----
t.join().unwrap();
⋮----
assert!(!slot_broadcast_stats.lock().unwrap().0.contains_key(&slot));
let (returned_count, returned_slot, _returned_instant) = receiver.recv().unwrap();
assert_eq!(returned_count, num_threads);
assert_eq!(returned_slot, slot);

================
File: turbine/src/broadcast_stage/broadcast_utils.rs
================
pub(super) struct ReceiveResults {
⋮----
const fn get_target_batch_bytes_default() -> u64 {
2 * get_data_shred_bytes_per_batch_typical()
⋮----
const fn get_target_batch_pad_bytes() -> u64 {
get_data_shred_bytes_per_batch_typical() / 20
⋮----
fn keep_coalescing_entries(
⋮----
let bytes_to_fill_erasure_batch = get_data_shred_bytes_per_batch_typical()
- (serialized_batch_byte_count % get_data_shred_bytes_per_batch_typical());
if bytes_to_fill_erasure_batch < get_target_batch_pad_bytes() {
⋮----
pub(super) fn recv_slot_entries(
⋮----
let (mut bank, (entry, mut last_tick_height)) = match carryover_entry.take() {
⋮----
None => receiver.recv_timeout(Duration::new(1, 0))?,
⋮----
assert!(last_tick_height <= bank.max_tick_height());
let mut entries = vec![entry];
while last_tick_height != bank.max_tick_height() {
let Ok((try_bank, (entry, tick_height))) = receiver.try_recv() else {
⋮----
if try_bank.slot() != bank.slot() {
warn!("Broadcast for slot: {} interrupted", bank.slot());
entries.clear();
⋮----
entries.push(entry);
⋮----
let mut serialized_batch_byte_count = serialized_size(&entries)?;
⋮----
.div_ceil(get_data_shred_bytes_per_batch_typical())
.saturating_mul(get_data_shred_bytes_per_batch_typical());
let max_batch_byte_count = next_full_batch_byte_count.max(get_target_batch_bytes_default());
⋮----
while keep_coalescing_entries(
⋮----
bank.max_tick_height(),
⋮----
receiver.recv_deadline(coalesce_start + ENTRY_COALESCE_DURATION)
⋮----
bank = try_bank.clone();
⋮----
let entry_bytes = serialized_size(&entry)?;
⋮----
*carryover_entry = Some((try_bank, (entry, tick_height)));
⋮----
process_stats.receive_elapsed = recv_start.elapsed().as_micros() as u64;
process_stats.coalesce_elapsed = coalesce_start.elapsed().as_micros() as u64;
Ok(ReceiveResults {
⋮----
pub(super) fn get_chained_merkle_root_from_parent(
⋮----
debug_assert_eq!(slot, 0u64);
return Ok(Hash::default());
⋮----
debug_assert!(parent < slot, "parent: {parent} >= slot: {slot}");
⋮----
.meta(parent)?
.ok_or(Error::UnknownSlotMeta(parent))?
⋮----
.ok_or(Error::UnknownLastIndex(parent))?;
⋮----
.get_data_shred(parent, index)?
.ok_or(Error::ShredNotFound {
⋮----
shred::layout::get_merkle_root(&shred).ok_or(Error::InvalidMerkleRoot {
⋮----
mod tests {
⋮----
fn setup_test() -> (GenesisConfig, Arc<Bank>, Transaction) {
⋮----
} = create_genesis_config(2);
⋮----
genesis_config.hash(),
⋮----
fn test_recv_slot_entries_1() {
let (genesis_config, bank0, tx) = setup_test();
⋮----
let (s, r) = unbounded();
let mut last_hash = genesis_config.hash();
assert!(bank1.max_tick_height() > 1);
let entries: Vec<_> = (1..bank1.max_tick_height() + 1)
.map(|i| {
let entry = Entry::new(&last_hash, 1, vec![tx.clone()]);
⋮----
s.send((bank1.clone(), (entry.clone(), i))).unwrap();
⋮----
.collect();
let mut res_entries = vec![];
⋮----
while let Ok(result) = recv_slot_entries(&r, &mut None, &mut ProcessShredsStats::default())
⋮----
assert_eq!(result.bank.slot(), bank1.slot());
⋮----
res_entries.extend(result.entries);
⋮----
assert_eq!(last_tick_height, bank1.max_tick_height());
assert_eq!(res_entries, entries);
⋮----
fn test_recv_slot_entries_2() {
⋮----
let bank2 = Arc::new(Bank::new_from_parent(bank1.clone(), &Pubkey::default(), 2));
⋮----
let expected_last_height = bank1.max_tick_height();
let last_entry = (1..=bank1.max_tick_height())
.map(|tick_height| {
⋮----
s.send((bank2.clone(), (entry.clone(), tick_height)))
.unwrap();
Some(entry)
⋮----
s.send((bank1.clone(), (entry, tick_height))).unwrap();
⋮----
.next_back()
.unwrap()
⋮----
bank_slot = result.bank.slot();
⋮----
assert_eq!(bank_slot, bank2.slot());
assert_eq!(last_tick_height, expected_last_height);
assert_eq!(res_entries, vec![last_entry]);

================
File: turbine/src/broadcast_stage/fail_entry_verification_broadcast_run.rs
================
pub(super) struct FailEntryVerificationBroadcastRun {
⋮----
impl FailEntryVerificationBroadcastRun {
pub(super) fn new(shred_version: u16) -> Self {
⋮----
good_shreds: vec![],
⋮----
impl BroadcastRun for FailEntryVerificationBroadcastRun {
fn run(
⋮----
let bank = receive_results.bank.clone();
⋮----
if bank.slot() != self.current_slot {
⋮----
bank.slot(),
bank.parent_slot(),
⋮----
.unwrap();
⋮----
self.current_slot = bank.slot();
⋮----
if bank.slot() > SLOT_TO_RESOLVE && !self.good_shreds.is_empty() {
info!("Resolving bad shreds");
⋮----
blockstore_sender.send((Arc::new(shreds), None))?;
⋮----
if last_tick_height == bank.max_tick_height() && bank.slot() < NUM_BAD_SLOTS {
let good_last_entry = receive_results.entries.pop().unwrap();
let mut bad_last_entry = good_last_entry.clone();
⋮----
Some((good_last_entry, bad_last_entry))
⋮----
bank.parent().unwrap().slot(),
(bank.tick_height() % bank.ticks_per_slot()) as u8,
⋮----
.expect("Expected to create a new shredder");
let (data_shreds, coding_shreds) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
last_tick_height == bank.max_tick_height() && last_entries.is_none(),
⋮----
if let Some(shred) = data_shreds.iter().max_by_key(|shred| shred.index()) {
self.chained_merkle_root = shred.merkle_root().unwrap();
⋮----
self.next_shred_index += data_shreds.len() as u32;
if let Some(index) = coding_shreds.iter().map(Shred::index).max() {
⋮----
let last_shreds = last_entries.map(|(good_last_entry, bad_last_entry)| {
let (good_last_data_shred, _) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
let (bad_last_data_shred, _) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
assert_eq!(good_last_data_shred.len(), 1);
self.chained_merkle_root = good_last_data_shred.last().unwrap().merkle_root().unwrap();
⋮----
blockstore_sender.send((data_shreds.clone(), None))?;
socket_sender.send((data_shreds, None))?;
⋮----
self.good_shreds.extend(good_last_data_shred.clone());
⋮----
blockstore_sender.send((good_last_data_shred, None))?;
⋮----
if blockstore.is_full(bank.slot()) {
⋮----
sleep(Duration::from_millis(10));
⋮----
blockstore_sender.send((bad_last_data_shred.clone(), None))?;
socket_sender.send((bad_last_data_shred, None))?;
⋮----
Ok(())
⋮----
fn transmit(
⋮----
let (shreds, _) = receiver.recv()?;
broadcast_shreds(
⋮----
cluster_info.socket_addr_space(),
⋮----
&shredstream_receiver_address.load(),
&shred_receiver_address.load(),
⋮----
fn record(&mut self, receiver: &RecordReceiver, blockstore: &Blockstore) -> Result<()> {
let (all_shreds, _) = receiver.recv()?;
⋮----
.insert_shreds(all_shreds.to_vec(), None, true)
.expect("Failed to insert shreds in blockstore");

================
File: turbine/src/broadcast_stage/standard_broadcast_run.rs
================
pub struct StandardBroadcastRun {
⋮----
enum BroadcastError {
⋮----
impl StandardBroadcastRun {
pub(super) fn new(shred_version: u16) -> Self {
⋮----
fn finish_prev_slot(
⋮----
return vec![];
⋮----
.unwrap()
.make_merkle_shreds_from_entries(
⋮----
.inspect(|shred| stats.record_shred(shred))
.collect();
if let Some(shred) = shreds.iter().max_by_key(|shred| shred.fec_set_index()) {
self.chained_merkle_root = shred.merkle_root().unwrap();
⋮----
self.report_and_reset_stats( true);
⋮----
fn entries_to_shreds(
⋮----
.inspect(|shred| {
process_stats.record_shred(shred);
let next_index = match shred.shred_type() {
⋮----
*next_index = (*next_index).max(shred.index() + 1);
⋮----
return Err(BroadcastError::TooManyShreds);
⋮----
Ok(shreds)
⋮----
fn test_process_receive_results(
⋮----
let (bsend, brecv) = unbounded();
let (ssend, srecv) = unbounded();
self.process_receive_results(
⋮----
let _ = self.transmit(
⋮----
let _ = self.record(&brecv, blockstore);
Ok(())
⋮----
fn process_receive_results(
⋮----
let num_entries = receive_results.entries.len();
let bank = receive_results.bank.clone();
⋮----
inc_new_counter_info!("broadcast_service-entries_received", num_entries);
⋮----
if self.slot != bank.slot() {
⋮----
self.finish_prev_slot(keypair, bank.ticks_per_slot() as u8, process_stats);
debug_assert!(shreds.iter().all(|shred| shred.slot() == self.slot));
let batch_info = Some(BroadcastShredBatchInfo {
⋮----
num_expected_batches: Some(self.num_batches + 1),
⋮----
socket_sender.send((shreds.clone(), batch_info.clone()))?;
blockstore_sender.send((shreds, batch_info))?;
⋮----
.meta(bank.slot())
⋮----
.filter(|slot_meta| slot_meta.received > 0 || slot_meta.consumed > 0)
.is_some()
⋮----
return Err(Error::DuplicateSlotBroadcast(bank.slot()));
⋮----
let chained_merkle_root = if self.slot == bank.parent_slot() {
⋮----
bank.slot(),
bank.parent_slot(),
⋮----
.unwrap_or_else(|err: Error| {
error!("Unknown chained Merkle root: {err:?}");
⋮----
self.slot = bank.slot();
self.parent = bank.parent_slot();
⋮----
let is_last_in_slot = last_tick_height == bank.max_tick_height();
⋮----
.saturating_add(bank.ticks_per_slot())
.saturating_sub(bank.max_tick_height());
⋮----
.entries_to_shreds(
⋮----
.unwrap();
if let Some(shred) = shreds.iter().find(|shred| shred.is_data()) {
if shred.index() == 0 {
⋮----
.insert_cow_shreds(
⋮----
.expect("Failed to insert shreds in blockstore");
⋮----
to_shreds_time.stop();
⋮----
let num_expected_batches = is_last_in_slot.then_some(self.num_batches);
⋮----
slot: bank.slot(),
⋮----
get_leader_schedule_time.stop();
⋮----
debug_assert!(shreds.iter().all(|shred| shred.slot() == bank.slot()));
⋮----
coding_send_time.stop();
process_stats.shredding_elapsed = to_shreds_time.as_us();
process_stats.get_leader_schedule_elapsed = get_leader_schedule_time.as_us();
process_stats.coding_send_elapsed = coding_send_time.as_us();
⋮----
if last_tick_height == bank.max_tick_height() {
self.report_and_reset_stats(false);
⋮----
fn insert(
⋮----
.first()
.map(|shred| shred.is_data() && shred.index() == 0)
.map(usize::from)
.unwrap_or_default();
let num_shreds = shreds.len();
let shreds = shreds.iter().skip(offset).map(Cow::Borrowed);
⋮----
let insert_shreds_elapsed = insert_shreds_start.elapsed();
⋮----
insert_shreds_elapsed: insert_shreds_elapsed.as_micros() as u64,
⋮----
self.update_insertion_metrics(&new_insert_shreds_stats, &broadcast_shred_batch_info);
⋮----
fn update_insertion_metrics(
⋮----
let mut insert_shreds_stats = self.insert_shreds_stats.lock().unwrap();
insert_shreds_stats.update(new_insertion_shreds_stats, broadcast_shred_batch_info);
⋮----
fn broadcast(
⋮----
trace!("Broadcasting {:?} shreds", shreds.len());
⋮----
is_xdp: matches!(sock, BroadcastSocket::Xdp(_)),
⋮----
transmit_stats.num_shreds = shreds.len();
broadcast_shreds(
⋮----
cluster_info.socket_addr_space(),
⋮----
transmit_time.stop();
transmit_stats.transmit_elapsed = transmit_time.as_us();
self.update_transmit_metrics(&transmit_stats, &broadcast_shred_batch_info);
⋮----
fn update_transmit_metrics(
⋮----
let mut transmit_shreds_stats = self.transmit_shreds_stats.lock().unwrap();
transmit_shreds_stats.update(new_transmit_shreds_stats, broadcast_shred_batch_info);
⋮----
fn report_and_reset_stats(&mut self, was_interrupted: bool) {
⋮----
Some(self.slot_broadcast_start.elapsed()),
⋮----
self.process_shreds_stats.submit(
⋮----
impl BroadcastRun for StandardBroadcastRun {
fn run(
⋮----
fn transmit(
⋮----
let (shreds, batch_info) = receiver.recv()?;
self.broadcast(
⋮----
&shredstream_receiver_address.load(),
&shred_receiver_address.load(),
⋮----
fn record(&mut self, receiver: &RecordReceiver, blockstore: &Blockstore) -> Result<()> {
let (shreds, slot_start_ts) = receiver.recv()?;
self.insert(blockstore, shreds, slot_start_ts);
⋮----
mod test {
⋮----
fn setup(
⋮----
let ledger_path = get_tmp_ledger_path!();
⋮----
Blockstore::open(&ledger_path).expect("Expected to be able to open database ledger"),
⋮----
let leader_pubkey = leader_keypair.pubkey();
⋮----
leader_keypair.clone(),
⋮----
let socket = bind_to_localhost_unique().expect("should bind");
let mut genesis_config = create_genesis_config(10_000).genesis_config;
genesis_config.ticks_per_slot = max_ticks_per_n_shreds(num_shreds_per_slot, None) + 1;
⋮----
let bank0 = bank_forks.read().unwrap().root_bank();
⋮----
fn test_interrupted_slot_last_shred() {
⋮----
assert!(run.completed);
⋮----
run.chained_merkle_root = Hash::new_from_array(rand::thread_rng().gen());
⋮----
let shreds = run.finish_prev_slot(
⋮----
.expect("Expected a shred that signals an interrupt");
assert_eq!(shred.parent().unwrap(), parent);
assert_eq!(shred.slot(), slot);
assert_eq!(shred.index(), next_shred_index);
assert!(shred.is_data());
assert!(shred.verify(&keypair.pubkey()));
⋮----
fn test_slot_interrupt() {
⋮----
setup(num_shreds_per_slot);
⋮----
let ticks0 = create_ticks(genesis_config.ticks_per_slot - 1, 0, genesis_config.hash());
⋮----
entries: ticks0.clone(),
bank: bank0.clone(),
last_tick_height: (ticks0.len() - 1) as u64,
⋮----
.test_process_receive_results(
⋮----
assert_eq!(
⋮----
assert_eq!(standard_broadcast_run.slot, 0);
assert_eq!(standard_broadcast_run.parent, 0);
assert!(!blockstore.is_full(0));
⋮----
assert_eq!(blockstore.get_slot_entries(0, 0).unwrap(), ticks0);
⋮----
let bank2 = Arc::new(Bank::new_from_parent(bank0, &leader_keypair.pubkey(), 2));
⋮----
assert!(num_shreds < num_shreds_per_slot);
let ticks1 = create_ticks(
max_ticks_per_n_shreds(num_shreds, None),
⋮----
genesis_config.hash(),
⋮----
entries: ticks1.clone(),
⋮----
last_tick_height: (ticks1.len() - 1) as u64,
⋮----
assert_eq!(standard_broadcast_run.slot, 2);
⋮----
assert!(standard_broadcast_run
⋮----
fn test_buffer_data_shreds() {
⋮----
let (ssend, _srecv) = unbounded();
⋮----
let ticks = create_ticks(num_ticks, 0, genesis_config.hash());
last_tick_height += (ticks.len() - 1) as u64;
⋮----
bank: bank.clone(),
⋮----
.process_receive_results(
⋮----
process_ticks((i + 1) * 100);
⋮----
while let Ok((recv_shreds, _)) = brecv.recv_timeout(Duration::from_secs(1)) {
shreds.extend(recv_shreds.deref().clone());
⋮----
assert!(shreds.len() >= DATA_SHREDS_PER_FEC_BLOCK * 2);
⋮----
process_ticks(75);
⋮----
fn test_slot_finish() {
⋮----
let ticks = create_ticks(genesis_config.ticks_per_slot, 0, genesis_config.hash());
⋮----
entries: ticks.clone(),
⋮----
last_tick_height: ticks.len() as u64,
⋮----
assert!(standard_broadcast_run.completed)
⋮----
fn entries_to_shreds_max() {
⋮----
let entries = create_ticks(10_000, 1, solana_hash::Hash::default());
⋮----
&entries[0..entries.len() - 2],
⋮----
.into_iter()
⋮----
info!("{} {}", data.len(), coding.len());
assert!(!data.is_empty());
assert!(!coding.is_empty());
let r = bs.entries_to_shreds(&keypair, &entries, 0, false, &mut stats, 10, 10);
info!("{r:?}");
assert_matches!(r, Err(BroadcastError::TooManyShreds));

================
File: turbine/src/addr_cache.rs
================
pub(crate) struct AddrCache {
⋮----
struct CacheEntry {
⋮----
impl AddrCache {
pub(crate) fn with_capacity(capacity: usize) -> Self {
⋮----
let capacity = capacity.saturating_mul(2).saturating_add(1);
⋮----
pub(crate) fn get(&self, shred: &ShredId) -> Option<( u8, &[SocketAddr])> {
⋮----
.get(&shred.slot())?
.get(shred.shred_type(), shred.index())
⋮----
pub(crate) fn put(
⋮----
self.get_cache_entry_mut(shred.slot())
.put(shred.shred_type(), shred.index(), entry);
self.maybe_trim_cache();
⋮----
pub(crate) fn record(&mut self, slot: Slot, stats: &mut RetransmitSlotStats) {
debug_assert!(stats.addrs.iter().all(|(shred, _, _)| shred.slot() == slot));
let num_shreds: usize = stats.num_shreds_received.iter().sum();
⋮----
self.window.push_back((slot, num_shreds));
*self.counts.entry(slot).or_default() += num_shreds;
self.maybe_trim_slot_counts();
⋮----
debug_assert!(self.verify());
if stats.addrs.is_empty() && !self.cache.contains_key(&slot) {
⋮----
let entry = self.get_cache_entry_mut(slot);
entry.max_index_code = entry.max_index_code.max(stats.max_index_code);
entry.max_index_data = entry.max_index_data.max(stats.max_index_data);
⋮----
debug_assert_eq!(shred.slot(), slot);
entry.put(shred.shred_type(), shred.index(), (root_distance, addrs));
⋮----
pub(crate) fn get_shreds(&mut self, num_shreds: usize) -> Vec<ShredId> {
fn make_shred(slot: Slot, (shred_type, index): (ShredType, usize)) -> ShredId {
⋮----
if self.counts.len() == 1 {
let slot = self.counts.keys().next().copied().unwrap();
⋮----
.get_cache_entry_mut(slot)
.get_shreds(EXTEND_BUFFER)
.take(num_shreds)
.map(|entry| make_shred(slot, entry))
.collect();
⋮----
.iter()
.map(|(&slot, &count)| (count, slot))
⋮----
counts.sort_unstable();
⋮----
while let Some(count) = num_shreds.checked_sub(out.len()).filter(|&k| k > 0) {
let Some((_, slot)) = counts.pop() else {
⋮----
let count = count.min(num_shreds * 3 / 4);
out.extend(
self.get_cache_entry_mut(slot)
⋮----
.take(count)
.map(|entry| make_shred(slot, entry)),
⋮----
fn get_cache_entry_mut(&mut self, slot: Slot) -> &mut CacheEntry {
⋮----
.entry(slot)
.or_insert_with(|| CacheEntry::new(ADDR_CAPACITY))
⋮----
fn maybe_trim_slot_counts(&mut self) {
⋮----
.checked_sub(ROLLING_WINDOW_NUM_SHREDS)
.filter(|&k| k > 0)
⋮----
let (slot, num_shreds) = self.window.front_mut().unwrap();
let count = count.min(*num_shreds);
⋮----
let Entry::Occupied(mut entry) = self.counts.entry(*slot) else {
panic!("Entry must exist if it has non-zero count.");
⋮----
*entry.get_mut() -= count;
if *entry.get() == 0 {
entry.remove_entry();
⋮----
self.window.pop_front();
⋮----
fn maybe_trim_cache(&mut self) {
if self.cache.len() <= self.capacity.saturating_mul(2) {
⋮----
.drain()
.map(|entry @ (slot, _)| {
let count = self.counts.get(&slot).copied().unwrap_or_default();
⋮----
let index = self.capacity.saturating_sub(1);
entries.select_nth_unstable_by_key(index, |&((slot, _), count)| Reverse((count, slot)));
self.cache.extend(
⋮----
.into_iter()
.take(self.capacity)
.map(|(entry, _)| entry),
⋮----
fn verify(&self) -> bool {
let num_shreds: usize = self.window.iter().map(|&(_, count)| count).sum();
⋮----
.fold(HashMap::new(), |mut acc, &(slot, count)| {
*acc.entry(slot).or_default() += count;
⋮----
&& self.window.iter().all(|&(_, count)| count > 0)
&& self.counts.values().all(|&count| count > 0)
⋮----
impl CacheEntry {
fn new(capacity: usize) -> Self {
⋮----
fn get(
⋮----
.get(shred_index as usize)?
.as_ref()
.map(|(root_distance, addrs)| (*root_distance, addrs.as_ref()))
⋮----
fn put(
⋮----
if cache.len() <= k {
cache.resize(k + 1, None);
⋮----
cache[k] = Some(entry)
⋮----
fn get_shreds(
⋮----
while matches!(self.code.get(self.index_code), Some(Some(_))) {
⋮----
while matches!(self.data.get(self.index_data), Some(Some(_))) {
⋮----
let max_index = self.max_index_code.max(self.max_index_data) as usize + extend_buffer;
self.index_code..max_index.min(MAX_CODE_SHREDS_PER_SLOT)
⋮----
.filter(|&k| matches!(self.code.get(k), None | Some(None)))
.map(|k| (ShredType::Code, k));
⋮----
self.index_data..max_index.min(MAX_DATA_SHREDS_PER_SLOT)
⋮----
.filter(|&k| matches!(self.data.get(k), None | Some(None)))
.map(|k| (ShredType::Data, k));
code.interleave(data)
⋮----
mod tests {
⋮----
fn test_cache_entry_get_shreds() {
⋮----
assert!(entry.get_shreds(3).eq([
⋮----
assert_eq!(entry.index_code, 0);
assert_eq!(entry.index_data, 0);
entry.put(ShredType::Code, 0, (0, Box::new([])));
entry.put(ShredType::Code, 2, (0, Box::new([])));
entry.put(ShredType::Data, 1, (0, Box::new([])));
assert!(entry.get_shreds(5).eq([
⋮----
assert_eq!(entry.index_code, 1);
⋮----
entry.put(ShredType::Code, 1, (0, Box::new([])));
entry.put(ShredType::Code, 4, (0, Box::new([])));
entry.put(ShredType::Data, 0, (0, Box::new([])));
entry.put(ShredType::Data, 3, (0, Box::new([])));
⋮----
assert_eq!(entry.index_code, 3);
assert_eq!(entry.index_data, 2);
⋮----
assert!(entry.get_shreds(4).eq([
⋮----
assert!(entry
⋮----
entry.put(ShredType::Code, 3, (0, Box::new([])));
entry.put(ShredType::Data, 2, (0, Box::new([])));
assert!(entry.get_shreds(7).eq([]));
assert_eq!(entry.index_code, 5);
assert_eq!(entry.index_data, 4);

================
File: turbine/src/broadcast_stage.rs
================
pub mod broadcast_duplicates_run;
mod broadcast_fake_shreds_run;
pub mod broadcast_metrics;
pub(crate) mod broadcast_utils;
mod fail_entry_verification_broadcast_run;
pub(crate) mod standard_broadcast_run;
⋮----
assert!(CLUSTER_NODES_CACHE_NUM_EPOCH_CAP >= 2);
assert!(CLUSTER_NODES_CACHE_NUM_EPOCH_CAP <= MAX_LEADER_SCHEDULE_STAKES as usize);
⋮----
pub(crate) type RecordReceiver = Receiver<(Arc<Vec<Shred>>, Option<BroadcastShredBatchInfo>)>;
pub(crate) type TransmitReceiver = Receiver<(Arc<Vec<Shred>>, Option<BroadcastShredBatchInfo>)>;
⋮----
pub enum Error {
⋮----
type Result<T> = std::result::Result<T, Error>;
⋮----
pub enum BroadcastStageReturnType {
⋮----
pub enum BroadcastStageType {
⋮----
impl BroadcastStageType {
⋮----
pub fn new_broadcast_stage(
⋮----
BroadcastDuplicatesRun::new(shred_version, config.clone()),
⋮----
trait BroadcastRun {
⋮----
struct Finalizer {
⋮----
impl Finalizer {
fn new(exit_sender: Arc<AtomicBool>) -> Self {
⋮----
impl Drop for Finalizer {
fn drop(&mut self) {
self.exit_sender.clone().store(true, Ordering::Relaxed);
⋮----
pub struct BroadcastStage {
⋮----
impl BroadcastStage {
⋮----
fn run(
⋮----
let res = broadcast_stage_run.run(
&cluster_info.keypair(),
⋮----
fn handle_error(r: Result<()>, name: &str) -> Option<BroadcastStageReturnType> {
⋮----
return Some(BroadcastStageReturnType::ChannelDisconnected);
⋮----
inc_new_counter_error!("streamer-broadcaster-error", 1, 1);
error!("{name} broadcaster error: {e:?}");
⋮----
fn new(
⋮----
let (socket_sender, socket_receiver) = unbounded();
let (blockstore_sender, blockstore_receiver) = unbounded();
let bs_run = broadcast_stage_run.clone();
let socket_sender_ = socket_sender.clone();
⋮----
let blockstore = blockstore.clone();
let cluster_info = cluster_info.clone();
⋮----
.name("solBroadcast".to_string())
.spawn(move || {
⋮----
.unwrap()
⋮----
let mut thread_hdls = vec![thread_hdl];
let num_broadcast_sockets_per_interface = socks.len() / cluster_info.bind_ip_addrs().len();
let num_interfaces: usize = cluster_info.bind_ip_addrs().len();
// Partition by interface
// With 2 interfaces and the default of 4 sockets per interface, `sockets_by_interface` is:
// sockets_by_interface = [[s0, s1, s2, s3], [s4, s5, s6, s7]]
let mut it = socks.into_iter();
⋮----
.map(|_| {
it.by_ref()
.take(num_broadcast_sockets_per_interface)
.collect()
⋮----
.collect();
⋮----
.into_iter()
.map(|sockets| sockets.into_iter())
⋮----
// Spawn `num_broadcast_sockets_per_interface` threads
// Each thread gets a socket from each interface (i.e. 2 sockets per thread if multihomed w/ 2 interfaces)
thread_hdls.extend((0..num_broadcast_sockets_per_interface).map(|_| {
⋮----
group.push(it.next().expect("aligned lengths"));
⋮----
let socket_receiver = socket_receiver.clone();
let mut bs_transmit = broadcast_stage_run.clone();
⋮----
let bank_forks = bank_forks.clone();
let quic_endpoint_sender = quic_endpoint_sender.clone();
let xdp_sender = xdp_sender.clone();
let shredstream_receiver_address = shredstream_receiver_address.clone();
let shred_receiver_address = shred_receiver_address.clone();
⋮----
let sock_variant = match xdp_sender.as_ref() {
⋮----
let active_index = cluster_info.bind_ip_addrs().active_index();
⋮----
let res = bs_transmit.transmit(
⋮----
.name("solBroadcastTx".to_string())
.spawn(run_transmit)
⋮----
// Blockstore::insert_threads() obtains and holds a write lock for the entire function.
// Until this changes, only a single inserter thread is necessary.
thread_hdls.push({
⋮----
let res = broadcast_stage_run.record(&blockstore_receiver, &blockstore);
⋮----
.name("solBroadcastRec".to_string())
.spawn(run_record)
⋮----
.name("solBroadcastRtx".to_string())
.spawn(move || loop {
⋮----
.unwrap();
thread_hdls.push(retransmit_thread);
⋮----
fn check_retransmit_signals(
⋮----
std::iter::once(retransmit_slots_receiver.recv_timeout(RECV_TIMEOUT)?)
.chain(retransmit_slots_receiver.try_iter())
⋮----
.get_data_shreds_for_slot(new_retransmit_slot, 0)
.expect("My own shreds must be reconstructable"),
⋮----
debug_assert!(data_shreds
⋮----
if !data_shreds.is_empty() {
socket_sender.send((data_shreds, None))?;
⋮----
.get_coding_shreds_for_slot(new_retransmit_slot, 0)
⋮----
debug_assert!(coding_shreds
⋮----
if !coding_shreds.is_empty() {
socket_sender.send((coding_shreds, None))?;
⋮----
Ok(())
⋮----
pub fn join(self) -> thread::Result<BroadcastStageReturnType> {
for thread_hdl in self.thread_hdls.into_iter() {
let _ = thread_hdl.join();
⋮----
Ok(BroadcastStageReturnType::ChannelDisconnected)
⋮----
fn update_peer_stats(
⋮----
if last_datapoint_submit.should_update(1000) {
cluster_nodes.submit_metrics("cluster_nodes_broadcast", timestamp());
⋮----
pub enum BroadcastSocket<'a> {
⋮----
pub fn broadcast_shreds(
⋮----
let mut result = Ok(());
⋮----
let bank_forks = bank_forks.read().unwrap();
(bank_forks.root_bank(), bank_forks.working_bank())
⋮----
.iter()
.chunk_by(|shred| shred.slot())
⋮----
.flat_map(|(slot, shreds)| {
⋮----
cluster_nodes_cache.get(slot, &root_bank, &working_bank, cluster_info);
update_peer_stats(&cluster_nodes, last_datapoint_submit);
shreds.filter_map(move |shred| {
let key = shred.id();
⋮----
.get_broadcast_peer(&key)?
.tvu(protocol)
.filter(|addr| socket_addr_space.check(addr))
.map(|addr| {
⋮----
})((shred.payload(), addr))
⋮----
.partition_map(std::convert::identity);
⋮----
packets.extend(shreds.iter().map(|shred| (shred.payload(), *ss_addr)));
⋮----
packets.extend(shreds.iter().map(|shred| (shred.payload(), *sr_addr)));
⋮----
packets.extend(shreds.iter().map(|shred| (shred.payload(), *ss_addr)))
⋮----
packets.extend(shreds.iter().map(|shred| (shred.payload(), *sr_addr)))
⋮----
shred_select.stop();
transmit_stats.shred_select += shred_select.as_us();
let num_udp_packets = packets.len();
⋮----
match batch_send(s, packets) {
⋮----
result = Err(Error::Io(ioerr));
⋮----
send_mmsg_time.stop();
transmit_stats.send_mmsg_elapsed += send_mmsg_time.as_us();
⋮----
for (idx, (payload, addr)) in packets.into_iter().enumerate() {
if let Err(e) = s.try_send(idx, addr, payload.clone()) {
⋮----
result = Err(Error::XdpChannelFull);
⋮----
send_xdp_time.stop();
transmit_stats.send_xdp_elapsed += send_xdp_time.as_us();
⋮----
transmit_stats.total_packets += num_udp_packets + quic_packets.len();
⋮----
if let Err(err) = quic_endpoint_sender.blocking_send((addr, payload.bytes.clone())) {
⋮----
result = Err(Error::from(err));
⋮----
quic_send_time.stop();
transmit_stats.send_quic_elapsed = quic_send_time.as_us();
⋮----
fn from(_: crossbeam_channel::SendError<T>) -> Error {
⋮----
fn from(_: tokio::sync::mpsc::error::SendError<T>) -> Error {
⋮----
pub mod test {
⋮----
fn make_transmit_shreds(
⋮----
let num_entries = max_ticks_per_n_shreds(num, None);
let entries = create_ticks(num_entries,  0, Hash::default());
⋮----
let (data_shreds, coding_shreds) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
Hash::new_from_array(rand::thread_rng().gen()),
⋮----
data_shreds.clone(),
coding_shreds.clone(),
⋮----
.map(|shred| Arc::new(vec![shred]))
.collect(),
⋮----
fn check_all_shreds_received(
⋮----
while let Ok((shreds, _)) = transmit_receiver.try_recv() {
if shreds[0].is_data() {
for data_shred in shreds.iter() {
assert_eq!(data_shred.index() as u64, data_index);
⋮----
assert_eq!(shreds[0].index() as u64, coding_index);
for coding_shred in shreds.iter() {
assert_eq!(coding_shred.index() as u64, coding_index);
⋮----
assert_eq!(num_expected_data_shreds, data_index);
assert_eq!(num_expected_coding_shreds, coding_index);
⋮----
fn test_duplicate_retransmit_signal() {
let ledger_path = get_tmp_ledger_path_auto_delete!();
let blockstore = Arc::new(Blockstore::open(ledger_path.path()).unwrap());
let (transmit_sender, transmit_receiver) = unbounded();
let (retransmit_slots_sender, retransmit_slots_receiver) = unbounded();
⋮----
make_transmit_shreds(updated_slot, 10);
let num_data_shreds = all_data_shreds.len();
let num_coding_shreds = all_coding_shreds.len();
assert!(num_data_shreds >= 10);
⋮----
.insert_shreds(all_data_shreds, None, true)
⋮----
.insert_shreds(all_coding_shreds, None, true)
⋮----
retransmit_slots_sender.send(updated_slot).unwrap();
⋮----
check_all_shreds_received(
⋮----
struct MockBroadcastStage {
⋮----
fn setup_dummy_broadcast_service(
⋮----
let blockstore = Arc::new(Blockstore::open(ledger_path).unwrap());
⋮----
let leader_info = Node::new_localhost_with_pubkey(&leader_keypair.pubkey());
⋮----
let broadcast_buddy = Node::new_localhost_with_pubkey(&buddy_keypair.pubkey());
⋮----
leader_info.info.clone(),
⋮----
cluster_info.insert_info(broadcast_buddy.info);
⋮----
let GenesisConfigInfo { genesis_config, .. } = create_genesis_config(10_000);
⋮----
let bank = bank_forks.read().unwrap().root_bank();
⋮----
blockstore.clone(),
⋮----
fn test_broadcast_ledger() {
⋮----
let (entry_sender, entry_receiver) = unbounded();
⋮----
let broadcast_service = setup_dummy_broadcast_service(
⋮----
ledger_path.path(),
⋮----
start_tick_height = bank.tick_height();
max_tick_height = bank.max_tick_height();
ticks_per_slot = bank.ticks_per_slot();
slot = bank.slot();
let ticks = create_ticks(max_tick_height - start_tick_height, 0, Hash::default());
for (i, tick) in ticks.into_iter().enumerate() {
⋮----
.send((bank.clone(), (tick, i as u64 + 1)))
.expect("Expect successful send to broadcast service");
⋮----
trace!(
⋮----
let mut entries = vec![];
⋮----
.get_slot_entries(slot, 0)
.expect("Expect entries to be present");
if entries.len() >= max_tick_height as usize {
⋮----
sleep(Duration::from_millis(1000));
⋮----
assert_eq!(entries.len(), max_tick_height as usize);
drop(entry_sender);
drop(retransmit_slots_sender);
⋮----
.join()
.expect("Expect successful join of broadcast service");

================
File: turbine/src/cluster_nodes.rs
================
thread_local! {
⋮----
pub enum Error {
⋮----
enum NodeId {
⋮----
pub(crate) struct ContactInfo {
⋮----
pub struct Node {
⋮----
pub struct ClusterNodes<T> {
⋮----
type LruCacheOnce<K, V> = RwLock<LruCache<K, Arc<OnceLock<V>>>>;
pub struct ClusterNodesCache<T> {
⋮----
impl Node {
⋮----
fn pubkey(&self) -> &Pubkey {
⋮----
NodeId::ContactInfo(node) => node.pubkey(),
⋮----
fn contact_info(&self) -> Option<&ContactInfo> {
⋮----
NodeId::ContactInfo(node) => Some(node),
⋮----
fn contact_info_mut(&mut self) -> Option<&mut ContactInfo> {
⋮----
impl ContactInfo {
⋮----
pub(crate) fn pubkey(&self) -> &Pubkey {
⋮----
pub(crate) fn wallclock(&self) -> u64 {
⋮----
pub(crate) fn tvu(&self, protocol: Protocol) -> Option<SocketAddr> {
⋮----
fn remove_tvu_addr(&mut self, protocol: Protocol) {
⋮----
pub(crate) fn submit_metrics(&self, name: &'static str, now: u64) {
⋮----
match node.contact_info().map(ContactInfo::wallclock) {
⋮----
let age = now.saturating_sub(wallclock);
⋮----
datapoint_info!(
⋮----
/// Encapsulates the possible RNG implementations for turbine.
/// This was implemented for the transition from ChaCha20 to ChaCha8.
⋮----
/// This was implemented for the transition from ChaCha20 to ChaCha8.
enum TurbineRng {
⋮----
enum TurbineRng {
⋮----
impl TurbineRng {
/// Create a new seeded TurbineRng of the correct implementation
    fn new_seeded(leader: &Pubkey, shred: &ShredId, use_cha_cha_8: bool) -> Self {
⋮----
fn new_seeded(leader: &Pubkey, shred: &ShredId, use_cha_cha_8: bool) -> Self {
let seed = shred.seed(leader);
⋮----
impl RngCore for TurbineRng {
fn next_u32(&mut self) -> u32 {
⋮----
TurbineRng::Legacy(cha_cha20_rng) => cha_cha20_rng.next_u32(),
TurbineRng::ChaCha8(cha_cha8_rng) => cha_cha8_rng.next_u32(),
⋮----
fn next_u64(&mut self) -> u64 {
⋮----
TurbineRng::Legacy(cha_cha20_rng) => cha_cha20_rng.next_u64(),
TurbineRng::ChaCha8(cha_cha8_rng) => cha_cha8_rng.next_u64(),
⋮----
fn fill_bytes(&mut self, dest: &mut [u8]) {
⋮----
TurbineRng::Legacy(cha_cha20_rng) => cha_cha20_rng.fill_bytes(dest),
TurbineRng::ChaCha8(cha_cha8_rng) => cha_cha8_rng.fill_bytes(dest),
⋮----
fn try_fill_bytes(&mut self, dest: &mut [u8]) -> Result<(), rand::Error> {
⋮----
TurbineRng::Legacy(cha_cha20_rng) => cha_cha20_rng.try_fill_bytes(dest),
TurbineRng::ChaCha8(cha_cha8_rng) => cha_cha8_rng.try_fill_bytes(dest),
⋮----
pub fn new(
⋮----
new_cluster_nodes(cluster_info, cluster_type, stakes, use_cha_cha_8)
⋮----
pub(crate) fn get_broadcast_peer(&self, shred: &ShredId) -> Option<&ContactInfo> {
⋮----
let index = self.weighted_shuffle.first(&mut rng)?;
self.nodes[index].contact_info()
⋮----
pub fn get_retransmit_addrs(
⋮----
) -> Result<(/*root_distance:*/ u8, Vec<SocketAddr>), Error> {
// Exclude slot leader from list of nodes.
⋮----
return Err(Error::Loopback {
⋮----
THREAD_LOCAL_WEIGHTED_SHUFFLE.with_borrow_mut(|weighted_shuffle| {
weighted_shuffle.clone_from(&self.weighted_shuffle);
if let Some(index) = self.index.get(slot_leader) {
weighted_shuffle.remove_index(*index);
⋮----
let (index, peers) = get_retransmit_peers(
⋮----
|k| self.nodes[k].pubkey() == &self.pubkey,
weighted_shuffle.shuffle(&mut rng),
⋮----
let protocol = get_broadcast_protocol(shred);
⋮----
.filter_map(|k| self.nodes[k].contact_info()?.tvu(protocol))
.filter(|addr| socket_addr_space.check(addr))
.collect();
let root_distance = get_root_distance(index, fanout);
Ok((root_distance, peers))
⋮----
// Returns the parent node in the turbine broadcast tree.
// Returns None if the node is the root of the tree or if it is not staked.
pub(crate) fn get_retransmit_parent(
⋮----
// Unstaked nodes' position in the turbine tree is not deterministic
⋮----
let Some(&index) = self.index.get(&self.pubkey) else {
return Ok(None);
⋮----
let mut weighted_shuffle = self.weighted_shuffle.clone();
if let Some(index) = self.index.get(leader).copied() {
weighted_shuffle.remove_index(index);
⋮----
.shuffle(&mut rng)
.map(|index| &self.nodes[index])
.take_while(|node| node.pubkey() != &self.pubkey)
⋮----
let parent = get_retransmit_parent(fanout, nodes.len(), &nodes);
Ok(parent.map(Node::pubkey).copied())
⋮----
pub fn new_cluster_nodes<T: 'static>(
⋮----
let self_pubkey = cluster_info.id();
let nodes = get_nodes(cluster_info, cluster_type, stakes);
⋮----
.iter()
.enumerate()
.map(|(ix, node)| (*node.pubkey(), ix))
⋮----
let stakes = nodes.iter().map(|node| node.stake);
⋮----
weighted_shuffle.remove_index(index[&self_pubkey]);
⋮----
// All staked nodes + other known tvu-peers + the node itself;
// sorted by (stake, pubkey) in descending order.
fn get_nodes(
⋮----
// The local node itself.
let stake = stakes.get(&self_pubkey).copied().unwrap_or_default();
let node = ContactInfo::from(&cluster_info.my_contact_info());
⋮----
// All known tvu-peers from gossip.
.chain(
⋮----
.tvu_peers(|node| ContactInfo::from(node))
.into_iter()
.map(|node| {
let stake = stakes.get(node.pubkey()).copied().unwrap_or_default();
⋮----
// All staked nodes.
⋮----
.filter(|(_, stake)| **stake > 0)
.map(|(&pubkey, &stake)| Node {
⋮----
sort_and_dedup_nodes(&mut nodes);
⋮----
dedup_tvu_addrs(&mut nodes);
⋮----
// Sorts nodes by highest stakes first and dedups by pubkey.
fn sort_and_dedup_nodes(nodes: &mut Vec<Node>) {
nodes.sort_unstable_by(|a, b| cmp_nodes_stake(b, a));
// dedup_by keeps the first of consecutive elements which compare equal.
// Because if all else are equal above sort puts NodeId::ContactInfo before
// NodeId::Pubkey, this will keep nodes with contact-info.
nodes.dedup_by(|a, b| a.pubkey() == b.pubkey());
⋮----
// Compares nodes by stake and tie breaks by pubkeys.
// For the same pubkey, NodeId::ContactInfo is considered > NodeId::Pubkey.
⋮----
fn cmp_nodes_stake(a: &Node, b: &Node) -> Ordering {
⋮----
.cmp(&b.stake)
.then_with(|| a.pubkey().cmp(b.pubkey()))
.then_with(|| match (&a.node, &b.node) {
⋮----
/// If set > 1 it allows the nodes to run behind a NAT.
/// This usecase is currently not supported.
⋮----
/// This usecase is currently not supported.
const MAX_NUM_NODES_PER_IP_ADDRESS: usize = 1;
/// Dedups socket addresses so that if there are 2 nodes in the cluster with the
/// same TVU socket-addr, we only send shreds to one of them.
⋮----
/// same TVU socket-addr, we only send shreds to one of them.
/// Additionally limits number of nodes at the same IP address to 1
⋮----
/// Additionally limits number of nodes at the same IP address to 1
fn dedup_tvu_addrs(nodes: &mut Vec<Node>) {
⋮----
fn dedup_tvu_addrs(nodes: &mut Vec<Node>) {
⋮----
let capacity = nodes.len().saturating_mul(2);
// Tracks (Protocol, SocketAddr) tuples already observed.
⋮----
// Maps IP addresses to number of nodes at that IP address.
⋮----
nodes.retain_mut(|node| {
⋮----
let Some(node) = node.contact_info_mut() else {
// Need to keep staked identities without gossip ContactInfo for
// deterministic shuffle.
⋮----
// Dedup socket addresses and limit nodes at same IP address.
⋮----
let Some(addr) = node.tvu(protocol) else {
⋮----
.entry((protocol, addr.ip()))
.and_modify(|count| *count += 1)
.or_insert(1);
if !addrs.insert((protocol, addr)) || count > MAX_NUM_NODES_PER_IP_ADDRESS {
// Remove the respective TVU address so that no more shreds are
// sent to this socket address.
node.remove_tvu_addr(protocol);
⋮----
// Always keep staked nodes for deterministic shuffle,
// but drop non-staked nodes if they have no valid TVU address.
⋮----
.any(|protocol| node.tvu(protocol).is_some())
⋮----
// root     : [0]
// 1st layer: [1, 2, ..., fanout]
// 2nd layer: [[fanout + 1, ..., fanout * 2],
//             [fanout * 2 + 1, ..., fanout * 3],
//             ...
//             [fanout * fanout + 1, ..., fanout * (fanout + 1)]]
// 3rd layer: ...
// ...
// The leader node broadcasts shreds to the root node.
// The root node retransmits the shreds to all nodes in the 1st layer.
// Each other node retransmits shreds to fanout many nodes in the next layer.
// For example the node k in the 1st layer will retransmit to nodes:
// fanout + k, 2*fanout + k, ..., fanout*fanout + k
fn get_retransmit_peers<T>(
⋮----
// Predicate fn which identifies this node in the shuffle.
⋮----
) -> (/*this node's index:*/ usize, impl Iterator<Item = T>) {
let mut nodes = nodes.into_iter();
let Some(index) = nodes.by_ref().position(pred) else {
⋮----
let offset = index.saturating_sub(1) % fanout;
⋮----
.step_by(step)
.take(fanout)
.scan(index, move |state, k| -> Option<T> {
let peer = nodes.by_ref().nth(k - *state - 1)?;
⋮----
Some(peer)
⋮----
fn get_retransmit_parent<T: Copy>(
⋮----
let index = index.checked_sub(1)? / fanout;
let index = index - index.saturating_sub(1) % fanout;
⋮----
nodes.get(index).copied()
⋮----
pub(crate) fn get(
⋮----
// Returns the cached entry for the epoch if it is either uninitialized
// or not expired yet. Discards the entry if it is already initialized
// but also expired.
⋮----
let entry: &Arc<OnceLock<(Instant, _)>> = cache.get(&epoch)?;
let Some((asof, _)) = entry.get() else {
return Some(entry.clone()); // not initialized yet
⋮----
(asof.elapsed() < ttl).then(|| entry.clone())
⋮----
let epoch_schedule = root_bank.epoch_schedule();
let epoch = epoch_schedule.get_epoch(shred_slot);
// Read from the cache with a shared lock.
⋮----
let cache = self.cache.read().unwrap();
get_epoch_entry(&cache, epoch, self.ttl)
⋮----
let use_cha_cha_8 = check_feature_activation(
⋮----
// Fall back to exclusive lock if there is a cache miss or the cached
// entry has already expired.
let entry: Arc<OnceLock<_>> = entry.unwrap_or_else(|| {
let mut cache = self.cache.write().unwrap();
get_epoch_entry(&cache, epoch, self.ttl).unwrap_or_else(|| {
// Either a cache miss here or the existing entry has already
// expired. Upsert and return an uninitialized entry.
⋮----
cache.put(epoch, Arc::clone(&entry));
⋮----
// Initialize if needed by only a single thread outside locks.
let (_, nodes) = entry.get_or_init(|| {
⋮----
.find_map(|bank| bank.epoch_staked_nodes(epoch))
.unwrap_or_else(|| {
error!(
⋮----
inc_new_counter_error!("cluster_nodes-unknown_epoch_staked_nodes", 1);
Arc::<HashMap<Pubkey, /*stake:*/ u64>>::default()
⋮----
root_bank.cluster_type(),
⋮----
nodes.clone()
⋮----
fn from(node: ContactInfo) -> Self {
⋮----
fn from(pubkey: Pubkey) -> Self {
⋮----
fn from(node: &GossipContactInfo) -> Self {
⋮----
pubkey: *node.pubkey(),
wallclock: node.wallclock(),
tvu_quic: node.tvu(Protocol::QUIC),
tvu_udp: node.tvu(Protocol::UDP),
⋮----
pub(crate) fn get_broadcast_protocol(_: &ShredId) -> Protocol {
⋮----
fn get_root_distance(index: usize, fanout: usize) -> u8 {
⋮----
} else if index <= fanout.saturating_add(1).saturating_mul(fanout) {
⋮----
3 // If changed, update MAX_NUM_TURBINE_HOPS.
⋮----
pub fn make_test_cluster<R: Rng>(
⋮----
HashMap<Pubkey, u64>, // stakes
⋮----
let (unstaked_numerator, unstaked_denominator) = unstaked_ratio.unwrap_or((1, 7));
let mut nodes: Vec<_> = repeat_with(|| {
⋮----
GossipContactInfo::new_localhost(&pubkey, /*wallclock:*/ timestamp())
⋮----
.take(num_nodes)
⋮----
nodes.shuffle(rng);
⋮----
nodes[0] = GossipContactInfo::new_localhost(&keypair.pubkey(), /*wallclock:*/ timestamp());
let this_node = nodes[0].clone();
⋮----
.filter_map(|node| {
if rng.gen_ratio(unstaked_numerator, unstaked_denominator) {
None // No stake for some of the nodes.
⋮----
Some((*node.pubkey(), rng.gen_range(0..20)))
⋮----
// Add some staked nodes with no contact-info.
stakes.extend(repeat_with(|| (Pubkey::new_unique(), rng.gen_range(0..20))).take(100));
⋮----
let now = timestamp();
⋮----
let mut gossip_crds = cluster_info.gossip.crds.write().unwrap();
// First node is pushed to crds table by ClusterInfo constructor.
for node in nodes.iter().skip(1) {
⋮----
assert_eq!(
⋮----
pub(crate) fn get_data_plane_fanout(shred_slot: Slot, root_bank: &Bank) -> usize {
if check_feature_activation(
⋮----
} else if check_feature_activation(
⋮----
// Allocate ~2% of slots to turbine fanout experiments.
⋮----
// feature_set::enable_turbine_fanout_experiments
// is already activated on all clusters.
⋮----
// Returns true if the feature is effective for the shred slot.
⋮----
pub fn check_feature_activation(feature: &Pubkey, shred_slot: Slot, root_bank: &Bank) -> bool {
match root_bank.feature_set.activated_slot(feature) {
⋮----
let feature_epoch = epoch_schedule.get_epoch(feature_slot);
let shred_epoch = epoch_schedule.get_epoch(shred_slot);
⋮----
mod tests {
⋮----
#[test_case(true /* chacha8 */)]
#[test_case(false /* chacha20 */)]
/// Test that we provide a complete coverage
    /// of all the nodes with weighted shuffles
⋮----
/// of all the nodes with weighted shuffles
    fn test_complete_cluster_coverage(use_cha_cha_8: bool) {
⋮----
fn test_complete_cluster_coverage(use_cha_cha_8: bool) {
⋮----
let (_nodes, stakes, cluster_info) = make_test_cluster(&mut rng, 20, Some((0, 1)));
let slot_leader = cluster_info.id();
// create a test cluster
⋮----
.unwrap()
.entries_to_merkle_shreds_for_tests(
⋮----
.pop()
.unwrap();
let mut weighted_shuffle = cluster_nodes.weighted_shuffle.clone();
let mut chacha_rng = TurbineRng::new_seeded(&slot_leader, &shred.id(), use_cha_cha_8);
⋮----
.shuffle(&mut chacha_rng)
.map(|i| &cluster_nodes.nodes[i])
⋮----
// Slot leader obviously has the shred
⋮----
// The root node has the shred sent to it initially
let mut queue = VecDeque::from([*shuffled_nodes[0].pubkey()]);
// traverse the turbine tree using the queue of nodes to visit (BFS)
while let Some(addr) = queue.pop_front() {
if !covered.insert(addr) {
panic!("Should not send to already covered nodes, instead sending to {addr}");
⋮----
let (_, peers) = get_retransmit_peers(
⋮----
|n: &Node| n.pubkey() == &addr,
shuffled_nodes.clone(),
⋮----
// visit all child nodes
⋮----
trace!("{} is child of {addr}", peer.pubkey());
queue.push_back(*peer.pubkey());
if stakes[peer.pubkey()] == 0 {
continue; // no check of retransmit parents for unstaked nodes
⋮----
// luckily for us, ClusterNodes<RetransmitStage> does not do anything with own identity
⋮----
peer_cluster_nodes.pubkey = *peer.pubkey();
// check that the parent computed by the child matches actual parent.
⋮----
.get_retransmit_parent(&slot_leader, &shred.id(), fanout)
⋮----
// Convert cluster_nodes into hashset of pubkeys
let all_nodes: HashSet<_> = cluster_nodes.nodes.iter().map(|n| *n.pubkey()).collect();
assert_eq!(all_nodes, covered, "All nodes must be covered");
⋮----
fn test_cluster_nodes_retransmit() {
⋮----
let (nodes, stakes, cluster_info) = make_test_cluster(&mut rng, 1_000, None);
// ClusterInfo::tvu_peers excludes the node itself.
⋮----
// All nodes with contact-info should be in the index.
// Staked nodes with no contact-info should be included.
assert!(cluster_nodes.nodes.len() > nodes.len());
// Assert that all nodes keep their contact-info.
// and, all staked nodes are also included.
⋮----
.map(|node| (node.pubkey(), node))
⋮----
assert_eq!(cluster_nodes[pubkey].stake, *stake);
⋮----
#[test_case(true)/*ChaCha8 */]
#[test_case(false)/*ChaCha20 */]
fn test_cluster_nodes_broadcast(use_cha_cha_8: bool) {
⋮----
// Excluding this node itself.
⋮----
// Checks (1) computed retransmit children against expected children and
// (2) computed parent of each child against the expected parent.
fn check_retransmit_nodes<T>(fanout: usize, nodes: &[T], peers: Vec<Vec<T>>)
⋮----
// Map node identities to their index within the shuffled tree.
⋮----
.copied()
⋮----
.map(|(k, node)| (node, k))
⋮----
let offset = peers.len();
// Root node's parent is None.
assert_eq!(get_retransmit_parent(fanout,  0, nodes), None);
for (k, peers) in peers.into_iter().enumerate() {
⋮----
get_retransmit_peers(fanout, |node| node == &nodes[k], nodes);
assert_eq!(peers, retransmit_peers.copied().collect::<Vec<_>>());
assert_eq!(index, k);
⋮----
let parent = Some(nodes[k]);
⋮----
assert_eq!(get_retransmit_parent(fanout, cache[&peer], nodes), parent);
⋮----
for k in offset..nodes.len() {
let (index, mut peers) = get_retransmit_peers(fanout, |node| node == &nodes[k], nodes);
assert_eq!(peers.next(), None);
⋮----
fn test_get_retransmit_nodes() {
⋮----
let peers = vec![
⋮----
check_retransmit_nodes( 2, &nodes, peers);
⋮----
check_retransmit_nodes( 3, &nodes, peers);
⋮----
fn test_get_retransmit_nodes_round_trip(fanout: usize, size: usize) {
⋮----
let mut nodes: Vec<_> = (0..size).collect();
nodes.shuffle(&mut rng);
⋮----
assert_eq!(get_retransmit_parent(fanout,  0, &nodes), None);
⋮----
let parent = get_retransmit_parent(fanout, k, &nodes).unwrap();
let (index, mut peers) = get_retransmit_peers(fanout, |node| node == &parent, &nodes);
assert_eq!(index, cache[&parent]);
assert_eq!(peers.find(|&&peer| peer == nodes[k]), Some(&nodes[k]));
⋮----
let (index, peers) = get_retransmit_peers(fanout, |node| node == &nodes[k], &nodes);
⋮----
assert_eq!(get_retransmit_parent(fanout, cache[peer], &nodes), parent);
⋮----
fn test_sort_and_dedup_nodes() {
⋮----
.take(50)
⋮----
let stakes = std::iter::repeat_with(|| rng.gen_range(0..100u64));
let stakes: HashMap<Pubkey, u64> = pubkeys.iter().copied().zip(stakes).collect();
⋮----
let pubkey = pubkeys.choose(&mut rng).copied().unwrap();
⋮----
let node = GossipContactInfo::new_localhost(&pubkey,  timestamp());
⋮----
.flatten()
.take(10_000)
⋮----
let mut unique_pubkeys: HashSet<Pubkey> = nodes.iter().map(Node::pubkey).copied().collect();
⋮----
for (a, b) in nodes.iter().tuple_windows() {
assert!(a.stake >= b.stake);
⋮----
assert!(a.pubkey() > b.pubkey());
⋮----
assert_matches!(node.node, NodeId::ContactInfo(_));
⋮----
assert!(unique_pubkeys.remove(node.pubkey()))
⋮----
assert!(unique_pubkeys.is_empty());

================
File: turbine/src/lib.rs
================
mod addr_cache;
pub mod broadcast_stage;
pub mod cluster_nodes;
pub mod quic_endpoint;
pub mod retransmit_stage;
pub mod sigverify_shreds;
pub mod xdp;
⋮----
extern crate log;
⋮----
extern crate solana_metrics;
⋮----
extern crate assert_matches;

================
File: turbine/src/quic_endpoint.rs
================
pub type AsyncTryJoinHandle = TryJoin<JoinHandle<()>, JoinHandle<()>>;
⋮----
pub enum Error {
⋮----
macro_rules! add_metric {
⋮----
pub fn new_quic_endpoint(
⋮----
let (cert, key) = new_dummy_x509_certificate(keypair);
let server_config = new_server_config(cert.clone(), key.clone_key())?;
let client_config = new_client_config(cert, key)?;
⋮----
let _guard = runtime.enter();
⋮----
Some(server_config),
⋮----
endpoint.set_default_client_config(client_config);
⋮----
let server_task = runtime.spawn(run_server(
endpoint.clone(),
sender.clone(),
bank_forks.clone(),
prune_cache_pending.clone(),
router.clone(),
cache.clone(),
⋮----
let client_task = runtime.spawn(run_client(
⋮----
Ok((endpoint, client_sender, task))
⋮----
pub fn close_quic_endpoint(endpoint: &Endpoint) {
endpoint.close(
⋮----
fn new_server_config(
⋮----
let mut config = tls_server_config_builder().with_single_cert(vec![cert], key)?;
config.alpn_protocols = vec![ALPN_TURBINE_PROTOCOL_ID.to_vec()];
⋮----
.map_err(|_err| rustls::Error::InvalidCertificate(CertificateError::BadSignature))?;
⋮----
.transport_config(Arc::new(new_transport_config()))
.migration(false);
Ok(config)
⋮----
fn new_client_config(
⋮----
let mut config = tls_client_config_builder().with_client_auth_cert(vec![cert], key)?;
⋮----
let mut config = ClientConfig::new(Arc::new(QuicClientConfig::try_from(config).unwrap()));
config.transport_config(Arc::new(new_transport_config()));
⋮----
fn new_transport_config() -> TransportConfig {
let max_idle_timeout = IdleTimeout::try_from(MAX_IDLE_TIMEOUT).unwrap();
⋮----
.datagram_receive_buffer_size(Some(DATAGRAM_RECEIVE_BUFFER_SIZE))
.datagram_send_buffer_size(DATAGRAM_SEND_BUFFER_SIZE)
.initial_mtu(INITIAL_MAXIMUM_TRANSMISSION_UNIT)
.keep_alive_interval(Some(KEEP_ALIVE_INTERVAL))
.max_concurrent_bidi_streams(VarInt::from(0u8))
.max_concurrent_uni_streams(VarInt::from(0u8))
.max_idle_timeout(Some(max_idle_timeout))
.min_mtu(MINIMUM_MAXIMUM_TRANSMISSION_UNIT)
.mtu_discovery_config(None);
⋮----
async fn run_server(
⋮----
tokio::task::spawn(report_metrics_task("turbine_quic_server", stats.clone()));
while let Some(incoming) = endpoint.accept().await {
let remote_addr: SocketAddr = incoming.remote_address();
let connecting = incoming.accept();
⋮----
tokio::task::spawn(handle_connecting_task(
⋮----
stats.clone(),
⋮----
debug!("Error while accepting incoming connection: {error:?} from {remote_addr}");
⋮----
report_metrics_task.abort();
⋮----
async fn run_client(
⋮----
tokio::task::spawn(report_metrics_task("turbine_quic_client", stats.clone()));
while let Some((remote_address, bytes)) = receiver.recv().await {
let Some(bytes) = try_route_bytes(&remote_address, bytes, &*router.read().await, &stats)
⋮----
let mut router = router.write().await;
let Some(bytes) = try_route_bytes(&remote_address, bytes, &router, &stats) else {
⋮----
sender.try_send(bytes).unwrap();
router.insert(remote_address, sender);
⋮----
tokio::task::spawn(make_connection_task(
⋮----
close_quic_endpoint(&endpoint);
router.write().await.clear();
⋮----
fn try_route_bytes(
⋮----
match router.get(remote_address) {
None => Some(bytes),
Some(sender) => match sender.try_send(bytes) {
⋮----
debug!("TrySendError::Full {remote_address}");
add_metric!(stats.router_try_send_error_full);
⋮----
Err(TrySendError::Closed(bytes)) => Some(bytes),
⋮----
async fn handle_connecting_task(
⋮----
if let Err(err) = handle_connecting(
⋮----
debug!("handle_connecting: {err:?}");
record_error(&err, &stats);
⋮----
async fn handle_connecting(
⋮----
let remote_address = connection.remote_address();
let remote_pubkey = get_remote_pubkey(&connection)?;
⋮----
router.write().await.insert(remote_address, sender);
⋮----
handle_connection(
⋮----
Ok(())
⋮----
async fn handle_connection(
⋮----
cache_connection(
⋮----
connection.clone(),
⋮----
let send_datagram_task = tokio::task::spawn(send_datagram_task(connection.clone(), receiver));
let read_datagram_task = tokio::task::spawn(read_datagram_task(
⋮----
Err(err) => error!("handle_connection: {remote_pubkey}, {remote_address}, {err:?}"),
⋮----
debug!("send_datagram_task: {remote_pubkey}, {remote_address}, {err:?}");
record_error(err, &stats);
⋮----
debug!("read_datagram_task: {remote_pubkey}, {remote_address}, {err:?}");
⋮----
drop_connection(remote_pubkey, &connection, &cache).await;
if let Entry::Occupied(entry) = router.write().await.entry(remote_address) {
if entry.get().is_closed() {
entry.remove();
⋮----
async fn read_datagram_task(
⋮----
debug_assert_eq!(sender.capacity(), None);
⋮----
match connection.read_datagram().await {
⋮----
if let Err(err) = sender.send((remote_pubkey, remote_address, bytes)) {
⋮----
return Err(Error::from(err));
⋮----
if let Some(err) = connection.close_reason() {
⋮----
debug!("connection.read_datagram: {remote_pubkey}, {remote_address}, {err:?}");
record_error(&Error::from(err), &stats);
⋮----
async fn send_datagram_task(
⋮----
async fn make_connection_task(
⋮----
if let Err(err) = make_connection(
⋮----
debug!("make_connection: {remote_address}, {err:?}");
⋮----
async fn make_connection(
⋮----
let server_name = socket_addr_to_quic_server_name(remote_address);
let connection = endpoint.connect(remote_address, &server_name)?.await?;
⋮----
connection.remote_address(),
get_remote_pubkey(&connection)?,
⋮----
fn get_remote_pubkey(connection: &Connection) -> Result<Pubkey, Error> {
⋮----
Some(remote_pubkey) => Ok(remote_pubkey),
⋮----
connection.close(
⋮----
Err(Error::InvalidIdentity(connection.remote_address()))
⋮----
async fn cache_connection(
⋮----
let mut cache = cache.lock().await;
⋮----
cache.insert(remote_pubkey, connection),
cache.len() >= CONNECTION_CACHE_CAPACITY.saturating_mul(2),
⋮----
old.close(
⋮----
if should_prune_cache && !prune_cache_pending.swap(true, Ordering::Relaxed) {
tokio::task::spawn(prune_connection_cache(
⋮----
async fn drop_connection(
⋮----
if let Entry::Occupied(entry) = cache.lock().await.entry(remote_pubkey) {
if entry.get().stable_id() == connection.stable_id() {
⋮----
async fn prune_connection_cache(
⋮----
debug_assert!(prune_cache_pending.load(Ordering::Relaxed));
⋮----
let root_bank = bank_forks.read().unwrap().root_bank();
root_bank.current_epoch_staked_nodes()
⋮----
if cache.len() < CONNECTION_CACHE_CAPACITY.saturating_mul(2) {
prune_cache_pending.store(false, Ordering::Relaxed);
⋮----
.drain()
.filter(|(_, connection)| connection.close_reason().is_none())
.map(|entry @ (pubkey, _)| {
let stake = staked_nodes.get(&pubkey).copied().unwrap_or_default();
⋮----
.collect();
⋮----
.select_nth_unstable_by_key(CONNECTION_CACHE_CAPACITY, |&(stake, _)| Reverse(stake));
⋮----
cache.extend(
⋮----
.into_iter()
.take(CONNECTION_CACHE_CAPACITY)
.map(|(_, entry)| entry),
⋮----
router.write().await.retain(|_, sender| !sender.is_closed());
⋮----
fn from(_: crossbeam_channel::SendError<T>) -> Self {
⋮----
struct TurbineQuicStats {
⋮----
async fn report_metrics_task(name: &'static str, stats: Arc<TurbineQuicStats>) {
⋮----
report_metrics(name, &stats);
⋮----
fn record_error(err: &Error, stats: &TurbineQuicStats) {
⋮----
add_metric!(stats.connect_error_other)
⋮----
add_metric!(stats.connect_error_invalid_remote_address)
⋮----
add_metric!(stats.connection_error_version_mismatch)
⋮----
add_metric!(stats.connection_error_transport_error)
⋮----
add_metric!(stats.connection_error_connection_closed)
⋮----
add_metric!(stats.connection_error_application_closed)
⋮----
Error::ConnectionError(ConnectionError::Reset) => add_metric!(stats.connection_error_reset),
⋮----
add_metric!(stats.connection_error_timed_out)
⋮----
add_metric!(stats.connection_error_locally_closed)
⋮----
Error::InvalidIdentity(_) => add_metric!(stats.invalid_identity),
⋮----
add_metric!(stats.send_datagram_error_unsupported_by_peer)
⋮----
add_metric!(stats.send_datagram_error_too_large)
⋮----
add_metric!(stats.send_datagram_error_connection_lost)
⋮----
add_metric!(stats.connect_error_cids_exhausted)
⋮----
add_metric!(stats.connect_error_invalid_server_name)
⋮----
add_metric!(stats.connection_error_cids_exhausted)
⋮----
fn report_metrics(name: &'static str, stats: &TurbineQuicStats) {
macro_rules! reset_metric {
⋮----
datapoint_info!(
⋮----
mod tests {
⋮----
fn test_quic_endpoint() {
⋮----
.worker_threads(8)
.enable_all()
.build()
.unwrap();
let keypairs: Vec<Keypair> = repeat_with(Keypair::new).take(NUM_ENDPOINTS).collect();
let port_range = localhost_port_range_for_tests();
⋮----
.map(|port| bind_to(ip_addr, port).unwrap())
.take(NUM_ENDPOINTS)
⋮----
.iter()
.map(UdpSocket::local_addr)
⋮----
repeat_with(crossbeam_channel::unbounded::<(Pubkey, SocketAddr, Bytes)>)
⋮----
.unzip();
⋮----
create_genesis_config( 100_000);
⋮----
multiunzip(keypairs.iter().zip(sockets).zip(senders).map(
⋮----
new_quic_endpoint(
runtime.handle(),
⋮----
.unwrap()
⋮----
for (i, (keypair, &address, sender)) in izip!(&keypairs, &addresses, &senders).enumerate() {
for (j, &address) in addresses.iter().enumerate() {
⋮----
let bytes = Bytes::from(format!("{i}=>{j}"));
sender.blocking_send((address, bytes)).unwrap();
⋮----
for (j, receiver) in receivers.iter().enumerate() {
⋮----
let entry = (keypair.pubkey(), address, bytes);
assert_eq!(receiver.recv_timeout(RECV_TIMEOUT).unwrap(), entry);
⋮----
drop(senders);
⋮----
runtime.block_on(task).unwrap();

================
File: turbine/src/retransmit_stage.rs
================
assert!(CLUSTER_NODES_CACHE_NUM_EPOCH_CAP >= 2);
assert!(CLUSTER_NODES_CACHE_NUM_EPOCH_CAP <= MAX_LEADER_SCHEDULE_STAKES as usize);
⋮----
struct RetransmitShredOutput {
⋮----
pub(crate) struct RetransmitSlotStats {
⋮----
struct RetransmitStats {
⋮----
impl RetransmitStats {
fn maybe_submit(
⋮----
if self.since.elapsed() < SUBMIT_CADENCE {
⋮----
.get(root_bank.slot(), root_bank, working_bank, cluster_info)
.submit_metrics("cluster_nodes_retransmit", timestamp());
datapoint_info!(
⋮----
struct ShredDeduper<const K: usize = 2> {
⋮----
fn new<R: Rng>(rng: &mut R, num_bits: u64) -> Self {
⋮----
fn maybe_reset<R: Rng>(
⋮----
.maybe_reset(rng, false_positive_rate, reset_cycle);
⋮----
fn dedup(&self, key: ShredId, shred: &[u8], max_duplicate_count: usize) -> bool {
⋮----
.map(|header| self.deduper.dedup(header))
.unwrap_or(true)
|| (0..max_duplicate_count).all(|i| self.shred_id_filter.dedup(&(key, i)))
⋮----
enum RetransmitSocket<'a> {
⋮----
pub fn new(
⋮----
} else if cluster_info.bind_ip_addrs().multihoming_enabled() {
⋮----
retransmit_sockets.len() / cluster_info.bind_ip_addrs().len();
let active_index = cluster_info.bind_ip_addrs().active_index();
let interface_offset = sockets_per_interface.saturating_mul(active_index);
⋮----
let socket: &UdpSocket = &retransmit_sockets[thread_index % retransmit_sockets.len()];
⋮----
pub fn get_socket(&self) -> &'a UdpSocket {
⋮----
unreachable!("get_socket() should not be called for XDP variants")
⋮----
fn retransmit(
⋮----
match retransmit_receiver.try_recv() {
⋮----
shred_buf.push(shreds);
⋮----
Err(TryRecvError::Disconnected) => return Err(RecvError),
⋮----
if cache_retransmit_addrs(
⋮----
return Ok(());
⋮----
shred_buf.push(retransmit_receiver.recv()?);
⋮----
let mut num_shreds = shred_buf[0].len();
⋮----
.try_iter()
.take(RETRANSMIT_BATCH_SIZE - 1)
⋮----
num_shreds += shreds.len();
⋮----
let bank_forks = bank_forks.read().unwrap();
(bank_forks.working_bank(), bank_forks.root_bank())
⋮----
epoch_fetch.stop();
stats.epoch_fetch += epoch_fetch.as_us();
⋮----
shred_deduper.maybe_reset(
⋮----
epoch_cache_update.stop();
stats.epoch_cache_update += epoch_cache_update.as_us();
⋮----
.iter()
.flatten()
.filter_map(|shred| shred::layout::get_slot(shred))
⋮----
.into_iter()
.filter_map(|slot: Slot| {
max_slots.retransmit.fetch_max(slot, Ordering::Relaxed);
let Some(slot_leader) = leader_schedule_cache.slot_leader_at(slot, Some(&working_bank))
⋮----
cluster_nodes_cache.get(slot, &root_bank, &working_bank, cluster_info);
Some((slot, (slot_leader, cluster_nodes)))
⋮----
.collect();
let socket_addr_space = cluster_info.socket_addr_space();
⋮----
let now = timestamp();
let entry = stats.entry(out.shred.slot()).or_default();
entry.record(now, out);
⋮----
let shred_receiver_address_local = shred_receiver_address.load();
⋮----
retransmit_shred(
⋮----
.drain(..)
⋮----
.enumerate()
.filter_map(|(index, shred)| retransmit_shred(shred, retransmit_socket(index), stats))
.fold(HashMap::new(), record)
⋮----
thread_pool.install(|| {
⋮----
.par_drain(..)
⋮----
.filter_map(|shred| {
⋮----
retransmit_socket(thread_pool.current_thread_index().unwrap()),
⋮----
.fold(HashMap::new, record)
.reduce(HashMap::new, RetransmitSlotStats::merge)
⋮----
stats.upsert_slot_stats(
⋮----
root_bank.slot(),
⋮----
timer_start.stop();
stats.total_time += timer_start.as_us();
stats.maybe_submit(
⋮----
xdp_sender.is_some(),
⋮----
Ok(())
⋮----
fn retransmit_shred(
⋮----
let key = shred::layout::get_shred_id(shred.as_ref())?;
if key.slot() < root_bank.slot()
|| shred_deduper.dedup(key, shred.as_ref(), MAX_DUPLICATE_COUNT)
⋮----
stats.num_shreds_skipped.fetch_add(1, Ordering::Relaxed);
⋮----
get_retransmit_addrs(&key, root_bank, cache, addr_cache, socket_addr_space, stats)?;
compute_turbine_peers.stop();
⋮----
.fetch_add(compute_turbine_peers.as_us(), Ordering::Relaxed);
let last_shred_in_slot = shred::wire::get_flags(shred.as_ref())
.map(|flags| flags.contains(ShredFlags::LAST_SHRED_IN_SLOT))
.unwrap_or_default();
⋮----
let num_addrs = addrs.len();
⋮----
.filter_map(|&addr| quic_endpoint_sender.try_send((addr, shred.clone())).ok())
.count()
⋮----
if (num_addrs > 0) || shred_receiver_addr.is_some() {
// shred receiver not included in the stats
⋮----
send_addrs.extend(addrs.iter());
⋮----
send_addrs.push(*addr);
⋮----
if let Err(e) = sender.try_send(key.index() as usize, send_addrs, shred) {
⋮----
.fetch_add(num_addrs, Ordering::Relaxed);
⋮----
let socket = socket.get_socket();
⋮----
match multi_target_send(socket, shred, &send_addrs) {
⋮----
error!(
⋮----
retransmit_time.stop();
⋮----
.fetch_add(num_addrs - num_nodes, Ordering::Relaxed);
stats.num_nodes.fetch_add(num_nodes, Ordering::Relaxed);
⋮----
.fetch_add(retransmit_time.as_us(), Ordering::Relaxed);
Some(RetransmitShredOutput {
⋮----
Cow::Owned(addrs) => Some(addrs.into_boxed_slice()),
⋮----
fn get_retransmit_addrs<'a>(
⋮----
) -> Option<(/*root_distance:*/ u8, Cow<'a, [SocketAddr]>)> {
if let Some((root_distance, addrs)) = addr_cache.get(shred) {
stats.addr_cache_hit.fetch_add(1, Ordering::Relaxed);
return Some((root_distance, Cow::Borrowed(addrs)));
⋮----
let (slot_leader, cluster_nodes) = cache.get(&shred.slot())?;
let data_plane_fanout = cluster_nodes::get_data_plane_fanout(shred.slot(), root_bank);
⋮----
.get_retransmit_addrs(slot_leader, shred, data_plane_fanout, socket_addr_space)
.inspect_err(|err| match err {
⋮----
stats.num_loopback_errs.fetch_add(1, Ordering::Relaxed);
⋮----
.ok()?;
stats.addr_cache_miss.fetch_add(1, Ordering::Relaxed);
Some((root_distance, Cow::Owned(addrs)))
⋮----
fn cache_retransmit_addrs(
⋮----
let shreds = addr_cache.get_shreds(thread_pool.current_num_threads() * 4);
if shreds.is_empty() {
⋮----
.map(ShredId::slot)
⋮----
let slot_leader = leader_schedule_cache.slot_leader_at(slot, Some(&working_bank))?;
⋮----
if cache.is_empty() {
⋮----
let data_plane_fanout = cluster_nodes::get_data_plane_fanout(shred.slot(), &root_bank);
⋮----
.get_retransmit_addrs(slot_leader, &shred, data_plane_fanout, socket_addr_space)
⋮----
Some((shred, (root_distance, addrs.into_boxed_slice())))
⋮----
if shreds.len() < PAR_ITER_MIN_NUM_SHREDS {
for (shred, entry) in shreds.into_iter().filter_map(get_retransmit_addrs) {
addr_cache.put(&shred, entry);
⋮----
let entries: Vec<_> = thread_pool.install(|| {
⋮----
.into_par_iter()
.filter_map(get_retransmit_addrs)
.collect()
⋮----
pub struct RetransmitStage {
⋮----
impl RetransmitStage {
⋮----
let num_threads = retransmit_sockets.len();
⋮----
.num_threads(num_threads)
.thread_name(|i| format!("solRetransmit{i:02}"))
.build()
.unwrap()
⋮----
.name("solRetransmittr".to_string())
.spawn({
⋮----
while retransmit(
⋮----
xdp_sender.as_ref(),
⋮----
rpc_subscriptions.as_deref(),
slot_status_notifier.as_ref(),
⋮----
votor_event_sender.as_ref(),
⋮----
.is_ok()
⋮----
.unwrap();
⋮----
pub fn join(self) -> thread::Result<()> {
self.retransmit_thread_handle.join()
⋮----
impl AddAssign for RetransmitSlotStats {
fn add_assign(&mut self, other: Self) {
⋮----
self.asof = self.asof.max(asof);
self.max_index_code = self.max_index_code.max(max_index_code);
self.max_index_data = self.max_index_data.max(max_index_data);
⋮----
self.outset.min(outset)
⋮----
if self.addrs.len() < addrs.len() {
⋮----
self.addrs.append(&mut addrs);
⋮----
fn new(now: Instant) -> Self {
⋮----
fn upsert_slot_stats(
⋮----
addr_cache.record(slot, &mut slot_stats);
match self.slot_stats.get_mut(&slot) {
⋮----
notify_subscribers(
⋮----
self.slot_stats.put(slot, slot_stats);
⋮----
while self.slot_stats.len() > Self::SLOT_STATS_CACHE_CAPACITY {
match self.slot_stats.pop_lru() {
Some((slot, stats)) => stats.submit(slot),
⋮----
impl RetransmitSlotStats {
fn record(&mut self, now: u64, out: RetransmitShredOutput) {
⋮----
self.outset.min(now)
⋮----
self.asof = self.asof.max(now);
let max_index = match out.shred.shred_type() {
⋮----
*max_index = (*max_index).max(out.shred.index());
⋮----
self.addrs.push((out.shred, out.root_distance, addrs));
⋮----
fn merge(mut acc: HashMap<Slot, Self>, other: HashMap<Slot, Self>) -> HashMap<Slot, Self> {
if acc.len() < other.len() {
⋮----
*acc.entry(key).or_default() += value;
⋮----
fn submit(&self, slot: Slot) {
let num_shreds: usize = self.num_shreds_received.iter().sum();
let num_nodes: usize = self.num_shreds_sent.iter().sum();
let elapsed_millis = self.asof.saturating_sub(self.outset);
⋮----
fn notify_subscribers(
⋮----
rpc_subscriptions.notify_slot_update(slot_update);
datapoint_info!("retransmit-first-shred", ("slot", slot, i64));
⋮----
.read()
⋮----
.notify_first_shred_received(slot);
⋮----
if let Err(err) = votor_event_sender.send(VotorEvent::FirstShred(slot)) {
warn!(
⋮----
mod tests {
⋮----
fn get_keypair() -> Keypair {
⋮----
.into_vec()
.as_deref()
.map(Keypair::try_from)
⋮----
fn test_shred_deduper() {
let keypair = get_keypair();
let entries = create_ticks(10, 1, Hash::new_unique());
⋮----
let shredder = Shredder::new(slot, parent, 1, 0).unwrap();
shredder.entries_to_merkle_shreds_for_tests(
⋮----
Hash::new_from_array(rand::thread_rng().gen()),
⋮----
let (shreds_data_5_4, shreds_code_5_4) = make_shreds_for_slot(5, 4, 0);
let (shreds_data_5_3, _shreds_code_5_3) = make_shreds_for_slot(5, 3, 0);
let (shreds_data_5_2, _shreds_code_5_2) = make_shreds_for_slot(5, 2, 0);
let shred = shreds_data_5_4.last().unwrap().clone();
assert!(
⋮----
let shred_dup = shreds_data_5_3.last().unwrap().clone();
⋮----
let shred_dup2 = shreds_data_5_2.last().unwrap().clone();
⋮----
let shred = shreds_code_5_4[4].clone();
⋮----
let (_, shreds_code_invalid) = make_shreds_for_slot(5, 4, 2);
let shred_inv_code_1 = shreds_code_invalid[2].clone();
assert_eq!(
⋮----
let (_, shreds_code_invalid) = make_shreds_for_slot(5, 4, 3);
let shred_inv_code_2 = shreds_code_invalid[1].clone();

================
File: turbine/src/sigverify_shreds.rs
================
enum ShredSigverifyError {
⋮----
enum ResignError {
⋮----
pub fn spawn_shred_sigverify(
⋮----
.num_threads(num_sigverify_threads.get())
.thread_name(|i| format!("solSvrfyShred{i:02}"))
.build()
.expect("new rayon threadpool");
⋮----
if deduper.maybe_reset(&mut rng, DEDUPER_FALSE_POSITIVE_RATE, DEDUPER_RESET_CYCLE) {
⋮----
let keypair = cluster_info.keypair();
match run_shred_sigverify(
⋮----
stats.maybe_submit();
⋮----
.name("solShredVerifr".to_string())
.spawn(run_shred_sigverify)
.unwrap()
⋮----
fn run_shred_sigverify<const K: usize>(
⋮----
let packets = shred_fetch_receiver.recv_timeout(RECV_TIMEOUT)?;
stats.num_packets += packets.len();
shred_buffer.push(packets);
⋮----
.try_iter()
.take(SIGVERIFY_SHRED_BATCH_SIZE - 1)
⋮----
stats.num_batches += shred_buffer.len();
stats.num_discards_pre += count_discards(shred_buffer);
stats.num_duplicates += thread_pool.install(|| {
⋮----
.par_iter_mut()
.flatten()
.filter(|packet| {
!packet.meta().discard()
&& shred::wire::get_shred(packet.as_ref())
.map(|shred| deduper.dedup(shred))
.unwrap_or(true)
&& !packet.meta().repair()
⋮----
.map(|mut packet| packet.meta_mut().set_discard(true))
.count()
⋮----
let bank_forks = bank_forks.read().unwrap();
(bank_forks.working_bank(), bank_forks.root_bank())
⋮----
verify_packets(
⋮----
&keypair.pubkey(),
⋮----
stats.num_discards_post += count_discards(shred_buffer);
⋮----
thread_pool.install(|| {
⋮----
.filter(|packet| !packet.meta().discard())
.for_each(|mut packet| {
if maybe_verify_and_resign_packet(
⋮----
.is_err()
⋮----
packet.meta_mut().set_discard(true);
⋮----
stats.resign_micros += resign_start.elapsed().as_micros() as u64;
⋮----
.iter()
.flat_map(|batch| batch.iter())
⋮----
.filter_map(|packet| {
let shred = shred::layout::get_shred(packet)?.to_vec();
Some((shred, packet.meta().repair()))
⋮----
.partition_map(|(shred, repair)| {
⋮----
stats.num_retransmit_shreds += shreds.len();
if let Err(send_err) = retransmit_sender.try_send(shreds.clone()) {
⋮----
stats.num_retransmit_stage_overflow_shreds += v.len();
⋮----
_ => unreachable!("EvictingSender holds on to both ends of the channel"),
⋮----
.into_iter()
.map(|shred| (shred,  false));
⋮----
.map(|shred| (shred,  true));
verified_sender.send(shreds.chain(repairs).collect())?;
stats.elapsed_micros += now.elapsed().as_micros() as u64;
shred_buffer.clear();
Ok(())
⋮----
fn maybe_verify_and_resign_packet(
⋮----
let repair = packet.meta().repair();
let shred = get_shred(packet.as_ref()).ok_or(shred::Error::InvalidPacketSize)?;
let is_signed = is_retransmitter_signed_variant(shred)?;
⋮----
&& !verify_retransmitter_signature(
⋮----
.fetch_add(1, Ordering::Relaxed);
⋮----
.map(|slot| {
check_feature_activation(
⋮----
.unwrap_or_default()
⋮----
return Err(ResignError::VerifyRetransmitterSignature);
⋮----
resign_packet(packet, keypair)?;
⋮----
fn verify_retransmitter_signature(
⋮----
let Some(leader) = leader_schedule_cache.slot_leader_at(shred.slot(), Some(working_bank))
⋮----
cluster_nodes_cache.get(shred.slot(), root_bank, working_bank, cluster_info);
let data_plane_fanout = cluster_nodes::get_data_plane_fanout(shred.slot(), root_bank);
let parent = match cluster_nodes.get_retransmit_parent(&leader, &shred, data_plane_fanout) {
⋮----
error!("get_retransmit_parent: {err:?}");
⋮----
if signature.verify(parent.as_ref(), merkle_root.as_ref()) {
⋮----
fn verify_packets(
⋮----
get_slot_leaders(self_pubkey, packets, leader_schedule_cache, working_bank)
.filter_map(|(slot, pubkey)| Some((slot, pubkey?)))
.chain(std::iter::once((Slot::MAX, Pubkey::default())))
.collect();
let out = verify_shreds(thread_pool, packets, &leader_slots, cache);
⋮----
fn get_slot_leaders<'a>(
⋮----
.iter_mut()
.flat_map(|batch| batch.iter_mut())
⋮----
.filter_map(move |mut packet| {
let shred = shred::layout::get_shred(packet.as_ref());
let slot = shred.and_then(shred::layout::get_slot)?;
⋮----
.slot_leader_at(slot, Some(bank))
.filter(|leader| leader != self_pubkey);
if leader.is_none() {
⋮----
Some((slot, leader))
⋮----
fn count_discards(packets: &[PacketBatch]) -> usize {
⋮----
.filter(|packet| packet.meta().discard())
⋮----
fn from(err: RecvTimeoutError) -> Self {
⋮----
fn from(_: SendError<T>) -> Self {
⋮----
struct ShredSigVerifyStats {
⋮----
impl ShredSigVerifyStats {
⋮----
fn new(now: Instant) -> Self {
⋮----
fn maybe_submit(&mut self) {
if self.since.elapsed() <= Self::METRICS_SUBMIT_CADENCE {
⋮----
datapoint_info!(
⋮----
mod tests {
⋮----
fn test_sigverify_shreds_verify_batches() {
⋮----
let leader_pubkey = leader_keypair.pubkey();
⋮----
&create_genesis_config_with_leader(100, &leader_pubkey, 10).genesis_config,
⋮----
batch.resize(batch_size, Packet::default());
let mut batches = vec![batch];
let entries = create_ticks(1, 1, Hash::new_unique());
let shredder = Shredder::new(1, 0, 1, 0).unwrap();
let (shreds_data, _shreds_code) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
let (shreds_data_wrong, _shreds_code_wrong) = shredder.entries_to_merkle_shreds_for_tests(
⋮----
let shred = shreds_data[0].clone();
batches[0][0].buffer_mut()[..shred.payload().len()].copy_from_slice(shred.payload());
batches[0][0].meta_mut().size = shred.payload().len();
let shred = shreds_data_wrong[0].clone();
batches[0][1].buffer_mut()[..shred.payload().len()].copy_from_slice(shred.payload());
batches[0][1].meta_mut().size = shred.payload().len();
⋮----
let thread_pool = ThreadPoolBuilder::new().num_threads(3).build().unwrap();
let working_bank = bank_forks.read().unwrap().working_bank();
⋮----
.map(PacketBatch::from)
⋮----
assert!(!batches[0].get(0).unwrap().meta().discard());
assert!(batches[0].get(1).unwrap().meta().discard());
⋮----
fn test_maybe_verify_and_resign_packet(repaired: bool, is_last_in_slot: bool) {
⋮----
let chained_merkle_root = Hash::new_from_array(rng.gen());
let shredder = Shredder::new(root_bank.slot(), root_bank.parent_slot(), 0, 0).unwrap();
let entries = vec![Entry::new(&Hash::default(), 0, vec![])];
⋮----
.make_merkle_shreds_from_entries(
⋮----
ContactInfo::new_localhost(&leader_pubkey, timestamp()),
⋮----
for shred in shreds.iter_mut() {
⋮----
let nonce = repaired.then(|| rng.gen::<Nonce>());
⋮----
let packet = &mut shred.payload().to_packet(nonce);
let buf_before = packet.buffer_mut().to_vec();
⋮----
packet.meta_mut().flags |= PacketFlags::REPAIR;
⋮----
maybe_verify_and_resign_packet(
&mut packet.into(),
⋮----
.expect("packet should pass the verification");
assert!(!packet.meta().discard());
assert_ne!(&buf_before, &packet.data(..).unwrap());
let mut bytes_packet = shred.payload().to_bytes_packet(nonce);
⋮----
bytes_packet.meta_mut().flags |= PacketFlags::REPAIR;
⋮----
let buf_addr = bytes_packet.buffer().as_ptr().addr();
⋮----
&mut bytes_packet.as_mut(),
⋮----
assert!(!bytes_packet.meta().discard());
let buf_addr_after = bytes_packet.buffer().as_ptr().addr();
assert_ne!(buf_addr, buf_addr_after);
⋮----
assert_eq!(buf_addr, buf_addr_after);

================
File: turbine/src/xdp.rs
================
pub use agave_xdp::set_cpu_affinity;
⋮----
pub struct XdpConfig {
⋮----
impl XdpConfig {
⋮----
impl Default for XdpConfig {
fn default() -> Self {
⋮----
cpus: vec![],
⋮----
pub fn new(interface: Option<impl Into<String>>, cpus: Vec<usize>, zero_copy: bool) -> Self {
⋮----
interface: interface.map(|s| s.into()),
⋮----
pub struct XdpSender {
⋮----
pub enum XdpAddrs {
⋮----
fn from(addr: SocketAddr) -> Self {
⋮----
fn from(addrs: Vec<SocketAddr>) -> Self {
⋮----
fn as_ref(&self) -> &[SocketAddr] {
⋮----
impl XdpSender {
⋮----
pub(crate) fn try_send(
⋮----
self.senders[sender_index % self.senders.len()].try_send((addr.into(), payload))
⋮----
pub struct XdpRetransmitter {
⋮----
impl XdpRetransmitter {
⋮----
pub fn new(
⋮----
Err("XDP is only supported on Linux".into())
⋮----
.map_err(|e| format!("failed to raise {cap:?} capability: {e}"))?;
⋮----
NetworkDevice::new(interface).unwrap()
⋮----
NetworkDevice::new_from_default_route().unwrap()
⋮----
Some(load_xdp_program(&dev).map_err(|e| format!("failed to attach xdp program: {e}"))?)
⋮----
caps::drop(None, CapSet::Effective, cap).unwrap();
⋮----
let (senders, receivers) = (0..config.cpus.len())
.map(|_| crossbeam_channel::bounded(config.rtx_channel_cap))
⋮----
let mut threads = vec![];
⋮----
threads.push(
⋮----
.name("solRetransmDrop".to_owned())
.spawn(move || {
⋮----
match drop_receiver.try_recv() {
⋮----
drop(i);
⋮----
drop(ebpf);
⋮----
.unwrap(),
⋮----
.into_iter()
.zip(config.cpus.into_iter())
.enumerate()
⋮----
let drop_sender = drop_sender.clone();
⋮----
.name(format!("solRetransmIO{i:02}"))
⋮----
tx_loop(
⋮----
QueueId(i as u64),
⋮----
Ok((Self { threads }, XdpSender { senders }))
⋮----
pub fn join(self) -> thread::Result<()> {
⋮----
handle.join()?;
⋮----
Ok(())
⋮----
pub fn master_ip_if_bonded(interface: &str) -> Option<Ipv4Addr> {
let master_ifindex_path = format!("/sys/class/net/{interface}/master/ifindex");
⋮----
let idx = contents.trim().parse().unwrap();
return Some(
⋮----
.and_then(|dev| dev.ipv4_addr())
.unwrap_or_else(|e| {
panic!(
⋮----
pub fn master_ip_if_bonded(_interface: &str) -> Option<Ipv4Addr> {

================
File: turbine/Cargo.toml
================
[package]
name = "solana-turbine"
documentation = "https://docs.rs/solana-turbine"
version = { workspace = true }
authors = { workspace = true }
description = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []

[dependencies]
agave-feature-set = { workspace = true }
agave-votor = { workspace = true }
agave-xdp = { workspace = true }
arc-swap = { workspace = true }
bincode = { workspace = true }
bytes = { workspace = true }
crossbeam-channel = { workspace = true }
futures = { workspace = true }
itertools = { workspace = true }
lazy-lru = { workspace = true }
log = { workspace = true }
lru = { workspace = true }
quinn = { workspace = true }
rand = "0.8.5"
rand_chacha = "0.3.1"
rayon = { workspace = true }
rustls = { workspace = true }
solana-clock = { workspace = true }
solana-cluster-type = { workspace = true }
solana-entry = { workspace = true }
solana-gossip = { workspace = true }
solana-hash = { workspace = true }
solana-keypair = { workspace = true }
solana-ledger = { workspace = true, features = ["agave-unstable-api"] }
solana-measure = { workspace = true }
solana-metrics = { workspace = true }
solana-native-token = { workspace = true }
solana-net-utils = { workspace = true }
solana-nohash-hasher = { workspace = true }
solana-perf = { workspace = true }
solana-poh = { workspace = true }
solana-pubkey = { workspace = true }
solana-quic-client = { workspace = true }
solana-rayon-threadlimit = { workspace = true }
solana-rpc = { workspace = true }
solana-rpc-client-api = { workspace = true }
solana-runtime = { workspace = true }
solana-signature = { workspace = true }
solana-signer = { workspace = true }
solana-streamer = { workspace = true }
solana-system-transaction = { workspace = true }
solana-time-utils = { workspace = true }
solana-tls-utils = { workspace = true }
solana-transaction-error = { workspace = true }
static_assertions = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
wincode = { workspace = true }

[target.'cfg(target_os = "linux")'.dependencies]
caps = { workspace = true }

[dev-dependencies]
agave-logger = { workspace = true }
assert_matches = { workspace = true }
bencher = { workspace = true }
bs58 = { workspace = true }
solana-genesis-config = { workspace = true }
solana-ledger = { workspace = true, features = ["agave-unstable-api","dev-context-only-utils"] }
solana-runtime = { workspace = true, features = ["dev-context-only-utils"] }
solana-signature = { workspace = true, features = ["rand"] }
solana-transaction = { workspace = true }
solana-turbine = { path = ".", features = ["agave-unstable-api"] }
test-case = { workspace = true }

[[bench]]
name = "cluster_info"
harness = false

[[bench]]
name = "cluster_nodes"
harness = false

================
File: udp-client/src/nonblocking/mod.rs
================
pub mod udp_client;

================
File: udp-client/src/nonblocking/udp_client.rs
================
pub struct UdpClientConnection {
⋮----
impl UdpClientConnection {
pub fn new_from_addr(socket: std::net::UdpSocket, server_addr: SocketAddr) -> Self {
socket.set_nonblocking(true).unwrap();
let socket = UdpSocket::from_std(socket).unwrap();
⋮----
impl ClientConnection for UdpClientConnection {
fn server_addr(&self) -> &SocketAddr {
⋮----
async fn send_data(&self, buffer: &[u8]) -> TransportResult<()> {
self.socket.send_to(buffer, self.addr).await?;
Ok(())
⋮----
async fn send_data_batch(&self, buffers: &[Vec<u8>]) -> TransportResult<()> {
let pkts: Vec<_> = buffers.iter().zip(repeat(self.server_addr())).collect();
batch_send(&self.socket, &pkts).await?;
⋮----
mod tests {
⋮----
async fn check_send_one(connection: &UdpClientConnection, reader: &UdpSocket) {
let packet = vec![111u8; PACKET_DATA_SIZE];
connection.send_data(&packet).await.unwrap();
let mut packets = vec![Packet::default(); 32];
let recv = recv_mmsg(reader, &mut packets[..]).await.unwrap();
assert_eq!(1, recv);
⋮----
async fn check_send_batch(connection: &UdpClientConnection, reader: &UdpSocket) {
let packets: Vec<_> = (0..32).map(|_| vec![0u8; PACKET_DATA_SIZE]).collect();
connection.send_data_batch(&packets).await.unwrap();
⋮----
assert_eq!(32, recv);
⋮----
async fn test_send_from_addr() {
let mut port_range = unique_port_range_for_tests(4);
let socket = bind_to_with_config(
⋮----
port_range.next().unwrap(),
⋮----
.unwrap();
⋮----
let reader_port = port_range.next().unwrap();
⋮----
let reader = bind_to_async(reader_ip, reader_port).await.expect("bind");
check_send_one(&connection, &reader).await;
check_send_batch(&connection, &reader).await;

================
File: udp-client/src/lib.rs
================
pub mod nonblocking;
pub mod udp_client;
⋮----
pub struct UdpPool {
⋮----
impl ConnectionPool for UdpPool {
type BaseClientConnection = Udp;
type NewConnectionConfig = UdpConfig;
fn add_connection(&mut self, config: &Self::NewConnectionConfig, addr: &SocketAddr) -> usize {
let connection = self.create_pool_entry(config, addr);
let idx = self.connections.len();
self.connections.push(connection);
⋮----
fn num_connections(&self) -> usize {
self.connections.len()
⋮----
fn get(&self, index: usize) -> Result<Arc<Self::BaseClientConnection>, ConnectionPoolError> {
⋮----
.get(index)
.cloned()
.ok_or(ConnectionPoolError::IndexOutOfRange)
⋮----
fn create_pool_entry(
⋮----
Arc::new(Udp(config.udp_socket.clone()))
⋮----
pub struct UdpConfig {
⋮----
impl NewConnectionConfig for UdpConfig {
fn new() -> Result<Self, ClientError> {
⋮----
.map_err(Into::<ClientError>::into)?;
Ok(Self {
⋮----
pub struct Udp(Arc<UdpSocket>);
impl BaseClientConnection for Udp {
type BlockingClientConnection = BlockingUdpConnection;
type NonblockingClientConnection = NonblockingUdpConnection;
fn new_blocking_connection(
⋮----
Arc::new(BlockingUdpConnection::new_from_addr(self.0.clone(), addr))
⋮----
fn new_nonblocking_connection(
⋮----
self.0.try_clone().unwrap(),
⋮----
pub struct UdpConnectionManager {}
impl ConnectionManager for UdpConnectionManager {
type ConnectionPool = UdpPool;
⋮----
fn new_connection_pool(&self) -> Self::ConnectionPool {
⋮----
fn new_connection_config(&self) -> Self::NewConnectionConfig {
UdpConfig::new().unwrap()
⋮----
fn update_key(&self, _key: &Keypair) -> Result<(), Box<dyn std::error::Error>> {
Ok(())

================
File: udp-client/src/udp_client.rs
================
pub struct UdpClientConnection {
⋮----
impl UdpClientConnection {
pub fn new_from_addr(local_socket: Arc<UdpSocket>, server_addr: SocketAddr) -> Self {
⋮----
impl ClientConnection for UdpClientConnection {
fn server_addr(&self) -> &SocketAddr {
⋮----
fn send_data_async(&self, data: Arc<Vec<u8>>) -> TransportResult<()> {
self.socket.send_to(data.as_ref(), self.addr)?;
Ok(())
⋮----
fn send_data_batch(&self, buffers: &[Vec<u8>]) -> TransportResult<()> {
let addr = self.server_addr();
let pkts = buffers.iter().map(|bytes| (bytes, addr));
Ok(batch_send(&self.socket, pkts)?)
⋮----
fn send_data_batch_async(&self, buffers: Vec<Vec<u8>>) -> TransportResult<()> {
⋮----
fn send_data(&self, buffer: &[u8]) -> TransportResult<()> {
self.socket.send_to(buffer, self.addr)?;

================
File: udp-client/Cargo.toml
================
[package]
name = "solana-udp-client"
description = "Solana UDP Client"
documentation = "https://docs.rs/solana-udp-client"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []
dev-context-only-utils = []

[dependencies]
async-trait = { workspace = true }
solana-connection-cache = { workspace = true }
solana-keypair = { workspace = true }
solana-net-utils = { workspace = true }
solana-streamer = { workspace = true }
solana-transaction-error = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true, features = ["full"] }

[dev-dependencies]
solana-net-utils = { workspace = true, features = ["dev-context-only-utils"] }
solana-packet = { workspace = true }
solana-streamer = { workspace = true, features = ["dev-context-only-utils"] }

================
File: unified-scheduler-logic/src/lib.rs
================
pub enum SchedulingMode {
⋮----
pub enum Capability {
⋮----
type CounterInner = u32;
pub type OrderedTaskId = u128;
mod utils {
⋮----
pub(super) struct ShortCounter(CounterInner);
impl ShortCounter {
pub(super) fn zero() -> Self {
Self(0)
⋮----
pub(super) fn one() -> Self {
Self(1)
⋮----
pub(super) fn is_one(&self) -> bool {
⋮----
pub(super) fn is_zero(&self) -> bool {
⋮----
pub(super) fn current(&self) -> CounterInner {
⋮----
pub(super) fn increment(self) -> Self {
Self(self.0.checked_add(1).unwrap())
⋮----
pub(super) fn decrement(self) -> Self {
Self(self.0.checked_sub(1).unwrap())
⋮----
pub(super) fn increment_self(&mut self) -> &mut Self {
*self = self.increment();
⋮----
pub(super) fn decrement_self(&mut self) -> &mut Self {
*self = self.decrement();
⋮----
pub(super) fn reset_to_zero(&mut self) -> &mut Self {
⋮----
pub(super) struct TokenCell<V>(UnsafeCell<V>);
⋮----
pub(super) fn new(value: V) -> Self {
Self(UnsafeCell::new(value))
⋮----
pub(super) fn with_borrow_mut<R>(
⋮----
f(unsafe { &mut *self.0.get() })
⋮----
unsafe impl<V> Sync for TokenCell<V> {}
pub(super) struct Token<V: 'static>(PhantomData<*mut V>);
⋮----
/// Returns the token to acquire a mutable reference to the inner value of [TokenCell].
        ///
⋮----
///
        /// This is intentionally left to be non-`const` to forbid unprotected sharing via static
⋮----
/// This is intentionally left to be non-`const` to forbid unprotected sharing via static
        /// variables among threads.
⋮----
/// variables among threads.
        ///
⋮----
///
        /// # Panics
⋮----
/// # Panics
        ///
⋮----
///
        /// This function will `panic!()` if called multiple times with same type `V` from the same
⋮----
/// This function will `panic!()` if called multiple times with same type `V` from the same
        /// thread to detect potential misuses.
⋮----
/// thread to detect potential misuses.
        ///
⋮----
///
        /// # Safety
⋮----
/// # Safety
        ///
⋮----
///
        /// This method should be called exactly once for each thread at most to avoid undefined
⋮----
/// This method should be called exactly once for each thread at most to avoid undefined
        /// behavior when used with [`Token`].
⋮----
/// behavior when used with [`Token`].
        #[must_use]
pub(super) unsafe fn assume_exclusive_mutating_thread() -> Self {
thread_local! {
⋮----
// TOKEN.with_borrow_mut can't panic because it's the only non-overlapping
assert!(
⋮----
Self(PhantomData)
⋮----
mod tests {
⋮----
fn test_second_creation_of_tokens_in_a_thread() {
⋮----
struct FakeQueue {
⋮----
fn test_ub_illegally_created_multiple_tokens() {
⋮----
queue.with_borrow_mut(&mut token1, |queue_mut1| {
queue_mut1.v.push(1);
queue.with_borrow_mut(&mut token2, |queue_mut2| {
queue_mut2.v.push(2);
queue_mut1.v.push(3);
⋮----
queue_mut1.v.push(4);
⋮----
dbg!(queue.0.into_inner());
⋮----
fn test_ub_illegally_shared_token_cell() {
⋮----
let queue2 = queue1.clone();
⋮----
let queue3 = queue1.clone();
⋮----
let (queue1, queue2) = (queue1.clone(), queue2.clone());
⋮----
queue1.with_borrow_mut(&mut token, |queue| {
queue.v.push(3);
⋮----
queue2.with_borrow_mut(&mut token, |queue| {
queue.v.push(4);
⋮----
thread1.join().unwrap();
thread2.join().unwrap();
⋮----
drop((queue1, queue2));
dbg!(Arc::into_inner(queue3).unwrap().0.into_inner());
⋮----
type LockResult = Result<(), ()>;
const_assert_eq!(mem::size_of::<LockResult>(), 1);
pub type Task = Arc<TaskInner>;
const_assert_eq!(mem::size_of::<Task>(), 8);
pub type BlockSize = usize;
⋮----
type UsageQueueToken = Token<UsageQueueInner>;
const_assert_eq!(mem::size_of::<UsageQueueToken>(), 0);
type BlockedUsageCountToken = Token<ShortCounter>;
const_assert_eq!(mem::size_of::<BlockedUsageCountToken>(), 0);
⋮----
pub struct TaskInner {
⋮----
impl TaskInner {
pub fn task_id(&self) -> OrderedTaskId {
⋮----
pub fn is_higher_priority(&self, other: &Self) -> bool {
match self.task_id().cmp(&other.task_id()) {
⋮----
Ordering::Equal => panic!("self-compariton"),
⋮----
pub fn consumed_block_size(&self) -> BlockSize {
⋮----
pub fn sanitized_epoch(&self) -> Epoch {
⋮----
pub fn alt_invalidation_slot(&self) -> Slot {
⋮----
pub fn transaction(&self) -> &RuntimeTransaction<SanitizedTransaction> {
⋮----
fn lock_contexts(&self) -> &[LockContext] {
⋮----
fn set_blocked_usage_count(&self, token: &mut BlockedUsageCountToken, count: ShortCounter) {
⋮----
.with_borrow_mut(token, |usage_count| {
⋮----
fn try_unblock(self: Task, token: &mut BlockedUsageCountToken) -> Option<Task> {
⋮----
.with_borrow_mut(token, |usage_count| usage_count.decrement_self().is_zero());
did_unblock.then_some(self)
⋮----
fn try_reblock(&self, token: &mut BlockedUsageCountToken) -> bool {
⋮----
if usage_count.is_zero() {
⋮----
usage_count.increment_self();
⋮----
pub fn into_transaction(self: Task) -> RuntimeTransaction<SanitizedTransaction> {
Task::into_inner(self).unwrap().transaction
⋮----
struct LockContext {
⋮----
const_assert_eq!(mem::size_of::<LockContext>(), 16);
impl LockContext {
fn new(usage_queue: UsageQueue, requested_usage: RequestedUsage) -> Self {
⋮----
fn with_usage_queue_mut<R>(
⋮----
self.usage_queue.0.with_borrow_mut(usage_queue_token, f)
⋮----
enum Usage<R, W> {
⋮----
fn requested_usage(&self) -> RequestedUsage {
⋮----
type FifoUsage = Usage<ShortCounter, ()>;
const_assert_eq!(mem::size_of::<FifoUsage>(), 8);
type PriorityUsage = Usage<BTreeMap<OrderedTaskId, Task>, Task>;
const_assert_eq!(mem::size_of::<PriorityUsage>(), 32);
⋮----
fn from(requested_usage: RequestedUsage) -> Self {
⋮----
impl PriorityUsage {
fn from(task: Task, requested_usage: RequestedUsage) -> Self {
⋮----
RequestedUsage::Readonly => Self::Readonly(BTreeMap::from([(task.task_id(), task)])),
⋮----
fn take_readable(maybe_usage: &mut Option<Self>) {
let Some(Self::Readonly(tasks)) = maybe_usage.take() else {
panic!();
⋮----
assert!(tasks.is_empty());
⋮----
fn take_writable(maybe_usage: &mut Option<Self>) -> Task {
let Some(Self::Writable(task)) = maybe_usage.take() else {
⋮----
enum RequestedUsage {
⋮----
type PriorityUsageQueue = BTreeMap<OrderedTaskId, UsageFromTask>;
trait PriorityUsageQueueExt: Sized {
⋮----
impl PriorityUsageQueueExt for PriorityUsageQueue {
fn insert_usage_from_task(&mut self, usage_from_task: UsageFromTask) {
self.insert(usage_from_task.1.task_id(), usage_from_task)
.unwrap_none();
⋮----
fn pop_first_usage_from_task(&mut self) -> Option<UsageFromTask> {
self.pop_first().map(|(_index, usage)| usage)
⋮----
fn first_usage_from_task(&self) -> Option<&UsageFromTask> {
self.first_key_value().map(|(_index, usage)| usage)
⋮----
enum UsageQueueInner {
⋮----
type UsageFromTask = (RequestedUsage, Task);
impl UsageQueueInner {
fn with_fifo() -> Self {
⋮----
fn with_priority() -> Self {
⋮----
fn new(capability: &Capability) -> Self {
⋮----
fn try_lock(&mut self, new_task: &Task, requested_usage: RequestedUsage) -> LockResult {
⋮----
None => Ok(FifoUsage::from(requested_usage)),
⋮----
RequestedUsage::Readonly => Ok(FifoUsage::Readonly(count.increment())),
RequestedUsage::Writable => Err(()),
⋮----
Some(FifoUsage::Writable(())) => Err(()),
⋮----
.map(|new_usage| {
*current_usage = Some(new_usage);
⋮----
.insert(new_task.task_id(), new_task.clone())
⋮----
Ok(())
⋮----
Some(PriorityUsage::Writable(_task)) => Err(()),
⋮----
*current_usage = Some(PriorityUsage::from(new_task.clone(), requested_usage));
⋮----
fn unlock(&mut self, task: &Task, requested_usage: RequestedUsage) -> Option<UsageFromTask> {
⋮----
if count.is_one() {
⋮----
count.decrement_self();
⋮----
RequestedUsage::Writable => unreachable!(),
⋮----
assert_matches!(requested_usage, RequestedUsage::Writable);
⋮----
None => unreachable!(),
⋮----
tasks.remove(&task.task_id()).unwrap();
if tasks.is_empty() {
⋮----
self.pop()
⋮----
fn push_blocked(&mut self, usage_from_task: UsageFromTask) {
assert_matches!(self.current_usage(), Some(_));
self.push(usage_from_task);
⋮----
fn pop_lockable_readonly(&mut self) -> Option<UsageFromTask> {
if matches!(self.peek_blocked(), Some((RequestedUsage::Readonly, _))) {
assert_matches!(self.current_usage(), Some(RequestedUsage::Readonly));
⋮----
fn current_usage(&self) -> Option<RequestedUsage> {
⋮----
current_usage.as_ref().map(|usage| usage.requested_usage())
⋮----
fn update_current_usage(&mut self, requested_usage: RequestedUsage, task: &Task) {
⋮----
*current_usage = Some(FifoUsage::from(requested_usage));
⋮----
*current_usage = Some(PriorityUsage::from(task.clone(), requested_usage));
⋮----
fn pop(&mut self) -> Option<UsageFromTask> {
⋮----
} => blocked_usages_from_tasks.pop_front(),
⋮----
} => blocked_usages_from_tasks.pop_first_usage_from_task(),
⋮----
fn push(&mut self, usage_from_task: UsageFromTask) {
⋮----
} => blocked_usages_from_tasks.push_back(usage_from_task),
⋮----
} => blocked_usages_from_tasks.insert_usage_from_task(usage_from_task),
⋮----
fn peek_blocked(&self) -> Option<&UsageFromTask> {
⋮----
} => blocked_usages_from_tasks.front(),
⋮----
} => blocked_usages_from_tasks.first_usage_from_task(),
⋮----
fn prepare_lock(
⋮----
if blocked_usages_from_tasks.is_empty() {
⋮----
Err(())
⋮----
assert!(blocked_usages_from_tasks.is_empty());
⋮----
if !new_task.is_higher_priority(current_task)
|| !current_task.try_reblock(token)
⋮----
return Err(());
⋮----
.insert_usage_from_task((RequestedUsage::Writable, reblocked_task));
⋮----
let Some((peeked_usage, peeked_task)) = self.peek_blocked() else {
return Ok(());
⋮----
assert_matches!(peeked_usage, RequestedUsage::Writable);
if !new_task.is_higher_priority(peeked_task) {
⋮----
.range(new_task.task_id()..)
.filter_map(|(&task_id, task)| {
task.try_reblock(token).then_some(task_id)
⋮----
for task_id in task_indexes.into_iter() {
let reblocked_task = current_tasks.remove(&task_id).unwrap();
⋮----
.insert_usage_from_task((RequestedUsage::Readonly, reblocked_task));
⋮----
if current_tasks.is_empty() {
⋮----
const_assert_eq!(mem::size_of::<TokenCell<UsageQueueInner>>(), 56);
⋮----
pub struct UsageQueue(Arc<TokenCell<UsageQueueInner>>);
const_assert_eq!(mem::size_of::<UsageQueue>(), 8);
impl UsageQueue {
pub fn new(capability: &Capability) -> Self {
Self(Arc::new(TokenCell::new(UsageQueueInner::new(capability))))
⋮----
pub struct SchedulingStateMachine {
⋮----
const_assert_eq!(mem::size_of::<SchedulingStateMachine>(), 56);
impl SchedulingStateMachine {
pub fn has_no_running_task(&self) -> bool {
self.running_task_count.is_zero()
⋮----
pub fn has_no_active_task(&self) -> bool {
self.active_task_count.is_zero()
⋮----
pub fn has_unblocked_task(&self) -> bool {
!self.unblocked_task_queue.is_empty()
⋮----
pub fn has_runnable_task(&self) -> bool {
self.has_unblocked_task() && self.is_task_runnable()
⋮----
fn is_task_runnable(&self) -> bool {
self.running_task_count.current() < self.max_running_task_count
⋮----
pub fn unblocked_task_queue_count(&self) -> usize {
self.unblocked_task_queue.len()
⋮----
fn active_task_count(&self) -> CounterInner {
self.active_task_count.current()
⋮----
fn handled_task_count(&self) -> CounterInner {
self.handled_task_count.current()
⋮----
fn unblocked_task_count(&self) -> CounterInner {
self.unblocked_task_count.current()
⋮----
fn total_task_count(&self) -> CounterInner {
self.total_task_count.current()
⋮----
pub fn schedule_task(&mut self, task: Task) -> Option<Task> {
self.schedule_or_buffer_task(task, false)
⋮----
pub fn buffer_task(&mut self, task: Task) {
self.schedule_or_buffer_task(task, true).unwrap_none();
⋮----
pub fn schedule_or_buffer_task(&mut self, task: Task, force_buffering: bool) -> Option<Task> {
self.total_task_count.increment_self();
self.active_task_count.increment_self();
self.try_lock_usage_queues(task).and_then(|task| {
if !self.is_task_runnable() || force_buffering {
self.unblocked_task_count.increment_self();
self.unblocked_task_queue.push_back(task);
⋮----
self.running_task_count.increment_self();
Some(task)
⋮----
pub fn schedule_next_unblocked_task(&mut self) -> Option<Task> {
if !self.is_task_runnable() {
⋮----
self.unblocked_task_queue.pop_front().inspect(|_| {
⋮----
pub fn deschedule_task(&mut self, task: &Task) {
self.running_task_count.decrement_self();
self.active_task_count.decrement_self();
self.handled_task_count.increment_self();
self.unlock_usage_queues(task);
⋮----
fn try_lock_usage_queues(&mut self, task: Task) -> Option<Task> {
⋮----
for context in task.lock_contexts() {
context.with_usage_queue_mut(&mut self.usage_queue_token, |usage_queue| {
⋮----
.prepare_lock(&mut self.count_token, &task, context.requested_usage)
.and_then(|()| usage_queue.try_lock(&task, context.requested_usage));
⋮----
blocked_usage_count.increment_self();
let usage_from_task = (context.requested_usage, task.clone());
usage_queue.push_blocked(usage_from_task);
⋮----
if blocked_usage_count.is_zero() {
⋮----
task.set_blocked_usage_count(&mut self.count_token, blocked_usage_count);
⋮----
fn unlock_usage_queues(&mut self, task: &Task) {
⋮----
let mut newly_lockable = usage_queue.unlock(task, context.requested_usage);
⋮----
.try_lock(&lockable_task, lockable_usage)
.unwrap();
if let Some(unblocked_task) = lockable_task.try_unblock(&mut self.count_token) {
self.unblocked_task_queue.push_back(unblocked_task);
⋮----
newly_lockable = matches!(lockable_usage, RequestedUsage::Readonly)
.then(|| usage_queue.pop_lockable_readonly())
.flatten();
⋮----
pub fn create_task(
⋮----
pub fn create_block_production_task(
⋮----
fn do_create_task(
⋮----
.message()
.account_keys()
.iter()
.enumerate()
.map(|(task_id, address)| {
⋮----
usage_queue_loader(*address),
if transaction.message().is_writable(task_id) {
⋮----
.collect();
⋮----
pub fn reinitialize(&mut self) {
assert!(self.has_no_active_task());
assert_eq!(self.running_task_count.current(), 0);
assert_eq!(self.unblocked_task_queue.len(), 0);
⋮----
active_task_count.reset_to_zero();
handled_task_count.reset_to_zero();
unblocked_task_count.reset_to_zero();
total_task_count.reset_to_zero();
⋮----
pub fn clear_and_reinitialize(&mut self) -> usize {
⋮----
while let Some(task) = self.schedule_next_unblocked_task() {
self.deschedule_task(&task);
count.increment_self();
⋮----
self.reinitialize();
count.current().try_into().unwrap()
⋮----
pub unsafe fn exclusively_initialize_current_thread_for_scheduling(
⋮----
.unwrap_or(CounterInner::MAX as usize)
.try_into()
⋮----
unsafe fn exclusively_initialize_current_thread_for_scheduling_for_test() -> Self {
⋮----
fn simplest_transaction() -> RuntimeTransaction<SanitizedTransaction> {
let message = Message::new(&[], Some(&Pubkey::new_unique()));
⋮----
fn transaction_with_readonly_address(
⋮----
transaction_with_readonly_address_with_payer(address, &Pubkey::new_unique())
⋮----
fn transaction_with_readonly_address_with_payer(
⋮----
accounts: vec![AccountMeta::new_readonly(address, false)],
data: vec![],
⋮----
let message = Message::new(&[instruction], Some(payer));
⋮----
fn transaction_with_writable_address(
⋮----
transaction_with_writable_address_with_payer(address, &Pubkey::new_unique())
⋮----
fn transaction_with_writable_address_with_payer(
⋮----
accounts: vec![AccountMeta::new(address, false)],
⋮----
fn create_address_loader(
⋮----
let usage_queues = usage_queues.unwrap_or_default();
⋮----
.borrow_mut()
.entry(address)
.or_insert_with(|| UsageQueue::new(capability))
.clone()
⋮----
fn test_scheduling_state_machine_creation() {
⋮----
assert_eq!(state_machine.active_task_count(), 0);
assert_eq!(state_machine.total_task_count(), 0);
assert!(state_machine.has_no_active_task());
⋮----
fn test_scheduling_state_machine_good_reinitialization() {
⋮----
state_machine.total_task_count.increment_self();
assert_eq!(state_machine.total_task_count(), 1);
state_machine.reinitialize();
⋮----
fn test_scheduling_state_machine_bad_reinitialization(capability: Capability) {
⋮----
let address_loader = &mut create_address_loader(None, &capability);
let task = SchedulingStateMachine::create_task(simplest_transaction(), 3, address_loader);
state_machine.schedule_task(task.clone()).unwrap();
let bad_reinitialize = catch_unwind(AssertUnwindSafe(|| state_machine.reinitialize()));
// Avoid leaks as dutifully detected by Miri; Namely, tasks could be leaked due to
// transient circular references of active tasks by PriorityUsage at stack unwinding, which
// only happens under known panic conditions.
// To avoid that deschedule the task after the panic. Doing this beforehand won't cause the
state_machine.deschedule_task(&task);
⋮----
resume_unwind(some_panic);
⋮----
fn test_create_task(capability: Capability) {
let sanitized = simplest_transaction();
let signature = *sanitized.signature();
⋮----
assert_eq!(task.task_id(), 3);
assert_eq!(task.transaction().signature(), &signature);
⋮----
fn test_non_conflicting_task_related_counts(capability: Capability) {
⋮----
let task = state_machine.schedule_task(task).unwrap();
assert_eq!(state_machine.active_task_count(), 1);
⋮----
fn test_conflicting_task_related_counts(capability: Capability) {
⋮----
let task1 = SchedulingStateMachine::create_task(sanitized.clone(), 101, address_loader);
let task2 = SchedulingStateMachine::create_task(sanitized.clone(), 102, address_loader);
let task3 = SchedulingStateMachine::create_task(sanitized.clone(), 103, address_loader);
⋮----
assert_matches!(
⋮----
assert_matches!(state_machine.schedule_task(task2.clone()), None);
state_machine.deschedule_task(&task1);
assert!(state_machine.has_unblocked_task());
assert_eq!(state_machine.unblocked_task_queue_count(), 1);
assert_eq!(state_machine.unblocked_task_count(), 0);
assert_eq!(
⋮----
assert_eq!(state_machine.unblocked_task_count(), 1);
assert!(!state_machine.has_unblocked_task());
assert_matches!(state_machine.schedule_next_unblocked_task(), None);
⋮----
assert_eq!(state_machine.unblocked_task_queue_count(), 0);
state_machine.deschedule_task(&task2);
⋮----
state_machine.deschedule_task(&task3);
⋮----
fn test_existing_blocking_task_then_newly_scheduled_task(capability: Capability) {
⋮----
assert_matches!(state_machine.schedule_task(task3.clone()), None);
⋮----
assert_eq!(state_machine.unblocked_task_count(), 2);
⋮----
fn test_multiple_readonly_task_and_counts(capability: Capability) {
⋮----
let sanitized1 = transaction_with_readonly_address(conflicting_address);
let sanitized2 = transaction_with_readonly_address(conflicting_address);
⋮----
assert_eq!(state_machine.active_task_count(), 2);
assert_eq!(state_machine.handled_task_count(), 0);
⋮----
assert_eq!(state_machine.handled_task_count(), 1);
⋮----
assert_eq!(state_machine.handled_task_count(), 2);
⋮----
fn test_all_blocking_readable_tasks_block_writable_task(capability: Capability) {
⋮----
let sanitized3 = transaction_with_writable_address(conflicting_address);
⋮----
assert_eq!(state_machine.active_task_count(), 3);
⋮----
fn test_readonly_then_writable_then_readonly_linearized(capability: Capability) {
⋮----
let sanitized2 = transaction_with_writable_address(conflicting_address);
let sanitized3 = transaction_with_readonly_address(conflicting_address);
⋮----
fn test_readonly_then_writable(capability: Capability) {
⋮----
fn test_blocked_tasks_writable_2_readonly_then_writable(capability: Capability) {
⋮----
let sanitized1 = transaction_with_writable_address(conflicting_address);
⋮----
let sanitized4 = transaction_with_writable_address(conflicting_address);
⋮----
assert_matches!(state_machine.schedule_task(task4.clone()), None);
⋮----
state_machine.deschedule_task(&task4);
⋮----
fn test_gradual_locking(capability: Capability) {
⋮----
let address_loader = &mut create_address_loader(Some(usage_queues.clone()), &capability);
⋮----
let usage_queues = usage_queues.borrow_mut();
let usage_queue = usage_queues.get(&conflicting_address).unwrap();
⋮----
.with_borrow_mut(&mut state_machine.usage_queue_token, |usage_queue| {
assert_matches!(usage_queue.current_usage(), Some(RequestedUsage::Writable));
⋮----
let fee_payer = task2.transaction().message().fee_payer();
let usage_queue = usage_queues.get(fee_payer).unwrap();
⋮----
fn test_unreachable_unlock_conditions1(capability: Capability) {
⋮----
let _ = usage_queue.unlock(task, RequestedUsage::Writable);
⋮----
fn test_unreachable_unlock_conditions2(capability: Capability) {
⋮----
usage_queue.update_current_usage(RequestedUsage::Writable, task);
let _ = usage_queue.unlock(task, RequestedUsage::Readonly);
⋮----
fn test_unreachable_unlock_conditions3(capability: Capability) {
⋮----
usage_queue.update_current_usage(RequestedUsage::Readonly, task);
⋮----
mod reblocking {
⋮----
fn assert_task_index(actual: Option<Task>, expected: Option<OrderedTaskId>) {
assert_eq!(actual.map(|task| task.task_id()), expected);
⋮----
macro_rules! assert_task_index {
⋮----
fn setup() -> (
⋮----
let mut address_loader = create_address_loader(None, &Capability::PriorityQueueing);
⋮----
transaction_with_readonly_address_with_payer(address, &payer),
⋮----
transaction_with_writable_address_with_payer(address, &payer),
⋮----
let t0_block_others = create_task((Writable, Pubkey::new_unique()), 100);
assert_task_index!(
⋮----
fn test_reblocked_tasks_lower_write_then_higher_write() {
let (mut s, mut create_task, t0_block_others) = setup();
⋮----
let t1_reblocked = create_task((Writable, reblocked_address), 102);
let t2_force_locked = create_task((Writable, reblocked_address), 10);
assert_task_index!(s.schedule_task(t1_reblocked.clone()), None);
assert_task_index!(s.schedule_task(t2_force_locked.clone()), None);
s.deschedule_task(&t0_block_others);
assert_task_index!(s.schedule_next_unblocked_task(), Some(10));
s.deschedule_task(&t2_force_locked);
assert_task_index!(s.schedule_next_unblocked_task(), Some(102));
s.deschedule_task(&t1_reblocked);
assert!(s.has_no_active_task());
⋮----
fn test_reblocked_tasks_lower_write_then_higher_read() {
⋮----
let t2_force_locked = create_task((Readonly, reblocked_address), 10);
⋮----
fn test_reblocked_tasks_lower_read_then_higher_read() {
⋮----
let t1_not_reblocked = create_task((Readonly, reblocked_address), 102);
let t2_skipped = create_task((Writable, reblocked_address), 103);
let t3_force_locked = create_task((Readonly, reblocked_address), 10);
assert_task_index!(s.schedule_task(t1_not_reblocked.clone()), None);
assert_task_index!(s.schedule_task(t2_skipped.clone()), None);
assert_task_index!(s.schedule_task(t3_force_locked.clone()), None);
⋮----
s.deschedule_task(&t3_force_locked);
⋮----
s.deschedule_task(&t1_not_reblocked);
assert_task_index!(s.schedule_next_unblocked_task(), Some(103));
s.deschedule_task(&t2_skipped);
⋮----
fn test_reblocked_tasks_lower_read_then_higher_write_full() {
⋮----
let t1_reblocked = create_task((Readonly, reblocked_address), 102);

================
File: unified-scheduler-logic/Cargo.toml
================
[package]
name = "solana-unified-scheduler-logic"
description = "The Solana unified scheduler logic"
documentation = "https://docs.rs/solana-unified-scheduler-logic"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []

[dependencies]
assert_matches = { workspace = true }
solana-clock = { workspace = true }
solana-pubkey = { workspace = true }
solana-runtime-transaction = { workspace = true }
solana-transaction = { workspace = true }
static_assertions = { workspace = true }
unwrap_none = { workspace = true }

[dev-dependencies]
solana-instruction = { workspace = true }
solana-message = { workspace = true }
solana-runtime-transaction = { workspace = true, features = [
    "dev-context-only-utils",
] }
test-case = { workspace = true }

================
File: unified-scheduler-pool/src/lib.rs
================
use qualifier_attr::qualifiers;
⋮----
mod sleepless_testing;
use crate::sleepless_testing::BuilderTracked;
⋮----
enum CheckPoint<'a> {
⋮----
type CountOrDefault = Option<usize>;
type AtomicSchedulerId = AtomicU64;
⋮----
pub struct SchedulerPool<S: SpawnableScheduler<TH>, TH: TaskHandler> {
⋮----
enum BlockProductionSchedulerInner<S: SpawnableScheduler<TH>, TH: TaskHandler> {
⋮----
fn can_put(&self, returned: &S::Inner) -> bool {
⋮----
assert_ne!(inner.id(), returned.id());
⋮----
Self::Taken(id) => *id == returned.id(),
⋮----
fn put_spawned(&mut self, inner: S::Inner) {
assert_matches!(mem::replace(self, Self::Pooled(inner)), Self::NotSpawned);
⋮----
fn trash_taken(&mut self) {
assert_matches!(mem::replace(self, Self::NotSpawned), Self::Taken(_));
⋮----
fn take_and_trash_pooled(&mut self) -> S::Inner {
let inner = self.take_pooled();
self.trash_taken();
⋮----
fn put_returned(&mut self, inner: S::Inner) {
let new = inner.id();
assert_matches!(mem::replace(self, Self::Pooled(inner)), Self::Taken(old) if old == new);
⋮----
fn peek_pooled(&self) -> Option<&S::Inner> {
⋮----
Self::Pooled(inner) => Some(inner),
⋮----
fn take_pooled(&mut self) -> S::Inner {
⋮----
panic!("cannot take: {self:?}")
⋮----
inner.id()
⋮----
unreachable!();
⋮----
pub struct HandlerContext {
⋮----
impl HandlerContext {
fn usage_queue_loader_for_newly_spawned(&self) -> UsageQueueLoader {
match self.banking_stage_helper.clone() {
⋮----
fn banking_stage_helper(&self) -> &BankingStageHelper {
self.banking_stage_helper.as_ref().unwrap()
⋮----
fn clone_for_scheduler_thread(&self) -> Self {
let mut context = self.clone();
if self.banking_stage_helper.is_some() {
context.disable_banking_packet_handler();
⋮----
fn disable_banking_packet_handler(&mut self) {
self.banking_packet_receiver = never();
⋮----
Box::new(|_, _| unreachable!("paired with never() receiver, this cannot be called"));
⋮----
struct CommonHandlerContext {
⋮----
impl CommonHandlerContext {
fn into_handler_context(
⋮----
struct BankingStageHandlerContext {
⋮----
trait_set! {
⋮----
// Make this `Clone`-able so that it can easily propagated to all the handler threads.
clone_trait_object!(BankingPacketHandler);
/// A helper struct for the banking stage integration, primarily used for task creation.
///
⋮----
///
/// This block-production struct is expected to be shared across the scheduler thread and its
⋮----
/// This block-production struct is expected to be shared across the scheduler thread and its
/// handler threads because all of them needs to handle task creation unlike block verification.
⋮----
/// handler threads because all of them needs to handle task creation unlike block verification.
///
⋮----
///
/// Particularly, usage_queue_loader is desired to be shared across handlers so that task creation
⋮----
/// Particularly, usage_queue_loader is desired to be shared across handlers so that task creation
/// can be processed in the multi-threaded way. For more details, see
⋮----
/// can be processed in the multi-threaded way. For more details, see
/// solana_core::banking_stage::unified_scheduler module doc.
⋮----
/// solana_core::banking_stage::unified_scheduler module doc.
#[derive(Debug)]
pub struct BankingStageHelper {
⋮----
// Supplemental identification for tasks of identical priority, allotted according to FIFO of
// batch granularity, resulting in the total order over the set of available tasks,
// collectively.
⋮----
// AtomicUsize's fetch_add entails the wrapping semantics. So, address such an overflowing, under
⋮----
impl BankingStageHelper {
fn new(new_task_sender: Sender<NewTaskPayload>) -> Self {
⋮----
pub fn generate_task_ids(&self, count: usize) -> usize {
self.next_task_id.fetch_add(count, Relaxed)
⋮----
fn is_task_id_overgrown(&self) -> bool {
self.next_task_id.load(Relaxed) > BANKING_STAGE_MAX_TASK_ID
⋮----
fn set_next_task_id(&self, next_task_id: usize) {
self.next_task_id.store(next_task_id, Relaxed);
⋮----
pub fn create_new_task(
⋮----
&mut |pubkey| self.usage_queue_loader.load(pubkey),
⋮----
fn recreate_task(&self, executed_task: Box<ExecutedTask>) -> Task {
let new_task_id = self.regenerated_task_id(executed_task.task.task_id());
let consumed_block_size = executed_task.consumed_block_size();
let sanitized_epoch = executed_task.sanitized_epoch();
let alt_invalidation_slot = executed_task.alt_invalidation_slot();
let transaction = executed_task.into_transaction();
self.create_new_task(
⋮----
pub fn send_new_task(&self, task: Task) {
⋮----
.send(NewTaskPayload::Payload(task))
.unwrap();
⋮----
pub fn new_task_id(task_id: usize, priority: u64) -> OrderedTaskId {
let reversed_priority = u64::MAX.wrapping_sub(priority) as OrderedTaskId;
⋮----
fn regenerated_task_id(&self, executed_task_id: OrderedTaskId) -> OrderedTaskId {
⋮----
(executed_task_id & REVERSED_PRIORITY_MASK) | (self.generate_task_ids(1) as OrderedTaskId)
⋮----
pub type DefaultSchedulerPool =
⋮----
fn new(
⋮----
fn do_new(
⋮----
info!("cleaner_main_loop: started...");
let weak_scheduler_pool: Weak<Self> = scheduler_pool_receiver.recv().unwrap();
⋮----
match scheduler_pool_receiver.recv_timeout(pool_cleaner_interval) {
Ok(_) => unreachable!(),
⋮----
let Some(scheduler_pool) = weak_scheduler_pool.upgrade() else {
⋮----
let Ok(mut scheduler_inners) = scheduler_pool.scheduler_inners.lock() else {
⋮----
idle_inners.extend(MakeExtractIf::extract_if(
scheduler_inners.deref_mut(),
|(_inner, pooled_at)| now.duration_since(*pooled_at) > max_pooling_duration,
⋮----
drop(scheduler_inners);
let idle_inner_count = idle_inners.len();
drop(idle_inners);
⋮----
let banking_stage_status = scheduler_pool.banking_stage_status();
if !exiting && matches!(banking_stage_status, Some(BankingStageStatus::Exited)) {
⋮----
scheduler_pool.unregister_banking_stage();
⋮----
if matches!(banking_stage_status, Some(BankingStageStatus::Inactive)) {
let Ok(mut inner) = scheduler_pool.block_production_scheduler_inner.lock()
⋮----
if let Some(pooled) = inner.peek_pooled() {
if pooled.is_overgrown() {
let pooled = inner.take_and_trash_pooled();
info!("idling BP scheduler ({}) is overgrown", pooled.id());
scheduler_pool.spawn_block_production_scheduler(&mut inner);
⋮----
scheduler_pool.trashed_scheduler_inners.lock()
⋮----
trashed_inners.push(pooled);
⋮----
drop(inner);
⋮----
pooled.discard_buffer();
⋮----
let Ok(mut trashed_inners) = scheduler_pool.trashed_scheduler_inners.lock()
⋮----
let trashed_inner_count = trashed_inners.len();
⋮----
drop(trashed_inners);
⋮----
let Ok(mut timeout_listeners) = scheduler_pool.timeout_listeners.lock() else {
⋮----
expired_listeners.extend(MakeExtractIf::extract_if(
timeout_listeners.deref_mut(),
⋮----
now.duration_since(*registered_at) > timeout_duration
⋮----
drop(timeout_listeners);
let count = expired_listeners.len();
⋮----
timeout_listener.trigger(scheduler_pool.clone());
⋮----
info!(
⋮----
info!("cleaner_main_loop: ...finished");
⋮----
.name("solScCleaner".to_owned())
.spawn_tracked(cleaner_main_loop)
⋮----
weak_self: weak_self.clone(),
⋮----
scheduler_pool_sender: scheduler_pool_sender.clone(),
⋮----
.send(Arc::downgrade(&scheduler_pool))
⋮----
pub fn new_dyn(
⋮----
fn self_arc(&self) -> Arc<Self> {
⋮----
.upgrade()
.expect("self-referencing Arc-ed pool")
⋮----
fn new_scheduler_id(&self) -> SchedulerId {
self.next_scheduler_id.fetch_add(1, Relaxed)
⋮----
fn return_scheduler(&self, scheduler: S::Inner) {
let should_trash = scheduler.is_trashed();
⋮----
self.block_production_scheduler_inner.lock().unwrap();
⋮----
if block_production_scheduler_inner.can_put(&scheduler) {
block_production_scheduler_inner.trash_taken();
self.spawn_block_production_scheduler(&mut block_production_scheduler_inner);
⋮----
.lock()
.expect("not poisoned")
.push(scheduler);
⋮----
} else if block_production_scheduler_inner.can_put(&scheduler) {
block_production_scheduler_inner.put_returned(scheduler);
⋮----
.push((scheduler, Instant::now()));
⋮----
drop(block_production_scheduler_inner);
⋮----
fn do_take_scheduler(&self, context: SchedulingContext) -> S {
self.do_take_resumed_scheduler(context, initialized_result_with_timings())
⋮----
fn do_take_resumed_scheduler(
⋮----
assert_matches!(result_with_timings, (Ok(_), _));
match context.mode() {
⋮----
self.scheduler_inners.lock().expect("not poisoned").pop()
⋮----
S::spawn(self.self_arc(), context, result_with_timings)
⋮----
assert!(
⋮----
.take_pooled();
⋮----
pub fn pooled_scheduler_count(&self) -> usize {
self.scheduler_inners.lock().expect("not poisoned").len()
⋮----
pub fn register_banking_stage(
⋮----
*self.banking_stage_handler_context.lock().unwrap() = Some(BankingStageHandlerContext {
⋮----
self.spawn_block_production_scheduler(
&mut self.block_production_scheduler_inner.lock().unwrap(),
⋮----
fn unregister_banking_stage(&self) {
let handler_context = &mut self.banking_stage_handler_context.lock().unwrap();
let handler_context = handler_context.as_mut().unwrap();
handler_context.banking_packet_receiver = never();
⋮----
fn banking_stage_status(&self) -> Option<BankingStageStatus> {
⋮----
.unwrap()
.as_mut()
.map(|context| context.banking_stage_monitor.status())
⋮----
fn create_handler_context(
⋮----
never(),
⋮----
unreachable!("paired with never() receiver, this cannot be called")
⋮----
let handler_context = self.banking_stage_handler_context.lock().unwrap();
let handler_context = handler_context.as_ref().unwrap();
⋮----
handler_context.banking_packet_receiver.clone(),
handler_context.banking_packet_handler.clone(),
Some(Arc::new(BankingStageHelper::new(new_task_sender.clone()))),
Some(handler_context.transaction_recorder.clone()),
⋮----
let thread_count = thread_count.unwrap_or(Self::default_handler_count());
assert!(thread_count >= 1);
self.common_handler_context.clone().into_handler_context(
⋮----
fn spawn_block_production_scheduler(
⋮----
self.self_arc(),
⋮----
initialized_result_with_timings(),
⋮----
let ((result, _timings), inner) = scheduler.into_inner();
assert_matches!(result, Ok(_));
block_production_scheduler_inner.put_spawned(inner);
⋮----
fn set_next_task_id_for_block_production(&self, next_task_id: usize) {
(*self.block_production_scheduler_inner.lock().unwrap())
.peek_pooled()
⋮----
.set_next_task_id_for_block_production(next_task_id);
⋮----
pub fn default_handler_count() -> usize {
⋮----
.ok()
.map(|non_zero| non_zero.get()),
⋮----
pub fn calculate_default_handler_count(detected_cpu_core_count: CountOrDefault) -> usize {
// Divide by 4 just not to consume all available CPUs just with handler threads, sparing for
// other active forks and other subsystems.
// Also, if available_parallelism fails (which should be very rare), use 4 threads,
// as a relatively conservatism assumption of modern multi-core systems ranging from
// engineers' laptops to production servers.
⋮----
.map(|core_count| (core_count / 4).max(1))
.unwrap_or(4)
⋮----
pub fn cli_message() -> &'static str {
⋮----
MESSAGE.get_or_init(|| {
format!(
⋮----
impl<S, TH> InstalledSchedulerPool for SchedulerPool<S, TH>
⋮----
fn take_resumed_scheduler(
⋮----
Box::new(self.do_take_resumed_scheduler(context, result_with_timings))
⋮----
fn register_timeout_listener(&self, timeout_listener: TimeoutListener) {
⋮----
.push((timeout_listener, Instant::now()));
⋮----
fn uninstalled_from_bank_forks(self: Arc<Self>) {
info!("SchedulerPool::uninstalled_from_bank_forks(): started...");
// Forcibly return back all taken schedulers back to this scheduler pool.
for (listener, _registered_at) in mem::take(&mut *self.timeout_listeners.lock().unwrap()) {
listener.trigger(self.clone());
⋮----
// Then, drop all schedulers in the pool.
mem::take(&mut *self.scheduler_inners.lock().unwrap());
mem::take(&mut *self.block_production_scheduler_inner.lock().unwrap());
mem::take(&mut *self.trashed_scheduler_inners.lock().unwrap());
// At this point, all circular references of this pool has been cut. And there should be
// only 1 strong rerefence unless the cleaner thread is active right now.
// So, wait a bit to unwrap the pool out of the sinful Arc finally here. Note that we can't resort to the
// Drop impl, because of the need to take the ownership of the join handle of the cleaner
// thread...
⋮----
// It seems solScCleaner is active... retry later
⋮----
sleep(Duration::from_millis(100));
// Yes, indefinite loop, but the situation isn't so different from the
// following join(), which indefinitely waits as well.
⋮----
// Accelerate cleaner thread joining by disconnection
⋮----
this.cleaner_thread.join().unwrap();
info!("SchedulerPool::uninstalled_from_bank_forks(): ...finished");
⋮----
pub trait TaskHandler: Send + Sync + Debug + Sized + 'static {
⋮----
pub struct DefaultTaskHandler;
impl TaskHandler for DefaultTaskHandler {
fn handle(
⋮----
let bank = scheduling_context.bank().unwrap();
let transaction = task.transaction();
let task_id = task.task_id();
let batch = match scheduling_context.mode() {
⋮----
// scheduler must properly prevent conflicting tx executions. thus, task handler isn't
bank.prepare_unlocked_batch_from_single_tx(transaction)
⋮----
if let Err(error) = bank.resanitize_transaction_minimally(
⋮----
task.sanitized_epoch(),
task.alt_invalidation_slot(),
⋮----
*result = Err(error);
⋮----
batch = bank.prepare_locked_batch_from_single_tx(transaction);
let lock_result = &batch.lock_results()[0];
⋮----
assert_matches!(lock_result, Err(TransactionError::AccountInUse));
if started.elapsed() > Duration::from_millis(400) {
*result = Err(TransactionError::CommitCancelled);
⋮----
sleep(Duration::from_micros(100));
⋮----
let transaction_indexes = match scheduling_context.mode() {
⋮----
vec![task_id.try_into().unwrap()]
⋮----
vec![]
⋮----
let pre_commit_callback = match scheduling_context.mode() {
⋮----
BlockProduction => Some(|processing_result: &'_ Result<ProcessedTransaction>| {
⋮----
return Err(processing_result.as_ref().unwrap_err().clone());
⋮----
// Now it's the procrastinated time of _optimistic_ provisioning of block cost at the
⋮----
processed_transaction.executed_units(),
processed_transaction.loaded_accounts_data_size(),
⋮----
bank.write_cost_tracker().unwrap().try_add(&cost)?;
⋮----
.as_ref()
⋮----
.record_transactions(
bank.bank_id(),
vec![transaction.to_versioned_transaction()],
⋮----
Ok(()) => Ok(starting_transaction_index),
⋮----
bank.write_cost_tracker().unwrap().remove(&cost);
Err(TransactionError::CommitCancelled)
⋮----
*result = execute_batch(
⋮----
handler_context.transaction_status_sender.as_ref(),
handler_context.replay_vote_sender.as_ref(),
⋮----
struct ExecutedTask {
⋮----
impl ExecutedTask {
fn new_boxed(task: Task) -> Box<Self> {
⋮----
result_with_timings: initialized_result_with_timings(),
⋮----
fn consumed_block_size(&self) -> BlockSize {
self.task.consumed_block_size()
⋮----
fn sanitized_epoch(&self) -> Epoch {
self.task.sanitized_epoch()
⋮----
fn alt_invalidation_slot(&self) -> Slot {
self.task.alt_invalidation_slot()
⋮----
fn into_transaction(self) -> RuntimeTransaction<SanitizedTransaction> {
self.task.into_transaction()
⋮----
enum SubchanneledPayload<P1, P2> {
⋮----
type NewTaskPayload = SubchanneledPayload<Task, Box<(SchedulingContext, ResultWithTimings)>>;
const_assert_eq!(mem::size_of::<NewTaskPayload>(), 16);
mod chained_channel {
⋮----
enum ChainedChannelPrivate<P, C> {
⋮----
pub(super) struct ChainedChannel<P, C>(ChainedChannelPrivate<P, C>);
⋮----
fn chain_to_new_channel(
⋮----
Self(ChainedChannelPrivate::ContextAndChannels(
⋮----
pub(super) struct ChainedChannelSender<P, C> {
⋮----
fn new(sender: Sender<ChainedChannel<P, C>>, aux_sender: Sender<P>) -> Self {
⋮----
pub(super) fn send_payload(
⋮----
.send(ChainedChannel(ChainedChannelPrivate::Payload(payload)))
⋮----
pub(super) fn send_aux_payload(&self, payload: P) -> std::result::Result<(), SendError<P>> {
self.aux_sender.send(payload)
⋮----
pub(super) fn send_chained_channel(
⋮----
self.sender.send(ChainedChannel::chain_to_new_channel(
context.clone(),
chained_receiver.clone(),
chained_aux_receiver.clone(),
⋮----
Ok(())
⋮----
pub(super) struct ChainedChannelReceiver<P, C: Clone> {
⋮----
pub(super) fn context(&self) -> &C {
⋮----
pub(super) fn for_select(&self) -> &Receiver<ChainedChannel<P, C>> {
⋮----
pub(super) fn aux_for_select(&self) -> &Receiver<P> {
⋮----
pub(super) fn never_receive_from_aux(&mut self) {
self.aux_receiver = never();
⋮----
pub(super) fn after_select(&mut self, message: ChainedChannel<P, C>) -> Option<P> {
⋮----
ChainedChannelPrivate::Payload(payload) => Some(payload),
⋮----
pub(super) fn unbounded<P, C: Clone>(
⋮----
struct UsageQueueLoaderInner {
⋮----
impl UsageQueueLoaderInner {
fn new(capability: Capability) -> Self {
⋮----
fn load(&self, address: Pubkey) -> UsageQueue {
⋮----
.entry(address)
.or_insert_with(|| UsageQueue::new(&self.capability))
.clone()
⋮----
fn count(&self) -> usize {
self.usage_queues.len()
⋮----
enum UsageQueueLoader {
⋮----
impl UsageQueueLoader {
fn usage_queue_loader(&self) -> &UsageQueueLoaderInner {
⋮----
fn load(&self, pubkey: Pubkey) -> UsageQueue {
self.usage_queue_loader().load(pubkey)
⋮----
fn is_overgrown(&self, max_usage_queue_count: usize) -> bool {
if self.usage_queue_loader().count() > max_usage_queue_count {
⋮----
} => banking_stage_helper.is_task_id_overgrown(),
⋮----
panic!()
⋮----
banking_stage_helper.set_next_task_id(next_task_id);
⋮----
fn disconnected<T>() -> Receiver<T> {
⋮----
pub struct PooledScheduler<TH: TaskHandler> {
⋮----
pub struct PooledSchedulerInner<S: SpawnableScheduler<TH>, TH: TaskHandler> {
⋮----
impl<S, TH> Drop for ThreadManager<S, TH>
⋮----
fn drop(&mut self) {
trace!("ThreadManager::drop() is called...");
if self.are_threads_joined() {
⋮----
error!(
⋮----
assert_matches!(self.session_result_with_timings, None);
let abort_detected = self.disconnect_new_task_sender();
⋮----
self.ensure_join_threads_after_abort(true);
⋮----
self.ensure_join_threads(true);
⋮----
assert_matches!(self.session_result_with_timings, Some((Ok(_), _)));
⋮----
fn is_aborted(&self) -> bool {
self.thread_manager.are_threads_joined()
⋮----
struct ThreadManager<S: SpawnableScheduler<TH>, TH: TaskHandler> {
⋮----
struct HandlerPanicked;
type HandlerResult = std::result::Result<Box<ExecutedTask>, HandlerPanicked>;
⋮----
fn new(pool: Arc<SchedulerPool<S, TH>>) -> Self {
⋮----
scheduler_id: pool.new_scheduler_id(),
⋮----
new_task_receiver: Some(new_task_receiver),
⋮----
handler_threads: vec![],
⋮----
fn execute_task_with_handler(
⋮----
debug!("handling task at {:?}", thread::current());
⋮----
fn max_running_task_count(mode: SchedulingMode, thread_count: usize) -> Option<usize> {
⋮----
Some(
⋮----
.checked_mul(MAX_RUNNING_TASK_COUNT_FACTOR)
.unwrap(),
⋮----
fn can_receive_unblocked_task(
⋮----
state_machine.has_unblocked_task()
⋮----
!session_ending && state_machine.has_runnable_task()
⋮----
fn can_finish_session(
⋮----
session_ending && state_machine.has_no_active_task()
⋮----
session_ending && state_machine.has_no_running_task()
⋮----
fn abort_or_accumulate_result_with_timings(
⋮----
executed_task.task.task_id(),
⋮----
timings.accumulate(&executed_task.result_with_timings.1);
⋮----
assert_eq!(executed_task.consumed_block_size(), 0);
⋮----
unreachable!()
⋮----
error!("error is detected while accumulating....: {error:?}");
⋮----
.checked_add(executed_task.consumed_block_size())
⋮----
debug!("error is detected while accumulating....: {error:?}");
⋮----
fn rebuffer_task_for_next_session(
⋮----
.banking_stage_helper()
.recreate_task(executed_task);
state_machine.buffer_task(task);
⋮----
fn take_session_result_with_timings(&mut self) -> ResultWithTimings {
self.session_result_with_timings.take().unwrap()
⋮----
fn put_session_result_with_timings(&mut self, result_with_timings: ResultWithTimings) {
⋮----
.replace(result_with_timings)
.unwrap_none();
⋮----
fn start_threads(
⋮----
let scheduling_mode = context.mode();
let mut current_slot = context.slot();
⋮----
assert!(context.is_preallocated());
⋮----
let handler_context = handler_context.clone_for_scheduler_thread();
let session_result_sender = self.session_result_sender.clone();
⋮----
.take()
.expect("no 2nd start_threads()");
⋮----
// ALL recv selectors are eager-evaluated ALWAYS by current crossbeam impl,
// which isn't great and is inconsistent with `if`s in the Rust's match
⋮----
dummy_receiver(Self::can_receive_unblocked_task(
⋮----
select_biased! {
⋮----
assert!(mem::replace(&mut is_finished, false));
⋮----
// Finalize the current session after asserting it's explicitly requested so.
⋮----
.send(result_with_timings)
.expect("always outlived receiver");
if matches!(scheduling_mode, BlockProduction) {
datapoint_info!(
⋮----
if matches!(scheduling_mode, BlockVerification) {
state_machine.reinitialize();
⋮----
assert!(mem::replace(&mut session_ending, false));
⋮----
let count = state_machine.clear_and_reinitialize();
⋮----
match new_task_receiver.recv() {
⋮----
sleepless_testing::at(CheckPoint::NewBufferedTask(task.task_id()));
assert_matches!(scheduling_mode, BlockProduction);
⋮----
.replace(context_and_result_with_timings.1)
⋮----
assert_eq!(scheduling_mode, new_context.mode());
assert!(!new_context.is_preallocated());
current_slot = new_context.slot();
⋮----
.send_chained_channel(
⋮----
result_with_timings = initialized_result_with_timings();
⋮----
Err(RecvError) => unreachable!(),
⋮----
result_with_timings = new_result_with_timings.unwrap();
⋮----
// There are several code-path reaching here out of the preceding unconditional
// `loop { ... }` by the use of `break 'nonaborted_main_loop;`. This scheduler
// thread will now initiate the termination process, indicating an abnormal abortion,
// in order to be handled gracefully by other threads.
// Firstly, send result_with_timings as-is, because it's expected for us to put the
// last result_with_timings into the channel without exception. Usually,
// result_with_timings will contain the Err variant at this point, indicating the
// occurrence of transaction error.
⋮----
// Next, drop `new_task_receiver`. After that, the paired singleton
drop(new_task_receiver);
⋮----
let mut handler_context = handler_context.clone();
let mut runnable_task_receiver = runnable_task_receiver.clone();
let finished_blocked_task_sender = finished_blocked_task_sender.clone();
let finished_idle_task_sender = finished_idle_task_sender.clone();
⋮----
let (task, sender) = select_biased! {
⋮----
defer! {
⋮----
runnable_task_receiver.context(),
⋮----
if sender.send(Ok(task)).is_err() {
warn!("handler_thread: scheduler thread aborted...");
⋮----
self.scheduler_thread = Some(
⋮----
.name(format!("solSchedule{mode_char}"))
.spawn_tracked(scheduler_main_loop)
⋮----
.map({
⋮----
.name(format!("solScHandle{mode_char}{thx:02}"))
.spawn_tracked(handler_main_loop())
⋮----
.collect();
⋮----
fn send_task(&self, task: Task) -> ScheduleResult {
debug!("send_task()");
⋮----
.map_err(|_| SchedulerAborted)
⋮----
fn ensure_join_threads(&mut self, should_receive_session_result: bool) {
trace!("ensure_join_threads() is called");
fn join_with_panic_message(join_handle: JoinHandle<()>) -> thread::Result<()> {
let thread = join_handle.thread().clone();
join_handle.join().inspect_err(|e| {
⋮----
panic!("{panic_message} (From: {thread:?})");
⋮----
if let Some(scheduler_thread) = self.scheduler_thread.take() {
for thread in self.handler_threads.drain(..) {
debug!("joining...: {thread:?}");
() = join_with_panic_message(thread).unwrap();
⋮----
() = join_with_panic_message(scheduler_thread).unwrap();
⋮----
let result_with_timings = self.session_result_receiver.recv().unwrap();
debug!("ensure_join_threads(): err: {:?}", result_with_timings.0);
self.put_session_result_with_timings(result_with_timings);
⋮----
warn!("ensure_join_threads(): skipping; already joined...");
⋮----
fn ensure_join_threads_after_abort(
⋮----
self.ensure_join_threads(should_receive_aborted_session_result);
⋮----
.unwrap_err()
⋮----
fn are_threads_joined(&self) -> bool {
if self.scheduler_thread.is_none() {
assert!(self.handler_threads.is_empty());
⋮----
fn end_session(&mut self) {
self.do_end_session(false)
⋮----
fn do_end_session(&mut self, nonblocking: bool) {
⋮----
assert!(self.session_result_with_timings.is_some());
debug!("end_session(): skipping; already joined the aborted threads..");
⋮----
} else if self.session_result_with_timings.is_some() {
debug!("end_session(): skipping; already result resides within thread manager..");
⋮----
debug!(
⋮----
.send(NewTaskPayload::CloseSubchannel)
.is_err();
⋮----
abort_detected = result_with_timings.0.is_err();
⋮----
self.ensure_join_threads_after_abort(false);
⋮----
debug!("end_session(): ended session at {:?}...", thread::current());
⋮----
fn unpause_started_session(&self) {
⋮----
.send(NewTaskPayload::UnpauseOpenedSubchannel)
⋮----
fn start_session(
⋮----
assert!(!self.are_threads_joined());
⋮----
.send(NewTaskPayload::OpenSubchannel(Box::new((
⋮----
.expect("no new session after aborted");
⋮----
fn discard_buffered_tasks(&self) {
self.new_task_sender.send(NewTaskPayload::Reset).unwrap();
⋮----
fn disconnect_new_task_sender(&mut self) -> bool {
⋮----
.send(NewTaskPayload::Disconnect)
.is_err()
⋮----
pub trait SchedulerInner {
⋮----
pub trait SpawnableScheduler<TH: TaskHandler>: InstalledScheduler {
⋮----
type Inner = PooledSchedulerInner<Self, TH>;
fn into_inner(mut self) -> (ResultWithTimings, Self::Inner) {
⋮----
manager.end_session();
manager.take_session_result_with_timings()
⋮----
fn from_inner(
⋮----
.start_session(context.clone(), result_with_timings);
⋮----
fn spawn(
⋮----
let mut thread_manager = ThreadManager::new(pool.clone());
⋮----
pool.create_handler_context(context.mode(), &thread_manager.new_task_sender);
let usage_queue_loader = handler_context.usage_queue_loader_for_newly_spawned();
thread_manager.start_threads(context.clone(), result_with_timings, handler_context);
⋮----
pub enum BankingStageStatus {
⋮----
pub trait BankingStageMonitor: Send + Debug {
⋮----
struct ExitedBankingMonitor;
impl BankingStageMonitor for ExitedBankingMonitor {
fn status(&mut self) -> BankingStageStatus {
⋮----
impl<TH: TaskHandler> InstalledScheduler for PooledScheduler<TH> {
fn id(&self) -> SchedulerId {
self.inner.id()
⋮----
fn context(&self) -> &SchedulingContext {
⋮----
fn schedule_execution(
⋮----
self.inner.usage_queue_loader.load(pubkey)
⋮----
self.inner.thread_manager.send_task(task)
⋮----
fn recover_error_after_abort(&mut self) -> TransactionError {
⋮----
.ensure_join_threads_after_abort(true)
⋮----
fn wait_for_termination(
⋮----
let (result_with_timings, uninstalled_scheduler) = self.into_inner();
⋮----
fn pause_for_recent_blockhash(&mut self) {
let nonblocking = matches!(self.context().mode(), BlockProduction);
self.inner.thread_manager.do_end_session(nonblocking);
⋮----
fn unpause_after_taken(&self) {
self.inner.thread_manager.unpause_started_session();
⋮----
impl<S, TH> SchedulerInner for PooledSchedulerInner<S, TH>
⋮----
fn is_trashed(&self) -> bool {
self.is_aborted() || self.is_overgrown()
⋮----
fn is_overgrown(&self) -> bool {
⋮----
.is_overgrown(self.thread_manager.pool.max_usage_queue_count)
⋮----
fn discard_buffer(&self) {
self.thread_manager.discard_buffered_tasks();
⋮----
impl<S, TH> UninstalledScheduler for PooledSchedulerInner<S, TH>
⋮----
fn return_to_pool(self: Box<Self>) {
self.thread_manager.pool.clone().return_scheduler(*self);
⋮----
mod tests {
⋮----
enum TestCheckPoint {
⋮----
fn test_scheduler_pool_new() {
⋮----
assert_eq!((Arc::strong_count(&pool), Arc::weak_count(&pool)), (1, 2));
let debug = format!("{pool:#?}");
assert!(!debug.is_empty());
⋮----
fn test_scheduler_spawn() {
⋮----
let scheduler = pool.take_scheduler(context);
let debug = format!("{scheduler:#?}");
⋮----
fn test_scheduler_drop_idle() {
⋮----
let pool = pool_raw.clone();
⋮----
let context2 = context1.clone();
let old_scheduler = pool.do_take_scheduler(context1);
let new_scheduler = pool.do_take_scheduler(context2);
let new_scheduler_id = new_scheduler.id();
Box::new(old_scheduler.into_inner().1).return_to_pool();
sleep(TEST_WAIT_FOR_IDLE);
Box::new(new_scheduler.into_inner().1).return_to_pool();
assert_eq!(pool_raw.scheduler_inners.lock().unwrap().len(), 2);
⋮----
assert_eq!(pool_raw.scheduler_inners.lock().unwrap().len(), 1);
assert_eq!(
⋮----
fn test_scheduler_drop_overgrown() {
⋮----
let small_scheduler = pool.do_take_scheduler(context1);
let small_scheduler_id = small_scheduler.id();
⋮----
.load(Pubkey::new_unique());
⋮----
let big_scheduler = pool.do_take_scheduler(context2);
⋮----
assert_eq!(pool_raw.scheduler_inners.lock().unwrap().len(), 0);
assert_eq!(pool_raw.trashed_scheduler_inners.lock().unwrap().len(), 0);
Box::new(small_scheduler.into_inner().1).return_to_pool();
Box::new(big_scheduler.into_inner().1).return_to_pool();
⋮----
assert_eq!(pool_raw.trashed_scheduler_inners.lock().unwrap().len(), 1);
⋮----
fn test_scheduler_drop_stale() {
⋮----
let context = SchedulingContext::for_verification(bank.clone());
⋮----
let bank = BankWithScheduler::new(bank, Some(scheduler));
pool.register_timeout_listener(bank.create_timeout_listener());
⋮----
assert_matches!(bank.wait_for_completed_scheduler(), Some((Ok(()), _)));
⋮----
fn test_scheduler_active_after_stale() {
⋮----
struct ExecuteTimingCounter;
impl TaskHandler for ExecuteTimingCounter {
⋮----
} = create_genesis_config(10_000);
⋮----
let (bank, _bank_forks) = setup_dummy_fork_graph(bank);
⋮----
genesis_config.hash(),
⋮----
bank.schedule_transaction_executions([(tx_before_stale, 0)].into_iter())
⋮----
bank.schedule_transaction_executions([(tx_after_stale, 1)].into_iter())
⋮----
let (result, timings) = bank.wait_for_completed_scheduler().unwrap();
assert_matches!(result, Ok(()));
assert_eq!(timings.metrics[ExecuteTimingType::CheckUs].0, 246);
⋮----
fn test_scheduler_pause_after_stale() {
⋮----
let GenesisConfigInfo { genesis_config, .. } = create_genesis_config(10_000);
⋮----
bank.fill_bank_with_ticks_for_tests();
let (result, _timings) = bank.wait_for_completed_scheduler().unwrap();
⋮----
fn test_scheduler_remain_stale_after_error() {
⋮----
let result = bank.schedule_transaction_executions([(tx_after_stale, 1)].into_iter());
assert_matches!(result, Err(TransactionError::AccountNotFound));
⋮----
enum AbortCase {
⋮----
struct FaultyHandler;
impl TaskHandler for FaultyHandler {
⋮----
*result = Err(TransactionError::AccountNotFound);
⋮----
fn do_test_scheduler_drop_abort(abort_case: AbortCase) {
⋮----
let scheduler = pool.do_take_scheduler(context);
scheduler.schedule_execution(tx, 0).unwrap();
⋮----
panic!("ThreadManager::drop() should be skipped...");
⋮----
let ((result, _), mut scheduler_inner) = scheduler.into_inner();
⋮----
.ensure_join_threads(dummy_flag);
⋮----
fn test_scheduler_drop_abort_unhandled() {
do_test_scheduler_drop_abort(AbortCase::Unhandled);
⋮----
fn test_scheduler_drop_abort_unhandled_while_panicking() {
do_test_scheduler_drop_abort(AbortCase::UnhandledWhilePanicking);
⋮----
fn test_scheduler_drop_abort_handled() {
do_test_scheduler_drop_abort(AbortCase::Handled);
⋮----
fn test_scheduler_drop_short_circuiting() {
⋮----
struct CountingHandler;
impl TaskHandler for CountingHandler {
⋮----
*TASK_COUNT.lock().unwrap() += 1;
⋮----
scheduler.schedule_execution(tx, i).unwrap();
⋮----
assert!(*TASK_COUNT.lock().unwrap() < MAX_TASK_COUNT);
⋮----
fn test_scheduler_pool_filo() {
⋮----
let scheduler1 = pool.do_take_scheduler(context.clone());
let scheduler_id1 = scheduler1.id();
let scheduler2 = pool.do_take_scheduler(context.clone());
let scheduler_id2 = scheduler2.id();
assert_ne!(scheduler_id1, scheduler_id2);
let (result_with_timings, scheduler1) = scheduler1.into_inner();
assert_matches!(result_with_timings, (Ok(()), _));
pool.return_scheduler(scheduler1);
let (result_with_timings, scheduler2) = scheduler2.into_inner();
⋮----
pool.return_scheduler(scheduler2);
let scheduler3 = pool.do_take_scheduler(context.clone());
assert_eq!(scheduler_id2, scheduler3.id());
let scheduler4 = pool.do_take_scheduler(context.clone());
assert_eq!(scheduler_id1, scheduler4.id());
⋮----
fn test_scheduler_pool_context_drop_unless_reinitialized() {
⋮----
let mut scheduler = pool.do_take_scheduler(context.clone());
scheduler.pause_for_recent_blockhash();
assert_matches!(
⋮----
fn test_scheduler_pool_context_replace() {
⋮----
assert!(!Arc::ptr_eq(old_bank, new_bank));
let old_context = &SchedulingContext::for_verification(old_bank.clone());
let new_context = &SchedulingContext::for_verification(new_bank.clone());
let scheduler = pool.do_take_scheduler(old_context.clone());
let scheduler_id = scheduler.id();
pool.return_scheduler(scheduler.into_inner().1);
let scheduler = pool.take_scheduler(new_context.clone());
assert_eq!(scheduler_id, scheduler.id());
assert!(Arc::ptr_eq(scheduler.context().bank().unwrap(), new_bank));
⋮----
fn test_scheduler_pool_install_into_bank_forks() {
⋮----
let mut bank_forks = bank_forks.write().unwrap();
⋮----
bank_forks.install_scheduler_pool(pool);
⋮----
fn test_scheduler_install_into_bank() {
⋮----
assert!(!bank_forks
⋮----
let mut child_bank = bank_forks.insert(child_bank);
assert!(child_bank.has_installed_scheduler());
bank_forks.remove(child_bank.slot());
child_bank.drop_scheduler();
assert!(!child_bank.has_installed_scheduler());
⋮----
fn setup_dummy_fork_graph(bank: Bank) -> (Arc<Bank>, Arc<RwLock<BankForks>>) {
let slot = bank.slot();
⋮----
let bank = bank_fork.read().unwrap().get(slot).unwrap();
bank.set_fork_graph_in_program_cache(Arc::downgrade(&bank_fork));
⋮----
fn test_scheduler_schedule_execution_success() {
⋮----
assert_eq!(bank.transaction_count(), 0);
⋮----
scheduler.schedule_execution(tx0, 0).unwrap();
⋮----
assert_eq!(bank.transaction_count(), 1);
⋮----
fn do_test_scheduler_schedule_execution_failure(extra_tx_after_failure: bool) {
⋮----
scheduler.schedule_execution(bad_tx, 0).unwrap();
⋮----
fn test_scheduler_schedule_execution_failure_with_extra_tx() {
do_test_scheduler_schedule_execution_failure(true);
⋮----
fn test_scheduler_schedule_execution_failure_without_extra_tx() {
do_test_scheduler_schedule_execution_failure(false);
⋮----
fn test_scheduler_schedule_execution_panic() {
⋮----
enum PanickingHanlderCheckPoint {
⋮----
struct PanickingHandler;
impl TaskHandler for PanickingHandler {
⋮----
panic!("This panic should be propagated.");
⋮----
Some(TX_COUNT.try_into().unwrap()),
⋮----
scheduler.schedule_execution(tx, task_id).unwrap();
⋮----
drop(progress);
bank.wait_for_completed_scheduler().unwrap().0.unwrap();
⋮----
fn test_scheduler_execution_failure_short_circuiting() {
⋮----
struct CountingFaultyHandler;
impl TaskHandler for CountingFaultyHandler {
⋮----
let bank = BankWithScheduler::new(bank, Some(Box::new(scheduler)));
⋮----
assert!(*TASK_COUNT.lock().unwrap() < 10);
⋮----
fn create_genesis_config_for_block_production(lamports: u64) -> GenesisConfigInfo {
⋮----
fn test_scheduler_schedule_execution_blocked_at_session_ending(
⋮----
struct StallingHandler;
impl TaskHandler for StallingHandler {
⋮----
_ => unreachable!(),
⋮----
} = create_genesis_config_for_block_production(10_000);
⋮----
let (record_sender, mut record_receiver) = record_channels(true);
⋮----
record_receiver.restart(bank.bank_id());
⋮----
pool.register_banking_stage(
⋮----
Box::new(|_, _| unreachable!()),
⋮----
let mut expected_transaction_count = Saturating(0);
assert_eq!(bank.transaction_count(), expected_transaction_count.0);
let context = SchedulingContext::new_with_mode(scheduling_mode, bank.clone());
⋮----
let old_scheduler_id = scheduler.id();
⋮----
scheduler.unpause_after_taken();
⋮----
.schedule_execution(tx0, STALLED_TRANSACTION_INDEX)
⋮----
.schedule_execution(tx1, BLOCKED_TRANSACTION_INDEX)
⋮----
bank.clone_without_scheduler(),
⋮----
bank.slot().checked_add(1).unwrap(),
⋮----
record_receiver.shutdown();
for _ in record_receiver.drain() {}
⋮----
assert_eq!(scheduler.id(), old_scheduler_id);
⋮----
fn test_block_production_scheduler_schedule_execution_retry() {
⋮----
&Err(TransactionError::WouldExceedMaxBlockCostLimit),
⋮----
&CheckPoint::SessionFinished(Some(FULL_BLOCK_SLOT)),
⋮----
&CheckPoint::TaskAccumulated(RETRIED_TRANSACTION_INDEX, &Ok(())),
⋮----
bank.clone(),
⋮----
bank.write_cost_tracker().unwrap().set_limits(0, 0, 0);
let context = SchedulingContext::for_production(bank.clone());
⋮----
bank.schedule_transaction_executions([(tx, ORIGINAL_TRANSACTION_INDEX)].into_iter())
⋮----
bank.unpause_new_block_production_scheduler();
⋮----
bank.write_cost_tracker()
⋮----
.set_limits(u64::MAX, u64::MAX, u64::MAX);
⋮----
fn test_scheduler_mismatched_scheduling_context_race() {
⋮----
struct TaskAndContextChecker;
impl TaskHandler for TaskAndContextChecker {
⋮----
assert_eq!(task.task_id() as Slot, scheduling_context.slot().unwrap());
⋮----
let bank0 = setup_dummy_fork_graph(bank0).0;
⋮----
bank0.clone(),
⋮----
bank0.slot().checked_add(1).unwrap(),
⋮----
Some(4),
⋮----
let context0 = &SchedulingContext::for_verification(bank0.clone());
let context1 = &SchedulingContext::for_verification(bank1.clone());
⋮----
.into_iter()
.cycle()
.take(10000)
⋮----
let scheduler = pool.take_scheduler(context.clone());
⋮----
.schedule_execution(dummy_tx.clone(), task_id)
⋮----
scheduler.wait_for_termination(false).1.return_to_pool();
⋮----
struct AsyncScheduler<const TRIGGER_RACE_CONDITION: bool>(
⋮----
fn do_wait(&self) {
let mut overall_result = Ok(());
⋮----
for handle in self.1.lock().unwrap().drain(..) {
let (result, timings) = handle.join().unwrap();
⋮----
Err(e) => overall_result = Err(e),
⋮----
overall_timings.accumulate(&timings);
⋮----
*self.0.lock().unwrap() = (overall_result, overall_timings);
⋮----
impl<const TRIGGER_RACE_CONDITION: bool> InstalledScheduler
⋮----
unimplemented!();
⋮----
let context = self.context().clone();
let pool = self.3.clone();
self.1.lock().unwrap().push(std::thread::spawn(move || {
⋮----
let mut result = Ok(());
⋮----
&pool.create_handler_context(
⋮----
self.do_wait();
⋮----
&mut *self.0.lock().unwrap(),
⋮----
impl<const TRIGGER_RACE_CONDITION: bool> SchedulerInner for AsyncScheduler<TRIGGER_RACE_CONDITION> {
⋮----
unimplemented!()
⋮----
fn set_next_task_id_for_block_production(&self, _next_task_id: usize) {
⋮----
impl<const TRIGGER_RACE_CONDITION: bool> UninstalledScheduler
⋮----
self.3.clone().return_scheduler(*self)
⋮----
type Inner = Self;
fn into_inner(self) -> (ResultWithTimings, Self::Inner) {
⋮----
Mutex::new(initialized_result_with_timings()),
Mutex::new(vec![]),
⋮----
fn do_test_scheduler_schedule_execution_recent_blockhash_edge_case<
⋮----
bank.freeze();
⋮----
slot.checked_add(1).unwrap(),
⋮----
bank.schedule_transaction_executions([(very_old_valid_tx, 0)].into_iter())
⋮----
fn test_scheduler_schedule_execution_recent_blockhash_edge_case_with_race() {
⋮----
fn test_scheduler_schedule_execution_recent_blockhash_edge_case_without_race() {
⋮----
fn test_default_handler_count() {
⋮----
fn test_enfoced_get_account_locks_validation() {
⋮----
let (bank, _bank_forks) = &setup_dummy_fork_graph(bank);
⋮----
tx.message.account_keys.push(tx.message.account_keys[0]);
⋮----
let result = &mut Ok(());
⋮----
let scheduling_context = &SchedulingContext::for_verification(bank.clone());
⋮----
banking_packet_receiver: never(),
⋮----
assert_matches!(result, Err(TransactionError::AccountLoadedTwice));
⋮----
enum TxResult {
⋮----
fn test_task_handler_poh_recording(tx_result: TxResult, should_succeed_to_record_to_poh: bool) {
⋮----
let bank = bank_forks.read().unwrap().working_bank_with_scheduler();
⋮----
Ok(()),
⋮----
Err(TransactionError::BlockhashNotFound),
⋮----
let scheduling_context = &SchedulingContext::for_production(bank.clone());
⋮----
transaction_status_sender: Some(TransactionStatusSender {
⋮----
transaction_recorder: Some(transaction_recorder),
⋮----
let task = SchedulingStateMachine::create_task(tx.clone(), 0, &mut |_| {
⋮----
assert_eq!(bank.transaction_error_count(), 0);
⋮----
if expected_tx_result.is_ok() {
⋮----
if matches!(tx_result, TxResult::ExecutedWithFailure) {
assert_eq!(bank.transaction_error_count(), 1);
⋮----
assert!(record_receiver.try_recv().is_ok());
⋮----
assert_eq!(result, &expected_tx_result);
⋮----
assert_matches!(receiver.try_recv(), Err(_));
assert!(record_receiver.try_recv().is_err());
⋮----
assert_matches!(result, Err(TransactionError::CommitCancelled));
⋮----
struct DummyBankingMinitor;
impl BankingStageMonitor for DummyBankingMinitor {
⋮----
fn test_block_production_scheduler_schedule_execution_success() {
⋮----
fn create_new_unconstrained_task(
⋮----
fn test_block_production_scheduler_buffering_on_spawn() {
⋮----
.send(BankingPacketBatch::default())
⋮----
assert_eq!(banking_packet_sender.len(), 1);
⋮----
helper.send_new_task(helper.create_new_unconstrained_task(tx0.clone(), 17))
⋮----
assert_eq!(banking_packet_sender.len(), 0);
⋮----
fn test_block_production_scheduler_buffering_before_new_session() {
⋮----
helper.send_new_task(helper.create_new_unconstrained_task(tx0.clone(), 18))
⋮----
let bank_tmp = BankWithScheduler::new(bank.clone(), Some(scheduler));
assert_matches!(bank_tmp.wait_for_completed_scheduler(), Some((Ok(()), _)));
⋮----
fn test_block_production_scheduler_take_without_registering() {
⋮----
let scheduler = pool.do_take_scheduler(context.clone());
Box::new(scheduler.into_inner().1).return_to_pool();
⋮----
fn test_block_production_scheduler_double_take_without_returning() {
⋮----
create_genesis_config_for_block_production(10_000);
⋮----
let scheduler2 = pool.do_take_scheduler(context);
Box::new(scheduler1.into_inner().1).return_to_pool();
Box::new(scheduler2.into_inner().1).return_to_pool();
⋮----
fn test_block_production_scheduler_drop_overgrown_on_returning() {
⋮----
let trashed_old_scheduler_id = scheduler.id();
⋮----
let respawned_new_scheduler_id = scheduler.id();
⋮----
assert_ne!(trashed_old_scheduler_id, respawned_new_scheduler_id);
⋮----
fn test_block_production_scheduler_drop_overgrown_on_idling() {
⋮----
struct InactiveBankingMinitor;
impl BankingStageMonitor for InactiveBankingMinitor {
⋮----
pool.set_next_task_id_for_block_production(BANKING_STAGE_MAX_TASK_ID + 1);
⋮----
fn test_block_production_scheduler_return_block_verification_scheduler_while_pooled() {
⋮----
let bank_tmp = BankWithScheduler::new(bank, Some(scheduler));
⋮----
fn test_block_production_scheduler_discard_on_reset() {
⋮----
struct SimpleBankingMinitor;
⋮----
impl BankingStageMonitor for SimpleBankingMinitor {
⋮----
if *START_DISCARD.lock().unwrap() {
⋮----
&CheckPoint::Discarded(DISCARDED_TASK_COUNT.try_into().unwrap()),
⋮----
helper.send_new_task(helper.create_new_unconstrained_task(tx0.clone(), task_id))
⋮----
*START_DISCARD.lock().unwrap() = true;

================
File: unified-scheduler-pool/src/sleepless_testing.rs
================
pub(crate) trait ScopeTracked<'scope>: Sized {
⋮----
pub(crate) trait BuilderTracked: Sized {
⋮----
mod real {
⋮----
struct Progress {
⋮----
struct JustCreated;
impl Progress {
fn new(check_points: impl Iterator<Item = String>, name: String) -> Self {
let initial_check_point = format!("{JustCreated:?}");
let check_points = [initial_check_point.clone()]
.into_iter()
.chain(check_points)
⋮----
fn change_current_check_point(&self, anchored_check_point: String) {
let mut current_index = self.current_index.lock().unwrap();
let Some(anchored_index) = self.anchored_index(*current_index, &anchored_check_point)
⋮----
trace!("Ignore {} at {:?}", anchored_check_point, current());
⋮----
let next_index = self.expected_next_index(*current_index);
let should_change = match anchored_index.cmp(&next_index) {
⋮----
trace!("Blocked on {} at {:?}", anchored_check_point, current());
// anchor is one of future check points; block the current thread until
// that happens
⋮----
.wait_while(current_index, |&mut current_index| {
⋮----
self.anchored_index(current_index, &anchored_check_point)
⋮----
// don't wait. seems the progress is made by other threads
⋮----
let next_index = self.expected_next_index(current_index);
match anchored_index.cmp(&next_index) {
⋮----
trace!(
⋮----
Less => unreachable!(),
⋮----
.unwrap();
⋮----
trace!("Progressed to: {} at {:?}", anchored_check_point, current());
⋮----
self.condvar.notify_all();
⋮----
fn expected_next_index(&self, current_index: usize) -> usize {
current_index.checked_add(1).unwrap()
⋮----
fn anchored_index(
⋮----
.iter()
.position(|check_point| check_point == anchored_check_point)
.map(|subslice_index| subslice_index.checked_add(current_index).unwrap())
⋮----
pub(crate) struct ActiveProgress(Arc<Progress>, ThreadId);
impl ActiveProgress {
fn new(progress: Arc<Progress>) -> Self {
let active_progress = Self(progress, current().id());
active_progress.activate();
⋮----
fn activate(&self) {
assert!(THREAD_REGISTRY
⋮----
fn deactivate(&self) {
if !panicking() {
assert_eq!(
⋮----
THREAD_REGISTRY.lock().unwrap().remove(&self.1).unwrap();
⋮----
impl Drop for ActiveProgress {
fn drop(&mut self) {
self.deactivate();
⋮----
pub(crate) fn setup(check_points: &[&dyn Debug]) -> ActiveProgress {
⋮----
.map(|check_point| format!("{check_point:?}")),
current().name().unwrap_or_default().to_string(),
⋮----
pub(crate) fn at<T: Debug>(check_point: T) {
let mut registry = THREAD_REGISTRY.lock().unwrap();
if let Some(progress) = registry.get_mut(&current().id()).cloned() {
drop(registry);
progress.change_current_check_point(format!("{check_point:?}"));
} else if current().name().unwrap_or_default().starts_with("test_") {
panic!("seems setup() isn't called yet?");
⋮----
pub(crate) mod thread {
⋮----
struct SpawningThreadTracker(Arc<(Mutex<bool>, Condvar)>);
struct SpawnedThreadTracker(Arc<(Mutex<bool>, Condvar)>, ThreadId, bool);
impl SpawningThreadTracker {
fn ensure_spawned_tracked(self) {
⋮----
let lock = lock.lock().unwrap();
assert!(cvar.wait_while(lock, |&mut tracked| !tracked).is_ok());
⋮----
impl SpawnedThreadTracker {
fn do_track(&mut self) {
⋮----
if let Some(progress) = registry.get(&self.1).cloned() {
assert!(registry.insert(current().id(), progress).is_none());
⋮----
*lock.lock().unwrap() = true;
cvar.notify_one();
⋮----
fn do_untrack(self) {
⋮----
registry.remove(&current().id()).unwrap();
⋮----
fn with_tracked<T: Send>(mut self, f: impl FnOnce() -> T + Send) -> T {
self.do_track();
let returned = f();
self.do_untrack();
⋮----
fn prepare_tracking() -> (SpawningThreadTracker, SpawnedThreadTracker) {
⋮----
let lock_and_condvar2 = lock_and_condvar1.clone();
let spawning_thread_tracker = SpawningThreadTracker(lock_and_condvar1);
let spawning_thread_id = current().id();
⋮----
SpawnedThreadTracker(lock_and_condvar2, spawning_thread_id, false);
⋮----
pub(crate) fn spawn_tracked<T: Send + 'static>(
⋮----
let (spawning_thread_tracker, spawned_thread_tracker) = prepare_tracking();
let spawned_thread = spawn(move || spawned_thread_tracker.with_tracked(f));
spawning_thread_tracker.ensure_spawned_tracked();
⋮----
fn spawn_tracked<T: Send + 'scope>(
⋮----
let spawned_thread = self.spawn(move || spawned_thread_tracker.with_tracked(f));
⋮----
impl BuilderTracked for Builder {
fn spawn_tracked<T: Send + 'static>(
⋮----
self.spawn(move || spawned_thread_tracker.with_tracked(f));
if spawned_thread_result.is_ok() {
⋮----
fn spawn_scoped_tracked<'scope, 'env, T: Send + 'scope>(
⋮----
self.spawn_scoped(scope, move || spawned_thread_tracker.with_tracked(f));
⋮----
mod dummy {
use std::fmt::Debug;
⋮----
pub(crate) fn at<T: Debug>(_check_point: T) {}
⋮----
spawn(f)
⋮----
self.spawn(f)
⋮----
self.spawn_scoped(scope, f)

================
File: unified-scheduler-pool/Cargo.toml
================
[package]
name = "solana-unified-scheduler-pool"
description = "The Solana unified scheduler pool"
documentation = "https://docs.rs/solana-unified-scheduler-pool"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []
dev-context-only-utils = []

[dependencies]
agave-banking-stage-ingress-types = { workspace = true }
aquamarine = { workspace = true }
assert_matches = { workspace = true }
crossbeam-channel = { workspace = true }
dashmap = { workspace = true }
derive-where = { workspace = true }
derive_more = { workspace = true }
dyn-clone = { workspace = true }
log = { workspace = true }
qualifier_attr = { workspace = true }
scopeguard = { workspace = true }
solana-clock = { workspace = true }
solana-cost-model = { workspace = true }
solana-ledger = { workspace = true }
solana-metrics = { workspace = true }
solana-poh = { workspace = true }
solana-pubkey = { workspace = true }
solana-runtime = { workspace = true }
solana-runtime-transaction = { workspace = true }
solana-svm = { workspace = true }
solana-svm-timings = { workspace = true }
solana-transaction = { workspace = true }
solana-transaction-error = { workspace = true }
solana-unified-scheduler-logic = { workspace = true }
static_assertions = { workspace = true }
trait-set = { workspace = true }
unwrap_none = { workspace = true }
vec_extract_if_polyfill = { workspace = true }

[dev-dependencies]
agave-logger = { workspace = true }
assert_matches = { workspace = true }
solana-clock = { workspace = true }
solana-entry = { workspace = true }
solana-hash = { workspace = true }
solana-keypair = { workspace = true }
solana-runtime = { workspace = true, features = ["dev-context-only-utils"] }
solana-system-transaction = { workspace = true }
test-case = { workspace = true }

================
File: validator/src/bin/solana-test-validator.rs
================
enum Output {
⋮----
fn main() {
⋮----
let matches = cli::test_app(version, &default_args).get_matches();
let output = if matches.is_present("quiet") {
⋮----
} else if matches.is_present("log") {
⋮----
let ledger_path = value_t_or_exit!(matches, "ledger_path", PathBuf);
let reset_ledger = matches.is_present("reset");
⋮----
.values_of("account_indexes")
.unwrap_or_default()
.map(|value| match value {
⋮----
_ => unreachable!(),
⋮----
.collect();
⋮----
if !ledger_path.exists() {
fs::create_dir(&ledger_path).unwrap_or_else(|err| {
println!(
⋮----
exit(1);
⋮----
let mut ledger_lock = ledger_lockfile(&ledger_path);
let _ledger_write_guard = lock_ledger(&ledger_path, &mut ledger_lock);
⋮----
remove_directory_contents(&ledger_path).unwrap_or_else(|err| {
println!("Error: Unable to remove {}: {}", ledger_path.display(), err);
⋮----
let validator_log_symlink = ledger_path.join("validator.log");
⋮----
let validator_log_with_timestamp = format!(
⋮----
symlink::symlink_file(&validator_log_with_timestamp, &validator_log_symlink).unwrap();
Some(ledger_path.join(validator_log_with_timestamp))
⋮----
info!("{} {}", crate_name!(), solana_version::version!());
info!("Starting validator with: {:#?}", std::env::args_os());
⋮----
let cli_config = if let Some(config_file) = matches.value_of("config_file") {
solana_cli_config::Config::load(config_file).unwrap_or_default()
⋮----
let cluster_rpc_client = value_t!(matches, "json_rpc_url", String)
.map(normalize_to_url_if_moniker)
.map(RpcClient::new);
let (mint_address, random_mint) = pubkey_of(&matches, "mint_address")
.map(|pk| (pk, false))
.unwrap_or_else(|| {
read_keypair_file(&cli_config.keypair_path)
.map(|kp| (kp.pubkey(), false))
.unwrap_or_else(|_| (Keypair::new().pubkey(), true))
⋮----
let rpc_port = value_t_or_exit!(matches, "rpc_port", u16);
⋮----
PubSubConfig::from_clap_arg_match(&matches).unwrap_or(PubSubConfig::default_for_tests());
let faucet_port = value_t_or_exit!(matches, "faucet_port", u16);
let ticks_per_slot = value_t!(matches, "ticks_per_slot", u64).ok();
let slots_per_epoch = value_t!(matches, "slots_per_epoch", Slot).ok();
let inflation_fixed = value_t!(matches, "inflation_fixed", f64).ok();
let gossip_port = value_t!(matches, "gossip_port", u16).ok();
let dynamic_port_range = matches.value_of("dynamic_port_range").map(|port_range| {
solana_net_utils::parse_port_range(port_range).unwrap_or_else(|| {
eprintln!("Failed to parse --dynamic-port-range");
⋮----
.value_of("bind_address")
.expect("Bind address has default value"),
⋮----
.unwrap_or_else(|err| {
eprintln!("Failed to parse --bind-address: {err}");
⋮----
let advertised_ip = if !bind_address.is_unspecified() && !bind_address.is_loopback() {
⋮----
let compute_unit_limit = value_t!(matches, "compute_unit_limit", u64).ok();
⋮----
.or_else(|_| read_keypair_file(address).map(|keypair| keypair.pubkey()))
⋮----
println!("Error: invalid {input_type} {address}: {err}");
⋮----
if !program_path.exists() {
⋮----
let mut upgradeable_programs_to_load = vec![];
if let Some(values) = matches.values_of("bpf_program") {
for (address, program) in values.into_iter().tuples() {
let address = parse_address(address, "address");
let program_path = parse_program_path(program);
upgradeable_programs_to_load.push(UpgradeableProgramInfo {
⋮----
if let Some(values) = matches.values_of("upgradeable_program") {
⋮----
values.into_iter().tuples::<(&str, &str, &str)>()
⋮----
.or_else(|_| {
read_keypair_file(upgrade_authority).map(|keypair| keypair.pubkey())
⋮----
println!("Error: invalid upgrade_authority {upgrade_authority}: {err}");
⋮----
let mut accounts_to_load = vec![];
if let Some(values) = matches.values_of("account") {
for (address, filename) in values.into_iter().tuples() {
⋮----
Some(address.parse::<Pubkey>().unwrap_or_else(|err| {
println!("Error: invalid address {address}: {err}");
⋮----
accounts_to_load.push(AccountInfo { address, filename });
⋮----
.values_of("account_dir")
⋮----
let accounts_to_clone: HashSet<_> = pubkeys_of(&matches, "clone_account")
.map(|v| v.into_iter().collect())
.unwrap_or_default();
let accounts_to_maybe_clone: HashSet<_> = pubkeys_of(&matches, "maybe_clone_account")
⋮----
pubkeys_of(&matches, "clone_upgradeable_program")
⋮----
let alt_accounts_to_clone: HashSet<_> = pubkeys_of(&matches, "deep_clone_address_lookup_table")
⋮----
let clone_feature_set = matches.is_present("clone_feature_set");
let warp_slot = if matches.is_present("warp_slot") {
Some(match matches.value_of("warp_slot") {
Some(_) => value_t_or_exit!(matches, "warp_slot", Slot),
⋮----
.as_ref()
.unwrap_or_else(|_| {
⋮----
.get_slot()
⋮----
println!("Unable to get current cluster slot: {err}");
⋮----
.value_of("faucet_sol")
.and_then(sol_str_to_lamports)
.unwrap();
let faucet_keypair_file = ledger_path.join("faucet-keypair.json");
if !faucet_keypair_file.exists() {
write_keypair_file(&Keypair::new(), faucet_keypair_file.to_str().unwrap()).unwrap_or_else(
⋮----
read_keypair_file(faucet_keypair_file.to_str().unwrap()).unwrap_or_else(|err| {
⋮----
let faucet_pubkey = faucet_keypair.pubkey();
let faucet_time_slice_secs = value_t_or_exit!(matches, "faucet_time_slice_secs", u64);
⋮----
.value_of("faucet_per_time_sol_cap")
.and_then(sol_str_to_lamports);
⋮----
.value_of("faucet_per_request_sol_cap")
⋮----
let (sender, receiver) = unbounded();
⋮----
Some(faucet_time_slice_secs),
⋮----
.enable_all()
.build()
⋮----
runtime.block_on(run_faucet(faucet, faucet_addr, Some(sender)));
⋮----
let _ = receiver.recv().expect("run faucet").unwrap_or_else(|err| {
println!("Error: failed to start faucet: {err}");
⋮----
let features_to_deactivate = pubkeys_of(&matches, "deactivate_feature").unwrap_or_default();
⋮----
if matches.is_present(name) {
println!("{long} argument ignored, ledger already exists");
⋮----
println_name_value(
⋮----
genesis.max_ledger_shreds = value_of(&matches, "limit_ledger_size");
genesis.max_genesis_archive_unpacked_size = Some(u64::MAX);
genesis.log_messages_bytes_limit = value_t!(matches, "log_messages_bytes_limit", usize).ok();
⋮----
value_t!(matches, "transaction_account_lock_limit", usize).ok();
genesis.enable_scheduler_bindings = matches.is_present("enable_scheduler_bindings");
let tower_storage = Arc::new(FileTowerStorage::new(ledger_path.clone()));
⋮----
if matches.is_present("geyser_plugin_config") {
⋮----
(Some(sender), Some(receiver))
⋮----
commands::bam::extract_bam_url(&matches).unwrap_or_else(|err| {
println!("Error: BAM URL invalid: {err}");
⋮----
rpc_addr: Some(SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), rpc_port)),
start_progress: genesis.start_progress.clone(),
⋮----
validator_exit: genesis.validator_exit.clone(),
⋮----
authorized_voter_keypairs: genesis.authorized_voter_keypairs.clone(),
staked_nodes_overrides: genesis.staked_nodes_overrides.clone(),
⋮----
tower_storage: tower_storage.clone(),
⋮----
bam_url: genesis.bam_url.clone(),
⋮----
Some(Dashboard::new(
⋮----
Some(&validator_log_symlink),
Some(&mut genesis.validator_exit.write().unwrap()),
⋮----
let rpc_bigtable_config = if matches.is_present("enable_rpc_bigtable_ledger_storage")
|| matches.is_present("enable_bigtable_ledger_upload")
⋮----
Some(RpcBigtableConfig {
enable_bigtable_ledger_upload: matches.is_present("enable_bigtable_ledger_upload"),
bigtable_instance_name: value_t_or_exit!(matches, "rpc_bigtable_instance", String),
bigtable_app_profile_id: value_t_or_exit!(
⋮----
.ledger_path(&ledger_path)
.tower_storage(tower_storage)
.add_account(
⋮----
.pubsub_config(pub_sub_config)
.rpc_port(rpc_port)
.add_upgradeable_programs_with_path(&upgradeable_programs_to_load)
.add_accounts_from_json_files(&accounts_to_load)
.unwrap_or_else(|e| {
println!("Error: add_accounts_from_json_files failed: {e}");
⋮----
.add_accounts_from_directories(&accounts_from_dirs)
⋮----
println!("Error: add_accounts_from_directories failed: {e}");
⋮----
.deactivate_features(&features_to_deactivate);
genesis.rpc_config(JsonRpcConfig {
⋮----
faucet_addr: Some(faucet_addr),
⋮----
if !accounts_to_clone.is_empty() {
if let Err(e) = genesis.clone_accounts(
⋮----
.expect("--clone-account requires --json-rpc-url argument"),
⋮----
println!("Error: clone_accounts failed: {e}");
⋮----
if !alt_accounts_to_clone.is_empty() {
if let Err(e) = genesis.deep_clone_address_lookup_table_accounts(
⋮----
.expect("--deep-clone-address-lookup-table requires --json-rpc-url argument"),
⋮----
println!("Error: alt_accounts_to_clone failed: {e}");
⋮----
if !accounts_to_maybe_clone.is_empty() {
⋮----
.expect("--maybe-clone requires --json-rpc-url argument"),
⋮----
if !upgradeable_programs_to_clone.is_empty() {
if let Err(e) = genesis.clone_upgradeable_programs(
⋮----
.expect("--clone-upgradeable-program requires --json-rpc-url argument"),
⋮----
println!("Error: clone_upgradeable_programs failed: {e}");
⋮----
if let Err(e) = genesis.clone_feature_set(
⋮----
.expect("--clone-feature-set requires --json-rpc-url argument"),
⋮----
println!("Error: clone_feature_set failed: {e}");
⋮----
genesis.warp_slot(warp_slot);
⋮----
genesis.ticks_per_slot(ticks_per_slot);
⋮----
genesis.epoch_schedule(EpochSchedule::custom(
⋮----
genesis.inflation(Inflation::new_fixed(inflation_fixed));
⋮----
genesis.gossip_host(advertised_ip);
⋮----
genesis.gossip_port(gossip_port);
⋮----
genesis.port_range(dynamic_port_range);
⋮----
genesis.bind_ip_addr(bind_address);
⋮----
genesis.geyser_plugin_config_files = Some(
values_t_or_exit!(matches, "geyser_plugin_config", String)
.into_iter()
.map(PathBuf::from)
.collect(),
⋮----
genesis.compute_unit_limit(compute_unit_limit);
⋮----
match genesis.start_with_mint_address_and_geyser_plugin_rpc(
⋮----
dashboard.run(Duration::from_millis(250));
⋮----
test_validator.join();
⋮----
drop(dashboard);
println!("Error: failed to start validator: {err}");
⋮----
fn remove_directory_contents(ledger_path: &Path) -> Result<(), io::Error> {
⋮----
if entry.metadata()?.is_dir() {
fs::remove_dir_all(entry.path())?
⋮----
fs::remove_file(entry.path())?
⋮----
Ok(())

================
File: validator/src/cli/thread_args.rs
================
pub struct DefaultThreadArgs {
⋮----
impl Default for DefaultThreadArgs {
fn default() -> Self {
⋮----
.to_string(),
⋮----
block_production_num_workers: BankingStage::default_num_workers().to_string(),
ip_echo_server_threads: IpEchoServerThreadsArg::bounded_default().to_string(),
rayon_global_threads: RayonGlobalThreadsArg::bounded_default().to_string(),
replay_forks_threads: ReplayForksThreadsArg::bounded_default().to_string(),
⋮----
TpuTransactionForwardReceiveThreadArgs::bounded_default().to_string(),
⋮----
TpuVoteTransactionReceiveThreads::bounded_default().to_string(),
tvu_receive_threads: TvuReceiveThreadsArg::bounded_default().to_string(),
tvu_retransmit_threads: TvuRetransmitThreadsArg::bounded_default().to_string(),
tvu_sigverify_threads: TvuShredSigverifyThreadsArg::bounded_default().to_string(),
⋮----
pub fn thread_args<'a>(defaults: &DefaultThreadArgs) -> Vec<Arg<'_, 'a>> {
vec![
⋮----
pub(crate) fn new_thread_arg<'a, T: ThreadArg>(default: &str) -> Arg<'_, 'a> {
⋮----
.long(T::LONG_NAME)
.takes_value(true)
.value_name("NUMBER")
.default_value(default)
.validator(|num| is_within_range(num, T::range()))
.hidden(hidden_unless_forced())
.help(T::HELP)
⋮----
pub struct NumThreadConfig {
⋮----
pub fn parse_num_threads_args(matches: &ArgMatches) -> NumThreadConfig {
⋮----
accounts_db_background_threads: value_t_or_exit!(
⋮----
accounts_db_foreground_threads: value_t_or_exit!(
⋮----
accounts_index_flush_threads: value_t_or_exit!(
⋮----
block_production_num_workers: value_t_or_exit!(
⋮----
ip_echo_server_threads: value_t_or_exit!(
⋮----
rayon_global_threads: value_t_or_exit!(matches, RayonGlobalThreadsArg::NAME, NonZeroUsize),
replay_forks_threads: value_t_or_exit!(matches, ReplayForksThreadsArg::NAME, NonZeroUsize),
replay_transactions_threads: value_t_or_exit!(
⋮----
tpu_transaction_forward_receive_threads: value_t_or_exit!(
⋮----
tpu_transaction_receive_threads: value_t_or_exit!(
⋮----
tpu_vote_transaction_receive_threads: value_t_or_exit!(
⋮----
tvu_receive_threads: value_t_or_exit!(matches, TvuReceiveThreadsArg::NAME, NonZeroUsize),
tvu_retransmit_threads: value_t_or_exit!(
⋮----
tvu_sigverify_threads: value_t_or_exit!(
⋮----
pub trait ThreadArg {
⋮----
/// The argument's long name
    const LONG_NAME: &'static str;
/// The argument's help message
    const HELP: &'static str;
/// The default number of threads
    fn default() -> usize;
/// The default number of threads, bounded by Self::max()
    /// This prevents potential CLAP issues on low core count machines where
⋮----
/// This prevents potential CLAP issues on low core count machines where
    /// a fixed value in Self::default() could be greater than Self::max()
⋮----
/// a fixed value in Self::default() could be greater than Self::max()
    fn bounded_default() -> usize {
⋮----
fn bounded_default() -> usize {
⋮----
/// The minimum allowed number of threads (inclusive)
    fn min() -> usize {
⋮----
fn min() -> usize {
⋮----
/// The maximum allowed number of threads (inclusive)
    fn max() -> usize {
⋮----
fn max() -> usize {
// By default, no thread pool should scale over the number of the machine's threads
⋮----
fn range() -> RangeInclusive<usize> {
⋮----
struct AccountsDbBackgroundThreadsArg;
impl ThreadArg for AccountsDbBackgroundThreadsArg {
⋮----
fn default() -> usize {
⋮----
struct AccountsDbForegroundThreadsArg;
impl ThreadArg for AccountsDbForegroundThreadsArg {
⋮----
struct AccountsIndexFlushThreadsArg;
impl ThreadArg for AccountsIndexFlushThreadsArg {
⋮----
accounts_index::default_num_flush_threads().get()
⋮----
struct BlockProductionNumWorkersArg;
impl ThreadArg for BlockProductionNumWorkersArg {
⋮----
BankingStage::default_num_workers().get()
⋮----
BankingStage::max_num_workers().get()
⋮----
struct IpEchoServerThreadsArg;
impl ThreadArg for IpEchoServerThreadsArg {
⋮----
solana_net_utils::DEFAULT_IP_ECHO_SERVER_THREADS.get()
⋮----
solana_net_utils::MINIMUM_IP_ECHO_SERVER_THREADS.get()
⋮----
struct RayonGlobalThreadsArg;
impl ThreadArg for RayonGlobalThreadsArg {
⋮----
struct ReplayForksThreadsArg;
impl ThreadArg for ReplayForksThreadsArg {
⋮----
// Default to single threaded fork execution
⋮----
// Choose a value that is small enough to limit the overhead of having a large thread pool
// while also being large enough to allow replay of all active forks in most scenarios
⋮----
struct ReplayTransactionsThreadsArg;
impl ThreadArg for ReplayTransactionsThreadsArg {
⋮----
struct TpuTransactionForwardReceiveThreadArgs;
impl ThreadArg for TpuTransactionForwardReceiveThreadArgs {
⋮----
struct TpuTransactionReceiveThreads;
impl ThreadArg for TpuTransactionReceiveThreads {
⋮----
struct TpuVoteTransactionReceiveThreads;
impl ThreadArg for TpuVoteTransactionReceiveThreads {
⋮----
struct TvuReceiveThreadsArg;
impl ThreadArg for TvuReceiveThreadsArg {
⋮----
solana_gossip::cluster_info::DEFAULT_NUM_TVU_RECEIVE_SOCKETS.get()
⋮----
solana_gossip::cluster_info::MINIMUM_NUM_TVU_RECEIVE_SOCKETS.get()
⋮----
struct TvuRetransmitThreadsArg;
impl ThreadArg for TvuRetransmitThreadsArg {
⋮----
solana_gossip::cluster_info::DEFAULT_NUM_TVU_RETRANSMIT_SOCKETS.get()
⋮----
solana_gossip::cluster_info::MINIMUM_NUM_TVU_RETRANSMIT_SOCKETS.get()
⋮----
struct TvuShredSigverifyThreadsArg;
impl ThreadArg for TvuShredSigverifyThreadsArg {
⋮----
get_thread_count()

================
File: validator/src/commands/authorized_voter/mod.rs
================
pub struct AuthorizedVoterAddArgs {
⋮----
impl FromClapArgMatches for AuthorizedVoterAddArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(AuthorizedVoterAddArgs {
authorized_voter_keypair: value_t!(matches, "authorized_voter_keypair", String).ok(),
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Adjust the validator authorized voters")
.setting(AppSettings::SubcommandRequiredElseHelp)
.setting(AppSettings::InferSubcommands)
.subcommand(
⋮----
.about("Add an authorized voter")
.arg(
⋮----
.index(1)
.value_name("KEYPAIR")
.required(false)
.takes_value(true)
.validator(is_keypair)
.help(
⋮----
.after_help(
⋮----
.about("Remove all authorized voters")
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
match matches.subcommand() {
⋮----
println!(
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.add_authorized_voter(authorized_voter_keypair.display().to_string())
⋮----
let authorized_voter_keypair = read_keypair(&mut stdin)?;
⋮----
.add_authorized_voter_from_bytes(Vec::from(
authorized_voter_keypair.to_bytes(),
⋮----
admin_client.await?.remove_all_authorized_voters().await
⋮----
println!("All authorized voters removed");
⋮----
_ => unreachable!(),
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_authorized_voter_add_default() {
let app = command();
let matches = app.get_matches_from(vec![COMMAND, "add"]);
let subcommand_matches = matches.subcommand_matches("add").unwrap();
let args = AuthorizedVoterAddArgs::from_clap_arg_match(subcommand_matches).unwrap();
assert_eq!(args, AuthorizedVoterAddArgs::default());
⋮----
fn verify_args_struct_by_command_authorized_voter_add_with_authorized_voter_keypair() {
let tmp_dir = tempfile::tempdir().unwrap();
let file = tmp_dir.path().join("id.json");
⋮----
solana_keypair::write_keypair_file(&keypair, &file).unwrap();
⋮----
let matches = app.get_matches_from(vec![COMMAND, "add", file.to_str().unwrap()]);
⋮----
assert_eq!(

================
File: validator/src/commands/bam/mod.rs
================
pub enum BamUrlError {
⋮----
fn normalize_bam_url(url_str: &str) -> Result<String, BamUrlError> {
let url_str_to_parse = if url_str.contains("://") {
url_str.into()
⋮----
format!("{DEFAULT_BAM_URL_SCHEME}://{url_str}")
⋮----
let url = Url::parse(&url_str_to_parse).map_err(|e| BamUrlError::InvalidUrlFormat {
url: url_str.to_string(),
⋮----
let scheme = url.scheme();
if !matches!(scheme, "http" | "https") {
return Err(BamUrlError::UnsupportedScheme {
scheme: scheme.to_string(),
⋮----
match url.host_str() {
⋮----
return Err(BamUrlError::EmptyHost {
⋮----
// Transform URL to add default port if missing
let final_url = match url.port() {
Some(_) => url, // Port already specified
⋮----
.set_port(Some(default_port))
.map_err(|_| BamUrlError::PortSetFailed {
⋮----
let final_url_string = final_url.to_string();
if url_str.ends_with('/') {
Ok(final_url_string)
⋮----
Ok(final_url_string.trim_end_matches('/').to_string())
⋮----
pub fn extract_bam_url(matches: &ArgMatches) -> Result<Option<String>, BamUrlError> {
match matches.value_of("bam_url") {
⋮----
if url.trim().is_empty() {
return Ok(None);
⋮----
normalize_bam_url(url).map(Some)
⋮----
None => Ok(None),
⋮----
pub fn argument() -> Arg<'static, 'static> {
⋮----
.long("bam-url")
.min_values(0)
.max_values(1)
.help("URL of BAM Node; leave empty to disable BAM.")
.takes_value(true)
⋮----
pub fn command(_default_args: &DefaultArgs) -> App<'_, '_> {
⋮----
.about("Set configuration for connection to a BAM node")
.arg(argument())
⋮----
pub fn execute(subcommand_matches: &ArgMatches, ledger_path: &Path) -> crate::commands::Result<()> {
if !subcommand_matches.is_present("bam_url") {
return Ok(());
⋮----
let bam_url = extract_bam_url(subcommand_matches)
.map_err(|e| -> Box<dyn std::error::Error> { Box::new(e) })?;
⋮----
.block_on(async move { admin_client.await?.set_bam_url(bam_url).await })?;
Ok(())
⋮----
mod tests {
⋮----
fn create_test_matches(bam_url: Option<&str>) -> ArgMatches<'_> {
let app = clap::App::new("test-app").arg(argument());
⋮----
vec!["test-app", "--bam-url", url]
⋮----
vec!["test-app"]
⋮----
app.get_matches_from(args)
⋮----
fn assert_eq_extract_bam_url<S: AsRef<str>, E: AsRef<str>>(input: S, expected: E) {
let matches = create_test_matches(Some(input.as_ref()));
let result = extract_bam_url(&matches);
assert_eq!(
⋮----
fn assert_extract_bam_url_error<S: AsRef<str>>(input: S, expected_variant: BamUrlError) {
⋮----
assert!(
⋮----
let actual_error = result.unwrap_err();
// Use matches! macro to check the error variant type
let matches_expected = matches!(
⋮----
// HTTP with port
⋮----
// HTTPS with port
⋮----
// No scheme with port (should default to http)
⋮----
// No scheme without port (should default to http with default port 50055)
⋮----
fn test_extract_bam_url_success(input: &str, expected: &str) {
assert_eq_extract_bam_url(input, expected);
⋮----
// Empty inputs
⋮----
fn test_extract_bam_url_empty_inputs(input: &str, _case: &str) {
let matches = create_test_matches(Some(input));
⋮----
// Unsupported schemes
⋮----
#[test_case("ssh://user@host.com", "ssh" ; "ssh scheme")]

================
File: validator/src/commands/block_engine/mod.rs
================
pub fn command(_default_args: &DefaultArgs) -> App<'_, '_> {
⋮----
.about("Set configuration for connection to a block engine")
.arg(
⋮----
.long("block-engine-url")
.help(
⋮----
.takes_value(true)
.required(true),
⋮----
.long("disable-block-engine-autoconfig")
.takes_value(false)
⋮----
.long("trust-block-engine-packets")
⋮----
pub fn execute(subcommand_matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
let block_engine_url = value_t_or_exit!(subcommand_matches, "block_engine_url", String);
⋮----
subcommand_matches.is_present("disable_block_engine_autoconfig");
let trust_packets = subcommand_matches.is_present("trust_block_engine_packets");
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.set_block_engine_config(
⋮----
Ok(())

================
File: validator/src/commands/contact_info/mod.rs
================
pub struct ContactInfoArgs {
⋮----
impl FromClapArgMatches for ContactInfoArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(ContactInfoArgs {
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Display the validator's contact info")
.arg(
⋮----
.long("output")
.takes_value(true)
.value_name("MODE")
.possible_values(&["json", "json-compact"])
.help("Output display mode"),
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
.block_on(async move { admin_client.await?.contact_info().await })?;
println!(
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_contact_info_output_json() {
verify_args_struct_by_command(
command(),
vec![COMMAND, "--output", "json"],
⋮----
fn verify_args_struct_by_command_contact_info_output_json_compact() {
⋮----
vec![COMMAND, "--output", "json-compact"],
⋮----
fn verify_args_struct_by_command_contact_info_output_default() {
⋮----
vec![COMMAND],
⋮----
fn verify_args_struct_by_command_contact_info_output_invalid() {
⋮----
vec![COMMAND, "--output", "invalid_output_type"],

================
File: validator/src/commands/exit/mod.rs
================
pub enum PostExitAction {
⋮----
pub struct ExitArgs {
⋮----
impl FromClapArgMatches for ExitArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
let post_exit_action = if matches.is_present("monitor") {
Some(PostExitAction::Monitor)
} else if matches.is_present("no_wait_for_exit") {
⋮----
Some(PostExitAction::Wait)
⋮----
if matches.is_present("wait_for_exit") {
eprintln!(
⋮----
if matches.is_present("monitor") {
⋮----
Ok(ExitArgs {
force: matches.is_present("force"),
⋮----
min_idle_time: value_t_or_exit!(matches, "min_idle_time", usize),
max_delinquent_stake: value_t_or_exit!(matches, "max_delinquent_stake", u8),
skip_new_snapshot_check: matches.is_present("skip_new_snapshot_check"),
skip_health_check: matches.is_present("skip_health_check"),
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Send an exit request to the validator")
.arg(
⋮----
.short("f")
.long("force")
.takes_value(false)
.help(
⋮----
.short("m")
.long("monitor")
⋮----
.requires("no_wait_for_exit")
.hidden(hidden_unless_forced())
.help("Monitor the validator after sending the exit request"),
⋮----
.long("wait-for-exit")
.conflicts_with("monitor")
⋮----
.help("Wait for the validator to terminate after sending the exit request"),
⋮----
.long("no-wait-for-exit")
⋮----
.conflicts_with("wait_for_exit")
.help("Do not wait for the validator to terminate after sending the exit request"),
⋮----
.long("min-idle-time")
.takes_value(true)
.validator(is_parsable::<usize>)
.value_name("MINUTES")
.default_value(DEFAULT_MIN_IDLE_TIME)
.help("Minimum time that the validator should not be leader before restarting"),
⋮----
.long("max-delinquent-stake")
⋮----
.validator(is_valid_percentage)
.default_value(DEFAULT_MAX_DELINQUENT_STAKE)
.value_name("PERCENT")
.help("The maximum delinquent stake % permitted for an exit"),
⋮----
.long("skip-new-snapshot-check")
.help("Skip check for a new snapshot"),
⋮----
.long("skip-health-check")
.help("Skip health check"),
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
// Grab the pid from the process before initiating exit as the running
// validator will be unable to respond after exit has returned.
//
// Additionally, only check the pid() RPC call result if it will be used.
// In an upgrade scenario, it is possible that a binary that calls pid()
// will be initiating exit against a process that doesn't support pid().
⋮----
let post_exit_action = exit_args.post_exit_action.clone();
let validator_pid = admin_rpc_service::runtime().block_on(async move {
⋮----
.pid()
⋮----
.map_err(|_err| Error::Dynamic(WAIT_FOR_EXIT_UNSUPPORTED_ERROR.into()))?,
⋮----
admin_client.exit().await?;
⋮----
println!("Exit request sent");
⋮----
None => Ok(()),
⋮----
Some(PostExitAction::Wait) => poll_until_pid_terminates(validator_pid),
⋮----
Ok(())
⋮----
fn poll_until_pid_terminates(pid: u32) -> Result<()> {
⋮----
println!("Waiting for agave-validator process {pid} to terminate");
⋮----
.raw_os_error()
.ok_or(Error::Dynamic("unable to read raw os error".into()))?;
⋮----
println!("Done, agave-validator process {pid} has terminated");
⋮----
Err(Error::Dynamic(
format!("unexpected invalid signal error for kill({pid}, 0)").into(),
⋮----
Err(io::Error::from(io::ErrorKind::PermissionDenied))?;
⋮----
format!("unexpected errno for kill({pid}, 0): {unknown}").into(),
⋮----
fn poll_until_pid_terminates(_pid: u32) -> Result<()> {
⋮----
"Unable to wait for agave-validator process termination on this platform".into(),
⋮----
mod tests {
⋮----
impl Default for ExitArgs {
fn default() -> Self {
⋮----
.parse()
.expect("invalid DEFAULT_MIN_IDLE_TIME"),
⋮----
.expect("invalid DEFAULT_MAX_DELINQUENT_STAKE"),
⋮----
post_exit_action: Some(PostExitAction::Wait),
⋮----
fn verify_args_struct_by_command_exit_default() {
verify_args_struct_by_command(command(), vec![COMMAND], ExitArgs::default());
⋮----
fn verify_args_struct_by_command_exit_with_force() {
verify_args_struct_by_command(
command(),
vec![COMMAND, "--force"],
⋮----
fn verify_args_struct_by_command_exit_with_post_exit_action() {
⋮----
vec![COMMAND, "--monitor", "--no-wait-for-exit"],
⋮----
post_exit_action: Some(PostExitAction::Monitor),
⋮----
vec![COMMAND, "--no-wait-for-exit"],
⋮----
vec![COMMAND, "--wait-for-exit"],
⋮----
fn verify_args_struct_by_command_exit_with_min_idle_time() {
⋮----
vec![COMMAND, "--min-idle-time", "60"],
⋮----
fn verify_args_struct_by_command_exit_with_max_delinquent_stake() {
⋮----
vec![COMMAND, "--max-delinquent-stake", "10"],
⋮----
fn verify_args_struct_by_command_exit_with_skip_new_snapshot_check() {
⋮----
vec![COMMAND, "--skip-new-snapshot-check"],
⋮----
fn verify_args_struct_by_command_exit_with_skip_health_check() {
⋮----
vec![COMMAND, "--skip-health-check"],

================
File: validator/src/commands/manage_block_production/mod.rs
================
pub struct ManageBlockProductionArgs {
⋮----
impl FromClapArgMatches for ManageBlockProductionArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(ManageBlockProductionArgs {
block_production_method: value_t!(
⋮----
.unwrap_or_default(),
transaction_structure: value_t!(matches, "transaction_struct", TransactionStructure)
⋮----
num_workers: value_t!(matches, "block_production_num_workers", NonZeroUsize)
.unwrap_or(BankingStage::default_num_workers()),
pacing_fill_time_millis: value_t!(
⋮----
pub fn command(default_args: &DefaultArgs) -> App<'_, '_> {
⋮----
.about("Manage block production")
.arg(
⋮----
.long("block-production-method")
.alias("method")
.value_name("METHOD")
.takes_value(true)
.possible_values(BlockProductionMethod::cli_names())
.default_value(BlockProductionMethod::default().into())
.help(BlockProductionMethod::cli_message()),
⋮----
.long("transaction-structure")
.alias("struct")
.value_name("STRUCT")
⋮----
.possible_values(TransactionStructure::cli_names())
.help(TransactionStructure::cli_message()),
⋮----
.long("block-production-num-workers")
.alias("num-workers")
.value_name("NUM")
⋮----
.help("Number of worker threads to use for block production"),
⋮----
.long("block-production-pacing-fill-time-millis")
.alias("pacing-fill-time-millis")
.value_name("MILLIS")
⋮----
.default_value(&default_args.block_production_pacing_fill_time_millis)
.help(
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
println!(
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.manage_block_production(
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_manage_block_production_default() {
⋮----
let app = command(&default_args);
let matches = app.get_matches_from(vec![COMMAND]);
let args = ManageBlockProductionArgs::from_clap_arg_match(&matches).unwrap();
assert_eq!(
⋮----
fn verify_args_struct_by_command_manage_block_production_with_args() {
⋮----
let matches = app.get_matches_from(vec![
⋮----
fn verify_args_struct_by_command_manage_block_production_with_args_pacing_disabled() {

================
File: validator/src/commands/monitor/mod.rs
================
pub fn command<'a>() -> App<'a, 'a> {
SubCommand::with_name("monitor").about("Monitor the validator")
⋮----
pub fn execute(_matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
monitor_validator(ledger_path)
⋮----
pub fn monitor_validator(ledger_path: &Path) -> Result<()> {
⋮----
dashboard.run(Duration::from_secs(2));
Ok(())

================
File: validator/src/commands/plugin/mod.rs
================
pub struct PluginUnloadArgs {
⋮----
impl FromClapArgMatches for PluginUnloadArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(PluginUnloadArgs {
name: value_t!(matches, "name", String)?,
⋮----
pub struct PluginLoadArgs {
⋮----
impl FromClapArgMatches for PluginLoadArgs {
⋮----
Ok(PluginLoadArgs {
config: value_t!(matches, "config", String)?,
⋮----
pub struct PluginReloadArgs {
⋮----
impl FromClapArgMatches for PluginReloadArgs {
⋮----
Ok(PluginReloadArgs {
⋮----
pub fn command<'a>() -> App<'a, 'a> {
let name_arg = Arg::with_name("name").required(true).takes_value(true);
let config_arg = Arg::with_name("config").required(true).takes_value(true);
⋮----
.about("Manage and view geyser plugins")
.setting(AppSettings::SubcommandRequiredElseHelp)
.setting(AppSettings::InferSubcommands)
.subcommand(SubCommand::with_name("list").about("List all current running geyser plugins"))
.subcommand(
⋮----
.about("Unload a particular geyser plugin. You must specify the geyser plugin name")
.arg(&name_arg),
⋮----
.about(
⋮----
.arg(&name_arg)
.arg(&config_arg),
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
match matches.subcommand() {
⋮----
.block_on(async move { admin_client.await?.list_plugins().await })?;
if !plugins.is_empty() {
println!("Currently the following plugins are loaded:");
for (plugin, i) in plugins.into_iter().zip(1..) {
println!("  {i}) {plugin}");
⋮----
println!("There are currently no plugins loaded");
⋮----
.block_on(async { admin_client.await?.unload_plugin(name.clone()).await })?;
println!("Successfully unloaded plugin: {name}");
⋮----
.block_on(async { admin_client.await?.load_plugin(config.clone()).await })?;
println!("Successfully loaded plugin: {name}");
⋮----
admin_rpc_service::runtime().block_on(async {
⋮----
.reload_plugin(name.clone(), config.clone())
⋮----
println!("Successfully reloaded plugin: {name}");
⋮----
_ => unreachable!(),
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_plugin_unload_default() {
⋮----
command(),
vec![COMMAND, "unload"],
⋮----
fn verify_args_struct_by_command_plugin_unload_with_name() {
let app = command();
let matches = app.get_matches_from(vec![COMMAND, "unload", "testname"]);
let subcommand_matches = matches.subcommand_matches("unload").unwrap();
let args = PluginUnloadArgs::from_clap_arg_match(subcommand_matches).unwrap();
assert_eq!(
⋮----
fn verify_args_struct_by_command_plugin_load_default() {
verify_args_struct_by_command_is_error::<PluginLoadArgs>(command(), vec![COMMAND, "load"]);
⋮----
fn verify_args_struct_by_command_plugin_load_with_config() {
⋮----
let matches = app.get_matches_from(vec![COMMAND, "load", "testconfig"]);
let subcommand_matches = matches.subcommand_matches("load").unwrap();
let args = PluginLoadArgs::from_clap_arg_match(subcommand_matches).unwrap();
⋮----
fn verify_args_struct_by_command_plugin_reload_default() {
⋮----
vec![COMMAND, "reload"],
⋮----
fn verify_args_struct_by_command_plugin_reload_with_name() {
⋮----
vec![COMMAND, "reload", "testname"],
⋮----
fn verify_args_struct_by_command_plugin_reload_with_name_and_config() {
⋮----
let matches = app.get_matches_from(vec![COMMAND, "reload", "testname", "testconfig"]);
let subcommand_matches = matches.subcommand_matches("reload").unwrap();
let args = PluginReloadArgs::from_clap_arg_match(subcommand_matches).unwrap();

================
File: validator/src/commands/relayer/mod.rs
================
pub fn command(default_args: &DefaultArgs) -> App<'_, '_> {
⋮----
.about("Set configuration for connection to a relayer")
.arg(
⋮----
.long("relayer-url")
.help("Relayer url. Set to empty string to disable relayer connection.")
.takes_value(true)
.required(true),
⋮----
.long("relayer-expected-heartbeat-interval-ms")
⋮----
.help("Interval at which the Relayer is expected to send heartbeat messages.")
.required(false)
.default_value(&default_args.relayer_expected_heartbeat_interval_ms),
⋮----
.long("relayer-max-failed-heartbeats")
⋮----
.help(
⋮----
.default_value(&default_args.relayer_max_failed_heartbeats),
⋮----
pub fn execute(subcommand_matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
let relayer_url = value_t_or_exit!(subcommand_matches, "relayer_url", String);
⋮----
value_of(subcommand_matches, "relayer_expected_heartbeat_interval_ms").unwrap();
⋮----
value_of(subcommand_matches, "relayer_max_failed_heartbeats").unwrap();
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.set_relayer_config(
⋮----
Ok(())

================
File: validator/src/commands/repair_shred_from_peer/mod.rs
================
pub struct RepairShredFromPeerArgs {
⋮----
impl FromClapArgMatches for RepairShredFromPeerArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(RepairShredFromPeerArgs {
pubkey: value_t!(matches, "pubkey", Pubkey).ok(),
slot: value_t!(matches, "slot", u64)?,
shred: value_t!(matches, "shred", u64)?,
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Request a repair from the specified validator")
.arg(
⋮----
.long("pubkey")
.value_name("PUBKEY")
.required(false)
.takes_value(true)
.validator(is_pubkey)
.help("Identity pubkey of the validator to repair from"),
⋮----
.long("slot")
.value_name("SLOT")
.required(true)
⋮----
.validator(is_parsable::<u64>)
.help("Slot to repair"),
⋮----
.long("shred")
.value_name("SHRED")
⋮----
.help("Shred to repair"),
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.repair_shred_from_peer(pubkey, slot, shred)
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_repair_shred_from_peer_missing_slot_and_shred() {
verify_args_struct_by_command_is_error::<RepairShredFromPeerArgs>(command(), vec![COMMAND]);
⋮----
command(),
vec![COMMAND, "--slot", "1"],
⋮----
vec![COMMAND, "--shred", "2"],
⋮----
fn verify_args_struct_by_command_repair_shred_from_peer_missing_pubkey() {
verify_args_struct_by_command(
⋮----
vec![COMMAND, "--slot", "1", "--shred", "2"],
⋮----
fn verify_args_struct_by_command_repair_shred_from_peer_with_pubkey() {
⋮----
vec![
⋮----
pubkey: Some(
Pubkey::from_str("ch1do11111111111111111111111111111111111111").unwrap(),

================
File: validator/src/commands/repair_whitelist/mod.rs
================
pub struct RepairWhitelistGetArgs {
⋮----
impl FromClapArgMatches for RepairWhitelistGetArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(RepairWhitelistGetArgs {
⋮----
pub struct RepairWhitelistSetArgs {
⋮----
impl FromClapArgMatches for RepairWhitelistSetArgs {
⋮----
let whitelist = values_t!(matches, "whitelist", Pubkey)?
.into_iter()
.unique()
⋮----
Ok(RepairWhitelistSetArgs { whitelist })
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Manage the validator's repair protocol whitelist")
.setting(AppSettings::SubcommandRequiredElseHelp)
.setting(AppSettings::InferSubcommands)
.subcommand(
⋮----
.about("Display the validator's repair protocol whitelist")
.arg(
⋮----
.long("output")
.takes_value(true)
.value_name("MODE")
.possible_values(&["json", "json-compact"])
.help("Output display mode"),
⋮----
.about("Set the validator's repair protocol whitelist")
.setting(AppSettings::ArgRequiredElseHelp)
⋮----
.long("whitelist")
.validator(is_pubkey)
.value_name("VALIDATOR IDENTITY")
.multiple(true)
⋮----
.required(true)
.help("Set the validator's repair protocol whitelist"),
⋮----
.after_help(
⋮----
.about("Clear the validator's repair protocol whitelist")
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
match matches.subcommand() {
⋮----
.block_on(async move { admin_client.await?.repair_whitelist().await })?;
println!(
⋮----
if whitelist.is_empty() {
return Ok(());
⋮----
set_repair_whitelist(ledger_path, whitelist)?;
⋮----
set_repair_whitelist(ledger_path, Vec::default())?;
⋮----
_ => unreachable!(),
⋮----
Ok(())
⋮----
fn set_repair_whitelist(ledger_path: &Path, whitelist: Vec<Pubkey>) -> Result<()> {
⋮----
.block_on(async move { admin_client.await?.set_repair_whitelist(whitelist).await })?;
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_repair_whitelist_get_default() {
let app = command();
let matches = app.get_matches_from(vec![COMMAND, "get"]);
let subcommand_matches = matches.subcommand_matches("get").unwrap();
let args = RepairWhitelistGetArgs::from_clap_arg_match(subcommand_matches).unwrap();
assert_eq!(
⋮----
fn verify_args_struct_by_command_repair_whitelist_get_with_output() {
⋮----
let matches = app.get_matches_from(vec![COMMAND, "get", "--output", "json"]);
⋮----
fn verify_args_struct_by_command_repair_whitelist_set_with_single_whitelist() {
⋮----
let matches = app.get_matches_from(vec![
⋮----
let subcommand_matches = matches.subcommand_matches("set").unwrap();
let args = RepairWhitelistSetArgs::from_clap_arg_match(subcommand_matches).unwrap();
⋮----
fn verify_args_struct_by_command_repair_whitelist_set_with_multiple_whitelist() {
⋮----
let mut args = RepairWhitelistSetArgs::from_clap_arg_match(subcommand_matches).unwrap();
args.whitelist.sort();

================
File: validator/src/commands/run/args/account_secondary_indexes.rs
================
impl FromClapArgMatches for AccountSecondaryIndexes {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
⋮----
.values_of("account_indexes")
.unwrap_or_default()
.map(|value| match value {
⋮----
_ => unreachable!(),
⋮----
.collect();
⋮----
values_t!(matches, "account_index_include_key", Pubkey)
⋮----
.iter()
.cloned()
⋮----
values_t!(matches, "account_index_exclude_key", Pubkey)
⋮----
let exclude_keys = !account_indexes_exclude_keys.is_empty();
let include_keys = !account_indexes_include_keys.is_empty();
let keys = if !account_indexes.is_empty() && (exclude_keys || include_keys) {
⋮----
Some(account_indexes_keys)
⋮----
Ok(AccountSecondaryIndexes {
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_run_with_account_indexes(
⋮----
..default_run_args.json_rpc_config.clone()
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
vec!["--account-index", arg_value],
⋮----
fn verify_args_struct_by_command_run_with_account_indexes_multiple() {
⋮----
vec![
⋮----
fn verify_args_struct_by_command_run_with_account_index_include_key() {
⋮----
keys: Some(AccountSecondaryIndexesIncludeExclude {
⋮----
fn verify_args_struct_by_command_run_with_account_index_exclude_key() {

================
File: validator/src/commands/run/args/blockstore_options.rs
================
struct RocksdbCompactionThreadsArg;
impl ThreadArg for RocksdbCompactionThreadsArg {
⋮----
fn default() -> usize {
solana_ledger::blockstore::default_num_compaction_threads().get()
⋮----
struct RocksdbFlushThreadsArg;
impl ThreadArg for RocksdbFlushThreadsArg {
⋮----
solana_ledger::blockstore::default_num_flush_threads().get()
⋮----
LazyLock::new(|| RocksdbCompactionThreadsArg::default().to_string());
⋮----
LazyLock::new(|| RocksdbFlushThreadsArg::default().to_string());
⋮----
impl FromClapArgMatches for BlockstoreOptions {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
⋮----
.value_of("wal_recovery_mode")
.map(BlockstoreRecoveryMode::from);
⋮----
compression_type: match matches.value_of("rocksdb_ledger_compression") {
⋮----
return Err(crate::commands::Error::Dynamic(
Box::<dyn std::error::Error>::from(format!(
⋮----
rocks_perf_sample_interval: value_t!(matches, "rocksdb_perf_sample_interval", usize)?,
⋮----
value_t!(matches, RocksdbCompactionThreadsArg::NAME, NonZeroUsize)?;
let rocksdb_flush_threads = value_t!(matches, RocksdbFlushThreadsArg::NAME, NonZeroUsize)?;
Ok(BlockstoreOptions {
⋮----
pub(crate) fn args<'a, 'b>() -> Vec<Arg<'a, 'b>> {
vec![
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_run_with_wal_recovery_mode_valid(
⋮----
recovery_mode: Some(expected_mode),
..default_run_args.blockstore_options.clone()
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
vec!["--wal-recovery-mode", arg_value],
⋮----
fn verify_args_struct_by_command_run_with_wal_recovery_mode_invalid() {
⋮----
verify_args_struct_by_command_run_is_error_with_identity_setup(
⋮----
vec!["--wal-recovery-mode", "invalid"],
⋮----
fn verify_args_struct_by_command_run_with_rocksdb_ledger_compression(
⋮----
..default_run_args.blockstore_options.column_options.clone()
⋮----
vec!["--rocksdb-ledger-compression", arg_value],
⋮----
fn verify_args_struct_by_command_run_with_rocksdb_ledger_compression_invalid() {
⋮----
vec!["--rocksdb-ledger-compression", "invalid"],
⋮----
fn verify_args_struct_by_command_run_with_rocksdb_perf_sample_interval() {
⋮----
vec!["--rocksdb-perf-sample-interval", "100"],
⋮----
fn verify_args_struct_by_command_run_with_rocksdb_compaction_threads() {
⋮----
num_rocksdb_compaction_threads: NonZeroUsize::new(1).unwrap(),
⋮----
vec!["--rocksdb-compaction-threads", "1"],
⋮----
fn verify_args_struct_by_command_run_with_rocksdb_flush_threads() {
⋮----
num_rocksdb_flush_threads: NonZeroUsize::new(1).unwrap(),
⋮----
vec!["--rocksdb-flush-threads", "1"],
⋮----
fn test_default_rocksdb_ledger_compression_unchanged() {
assert_eq!(DEFAULT_ROCKSDB_LEDGER_COMPRESSION, "none");
⋮----
fn test_default_rocksdb_perf_sample_interval_unchanged() {
assert_eq!(DEFAULT_ROCKSDB_PERF_SAMPLE_INTERVAL, "0");
⋮----
fn test_default_rocksdb_compaction_threads_unchanged() {
assert_eq!(
⋮----
fn test_valid_range_rocksdb_compaction_threads_unchanged() {
⋮----
fn test_default_rocksdb_flush_threads_unchanged() {
⋮----
fn test_valid_range_rocksdb_flush_threads_unchanged() {
⋮----
fn test_default_rocksdb_shred_compaction_unchanged() {
assert_eq!(DEFAULT_ROCKSDB_SHRED_COMPACTION, "level");

================
File: validator/src/commands/run/args/json_rpc_config.rs
================
solana_rpc_client_api::request::DELINQUENT_VALIDATOR_SLOT_DISTANCE.to_string()
⋮----
LazyLock::new(|| solana_rpc_client_api::request::MAX_MULTIPLE_ACCOUNTS.to_string());
static DEFAULT_RPC_THREADS: LazyLock<String> = LazyLock::new(|| num_cpus::get().to_string());
⋮----
LazyLock::new(|| (1.max(num_cpus::get() / 4)).to_string());
⋮----
LazyLock::new(|| solana_rpc::rpc::MAX_REQUEST_BODY_SIZE.to_string());
impl FromClapArgMatches for JsonRpcConfig {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
let rpc_bigtable_config = if matches.is_present("enable_rpc_bigtable_ledger_storage")
|| matches.is_present("enable_bigtable_ledger_upload")
⋮----
Some(RpcBigtableConfig::from_clap_arg_match(matches)?)
⋮----
Ok(JsonRpcConfig {
enable_rpc_transaction_history: matches.is_present("enable_rpc_transaction_history"),
⋮----
.is_present("enable_extended_tx_metadata_storage"),
⋮----
.value_of("rpc_faucet_addr")
.map(|address| {
solana_net_utils::parse_host_port(address).map_err(|err| {
⋮----
format!("failed to parse rpc_faucet_addr: {err}"),
⋮----
.transpose()?,
health_check_slot_distance: value_t!(matches, "health_check_slot_distance", u64)?,
skip_preflight_health_check: matches.is_present("skip_preflight_health_check"),
⋮----
max_multiple_accounts: Some(value_t!(matches, "rpc_max_multiple_accounts", usize)?),
⋮----
rpc_threads: value_t!(matches, "rpc_threads", usize)?,
rpc_blocking_threads: value_t!(matches, "rpc_blocking_threads", usize)?,
rpc_niceness_adj: value_t!(matches, "rpc_niceness_adj", i8)?,
full_api: matches.is_present("full_rpc_api"),
rpc_scan_and_fix_roots: matches.is_present("rpc_scan_and_fix_roots"),
max_request_body_size: Some(value_t!(matches, "rpc_max_request_body_size", usize)?),
⋮----
pub(crate) fn args<'a, 'b>() -> Vec<Arg<'a, 'b>> {
vec![
⋮----
pub(super) mod tests {
⋮----
use crate::commands::run::args::tests::verify_args_struct_by_command_run_is_error_with_identity_setup;
⋮----
pub fn default_json_rpc_config() -> JsonRpcConfig {
⋮----
health_check_slot_distance: DEFAULT_HEALTH_CHECK_SLOT_DISTANCE.parse().unwrap(),
max_multiple_accounts: Some(DEFAULT_MAX_MULTIPLE_ACCOUNTS.parse().unwrap()),
rpc_threads: DEFAULT_RPC_THREADS.parse().unwrap(),
rpc_blocking_threads: DEFAULT_RPC_BLOCKING_THREADS.parse().unwrap(),
rpc_niceness_adj: DEFAULT_RPC_NICENESS_ADJ.parse().unwrap(),
max_request_body_size: Some(DEFAULT_RPC_MAX_REQUEST_BODY_SIZE.parse().unwrap()),
⋮----
fn verify_args_struct_by_command_run_with_enable_rpc_transaction_history() {
⋮----
..default_run_args.json_rpc_config.clone()
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
vec!["--enable-rpc-transaction-history"],
⋮----
fn verify_args_struct_by_command_run_with_enable_extended_tx_metadata_storage() {
⋮----
fn verify_args_struct_by_command_run_with_rpc_faucet_addr() {
⋮----
faucet_addr: Some(SocketAddr::from((Ipv4Addr::LOCALHOST, 8000))),
⋮----
vec!["--rpc-faucet-address", "127.0.0.1:8000"],
⋮----
fn verify_args_struct_by_command_run_with_health_check_slot_distance() {
⋮----
vec!["--health-check-slot-distance", "100"],
⋮----
fn verify_args_struct_by_command_run_with_skip_preflight_health_check() {
⋮----
vec!["--skip-preflight-health-check"],
⋮----
fn verify_args_struct_by_command_run_with_max_multiple_accounts() {
⋮----
max_multiple_accounts: Some(9999),
⋮----
vec!["--rpc-max-multiple-accounts", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_rpc_threads() {
⋮----
vec!["--rpc-threads", "10"],
⋮----
fn verify_args_struct_by_command_run_with_rpc_blocking_threads() {
⋮----
vec!["--rpc-blocking-threads", "999"],
⋮----
fn verify_args_struct_by_command_run_with_rpc_niceness_adj() {
⋮----
vec!["--rpc-niceness-adjustment", "10"],
⋮----
verify_args_struct_by_command_run_is_error_with_identity_setup(
⋮----
fn verify_args_struct_by_command_run_with_full_api() {
⋮----
notification_threads: Some(
⋮----
.unwrap(),
⋮----
..default_run_args.pub_sub_config.clone()
⋮----
vec!["--full-rpc-api"],
⋮----
fn verify_args_struct_by_command_run_with_rpc_scan_and_fix_roots() {
⋮----
fn verify_args_struct_by_command_run_with_rpc_max_request_body_size() {
⋮----
max_request_body_size: Some(999),
⋮----
vec!["--rpc-max-request-body-size", "999"],
⋮----
fn test_default_health_check_slot_distance_unchanged() {
assert_eq!(*DEFAULT_HEALTH_CHECK_SLOT_DISTANCE, "128");
⋮----
fn test_default_max_multiple_accounts_unchanged() {
assert_eq!(*DEFAULT_MAX_MULTIPLE_ACCOUNTS, "100");
⋮----
fn test_default_rpc_threads_unchanged() {
assert_eq!(*DEFAULT_RPC_THREADS, num_cpus::get().to_string());
⋮----
fn test_default_rpc_blocking_threads_unchanged() {
assert_eq!(
⋮----
fn test_default_rpc_niceness_adj_unchanged() {
assert_eq!(DEFAULT_RPC_NICENESS_ADJ, "0");
⋮----
fn test_default_rpc_max_request_body_size_unchanged() {
assert_eq!(*DEFAULT_RPC_MAX_REQUEST_BODY_SIZE, 51_200.to_string());

================
File: validator/src/commands/run/args/pub_sub_config.rs
================
use qualifier_attr::qualifiers;
⋮----
LazyLock::new(|| PubSubConfig::default().max_active_subscriptions.to_string());
⋮----
.to_string()
⋮----
LazyLock::new(|| PubSubConfig::default().queue_capacity_items.to_string());
⋮----
LazyLock::new(|| PubSubConfig::default().queue_capacity_bytes.to_string());
⋮----
LazyLock::new(|| PubSubConfig::default_for_tests().worker_threads.to_string());
⋮----
LazyLock::new(|| get_thread_count().to_string());
pub(crate) fn args<'a, 'b>(test_validator: bool) -> Vec<Arg<'a, 'b>> {
⋮----
.long("rpc-pubsub-notification-threads")
.takes_value(true)
.value_name("NUM_THREADS")
.validator(is_parsable::<usize>)
.help(
⋮----
rpc_pubsub_notification_threads.default_value(&DEFAULT_TEST_RPC_PUBSUB_WORKER_THREADS),
⋮----
.default_value_if(
⋮----
.requires("full_rpc_api"),
⋮----
vec![
⋮----
impl FromClapArgMatches for PubSubConfig {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(PubSubConfig {
enable_block_subscription: matches.is_present("rpc_pubsub_enable_block_subscription"),
enable_vote_subscription: matches.is_present("rpc_pubsub_enable_vote_subscription"),
max_active_subscriptions: value_t!(
⋮----
queue_capacity_items: value_t!(matches, "rpc_pubsub_queue_capacity_items", usize)?,
queue_capacity_bytes: value_t!(matches, "rpc_pubsub_queue_capacity_bytes", usize)?,
worker_threads: value_t!(matches, "rpc_pubsub_worker_threads", usize)?,
notification_threads: value_t!(matches, "rpc_pubsub_notification_threads", usize)
.ok()
.and_then(NonZeroUsize::new),
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_run_with_enable_block_subscription() {
⋮----
..default_run_args.json_rpc_config.clone()
⋮----
..default_run_args.pub_sub_config.clone()
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
fn verify_args_struct_by_command_run_with_enable_vote_subscription() {
⋮----
vec!["--rpc-pubsub-enable-vote-subscription"],
⋮----
fn verify_args_struct_by_command_run_with_max_active_subscriptions() {
⋮----
vec!["--rpc-pubsub-max-active-subscriptions", "1000"],
⋮----
fn verify_args_struct_by_command_run_with_queue_capacity_items() {
⋮----
vec!["--rpc-pubsub-queue-capacity-items", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_queue_capacity_bytes() {
⋮----
vec!["--rpc-pubsub-queue-capacity-bytes", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_worker_threads() {
⋮----
vec!["--rpc-pubsub-worker-threads", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_notification_threads() {
⋮----
notification_threads: Some(NonZeroUsize::new(9999).unwrap()),
⋮----
fn test_default_rpc_pubsub_max_active_subscriptions_unchanged() {
assert_eq!(
⋮----
fn test_default_rpc_pubsub_queue_capacity_items_unchanged() {
⋮----
fn test_default_rpc_pubsub_queue_capacity_bytes_unchanged() {
⋮----
fn test_default_rpc_pubsub_worker_threads_unchanged() {
assert_eq!(DEFAULT_RPC_PUBSUB_WORKER_THREADS, "4");

================
File: validator/src/commands/run/args/rpc_bigtable_config.rs
================
LazyLock::new(|| solana_storage_bigtable::DEFAULT_MAX_MESSAGE_SIZE.to_string());
impl FromClapArgMatches for RpcBigtableConfig {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(RpcBigtableConfig {
enable_bigtable_ledger_upload: matches.is_present("enable_bigtable_ledger_upload"),
bigtable_instance_name: value_t!(matches, "rpc_bigtable_instance_name", String)?,
bigtable_app_profile_id: value_t!(matches, "rpc_bigtable_app_profile_id", String)?,
timeout: value_t!(matches, "rpc_bigtable_timeout", u64)
.ok()
.map(Duration::from_secs),
max_message_size: value_t!(matches, "rpc_bigtable_max_message_size", usize)?,
⋮----
pub(crate) fn args<'a, 'b>() -> Vec<Arg<'a, 'b>> {
vec![
⋮----
mod tests {
⋮----
fn default_rpc_bigtable_config() -> RpcBigtableConfig {
⋮----
timeout: Some(Duration::from_secs(30)),
⋮----
fn verify_args_struct_by_command_run_with_enable_rpc_bigtable_ledger_storage() {
⋮----
rpc_bigtable_config: Some(RpcBigtableConfig {
..default_rpc_bigtable_config()
⋮----
..default_run_args.json_rpc_config.clone()
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
fn verify_args_struct_by_command_run_with_enable_bigtable_ledger_upload() {
⋮----
fn verify_args_struct_by_command_run_with_rpc_bigtable_instance_name() {
⋮----
bigtable_instance_name: "my-custom-instance-name".to_string(),
⋮----
fn verify_args_struct_by_command_run_with_rpc_bigtable_app_profile_id() {
⋮----
bigtable_app_profile_id: "my-custom-app-profile-id".to_string(),
⋮----
fn verify_args_struct_by_command_run_with_rpc_bigtable_timeout() {
⋮----
timeout: Some(Duration::from_secs(99999)),
⋮----
fn verify_args_struct_by_command_run_with_rpc_bigtable_max_message_size() {
⋮----
fn test_default_bigtable_instance_name_unchanged() {
assert_eq!(DEFAULT_BIGTABLE_INSTANCE_NAME, "solana-ledger");
⋮----
fn test_default_bigtable_app_profile_id_unchanged() {
assert_eq!(DEFAULT_BIGTABLE_APP_PROFILE_ID, "default");
⋮----
fn test_default_bigtable_timeout_unchanged() {
assert_eq!(DEFAULT_BIGTABLE_TIMEOUT, "30");
⋮----
fn test_default_bigtable_max_message_size_unchanged() {
assert_eq!(*DEFAULT_BIGTABLE_MAX_MESSAGE_SIZE, "67108864");

================
File: validator/src/commands/run/args/rpc_bootstrap_config.rs
================
LazyLock::new(|| MAX_GENESIS_ARCHIVE_UNPACKED_SIZE.to_string());
⋮----
impl Default for RpcBootstrapConfig {
fn default() -> Self {
⋮----
impl FromClapArgMatches for RpcBootstrapConfig {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
let no_genesis_fetch = matches.is_present("no_genesis_fetch");
let no_snapshot_fetch = matches.is_present("no_snapshot_fetch");
⋮----
.value_of("check_vote_account")
.map(|url| url.to_string());
let only_known_rpc = matches.is_present("only_known_rpc");
⋮----
value_t!(matches, "max_genesis_archive_unpacked_size", u64).map_err(|err| {
Box::<dyn std::error::Error>::from(format!(
⋮----
let no_incremental_snapshots = matches.is_present("no_incremental_snapshots");
Ok(Self {
⋮----
pub(crate) fn args<'a, 'b>() -> Vec<Arg<'a, 'b>> {
vec![
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_run_with_no_genesis_fetch() {
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
default_run_args.clone(),
vec!["--no-genesis-fetch"],
⋮----
fn verify_args_struct_by_command_run_with_no_snapshot_fetch() {
⋮----
vec!["--no-snapshot-fetch"],
⋮----
fn verify_args_struct_by_command_run_with_check_vote_account() {
⋮----
entrypoints: vec![SocketAddr::new(
⋮----
check_vote_account: Some("https://api.mainnet-beta.solana.com".to_string()),
⋮----
fn verify_args_struct_by_command_run_with_only_known_rpc() {
⋮----
let known_validators = Some(HashSet::from([known_validators_pubkey]));
⋮----
fn verify_args_struct_by_command_run_with_incremental_snapshot_fetch() {
⋮----
vec!["--no-incremental-snapshots"],
⋮----
fn test_default_max_genesis_archive_unpacked_size_unchanged() {
assert_eq!(

================
File: validator/src/commands/run/args/send_transaction_config.rs
================
.to_string()
⋮----
impl FromClapArgMatches for SendTransactionServiceConfig {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
let batch_send_rate_ms = value_t!(matches, "rpc_send_transaction_batch_ms", u64)?;
let retry_rate_ms = value_t!(matches, "rpc_send_transaction_retry_ms", u64)?;
⋮----
return Err(Error::Dynamic(Box::<dyn std::error::Error>::from(format!(
⋮----
let batch_size = value_t!(matches, "rpc_send_transaction_batch_size", usize)?;
⋮----
.values_of("rpc_send_transaction_tpu_peer")
.map(|values| values.map(solana_net_utils::parse_host_port).collect())
.transpose()
.map_err(|e| {
Error::Dynamic(Box::<dyn std::error::Error>::from(format!(
⋮----
value_t!(matches, "rpc_send_transaction_default_max_retries", usize).ok();
⋮----
value_t!(matches, "rpc_send_transaction_service_max_retries", usize)?;
⋮----
value_t!(matches, "rpc_send_transaction_retry_pool_max_size", usize)?;
⋮----
matches.is_present("rpc_send_transaction_also_leader");
let leader_forward_count = if tpu_peers.is_some() && !rpc_send_transaction_also_leader {
⋮----
value_t!(matches, "rpc_send_transaction_leader_forward_count", u64)?
⋮----
Ok(SendTransactionServiceConfig {
⋮----
pub(crate) fn args<'a, 'b>() -> Vec<Arg<'a, 'b>> {
vec![
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_run_with_retry_rate_ms() {
⋮----
..default_run_args.send_transaction_service_config.clone()
⋮----
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
vec!["--rpc-send-retry-ms", "99999"],
⋮----
fn verify_args_struct_by_command_run_with_batch_size() {
⋮----
vec!["--rpc-send-batch-size", "1"],
⋮----
fn verify_args_struct_by_command_run_with_batch_send_rate_ms() {
⋮----
vec!["--rpc-send-batch-ms", "1999"],
⋮----
fn verify_args_struct_by_command_run_with_default_max_retries() {
⋮----
default_max_retries: Some(9999),
⋮----
vec!["--rpc-send-default-max-retries", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_service_max_retries() {
⋮----
vec!["--rpc-send-service-max-retries", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_retry_pool_max_size() {
⋮----
vec!["--rpc-send-transaction-retry-pool-max-size", "9999"],
⋮----
fn verify_args_struct_by_command_run_with_tpu_peers() {
⋮----
tpu_peers: Some(vec![SocketAddr::from((Ipv4Addr::LOCALHOST, 8000))]),
⋮----
vec!["--rpc-send-transaction-tpu-peer", "127.0.0.1:8000"],
⋮----
tpu_peers: Some(vec![
⋮----
fn verify_args_struct_by_command_run_with_rpc_send_transaction_leader_forward_count() {
⋮----
vec!["--rpc-send-leader-count", "100"],
⋮----
fn test_default_rpc_send_transaction_batch_ms_unchanged() {
assert_eq!(*DEFAULT_RPC_SEND_TRANSACTION_BATCH_MS, "1");
⋮----
fn test_valid_range_rpc_send_transaction_batch_ms_unchanged() {
assert_eq!(VALID_RANGE_RPC_SEND_TRANSACTION_BATCH_MS, 1..=100_000);
⋮----
fn test_default_rpc_send_transaction_retry_ms_unchanged() {
assert_eq!(*DEFAULT_RPC_SEND_TRANSACTION_RETRY_MS, "2000");
⋮----
fn test_default_rpc_send_transaction_batch_size_unchanged() {
assert_eq!(*DEFAULT_RPC_SEND_TRANSACTION_BATCH_SIZE, "1");
⋮----
fn test_valid_range_rpc_send_transaction_batch_size_unchanged() {
assert_eq!(VALID_RANGE_RPC_SEND_TRANSACTION_BATCH_SIZE, 1..=10_000);
⋮----
fn test_default_rpc_send_transaction_service_max_retries_unchanged() {
assert_eq!(
⋮----
fn test_default_rpc_send_transaction_retry_pool_max_size_unchanged() {
⋮----
fn test_default_rpc_send_transaction_leader_forward_count_unchanged() {
assert_eq!(*DEFAULT_RPC_SEND_TRANSACTION_LEADER_FORWARD_COUNT, "2");

================
File: validator/src/commands/run/args.rs
================
pub mod account_secondary_indexes;
pub mod blockstore_options;
pub mod json_rpc_config;
pub mod pub_sub_config;
pub mod rpc_bigtable_config;
pub mod rpc_bootstrap_config;
pub mod send_transaction_config;
⋮----
pub struct RunArgs {
⋮----
impl FromClapArgMatches for RunArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
⋮----
keypair_of(matches, "identity").ok_or(clap::Error::with_description(
⋮----
let ledger_path = PathBuf::from(matches.value_of("ledger_path").ok_or(
⋮----
create_and_canonicalize_directory(ledger_path.as_path()).map_err(|err| {
crate::commands::Error::Dynamic(Box::<dyn std::error::Error>::from(format!(
⋮----
.value_of("logfile")
.map(String::from)
.unwrap_or_else(|| format!("agave-validator-{}.log", identity_keypair.pubkey()));
⋮----
Some(PathBuf::from(logfile))
⋮----
let mut entrypoints = values_t!(matches, "entrypoint", String).unwrap_or_default();
entrypoints.sort();
entrypoints.dedup();
⋮----
.into_iter()
.map(|entrypoint| {
solana_net_utils::parse_host_port(&entrypoint).map_err(|err| {
⋮----
let known_validators = validators_set(
&identity_keypair.pubkey(),
⋮----
let socket_addr_space = SocketAddrSpace::new(matches.is_present("allow_private_addr"));
Ok(RunArgs {
⋮----
pub fn add_args<'a>(app: App<'a, 'a>, default_args: &'a DefaultArgs) -> App<'a, 'a> {
app.arg(
⋮----
.long(SKIP_SEED_PHRASE_VALIDATION_ARG.long)
.help(SKIP_SEED_PHRASE_VALIDATION_ARG.help),
⋮----
.arg(
⋮----
.short("i")
.long("identity")
.value_name("KEYPAIR")
.takes_value(true)
.validator(is_keypair_or_ask_keyword)
.help("Validator identity keypair"),
⋮----
.long("authorized-voter")
⋮----
.requires("vote_account")
.multiple(true)
.help(
⋮----
.long("vote-account")
.value_name("ADDRESS")
⋮----
.validator(is_pubkey_or_keypair)
.requires("identity")
⋮----
.long("init-complete-file")
.value_name("FILE")
⋮----
.short("l")
.long("ledger")
.value_name("DIR")
⋮----
.required(true)
.default_value(&default_args.ledger_path)
.help("Use DIR as ledger location"),
⋮----
.short("n")
.long("entrypoint")
.value_name("HOST:PORT")
⋮----
.validator(solana_net_utils::is_host_port)
.help("Rendezvous with the cluster at this gossip entrypoint"),
⋮----
.long("no-voting")
.takes_value(false)
.help("Launch validator without voting"),
⋮----
.long("restricted-repair-only-mode")
⋮----
.long("rpc-port")
.value_name("PORT")
⋮----
.validator(port_validator)
.help("Enable JSON RPC on this port, and the next port for the RPC websocket"),
⋮----
.long("private-rpc")
⋮----
.help("Do not publish the RPC port for use by others"),
⋮----
.long("no-port-check")
⋮----
.hidden(hidden_unless_forced())
.help("Do not perform TCP/UDP reachable port checks at start-up"),
⋮----
.long("accounts")
.value_name("PATHS")
⋮----
.long("account-shrink-path")
.value_name("PATH")
⋮----
.help("Path to accounts shrink path which can hold a compacted account set."),
⋮----
.long("snapshots")
⋮----
.help("Use DIR as the base location for snapshots.")
.long_help(
⋮----
.long(use_snapshot_archives_at_startup::cli::LONG_ARG)
⋮----
.possible_values(use_snapshot_archives_at_startup::cli::POSSIBLE_VALUES)
.default_value(use_snapshot_archives_at_startup::cli::default_value())
.help(use_snapshot_archives_at_startup::cli::HELP)
.long_help(use_snapshot_archives_at_startup::cli::LONG_HELP),
⋮----
.long("full-snapshot-archive-path")
⋮----
.help("Use DIR as full snapshot archives location [default: --snapshots value]"),
⋮----
.long("incremental-snapshot-archive-path")
.conflicts_with("no-incremental-snapshots")
⋮----
.help("Use DIR as incremental snapshot archives location [default: --snapshots value]"),
⋮----
.long("tower")
⋮----
.help("Use DIR as file tower storage location [default: --ledger value]"),
⋮----
.long("gossip-port")
⋮----
.help("Gossip port number for the validator"),
⋮----
.long("public-tpu-address")
.alias("tpu-host-addr")
⋮----
.long("public-tpu-forwards-address")
⋮----
.long("public-tvu-address")
.alias("tvu-host-addr")
⋮----
.long("tpu-vortexor-receiver-address")
⋮----
.long("public-rpc-address")
⋮----
.conflicts_with("private_rpc")
⋮----
.long("dynamic-port-range")
.value_name("MIN_PORT-MAX_PORT")
⋮----
.default_value(&default_args.dynamic_port_range)
.validator(port_range_validator)
.help("Range to use for dynamically assigned ports"),
⋮----
.long("maximum-local-snapshot-age")
.value_name("NUMBER_OF_SLOTS")
⋮----
.default_value(&default_args.maximum_local_snapshot_age)
⋮----
.long("no-snapshots")
⋮----
.conflicts_with_all(&[
⋮----
.help("Disable all snapshot generation"),
⋮----
.long("snapshot-interval-slots")
.alias("incremental-snapshot-interval-slots")
.value_name("NUMBER")
⋮----
.default_value(&default_args.incremental_snapshot_archive_interval_slots)
.validator(is_non_zero)
.help("Number of slots between generating snapshots")
⋮----
.long("full-snapshot-interval-slots")
⋮----
.default_value(&default_args.full_snapshot_archive_interval_slots)
⋮----
.help("Number of slots between generating full snapshots")
⋮----
.long("maximum-full-snapshots-to-retain")
.alias("maximum-snapshots-to-retain")
⋮----
.default_value(&default_args.maximum_full_snapshot_archives_to_retain)
.validator(validate_maximum_full_snapshot_archives_to_retain)
⋮----
.long("maximum-incremental-snapshots-to-retain")
⋮----
.default_value(&default_args.maximum_incremental_snapshot_archives_to_retain)
.validator(validate_maximum_incremental_snapshot_archives_to_retain)
⋮----
.long("snapshot-packager-niceness-adjustment")
.value_name("ADJUSTMENT")
⋮----
.validator(solana_perf::thread::is_niceness_adjustment_valid)
.default_value(&default_args.snapshot_packager_niceness_adjustment)
⋮----
.long("minimal-snapshot-download-speed")
.value_name("MINIMAL_SNAPSHOT_DOWNLOAD_SPEED")
⋮----
.default_value(&default_args.min_snapshot_download_speed)
⋮----
.long("maximum-snapshot-download-abort")
.value_name("MAXIMUM_SNAPSHOT_DOWNLOAD_ABORT")
⋮----
.default_value(&default_args.max_snapshot_download_abort)
⋮----
.long("contact-debug-interval")
.value_name("CONTACT_DEBUG_INTERVAL")
⋮----
.default_value(&default_args.contact_debug_interval)
.help("Milliseconds between printing contact debug from gossip."),
⋮----
.long("no-poh-speed-test")
⋮----
.help("Skip the check for PoH speed."),
⋮----
.long("no-os-network-limits-test")
.help("Skip checks for OS network limits."),
⋮----
.long("no-os-memory-stats-reporting")
⋮----
.help("Disable reporting of OS memory statistics."),
⋮----
.long("no-os-network-stats-reporting")
⋮----
.help("Disable reporting of OS network statistics."),
⋮----
.long("no-os-cpu-stats-reporting")
⋮----
.help("Disable reporting of OS CPU statistics."),
⋮----
.long("no-os-disk-stats-reporting")
⋮----
.help("Disable reporting of OS disk statistics."),
⋮----
.long("snapshot-version")
.value_name("SNAPSHOT_VERSION")
.validator(is_parsable::<SnapshotVersion>)
⋮----
.default_value(default_args.snapshot_version.into())
.help("Output snapshot version"),
⋮----
.long("skip-startup-ledger-verification")
⋮----
.help("Skip ledger verification at validator bootup."),
⋮----
.long("require-tower")
⋮----
.help("Refuse to start if saved tower state is not found"),
⋮----
.long("expected-genesis-hash")
.value_name("HASH")
⋮----
.validator(hash_validator)
.help("Require the genesis have this hash"),
⋮----
.long("expected-bank-hash")
⋮----
.help("When wait-for-supermajority <x>, require the bank at <x> to have this hash"),
⋮----
.long("expected-shred-version")
.value_name("VERSION")
⋮----
.validator(is_parsable::<u16>)
.help("Require the shred version be this value"),
⋮----
.short("o")
.long("log")
⋮----
.long("wait-for-supermajority")
.requires("expected_bank_hash")
.requires("expected_shred_version")
.value_name("SLOT")
.validator(is_slot)
⋮----
.long("no-wait-for-vote-to-start-leader")
⋮----
.long("hard-fork")
⋮----
.help("Add a hard fork at this slot"),
⋮----
.alias("trusted-validator")
.long("known-validator")
.validator(is_pubkey)
.value_name("VALIDATOR IDENTITY")
⋮----
.long("debug-key")
⋮----
.help("Log when transactions are processed which reference a given key."),
⋮----
.long("repair-validator")
⋮----
.long("repair-whitelist")
⋮----
.long("gossip-validator")
⋮----
.long("tpu-connection-pool-size")
⋮----
.default_value(&default_args.tpu_connection_pool_size)
.validator(is_parsable::<usize>)
.help("Controls the TPU connection pool size per remote address"),
⋮----
.long("tpu-max-connections-per-ipaddr-per-minute")
⋮----
.default_value(&default_args.tpu_max_connections_per_ipaddr_per_minute)
.validator(is_parsable::<u32>)
⋮----
.help("Controls the rate of the clients connections per IpAddr per minute."),
⋮----
.long("vote-use-quic")
⋮----
.default_value(&default_args.vote_use_quic)
⋮----
.help("Controls if to use QUIC to send votes."),
⋮----
.long("tpu-max-connections-per-peer")
⋮----
.long("tpu-max-connections-per-unstaked-peer")
⋮----
.default_value(&default_args.tpu_max_connections_per_unstaked_peer)
⋮----
.help("Controls the max concurrent connections per IpAddr for unstaked clients."),
⋮----
.long("tpu-max-connections-per-staked-peer")
⋮----
.default_value(&default_args.tpu_max_connections_per_staked_peer)
⋮----
.help("Controls the max concurrent connections per staked identity."),
⋮----
.long("tpu-max-staked-connections")
⋮----
.default_value(&default_args.tpu_max_staked_connections)
⋮----
.help("Controls the max concurrent connections for TPU from staked nodes."),
⋮----
.long("tpu-max-unstaked-connections")
⋮----
.default_value(&default_args.tpu_max_unstaked_connections)
⋮----
.help("Controls the max concurrent connections fort TPU from unstaked nodes."),
⋮----
.long("tpu-max-fwd-staked-connections")
⋮----
.default_value(&default_args.tpu_max_fwd_staked_connections)
⋮----
.help("Controls the max concurrent connections for TPU-forward from staked nodes."),
⋮----
.long("tpu-max-fwd-unstaked-connections")
⋮----
.default_value(&default_args.tpu_max_fwd_unstaked_connections)
⋮----
.help("Controls the max concurrent connections for TPU-forward from unstaked nodes."),
⋮----
.long("tpu-max-streams-per-ms")
⋮----
.default_value(&default_args.tpu_max_streams_per_ms)
⋮----
.help("Controls the max number of streams for a TPU service."),
⋮----
.long("num-quic-endpoints")
⋮----
.default_value(&default_args.num_quic_endpoints)
⋮----
.long("staked-nodes-overrides")
⋮----
.long("bind-address")
.value_name("HOST")
⋮----
.validator(solana_net_utils::is_host)
.default_value(&default_args.bind_address)
⋮----
.long("rpc-bind-address")
⋮----
.long("geyser-plugin-config")
.alias("accountsdb-plugin-config")
⋮----
.help("Specify the configuration file for the Geyser plugin."),
⋮----
.long("geyser-plugin-always-enabled")
.value_name("BOOLEAN")
⋮----
.help("Еnable Geyser interface even if no Geyser configs are specified."),
⋮----
.long("snapshot-archive-format")
.alias("snapshot-compression")
.possible_values(SUPPORTED_ARCHIVE_COMPRESSION)
.default_value(&default_args.snapshot_archive_format)
.value_name("ARCHIVE_TYPE")
⋮----
.help("Snapshot archive format to use."),
⋮----
.long("snapshot-zstd-compression-level")
.default_value(&default_args.snapshot_zstd_compression_level)
.value_name("LEVEL")
⋮----
.help("The compression level to use when archiving with zstd")
⋮----
.long("experimental-poh-pinned-cpu-core")
⋮----
.value_name("CPU_CORE_INDEX")
.validator(|s| {
let core_index = usize::from_str(&s).map_err(|e| e.to_string())?;
⋮----
.map(|cids| cids.len() - 1)
.unwrap_or(0);
⋮----
return Err(format!("core index must be in the range [0, {max_index}]"));
⋮----
Ok(())
⋮----
.help("EXPERIMENTAL: Specify which CPU core PoH is pinned to"),
⋮----
.long("poh-hashes-per-batch")
⋮----
.value_name("NUM")
.help("Specify hashes per batch in PoH service"),
⋮----
.long("process-ledger-before-services")
⋮----
.help("Process the local ledger fully before starting networking services"),
⋮----
.long("account-index")
⋮----
.possible_values(&["program-id", "spl-token-owner", "spl-token-mint"])
.value_name("INDEX")
.help("Enable an accounts index, indexed by the selected account field"),
⋮----
.long(EXCLUDE_KEY)
⋮----
.value_name("KEY")
.help("When account indexes are enabled, exclude this key from the index."),
⋮----
.long(INCLUDE_KEY)
⋮----
.conflicts_with("account_index_exclude_key")
⋮----
.long("accounts-db-verify-refcounts")
⋮----
.hidden(hidden_unless_forced()),
⋮----
.long("accounts-db-scan-filter-for-shrinking")
⋮----
.possible_values(&["all", "only-abnormal", "only-abnormal-with-verify"])
⋮----
.long("no-skip-initial-accounts-db-clean")
.help("Do not skip the initial cleaning of accounts when verifying snapshot bank")
⋮----
.long("accounts-db-access-storages-method")
.value_name("METHOD")
⋮----
.possible_values(&["mmap", "file"])
.help("Access account storages using this method"),
⋮----
.long("accounts-db-ancient-append-vecs")
.value_name("SLOT-OFFSET")
.validator(is_parsable::<i64>)
⋮----
.long("accounts-db-ancient-storage-ideal-size")
.value_name("BYTES")
.validator(is_parsable::<u64>)
⋮----
.help("The smallest size of ideal ancient storage.")
⋮----
.long("accounts-db-max-ancient-storages")
.value_name("USIZE")
⋮----
.help("The number of ancient storages the ancient slot combining should converge to.")
⋮----
.long("accounts-db-cache-limit-mb")
.value_name("MEGABYTES")
⋮----
.long("accounts-db-read-cache-limit")
.value_name("LOW,HIGH")
⋮----
.min_values(2)
.max_values(2)
.multiple(false)
.require_delimiter(true)
.help("How large the read cache for account data can become, in bytes")
⋮----
.long("accounts-db-mark-obsolete-accounts")
.help("Controls obsolete account tracking")
⋮----
.possible_values(&["enabled", "disabled"])
⋮----
.long("accounts-index-scan-results-limit-mb")
⋮----
.long("accounts-index-bins")
.value_name("BINS")
.validator(is_pow2)
⋮----
.help("Number of bins to divide the accounts index into"),
⋮----
.long("accounts-index-initial-accounts-count")
⋮----
.help("Pre-allocate the accounts index, assuming this many accounts")
⋮----
.long("accounts-index-path")
⋮----
.requires("enable_accounts_disk_index")
⋮----
.long("enable-accounts-disk-index")
.help("Enables the disk-based accounts index")
⋮----
.long("accounts-shrink-optimize-total-space")
⋮----
.default_value(&default_args.accounts_shrink_optimize_total_space)
⋮----
.long("accounts-shrink-ratio")
⋮----
.value_name("RATIO")
.default_value(&default_args.accounts_shrink_ratio)
⋮----
.long("allow-private-addr")
⋮----
.help("Allow contacting private ip addresses")
⋮----
.long("log-messages-bytes-limit")
⋮----
.help("Maximum number of bytes written to the program log before truncation"),
⋮----
.long("enable-banking-trace")
⋮----
.validator(is_parsable::<DirByteLimit>)
⋮----
.default_value(&default_args.banking_trace_dir_byte_limit)
⋮----
.long("disable-banking-trace")
.conflicts_with("banking_trace_dir_byte_limit")
⋮----
.help("Disables the banking trace"),
⋮----
.long("delay-leader-block-for-pending-fork")
⋮----
.long("block-verification-method")
⋮----
.possible_values(BlockVerificationMethod::cli_names())
.default_value(BlockVerificationMethod::default().into())
.help(BlockVerificationMethod::cli_message()),
⋮----
.long("block-production-method")
⋮----
.possible_values(BlockProductionMethod::cli_names())
.default_value(BlockProductionMethod::default().into())
.help(BlockProductionMethod::cli_message()),
⋮----
.long("block-production-pacing-fill-time-millis")
.value_name("MILLIS")
⋮----
.default_value(&default_args.block_production_pacing_fill_time_millis)
⋮----
.long("enable-scheduler-bindings")
⋮----
.help("Enables external processes to connect and manage block production"),
⋮----
.long("unified-scheduler-handler-threads")
.value_name("COUNT")
⋮----
.validator(|s| is_within_range(s, 1..))
.help(DefaultSchedulerPool::cli_message()),
⋮----
.long("wen-restart")
⋮----
.required(false)
.conflicts_with("wait_for_supermajority")
.requires("wen_restart_coordinator")
.help(WEN_RESTART_HELP),
⋮----
.long("wen-restart-coordinator")
⋮----
.value_name("PUBKEY")
⋮----
.requires("wen_restart")
⋮----
.arg(bam::argument())
⋮----
.long("block-engine-url")
⋮----
.takes_value(true),
⋮----
.long("relayer-url")
.help("Relayer url. Set to empty string to disable relayer connection.")
⋮----
.long("relayer-expected-heartbeat-interval-ms")
⋮----
.help("Interval at which the Relayer is expected to send heartbeat messages.")
.default_value(&default_args.relayer_expected_heartbeat_interval_ms),
⋮----
.long("relayer-max-failed-heartbeats")
⋮----
.default_value(&default_args.relayer_max_failed_heartbeats),
⋮----
.long("trust-block-engine-packets")
⋮----
.long("tip-payment-program-pubkey")
.value_name("TIP_PAYMENT_PROGRAM_PUBKEY")
⋮----
.help("The public key of the tip-payment program"),
⋮----
.long("tip-distribution-program-pubkey")
.value_name("TIP_DISTRIBUTION_PROGRAM_PUBKEY")
⋮----
.help("The public key of the tip-distribution program."),
⋮----
.long("merkle-root-upload-authority")
.value_name("MERKLE_ROOT_UPLOAD_AUTHORITY")
⋮----
.help("The public key of the authorized merkle-root uploader."),
⋮----
.long("commission-bps")
.value_name("COMMISSION_BPS")
⋮----
.help("The commission validator takes from tips expressed in basis points."),
⋮----
.long("disable-block-engine-autoconfig")
.value_name("DISABLE_BLOCK_ENGINE_AUTOCONFIG")
⋮----
.long("shred-receiver-address")
.value_name("SHRED_RECEIVER_ADDRESS")
⋮----
.long("shred-retransmit-receiver-address")
.value_name("SHRED_RETRANSMIT_RECEIVER_ADDRESS")
⋮----
.long("experimental-retransmit-xdp-interface")
⋮----
.value_name("INTERFACE")
.requires("retransmit_xdp_cpu_cores")
.help("EXPERIMENTAL: The network interface to use for XDP retransmit"),
⋮----
.long("experimental-retransmit-xdp-cpu-cores")
⋮----
.value_name("CPU_LIST")
.validator(|value| {
validate_cpu_ranges(value, "--experimental-retransmit-xdp-cpu-cores")
⋮----
.help("EXPERIMENTAL: Enable XDP retransmit on the specified CPU cores"),
⋮----
.long("experimental-retransmit-xdp-zero-copy")
⋮----
.help("EXPERIMENTAL: Enable XDP zero copy. Requires hardware support"),
⋮----
.args(&pub_sub_config::args( false))
.args(&json_rpc_config::args())
.args(&rpc_bigtable_config::args())
.args(&send_transaction_config::args())
.args(&rpc_bootstrap_config::args())
.args(&blockstore_options::args())
⋮----
fn validators_set(
⋮----
if matches.is_present(matches_name) {
let validators_set: Option<HashSet<Pubkey>> = values_t!(matches, matches_name, Pubkey)
.ok()
.map(|validators| validators.into_iter().collect());
⋮----
if validators_set.contains(identity_pubkey) {
return Err(crate::commands::Error::Dynamic(
Box::<dyn std::error::Error>::from(format!(
⋮----
Ok(validators_set)
⋮----
Ok(None)
⋮----
mod tests {
⋮----
impl Default for RunArgs {
fn default() -> Self {
⋮----
let ledger_path = absolute(PathBuf::from("ledger")).unwrap();
⋮----
PathBuf::from(format!("agave-validator-{}.log", identity_keypair.pubkey()));
let entrypoints = vec![];
⋮----
logfile: Some(logfile),
⋮----
impl Clone for RunArgs {
fn clone(&self) -> Self {
⋮----
identity_keypair: self.identity_keypair.insecure_clone(),
logfile: self.logfile.clone(),
entrypoints: self.entrypoints.clone(),
known_validators: self.known_validators.clone(),
⋮----
ledger_path: self.ledger_path.clone(),
rpc_bootstrap_config: self.rpc_bootstrap_config.clone(),
blockstore_options: self.blockstore_options.clone(),
json_rpc_config: self.json_rpc_config.clone(),
pub_sub_config: self.pub_sub_config.clone(),
send_transaction_service_config: self.send_transaction_service_config.clone(),
⋮----
fn verify_args_struct_by_command(
⋮----
let app = add_args(App::new("run_command"), default_args)
.args(&thread_args(&default_args.thread_args));
⋮----
[&["run_command"], &args[..]].concat(),
⋮----
fn verify_args_struct_by_command_run_with_identity() {
⋮----
let tmp_dir = tempfile::tempdir().unwrap();
let file = tmp_dir.path().join("id.json");
let keypair = default_run_args.identity_keypair.insecure_clone();
solana_keypair::write_keypair_file(&keypair, &file).unwrap();
⋮----
identity_keypair: keypair.insecure_clone(),
⋮----
verify_args_struct_by_command(
⋮----
vec!["-i", file.to_str().unwrap()],
expected_args.clone(),
⋮----
vec!["--identity", file.to_str().unwrap()],
⋮----
pub fn verify_args_struct_by_command_run_with_identity_setup(
⋮----
let args = [&["--identity", file.to_str().unwrap()], &args[..]].concat();
verify_args_struct_by_command(&default_args, args, expected_args);
⋮----
pub fn verify_args_struct_by_command_run_is_error_with_identity_setup(
⋮----
let app = add_args(App::new("run_command"), &default_args)
⋮----
&["--identity", file.to_str().unwrap()][..],
⋮----
.concat(),
⋮----
fn verify_args_struct_by_command_run_with_ledger_path() {
⋮----
let tmp_dir = fs::canonicalize(tempfile::tempdir().unwrap()).unwrap();
let ledger_path = tmp_dir.join("nonexistent_ledger_path");
assert!(!fs::exists(&ledger_path).unwrap());
⋮----
ledger_path: ledger_path.clone(),
..default_run_args.clone()
⋮----
verify_args_struct_by_command_run_with_identity_setup(
⋮----
vec!["--ledger", ledger_path.to_str().unwrap()],
⋮----
assert!(fs::exists(&ledger_path).unwrap());
⋮----
let ledger_path = tmp_dir.path().join("existing_ledger_path");
fs::create_dir_all(&ledger_path).unwrap();
let ledger_path = fs::canonicalize(ledger_path).unwrap();
assert!(fs::exists(ledger_path.as_path()).unwrap());
⋮----
defer! {
⋮----
ledger_path: absolute(&ledger_path).unwrap(),
⋮----
fn verify_args_struct_by_command_run_with_log() {
⋮----
logfile: Some(PathBuf::from(format!(
⋮----
default_run_args.clone(),
vec![],
⋮----
vec!["-o", "-"],
⋮----
logfile: Some(PathBuf::from("custom_log.log")),
⋮----
vec!["--log", "custom_log.log"],
⋮----
fn verify_args_struct_by_command_run_with_entrypoints() {
⋮----
entrypoints: vec![SocketAddr::new(
⋮----
vec!["-n", "127.0.0.1:8000"],
⋮----
vec!["--entrypoint", "127.0.0.1:8000"],
⋮----
entrypoints: vec![
⋮----
vec![
⋮----
fn verify_args_struct_by_command_run_with_known_validators() {
⋮----
let known_validators = Some(HashSet::from([known_validators_pubkey]));
⋮----
vec!["--known-validator", &known_validators_pubkey.to_string()],
⋮----
vec!["--trusted-validator", &known_validators_pubkey.to_string()],
⋮----
let known_validators = Some(HashSet::from([
⋮----
solana_keypair::write_keypair_file(&default_run_args.identity_keypair, &file).unwrap();
let matches = add_args(App::new("run_command"), &default_args).get_matches_from(vec![
⋮----
assert!(result.is_err());
let error = result.unwrap_err();
assert_eq!(
⋮----
fn verify_args_struct_by_command_run_with_max_genesis_archive_unpacked_size() {
⋮----
fn verify_args_struct_by_command_run_with_allow_private_addr() {
⋮----
vec!["--allow-private-addr"],

================
File: validator/src/commands/run/execute.rs
================
pub enum Operation {
⋮----
pub fn execute(
⋮----
if let Some(logfile) = logfile.as_ref() {
println!("log file: {}", logfile.display());
⋮----
let use_progress_bar = logfile.is_none();
agave_logger::initialize_logging(logfile.clone());
info!("{} {}", crate_name!(), solana_version);
info!("Starting validator with: {:#?}", std::env::args_os());
⋮----
let authorized_voter_keypairs = keypairs_of(matches, "authorized_voter_keypairs")
.map(|keypairs| keypairs.into_iter().map(Arc::new).collect())
.unwrap_or_else(|| vec![Arc::new(keypair_of(matches, "identity").expect("identity"))]);
⋮----
.value_of("staked_nodes_overrides")
.map(str::to_string);
⋮----
Some(p) => load_staked_nodes_overrides(p).unwrap_or_else(|err| {
error!("Failed to load stake-nodes-overrides from {p}: {err}");
⋮----
.exit()
⋮----
let init_complete_file = matches.value_of("init_complete_file");
let private_rpc = matches.is_present("private_rpc");
let do_port_check = !matches.is_present("no_port_check");
⋮----
let max_ledger_shreds = if matches.is_present("limit_ledger_size") {
let limit_ledger_size = match matches.value_of("limit_ledger_size") {
Some(_) => value_t_or_exit!(matches, "limit_ledger_size", u64),
⋮----
Err(format!(
⋮----
Some(limit_ledger_size)
⋮----
let debug_keys: Option<Arc<HashSet<_>>> = if matches.is_present("debug_key") {
Some(Arc::new(
values_t_or_exit!(matches, "debug_key", Pubkey)
.into_iter()
.collect(),
⋮----
let repair_validators = validators_set(
&identity_keypair.pubkey(),
⋮----
let repair_whitelist = validators_set(
⋮----
let repair_whitelist = Arc::new(RwLock::new(repair_whitelist.unwrap_or_default()));
let gossip_validators = validators_set(
⋮----
.values_of("bind_address")
.expect("bind_address should always be present due to default")
.map(solana_net_utils::parse_host)
⋮----
BindIpAddrs::new(parsed).map_err(|err| format!("invalid bind_addresses: {err}"))?
⋮----
if bind_addresses.len() > 1 {
⋮----
if matches.is_present(flag) {
Err(String::from(msg))?;
⋮----
let rpc_bind_address = if matches.is_present("rpc_bind_address") {
solana_net_utils::parse_host(matches.value_of("rpc_bind_address").unwrap())
.expect("invalid rpc_bind_address")
⋮----
solana_net_utils::parse_host("127.0.0.1").unwrap()
⋮----
bind_addresses.active()
⋮----
let contact_debug_interval = value_t_or_exit!(matches, "contact_debug_interval", u64);
⋮----
let restricted_repair_only_mode = matches.is_present("restricted_repair_only_mode");
⋮----
value_t_or_exit!(matches, "accounts_shrink_optimize_total_space", bool);
let vote_use_quic = value_t_or_exit!(matches, "vote_use_quic", bool);
let tpu_enable_udp = if matches.is_present("tpu_enable_udp") {
warn!("Submission of TPU transactions via UDP is deprecated.");
⋮----
let tpu_connection_pool_size = value_t_or_exit!(matches, "tpu_connection_pool_size", usize);
let shrink_ratio = value_t_or_exit!(matches, "accounts_shrink_ratio", f64);
if !(0.0..=1.0).contains(&shrink_ratio) {
⋮----
if !run_args.socket_addr_space.check(addr) {
Err(format!("invalid entrypoint address: {addr}"))?;
⋮----
let expected_shred_version = value_t!(matches, "expected_shred_version", u16)
.ok()
.or_else(|| get_cluster_shred_version(&entrypoint_addrs, bind_addresses.active()));
let tower_path = value_t!(matches, "tower", PathBuf)
⋮----
.unwrap_or_else(|| ledger_path.clone());
⋮----
num_flush_threads: Some(accounts_index_flush_threads),
⋮----
if let Ok(bins) = value_t!(matches, "accounts_index_bins", usize) {
accounts_index_config.bins = Some(bins);
⋮----
value_t!(matches, "accounts_index_initial_accounts_count", usize)
⋮----
accounts_index_config.num_initial_accounts = Some(num_initial_accounts);
⋮----
accounts_index_config.index_limit = if !matches.is_present("enable_accounts_disk_index") {
⋮----
let mut accounts_index_paths: Vec<PathBuf> = if matches.is_present("accounts_index_path") {
values_t_or_exit!(matches, "accounts_index_path", String)
⋮----
.map(PathBuf::from)
.collect()
⋮----
vec![]
⋮----
if accounts_index_paths.is_empty() {
accounts_index_paths = vec![ledger_path.join("accounts_index")];
⋮----
accounts_index_config.drives = Some(accounts_index_paths);
⋮----
value_t!(matches, "accounts_index_scan_results_limit_mb", usize)
⋮----
.map(|mb| mb * MB);
⋮----
values_t!(matches, "account_shrink_path", String)
.map(|shrink_paths| shrink_paths.into_iter().map(PathBuf::from).collect())
.ok();
⋮----
.as_ref()
.map(|paths| {
create_and_canonicalize_directories(paths)
.map_err(|err| format!("unable to access account shrink path: {err}"))
⋮----
.transpose()?;
⋮----
create_all_accounts_run_and_snapshot_dirs(&paths)
.map_err(|err| format!("unable to create account subdirectories: {err}"))
⋮----
.transpose()?
.unzip();
⋮----
values_of::<usize>(matches, "accounts_db_read_cache_limit").map(|limits| {
match limits.len() {
⋮----
unreachable!("invalid number of values given to accounts-db-read-cache-limit")
⋮----
.value_of("accounts_db_access_storages_method")
.map(|method| match method {
⋮----
warn!("Using `mmap` for `--accounts-db-access-storages-method` is now deprecated.");
⋮----
unreachable!("invalid value given to accounts-db-access-storages-method")
⋮----
.unwrap_or_default();
⋮----
.value_of("accounts_db_scan_filter_for_shrinking")
.map(|filter| match filter {
⋮----
unreachable!("invalid value given to accounts_db_scan_filter_for_shrinking")
⋮----
.value_of("accounts_db_mark_obsolete_accounts")
.map(|mark_obsolete_accounts| {
⋮----
unreachable!("invalid value given to accounts_db_mark_obsolete_accounts")
⋮----
index: Some(accounts_index_config),
account_indexes: Some(account_indexes.clone()),
base_working_path: Some(ledger_path.clone()),
⋮----
write_cache_limit_bytes: value_t!(matches, "accounts_db_cache_limit_mb", u64)
⋮----
.map(|mb| mb * MB as u64),
ancient_append_vec_offset: value_t!(matches, "accounts_db_ancient_append_vecs", i64).ok(),
ancient_storage_ideal_size: value_t!(
⋮----
.ok(),
max_ancient_storages: value_t!(matches, "accounts_db_max_ancient_storages", usize).ok(),
exhaustively_verify_refcounts: matches.is_present("accounts_db_verify_refcounts"),
⋮----
num_background_threads: Some(accounts_db_background_threads),
num_foreground_threads: Some(accounts_db_foreground_threads),
⋮----
let on_start_geyser_plugin_config_files = if matches.is_present("geyser_plugin_config") {
Some(
values_t_or_exit!(matches, "geyser_plugin_config", String)
⋮----
let starting_with_geyser_plugins: bool = on_start_geyser_plugin_config_files.is_some()
|| matches.is_present("geyser_plugin_always_enabled");
let xdp_interface = matches.value_of("retransmit_xdp_interface");
let xdp_zero_copy = matches.is_present("retransmit_xdp_zero_copy");
let retransmit_xdp = matches.value_of("retransmit_xdp_cpu_cores").map(|cpus| {
⋮----
parse_cpu_ranges(cpus).unwrap(),
⋮----
if let Ok(account_paths) = values_t!(matches, "account_paths", String) {
⋮----
.join(",")
.split(',')
⋮----
vec![ledger_path.join("accounts")]
⋮----
let account_paths = create_and_canonicalize_directories(account_paths)
.map_err(|err| format!("unable to access account path: {err}"))?;
⋮----
create_all_accounts_run_and_snapshot_dirs(&account_paths)
.map_err(|err| format!("unable to create account directories: {err}"))?;
⋮----
.chain(account_shrink_snapshot_paths)
⋮----
let snapshot_config = new_snapshot_config(
⋮----
let use_snapshot_archives_at_startup = value_t_or_exit!(
⋮----
let voting_disabled = matches.is_present("no_voting") || restricted_repair_only_mode;
let tip_manager_config = tip_manager_config_from_matches(matches, voting_disabled);
⋮----
block_engine_url: if matches.is_present("block_engine_url") {
value_of(matches, "block_engine_url").expect("couldn't parse block_engine_url")
⋮----
disable_block_engine_autoconfig: matches.is_present("disable_block_engine_autoconfig"),
trust_packets: matches.is_present("trust_block_engine_packets"),
⋮----
value_of(matches, "relayer_expected_heartbeat_interval_ms").unwrap();
assert!(
⋮----
let max_failed_heartbeats: u64 = value_of(matches, "relayer_max_failed_heartbeats").unwrap();
⋮----
relayer_url: if matches.is_present("relayer_url") {
value_of(matches, "relayer_url").expect("couldn't parse relayer_url")
⋮----
"".to_string()
⋮----
.value_of("shred_receiver_address")
.map(|addr| SocketAddr::from_str(addr).expect("shred_receiver_address invalid")),
⋮----
.value_of("shred_retransmit_receiver_address")
.map(|addr| {
SocketAddr::from_str(addr).expect("shred_retransmit_receiver_address invalid")
⋮----
require_tower: matches.is_present("require_tower"),
⋮----
halt_at_slot: value_t!(matches, "dev_halt_at_slot", Slot).ok(),
⋮----
.value_of("expected_genesis_hash")
.map(|s| Hash::from_str(s).unwrap()),
⋮----
.value_of("expected_bank_hash")
⋮----
new_hard_forks: hardforks_of(matches, "hard_forks"),
⋮----
geyser_plugin_always_enabled: matches.is_present("geyser_plugin_always_enabled"),
rpc_addrs: value_t!(matches, "rpc_port", u16).ok().map(|rpc_port| {
⋮----
voting_disabled: matches.is_present("no_voting") || restricted_repair_only_mode,
wait_for_supermajority: value_t!(matches, "wait_for_supermajority", Slot).ok(),
⋮----
run_verification: !matches.is_present("skip_startup_ledger_verification"),
⋮----
no_poh_speed_test: matches.is_present("no_poh_speed_test"),
no_os_memory_stats_reporting: matches.is_present("no_os_memory_stats_reporting"),
no_os_network_stats_reporting: matches.is_present("no_os_network_stats_reporting"),
no_os_cpu_stats_reporting: matches.is_present("no_os_cpu_stats_reporting"),
no_os_disk_stats_reporting: matches.is_present("no_os_disk_stats_reporting"),
⋮----
poh_pinned_cpu_core: value_of(matches, "poh_pinned_cpu_core")
.unwrap_or(poh_service::DEFAULT_PINNED_CPU_CORE),
poh_hashes_per_batch: value_of(matches, "poh_hashes_per_batch")
.unwrap_or(poh_service::DEFAULT_HASHES_PER_BATCH),
process_ledger_before_services: matches.is_present("process_ledger_before_services"),
⋮----
accounts_db_force_initial_clean: matches.is_present("no_skip_initial_accounts_db_clean"),
⋮----
no_wait_for_vote_to_start_leader: matches.is_present("no_wait_for_vote_to_start_leader"),
⋮----
log_messages_bytes_limit: value_of(matches, "log_messages_bytes_limit"),
⋮----
staked_nodes_overrides: staked_nodes_overrides.clone(),
⋮----
.is_present("delay_leader_block_for_pending_fork"),
wen_restart_proto_path: value_t!(matches, "wen_restart", PathBuf).ok(),
wen_restart_coordinator: value_t!(matches, "wen_restart_coordinator", Pubkey).ok(),
⋮----
block_verification_method: value_t_or_exit!(
⋮----
unified_scheduler_handler_threads: value_t!(
⋮----
block_production_method: value_t_or_exit!(
⋮----
scheduler_pacing: value_t_or_exit!(
⋮----
enable_block_production_forwarding: staked_nodes_overrides_path.is_some(),
enable_scheduler_bindings: matches.is_present("enable_scheduler_bindings"),
banking_trace_dir_byte_limit: parse_banking_trace_dir_byte_limit(matches),
⋮----
SnapshotPackagerService::NAME.to_string(),
⋮----
.into(),
⋮----
.map(|xdp| xdp.cpus.clone())
.unwrap_or_default()
.iter()
.cloned()
⋮----
if !reserved.is_empty() {
⋮----
.map(|core_id| core_id.id)
⋮----
let available = available.difference(&reserved);
set_cpu_affinity(available.into_iter().copied()).unwrap();
⋮----
let vote_account = pubkey_of(matches, "vote_account").unwrap_or_else(|| {
⋮----
warn!("--vote-account not specified, validator will not vote");
⋮----
Keypair::new().pubkey()
⋮----
solana_net_utils::parse_port_range(matches.value_of("dynamic_port_range").unwrap())
.expect("invalid dynamic_port_range");
let maximum_local_snapshot_age = value_t_or_exit!(matches, "maximum_local_snapshot_age", u64);
⋮----
value_t_or_exit!(matches, "minimal_snapshot_download_speed", f32);
⋮----
value_t_or_exit!(matches, "maximum_snapshot_download_abort", u64);
⋮----
warn!(
⋮----
.value_of("public_rpc_addr")
⋮----
.map_err(|err| format!("failed to parse public rpc address: {err}"))
⋮----
if !matches.is_present("no_os_network_limits_test") {
⋮----
info!("OS network limits test passed.");
⋮----
Err("OS network limit test failed. See \
⋮----
.to_string())?;
⋮----
let mut ledger_lock = ledger_lockfile(&ledger_path);
let _ledger_write_guard = lock_ledger(&ledger_path, &mut ledger_lock);
⋮----
let (sender, receiver) = unbounded();
(Some(sender), Some(receiver))
⋮----
rpc_addr: validator_config.rpc_addrs.map(|(rpc_addr, _)| rpc_addr),
⋮----
validator_exit: validator_config.validator_exit.clone(),
validator_exit_backpressure: validator_config.validator_exit_backpressure.clone(),
start_progress: start_progress.clone(),
authorized_voter_keypairs: authorized_voter_keypairs.clone(),
post_init: admin_service_post_init.clone(),
tower_storage: validator_config.tower_storage.clone(),
⋮----
bam_url: validator_config.bam_url.clone(),
⋮----
.value_of("advertised_ip")
.map(|advertised_ip| {
⋮----
.map_err(|err| format!("failed to parse --advertised-ip: {err}"))
⋮----
} else if !bind_addresses.active().is_unspecified() && !bind_addresses.active().is_loopback() {
⋮----
} else if !entrypoint_addrs.is_empty() {
let mut order: Vec<_> = (0..entrypoint_addrs.len()).collect();
order.shuffle(&mut rng());
⋮----
.find_map(|i| {
⋮----
info!(
⋮----
bind_addresses.active(),
⋮----
.map_or_else(
⋮----
warn!("Failed to contact cluster entrypoint {entrypoint_addr}: {err}");
⋮----
.ok_or_else(|| "unable to determine the validator's public IP address".to_string())?
⋮----
let gossip_port = value_t!(matches, "gossip_port", u16).or_else(|_| {
solana_net_utils::find_available_port_in_range(bind_addresses.active(), (0, 1))
.map_err(|err| format!("unable to find an available gossip port: {err}"))
⋮----
.value_of("public_tpu_addr")
.map(|public_tpu_addr| {
⋮----
.map_err(|err| format!("failed to parse --public-tpu-address: {err}"))
⋮----
.value_of("public_tpu_forwards_addr")
.map(|public_tpu_forwards_addr| {
⋮----
.map_err(|err| format!("failed to parse --public-tpu-forwards-address: {err}"))
⋮----
.value_of("public_tvu_addr")
.map(|public_tvu_addr| {
⋮----
.map_err(|err| format!("failed to parse --public-tvu-address: {err}"))
⋮----
if bind_addresses.len() > 1 && public_tvu_addr.is_some() {
Err(String::from(
⋮----
.value_of("tpu_vortexor_receiver_address")
.map(|tpu_vortexor_receiver_address| {
solana_net_utils::parse_host_port(tpu_vortexor_receiver_address).unwrap_or_else(
⋮----
eprintln!("Failed to parse --tpu-vortexor-receiver-address: {err}");
exit(1);
⋮----
info!("tpu_vortexor_receiver_address is {tpu_vortexor_receiver_address:?}");
let num_quic_endpoints = value_t_or_exit!(matches, "num_quic_endpoints", NonZeroUsize);
⋮----
.value_of("tpu_max_connections_per_peer")
.and_then(|v| v.parse().ok());
⋮----
.unwrap_or_else(|| value_t_or_exit!(matches, "tpu_max_connections_per_unstaked_peer", u64));
⋮----
.unwrap_or_else(|| value_t_or_exit!(matches, "tpu_max_connections_per_staked_peer", u64));
let tpu_max_staked_connections = value_t_or_exit!(matches, "tpu_max_staked_connections", u64);
⋮----
value_t_or_exit!(matches, "tpu_max_unstaked_connections", u64);
⋮----
value_t_or_exit!(matches, "tpu_max_fwd_staked_connections", u64);
⋮----
value_t_or_exit!(matches, "tpu_max_fwd_unstaked_connections", u64);
⋮----
value_t_or_exit!(matches, "tpu_max_connections_per_ipaddr_per_minute", u64);
let max_streams_per_ms = value_t_or_exit!(matches, "tpu_max_streams_per_ms", u64);
⋮----
.map(ContactInfo::new_gossip_entry_point)
⋮----
let mut node = Node::new_with_external_ip(&identity_keypair.pubkey(), node_config);
⋮----
if validator_config.wen_restart_proto_path.is_some() {
Err("--restricted-repair-only-mode is not compatible with --wen_restart".to_string())?;
⋮----
node.info.remove_tpu();
node.info.remove_tpu_forwards();
node.info.remove_tvu();
node.info.remove_serve_repair();
node.info.remove_alpenglow();
⋮----
macro_rules! set_socket {
⋮----
set_socket!(set_rpc, public_rpc_addr, "RPC");
set_socket!(set_rpc_pubsub, public_rpc_addr, "RPC-pubsub");
⋮----
.gossip()
.expect("Operator must spin up node with valid gossip address")
.ip();
set_socket!(set_rpc, (addr, rpc_addr.port()), "RPC");
set_socket!(set_rpc_pubsub, (addr, rpc_pubsub_addr.port()), "RPC-pubsub");
⋮----
solana_metrics::set_host_id(identity_keypair.pubkey().to_string());
solana_metrics::set_panic_hook("validator", Some(String::from(solana_version)));
⋮----
if !cluster_entrypoints.is_empty() {
⋮----
authorized_voter_keypairs.clone(),
⋮----
*start_progress.write().unwrap() = ValidatorStartProgress::Initializing;
⋮----
info!("Validator ledger initialization complete");
return Ok(());
⋮----
node.info.hot_swap_pubkey(identity_keypair.pubkey());
⋮----
.try_into()
.unwrap(),
⋮----
max_staked_connections: tpu_max_staked_connections.try_into().unwrap(),
max_unstaked_connections: tpu_max_unstaked_connections.try_into().unwrap(),
⋮----
max_staked_connections: tpu_max_fwd_staked_connections.try_into().unwrap(),
max_unstaked_connections: tpu_max_fwd_unstaked_connections.try_into().unwrap(),
⋮----
Ok(validator) => Ok(validator),
⋮----
if matches!(
⋮----
error!(
⋮----
exit(200);
⋮----
Err(format!("{err:?}"))
⋮----
File::create(filename).map_err(|err| format!("unable to create {filename}: {err}"))?;
⋮----
info!("Validator initialized");
validator.listen_for_signals()?;
validator.join();
info!("Validator exiting..");
Ok(())
⋮----
fn hardforks_of(matches: &ArgMatches<'_>, name: &str) -> Option<Vec<Slot>> {
if matches.is_present(name) {
Some(values_t_or_exit!(matches, name, Slot))
⋮----
fn validators_set(
⋮----
if matches.is_present(matches_name) {
let validators_set: HashSet<_> = values_t_or_exit!(matches, matches_name, Pubkey)
⋮----
.collect();
if validators_set.contains(identity_pubkey) {
⋮----
Ok(Some(validators_set))
⋮----
Ok(None)
⋮----
fn get_cluster_shred_version(entrypoints: &[SocketAddr], bind_address: IpAddr) -> Option<u16> {
⋮----
let mut index: Vec<_> = (0..entrypoints.len()).collect();
index.shuffle(&mut rand::rng());
index.into_iter().map(|i| &entrypoints[i])
⋮----
Err(err) => eprintln!("get_cluster_shred_version failed: {entrypoint}, {err}"),
Ok(0) => eprintln!("entrypoint {entrypoint} returned shred-version zero"),
⋮----
info!("obtained shred-version {shred_version} from {entrypoint}");
return Some(shred_version);
⋮----
fn parse_banking_trace_dir_byte_limit(matches: &ArgMatches) -> u64 {
if matches.is_present("disable_banking_trace") {
⋮----
value_t_or_exit!(matches, "banking_trace_dir_byte_limit", u64)
⋮----
fn new_snapshot_config(
⋮----
if matches.is_present("no_snapshots") {
⋮----
value_t_or_exit!(matches, "snapshot_interval_slots", NonZeroU64),
⋮----
value_t_or_exit!(matches, "full_snapshot_interval_slots", NonZeroU64);
⋮----
if matches.occurrences_of("full_snapshot_interval_slots") > 0 {
⋮----
let full_snapshot_interval_slots = full_snapshot_interval_slots.get();
⋮----
.value_of("snapshots")
.map(Path::new)
.unwrap_or(ledger_path);
let snapshots_dir = create_and_canonicalize_directory(snapshots_dir).map_err(|err| {
format!(
⋮----
.any(|account_path| account_path == &snapshots_dir)
⋮----
Err(
⋮----
.to_string(),
⋮----
let bank_snapshots_dir = snapshots_dir.join(BANK_SNAPSHOTS_DIR);
fs::create_dir_all(&bank_snapshots_dir).map_err(|err| {
⋮----
.value_of("full_snapshot_archive_path")
⋮----
.unwrap_or_else(|| snapshots_dir.clone());
fs::create_dir_all(&full_snapshot_archives_dir).map_err(|err| {
⋮----
.value_of("incremental_snapshot_archive_path")
⋮----
fs::create_dir_all(&incremental_snapshot_archives_dir).map_err(|err| {
⋮----
let archive_format_str = value_t_or_exit!(matches, "snapshot_archive_format", String);
⋮----
.unwrap_or_else(|| panic!("Archive format not recognized: {archive_format_str}"));
⋮----
value_t_or_exit!(matches, "snapshot_zstd_compression_level", i32);
⋮----
.value_of("snapshot_version")
.map(|value| {
⋮----
.map_err(|err| format!("unable to parse snapshot version: {err}"))
⋮----
.unwrap_or(SnapshotVersion::default());
⋮----
value_t_or_exit!(matches, "maximum_full_snapshots_to_retain", NonZeroUsize);
let maximum_incremental_snapshot_archives_to_retain = value_t_or_exit!(
⋮----
value_t_or_exit!(matches, "snapshot_packager_niceness_adj", i8);
⋮----
if !is_snapshot_config_valid(&snapshot_config) {
⋮----
Ok(snapshot_config)
⋮----
fn tip_manager_config_from_matches(
⋮----
tip_payment_program_id: pubkey_of(matches, "tip_payment_program_pubkey").unwrap_or_else(
⋮----
panic!(
⋮----
tip_distribution_program_id: pubkey_of(matches, "tip_distribution_program_pubkey")
.unwrap_or_else(|| {
⋮----
merkle_root_upload_authority: pubkey_of(matches, "merkle_root_upload_authority")
⋮----
vote_account: pubkey_of(matches, "vote_account").unwrap_or_else(|| {
⋮----
panic!("--vote-account argument required when validator is voting");
⋮----
commission_bps: value_t!(matches, "commission_bps", u16).unwrap_or_else(|_| {
⋮----
panic!("--commission-bps argument required when validator is voting");

================
File: validator/src/commands/run/mod.rs
================
pub mod args;
pub mod execute;

================
File: validator/src/commands/set_identity/mod.rs
================
pub struct SetIdentityArgs {
⋮----
impl FromClapArgMatches for SetIdentityArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(SetIdentityArgs {
identity: value_t!(matches, "identity", String).ok(),
require_tower: matches.is_present("require_tower"),
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Set the validator identity")
.arg(
⋮----
.index(1)
.value_name("KEYPAIR")
.required(false)
.takes_value(true)
.validator(is_keypair)
.help("Path to validator identity keypair [default: read JSON keypair from stdin]"),
⋮----
.long("require-tower")
.takes_value(false)
.help("Refuse to set the validator identity if saved tower state is not found"),
⋮----
.after_help(
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
println!(
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.set_identity(identity_keypair.display().to_string(), require_tower)
⋮----
let identity_keypair = read_keypair(&mut stdin)?;
println!("New validator identity: {}", identity_keypair.pubkey());
⋮----
.set_identity_from_bytes(Vec::from(identity_keypair.to_bytes()), require_tower)
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_set_identity_default() {
verify_args_struct_by_command(command(), vec![COMMAND], SetIdentityArgs::default());
⋮----
fn verify_args_struct_by_command_set_identity_with_identity_file() {
let tmp_dir = tempfile::tempdir().unwrap();
let file = tmp_dir.path().join("id.json");
⋮----
solana_keypair::write_keypair_file(&keypair, &file).unwrap();
verify_args_struct_by_command(
command(),
vec![COMMAND, file.to_str().unwrap()],
⋮----
identity: Some(file.to_str().unwrap().to_string()),
⋮----
fn verify_args_struct_by_command_set_identity_with_require_tower() {
⋮----
vec![COMMAND, "--require-tower"],

================
File: validator/src/commands/set_log_filter/mod.rs
================
pub struct SetLogFilterArgs {
⋮----
impl FromClapArgMatches for SetLogFilterArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(SetLogFilterArgs {
filter: value_t!(matches, "filter", String)?,
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Adjust the validator log filter")
.arg(
⋮----
.takes_value(true)
.index(1)
.help("New filter using the same format as the RUST_LOG environment variable"),
⋮----
.after_help("Note: the new filter only applies to the currently running validator instance")
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.set_log_filter(set_log_filter_args.filter)
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_set_log_filter_default() {
let matches = command().get_matches_from(vec![COMMAND]);
assert!(SetLogFilterArgs::from_clap_arg_match(&matches).is_err());
⋮----
fn verify_args_struct_by_command_set_log_filter_with_filter() {
verify_args_struct_by_command(
command(),
vec![COMMAND, "expected_filter_value"],
⋮----
filter: "expected_filter_value".to_string(),

================
File: validator/src/commands/set_public_address/mod.rs
================
pub struct SetPublicAddressArgs {
⋮----
impl FromClapArgMatches for SetPublicAddressArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
⋮----
Ok(matches
.value_of(arg_name)
.map(|host_port| {
solana_net_utils::parse_host_port(host_port).map_err(|err| {
format!(
⋮----
.transpose()?)
⋮----
Ok(SetPublicAddressArgs {
tpu_addr: parse_arg_addr("tpu_addr", "tpu")?,
tpu_forwards_addr: parse_arg_addr("tpu_forwards_addr", "tpu-forwards")?,
tvu_addr: parse_arg_addr("tvu_addr", "tvu")?,
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Specify addresses to advertise in gossip")
.arg(
⋮----
.long("tpu")
.value_name("HOST:PORT")
.takes_value(true)
.validator(solana_net_utils::is_host_port)
.help("TPU address to advertise in gossip"),
⋮----
.long("tpu-forwards")
⋮----
.help("TPU Forwards address to advertise in gossip"),
⋮----
.long("tvu")
⋮----
.help("TVU address to advertise in gossip"),
⋮----
.group(
⋮----
.args(&["tpu_addr", "tpu_forwards_addr", "tvu_addr"])
.required(true)
.multiple(true),
⋮----
.after_help("Note: At least one arg must be used. Using multiple is ok")
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
macro_rules! set_public_address {
⋮----
set_public_address!(set_public_address_args.tpu_addr, set_public_tpu_address)?;
set_public_address!(
⋮----
set_public_address!(set_public_address_args.tvu_addr, set_public_tvu_address)?;
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_set_public_default() {
verify_args_struct_by_command_is_error::<SetPublicAddressArgs>(command(), vec![COMMAND]);
⋮----
fn verify_args_struct_by_command_set_public_address_tpu() {
verify_args_struct_by_command(
command(),
vec![COMMAND, "--tpu", "127.0.0.1:8080"],
⋮----
tpu_addr: Some(SocketAddr::from(([127, 0, 0, 1], 8080))),
⋮----
fn verify_args_struct_by_command_set_public_address_tpu_forwards() {
⋮----
vec![COMMAND, "--tpu-forwards", "127.0.0.1:8081"],
⋮----
tpu_forwards_addr: Some(SocketAddr::from(([127, 0, 0, 1], 8081))),
⋮----
fn verify_args_struct_by_command_set_public_address_tpu_and_tpu_forwards() {
⋮----
vec![
⋮----
tvu_addr: Some(SocketAddr::from(([127, 0, 0, 1], 8082))),

================
File: validator/src/commands/shred/mod.rs
================
pub fn shred_receiver_command(_default_args: &DefaultArgs) -> App<'_, '_> {
⋮----
.about("Set shred receiver address")
.arg(
⋮----
.long("shred-receiver-address")
.value_name("SHRED_RECEIVER_ADDRESS")
.takes_value(true)
.help(
⋮----
.required(true),
⋮----
pub fn shred_retransmit_receiver_command(_default_args: &DefaultArgs) -> App<'_, '_> {
⋮----
.about("Set shred retransmit receiver address")
⋮----
.long("shred-retransmit-receiver-address")
.value_name("SHRED_RETRANSMIT_RECEIVER_ADDRESS")
⋮----
pub fn set_shred_receiver_execute(
⋮----
let addr = value_t_or_exit!(subcommand_matches, "shred_receiver_address", String);
⋮----
.block_on(async move { admin_client.await?.set_shred_receiver_address(addr).await })?;
Ok(())
⋮----
pub fn set_shred_retransmit_receiver_execute(
⋮----
let addr = value_t_or_exit!(
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.set_shred_retransmit_receiver_address(addr)

================
File: validator/src/commands/staked_nodes_overrides/mod.rs
================
pub struct StakedNodesOverridesArgs {
⋮----
impl FromClapArgMatches for StakedNodesOverridesArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(StakedNodesOverridesArgs {
⋮----
.value_of("path")
.expect("path is required")
.to_string(),
⋮----
pub fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Overrides stakes of specific node identities.")
.arg(
⋮----
.value_name("PATH")
.takes_value(true)
.required(true)
.help(
⋮----
.after_help(
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
admin_rpc_service::runtime().block_on(async move {
⋮----
.set_staked_nodes_overrides(staked_nodes_overrides_args.path)
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn verify_args_struct_by_command_staked_nodes_overrides_default() {
⋮----
command(),
vec![COMMAND],
⋮----
fn verify_args_struct_by_command_staked_nodes_overrides_path() {
verify_args_struct_by_command(
⋮----
vec![COMMAND, "test.json"],
⋮----
path: "test.json".to_string(),

================
File: validator/src/commands/wait_for_restart_window/mod.rs
================
pub struct WaitForRestartWindowArgs {
⋮----
impl FromClapArgMatches for WaitForRestartWindowArgs {
fn from_clap_arg_match(matches: &ArgMatches) -> Result<Self> {
Ok(WaitForRestartWindowArgs {
min_idle_time: value_t_or_exit!(matches, "min_idle_time", usize),
identity: pubkey_of(matches, "identity"),
max_delinquent_stake: value_t_or_exit!(matches, "max_delinquent_stake", u8),
skip_new_snapshot_check: matches.is_present("skip_new_snapshot_check"),
skip_health_check: matches.is_present("skip_health_check"),
⋮----
pub(crate) fn command<'a>() -> App<'a, 'a> {
⋮----
.about("Monitor the validator for a good time to restart")
.arg(
⋮----
.long("min-idle-time")
.takes_value(true)
.validator(is_parsable::<usize>)
.value_name("MINUTES")
.default_value(DEFAULT_MIN_IDLE_TIME)
.help("Minimum time that the validator should not be leader before restarting"),
⋮----
.long("identity")
.value_name("ADDRESS")
⋮----
.validator(is_pubkey_or_keypair)
.help("Validator identity to monitor [default: your validator]"),
⋮----
.long("max-delinquent-stake")
⋮----
.validator(is_valid_percentage)
.value_name("PERCENT")
.default_value(DEFAULT_MAX_DELINQUENT_STAKE)
.help("The maximum delinquent stake % permitted for a restart"),
⋮----
.long("skip-new-snapshot-check")
.help("Skip check for a new snapshot"),
⋮----
.long("skip-health-check")
.help("Skip health check"),
⋮----
.after_help(
⋮----
pub fn execute(matches: &ArgMatches, ledger_path: &Path) -> Result<()> {
⋮----
wait_for_restart_window(
⋮----
Ok(())
⋮----
pub fn wait_for_restart_window(
⋮----
.block_on(async move { admin_client.await?.rpc_addr().await })
.map_err(|err| format!("validator RPC address request failed: {err}"))?
.ok_or("validator RPC is unavailable".to_string())?;
⋮----
let my_identity = rpc_client.get_identity()?;
let identity = identity.unwrap_or(my_identity);
⋮----
println_name_value("Identity:", &identity.to_string());
println_name_value(
⋮----
&format!("{min_idle_slots} slots (~{min_idle_time_in_minutes} minutes)"),
⋮----
println!("Maximum permitted delinquency: {max_delinquency_percentage}%");
⋮----
let mut upcoming_idle_windows = vec![]; // Vec<(starting slot, idle window length in slots)>
let progress_bar = new_spinner_progress_bar();
⋮----
let snapshot_slot_info = rpc_client.get_highest_snapshot_slot().ok();
⋮----
.as_ref()
.map(|snapshot_slot_info| snapshot_slot_info.incremental.is_some())
.unwrap_or_default();
⋮----
let epoch_info = rpc_client.get_epoch_info_with_commitment(CommitmentConfig::processed())?;
let healthy = skip_health_check || rpc_client.get_health().ok().is_some();
⋮----
let vote_accounts = rpc_client.get_vote_accounts()?;
⋮----
.iter()
.map(|va| va.activated_stake)
.sum();
⋮----
progress_bar.set_message(format!(
⋮----
.get_leader_schedule_with_config(
Some(first_slot_in_epoch),
⋮----
identity: Some(identity.to_string()),
⋮----
.ok_or_else(|| {
format!("Unable to get leader schedule from slot {first_slot_in_epoch}")
⋮----
.get(&identity.to_string())
.cloned()
.unwrap_or_default()
.into_iter()
.map(|slot_index| first_slot_in_epoch.saturating_add(slot_index as u64))
.filter(|slot| *slot > epoch_info.absolute_slot)
⋮----
upcoming_idle_windows.clear();
⋮----
let mut leader_schedule = leader_schedule.clone();
⋮----
while let Some(next_leader_slot) = leader_schedule.pop_front() {
⋮----
max_idle_window = max_idle_window.max(idle_window);
⋮----
upcoming_idle_windows.push((idle_window_start_slot, idle_window));
⋮----
if !leader_schedule.is_empty() && upcoming_idle_windows.is_empty() {
return Err(format!(
⋮----
.into());
⋮----
current_epoch = Some(epoch_info.epoch);
⋮----
style("Node is unhealthy").red().to_string()
⋮----
// Wait until a hole in the leader schedule before restarting the node
⋮----
Err("Current epoch is almost complete".to_string())
⋮----
.front()
.map(|slot| *slot < epoch_info.absolute_slot)
.unwrap_or(false)
⋮----
leader_schedule.pop_front();
⋮----
.first()
.map(|(slot, _)| *slot < epoch_info.absolute_slot)
⋮----
upcoming_idle_windows.pop();
⋮----
match leader_schedule.front() {
⋮----
Ok(()) // Validator has no leader slots
⋮----
next_leader_slot.saturating_sub(epoch_info.absolute_slot);
⋮----
Err(match upcoming_idle_windows.first() {
⋮----
format!(
⋮----
None => format!(
⋮----
break; // Restart!
⋮----
let snapshot_slot = snapshot_slot_info.map(|snapshot_slot_info| {
⋮----
.unwrap_or(snapshot_slot_info.full)
⋮----
if restart_snapshot.is_none() {
⋮----
"Waiting for a new snapshot".to_string()
⋮----
style("Delinquency too high").red().to_string()
⋮----
// Restarts using just a full snapshot will put the node significantly
// further behind than if an incremental snapshot is also used, as full
// snapshots are larger and take much longer to create.
//
// Therefore if the node just created a new full snapshot, wait a
// little longer until it creates the first incremental snapshot for
// the full snapshot.
"Waiting for incremental snapshot".to_string()
⋮----
Err(why) => style(why).yellow().to_string(),
⋮----
drop(progress_bar);
println!("{}", style("Ready to restart").green());
⋮----
mod tests {
⋮----
impl Default for WaitForRestartWindowArgs {
fn default() -> Self {
⋮----
.parse()
.expect("invalid DEFAULT_MIN_IDLE_TIME"),
⋮----
.expect("invalid DEFAULT_MAX_DELINQUENT_STAKE"),
⋮----
fn verify_args_struct_by_command_wait_for_restart_window_default() {
verify_args_struct_by_command(
command(),
vec![COMMAND],
⋮----
fn verify_args_struct_by_command_wait_for_restart_window_skip_new_snapshot_check() {
⋮----
vec![COMMAND, "--skip-new-snapshot-check"],
⋮----
fn verify_args_struct_by_command_wait_for_restart_window_skip_health_check() {
⋮----
vec![COMMAND, "--skip-health-check"],
⋮----
fn verify_args_struct_by_command_wait_for_restart_window_min_idle_time() {
⋮----
vec![COMMAND, "--min-idle-time", "60"],
⋮----
fn verify_args_struct_by_command_wait_for_restart_window_identity() {
⋮----
vec![
⋮----
identity: Some(
Pubkey::from_str("ch1do11111111111111111111111111111111111111").unwrap(),
⋮----
fn verify_args_struct_by_command_wait_for_restart_window_max_delinquent_stake() {
⋮----
vec![COMMAND, "--max-delinquent-stake", "10"],

================
File: validator/src/commands/mod.rs
================
pub mod authorized_voter;
pub mod bam;
pub mod block_engine;
pub mod contact_info;
pub mod exit;
pub mod manage_block_production;
pub mod monitor;
pub mod plugin;
pub mod relayer;
pub mod repair_shred_from_peer;
pub mod repair_whitelist;
pub mod run;
pub mod set_identity;
pub mod set_log_filter;
pub mod set_public_address;
pub mod shred;
pub mod staked_nodes_overrides;
pub mod wait_for_restart_window;
use thiserror::Error;
⋮----
pub enum Error {
⋮----
pub type Result<T> = std::result::Result<T, Error>;
pub trait FromClapArgMatches {
⋮----
pub mod tests {
use std::fmt::Debug;
pub fn verify_args_struct_by_command<T>(app: clap::App, vec: Vec<&str>, expected_arg: T)
⋮----
let matches = app.get_matches_from(vec);
⋮----
pub fn verify_args_struct_by_command_is_error<T>(app: clap::App, vec: Vec<&str>)
⋮----
let matches = app.get_matches_from_safe(vec);
assert!(matches.is_err());

================
File: validator/src/admin_rpc_service.rs
================
pub struct AdminRpcRequestMetadata {
⋮----
impl Metadata for AdminRpcRequestMetadata {}
impl AdminRpcRequestMetadata {
fn with_post_init<F, R>(&self, func: F) -> Result<R>
⋮----
if let Some(post_init) = self.post_init.read().unwrap().as_ref() {
func(post_init)
⋮----
Err(jsonrpc_core::error::Error::invalid_params(
⋮----
pub struct AdminRpcContactInfo {
⋮----
pub struct AdminRpcRepairWhitelist {
⋮----
fn from(node: ContactInfo) -> Self {
macro_rules! unwrap_socket {
⋮----
id: node.pubkey().to_string(),
last_updated_timestamp: node.wallclock(),
gossip: unwrap_socket!(gossip),
tvu: unwrap_socket!(tvu, Protocol::UDP),
tvu_quic: unwrap_socket!(tvu, Protocol::QUIC),
serve_repair_quic: unwrap_socket!(serve_repair, Protocol::QUIC),
tpu: unwrap_socket!(tpu, Protocol::UDP),
tpu_forwards: unwrap_socket!(tpu_forwards, Protocol::UDP),
tpu_vote: unwrap_socket!(tpu_vote, Protocol::UDP),
rpc: unwrap_socket!(rpc),
rpc_pubsub: unwrap_socket!(rpc_pubsub),
serve_repair: unwrap_socket!(serve_repair, Protocol::UDP),
shred_version: node.shred_version(),
⋮----
impl Display for AdminRpcContactInfo {
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
writeln!(f, "Identity: {}", self.id)?;
writeln!(f, "Gossip: {}", self.gossip)?;
writeln!(f, "TVU: {}", self.tvu)?;
writeln!(f, "TVU QUIC: {}", self.tvu_quic)?;
writeln!(f, "TPU: {}", self.tpu)?;
writeln!(f, "TPU Forwards: {}", self.tpu_forwards)?;
writeln!(f, "TPU Votes: {}", self.tpu_vote)?;
writeln!(f, "RPC: {}", self.rpc)?;
writeln!(f, "RPC Pubsub: {}", self.rpc_pubsub)?;
writeln!(f, "Serve Repair: {}", self.serve_repair)?;
writeln!(f, "Last Updated Timestamp: {}", self.last_updated_timestamp)?;
writeln!(f, "Shred Version: {}", self.shred_version)
⋮----
impl Display for AdminRpcRepairWhitelist {
⋮----
writeln!(f, "Repair whitelist: {:?}", &self.whitelist)
⋮----
pub trait AdminRpc {
⋮----
pub struct AdminRpcImpl;
impl AdminRpc for AdminRpcImpl {
type Metadata = AdminRpcRequestMetadata;
fn exit(&self, meta: Self::Metadata) -> Result<()> {
debug!("exit admin rpc request received");
⋮----
.name("solProcessExit".into())
.spawn(move || {
⋮----
info!("validator exit requested");
meta.validator_exit.write().unwrap().exit();
if !meta.validator_exit_backpressure.is_empty() {
let service_names = meta.validator_exit_backpressure.keys();
info!("Wait for these services to complete: {service_names:?}");
⋮----
for (name, flag) in meta.validator_exit_backpressure.iter() {
let is_flag_raised = flag.load(Ordering::Relaxed);
⋮----
info!("{name}'s exit backpressure flag is raised");
⋮----
info!("All services have completed");
⋮----
.ok()
.and_then(|x| x.parse().ok())
.unwrap_or(5),
⋮----
warn!("validator exit timeout");
⋮----
.unwrap();
Ok(())
⋮----
fn pid(&self, _meta: Self::Metadata) -> Result<u32> {
Ok(std::process::id())
⋮----
fn reload_plugin(
⋮----
let (response_sender, response_receiver) = oneshot_channel();
⋮----
.send(GeyserPluginManagerRequest::ReloadPlugin {
⋮----
.expect("GeyerPluginService should never drop request receiver");
⋮----
return Err(jsonrpc_core::Error {
⋮----
message: "No geyser plugin service".to_string(),
⋮----
.expect("GeyerPluginService's oneshot sender shouldn't drop early")
⋮----
fn load_plugin(&self, meta: Self::Metadata, config_file: String) -> BoxFuture<Result<String>> {
⋮----
.send(GeyserPluginManagerRequest::LoadPlugin {
⋮----
fn unload_plugin(&self, meta: Self::Metadata, name: String) -> BoxFuture<Result<()>> {
⋮----
.send(GeyserPluginManagerRequest::UnloadPlugin {
⋮----
fn list_plugins(&self, meta: Self::Metadata) -> BoxFuture<Result<Vec<String>>> {
⋮----
.send(GeyserPluginManagerRequest::ListPlugins { response_sender })
⋮----
fn rpc_addr(&self, meta: Self::Metadata) -> Result<Option<SocketAddr>> {
debug!("rpc_addr admin rpc request received");
Ok(meta.rpc_addr)
⋮----
fn set_log_filter(&self, filter: String) -> Result<()> {
debug!("set_log_filter admin rpc request received");
⋮----
fn start_time(&self, meta: Self::Metadata) -> Result<SystemTime> {
debug!("start_time admin rpc request received");
Ok(meta.start_time)
⋮----
fn start_progress(&self, meta: Self::Metadata) -> Result<ValidatorStartProgress> {
debug!("start_progress admin rpc request received");
Ok(*meta.start_progress.read().unwrap())
⋮----
fn add_authorized_voter(&self, meta: Self::Metadata, keypair_file: String) -> Result<()> {
debug!("add_authorized_voter request received");
let authorized_voter = read_keypair_file(keypair_file)
.map_err(|err| jsonrpc_core::error::Error::invalid_params(format!("{err}")))?;
⋮----
fn add_authorized_voter_from_bytes(
⋮----
debug!("add_authorized_voter_from_bytes request received");
let authorized_voter = Keypair::try_from(keypair.as_ref()).map_err(|err| {
jsonrpc_core::error::Error::invalid_params(format!(
⋮----
fn remove_all_authorized_voters(&self, meta: Self::Metadata) -> Result<()> {
debug!("remove_all_authorized_voters received");
meta.authorized_voter_keypairs.write().unwrap().clear();
⋮----
fn set_block_engine_config(
⋮----
debug!("set_block_engine_config request received");
⋮----
meta.with_post_init(|post_init| {
*post_init.block_engine_config.lock().unwrap() = config;
⋮----
fn set_bam_url(&self, meta: Self::Metadata, bam_url: Option<String>) -> Result<()> {
let old_bam_url = meta.bam_url.lock().unwrap().clone();
⋮----
Some(url) if url.trim().is_empty() => (None, true),
Some(url) => (Some(url), false),
⋮----
let new_bam_url = bam_url.as_ref().map(|url| url.to_string());
debug!("set_bam_url old= {old_bam_url:?}, new={new_bam_url:?}");
⋮----
return Err(jsonrpc_core::error::Error::invalid_params(format!(
⋮----
datapoint_info!(
⋮----
*meta.bam_url.lock().unwrap() = bam_url;
⋮----
fn set_identity(
⋮----
debug!("set_identity request received");
let identity_keypair = read_keypair_file(&keypair_file).map_err(|err| {
⋮----
fn set_identity_from_bytes(
⋮----
debug!("set_identity_from_bytes request received");
let identity_keypair = Keypair::try_from(identity_keypair.as_ref()).map_err(|err| {
⋮----
fn set_relayer_config(
⋮----
debug!("set_relayer_config request received");
⋮----
*post_init.relayer_config.lock().unwrap() = config;
⋮----
fn set_shred_receiver_address(&self, meta: Self::Metadata, addr: String) -> Result<()> {
let shred_receiver_address = if addr.is_empty() {
⋮----
Some(SocketAddr::from_str(&addr).map_err(|_| {
⋮----
.store(Arc::new(shred_receiver_address));
⋮----
fn set_shred_retransmit_receiver_address(
⋮----
fn set_staked_nodes_overrides(&self, meta: Self::Metadata, path: String) -> Result<()> {
let loaded_config = load_staked_nodes_overrides(&path)
.map_err(|err| {
error!("Failed to load staked nodes overrides from {path}: {err}");
⋮----
let mut write_staked_nodes = meta.staked_nodes_overrides.write().unwrap();
write_staked_nodes.clear();
write_staked_nodes.extend(loaded_config);
info!("Staked nodes overrides loaded from {path}");
debug!("overrides map: {write_staked_nodes:?}");
⋮----
fn contact_info(&self, meta: Self::Metadata) -> Result<AdminRpcContactInfo> {
meta.with_post_init(|post_init| Ok(post_init.cluster_info.my_contact_info().into()))
⋮----
fn select_active_interface(&self, meta: Self::Metadata, interface: IpAddr) -> Result<()> {
debug!("select_active_interface received: {interface}");
⋮----
let node = post_init.node.as_ref().ok_or_else(|| {
⋮----
node.switch_active_interface(interface, &post_init.cluster_info)
.map_err(|e| {
jsonrpc_core::Error::invalid_params(format!(
⋮----
info!("Switched primary interface to {interface}");
⋮----
fn repair_shred_from_peer(
⋮----
debug!("repair_shred_from_peer request received");
⋮----
post_init.cluster_info.clone(),
post_init.cluster_slots.clone(),
⋮----
&post_init.repair_socket.clone(),
post_init.outstanding_repair_requests.clone(),
⋮----
fn repair_whitelist(&self, meta: Self::Metadata) -> Result<AdminRpcRepairWhitelist> {
debug!("repair_whitelist request received");
⋮----
.read()
.unwrap()
.iter()
.copied()
.collect();
Ok(AdminRpcRepairWhitelist { whitelist })
⋮----
fn set_repair_whitelist(&self, meta: Self::Metadata, whitelist: Vec<Pubkey>) -> Result<()> {
debug!("set_repair_whitelist request received");
let whitelist: HashSet<Pubkey> = whitelist.into_iter().collect();
⋮----
*post_init.repair_whitelist.write().unwrap() = whitelist;
warn!(
⋮----
fn get_secondary_index_key_size(
⋮----
debug!("get_secondary_index_key_size rpc request received: {pubkey_str:?}");
let index_key = verify_pubkey(&pubkey_str)?;
⋮----
let bank = post_init.bank_forks.read().unwrap().root_bank();
let enabled_account_indexes = &bank.accounts().accounts_db.account_indexes;
if enabled_account_indexes.is_empty() {
debug!("get_secondary_index_key_size: secondary index not enabled.");
return Ok(HashMap::new());
⋮----
if !enabled_account_indexes.include_key(&index_key) {
return Err(RpcCustomError::KeyExcludedFromSecondaryIndex {
index_key: index_key.to_string(),
⋮----
.into());
⋮----
let accounts_index = &bank.accounts().accounts_db.accounts_index;
⋮----
.filter_map(|index| {
⋮----
.get_index_key_size(index, &index_key)
.map(|size| (rpc_account_index_from_account_index(index), size))
⋮----
if found_sizes.is_empty() {
debug!("get_secondary_index_key_size: key not found in the secondary index.");
⋮----
Ok(found_sizes)
⋮----
fn set_public_tpu_address(
⋮----
debug!("set_public_tpu_address rpc request received: {public_tpu_addr}");
⋮----
.my_contact_info()
.tpu(Protocol::QUIC)
.ok_or_else(|| {
error!(
⋮----
.set_tpu_quic(public_tpu_addr)
⋮----
error!("Failed to set public TPU QUIC address to {public_tpu_addr}: {err}");
⋮----
let my_contact_info = post_init.cluster_info.my_contact_info();
⋮----
fn set_public_tpu_forwards_address(
⋮----
debug!("set_public_tpu_forwards_address rpc request received: {public_tpu_forwards_addr}");
⋮----
.tpu_forwards(Protocol::QUIC)
⋮----
.set_tpu_forwards_quic(public_tpu_forwards_addr)
⋮----
fn set_public_tvu_address(
⋮----
debug!("set_public_tvu_address rpc request received: {public_tvu_addr}");
⋮----
.tvu(Protocol::UDP)
⋮----
.set_tvu_socket(public_tvu_addr)
⋮----
error!("Failed to set public TVU address to {public_tvu_addr}: {err}");
⋮----
fn manage_block_production(
⋮----
debug!("manage_block_production rpc request received");
⋮----
warn!("TransactionStructure::Sdk has no effect on block production");
⋮----
.try_send(BankingControlMsg::Internal {
⋮----
.is_err()
⋮----
error!("Banking stage already switching schedulers");
return Err(jsonrpc_core::error::Error::internal_error());
⋮----
impl AdminRpcImpl {
fn add_authorized_voter_keypair(
⋮----
let mut authorized_voter_keypairs = meta.authorized_voter_keypairs.write().unwrap();
⋮----
.any(|x| x.pubkey() == authorized_voter.pubkey())
⋮----
authorized_voter_keypairs.push(Arc::new(authorized_voter));
⋮----
fn set_identity_keypair(
⋮----
let _ = Tower::restore(meta.tower_storage.as_ref(), &identity_keypair.pubkey())
⋮----
for (key, notifier) in &*post_init.notifies.read().unwrap() {
if let Err(err) = notifier.update_key(&identity_keypair) {
error!("Error updating network layer keypair: {err} on {key:?}");
⋮----
solana_metrics::set_host_id(identity_keypair.pubkey().to_string());
⋮----
.set_keypair(Arc::new(identity_keypair));
warn!("Identity set to {}", post_init.cluster_info.id());
⋮----
fn rpc_account_index_from_account_index(account_index: &AccountIndex) -> RpcAccountIndex {
⋮----
pub fn run(ledger_path: &Path, metadata: AdminRpcRequestMetadata) {
let admin_rpc_path = admin_rpc_path(ledger_path);
⋮----
.thread_name("solAdminRpcEl")
.worker_threads(3)
.enable_all()
.build()
⋮----
.name("solAdminRpc".to_string())
⋮----
io.extend_with(AdminRpcImpl.to_delegate());
let validator_exit = metadata.validator_exit.clone();
⋮----
metadata.clone()
⋮----
.event_loop_executor(event_loop.handle().clone())
.start(&format!("{}", admin_rpc_path.display()));
⋮----
warn!("Unable to start admin rpc service: {err:?}");
⋮----
info!("started admin rpc service!");
let close_handle = server.close_handle();
⋮----
.write()
⋮----
.register_exit(Box::new(move || {
close_handle.close();
⋮----
server.wait();
⋮----
fn admin_rpc_path(ledger_path: &Path) -> PathBuf {
⋮----
if let Some(ledger_filename) = ledger_path.file_name() {
PathBuf::from(format!(
⋮----
ledger_path.join("admin.rpc")
⋮----
pub async fn connect(ledger_path: &Path) -> std::result::Result<gen_client::Client, RpcError> {
⋮----
if !admin_rpc_path.exists() {
Err(RpcError::Client(format!(
⋮----
ipc::connect::<_, gen_client::Client>(&format!("{}", admin_rpc_path.display())).await
⋮----
pub fn runtime() -> Runtime {
⋮----
.thread_name("solAdminRpcRt")
⋮----
.worker_threads(2)
⋮----
.expect("new tokio runtime")
⋮----
pub struct StakedNodesOverrides {
⋮----
pub fn deserialize_pubkey_map<'de, D>(des: D) -> std::result::Result<HashMap<Pubkey, u64>, D::Error>
⋮----
for (key, value) in container.iter() {
let typed_key = Pubkey::try_from(key.as_str())
.map_err(|_| serde::de::Error::invalid_type(serde::de::Unexpected::Map, &"PubKey"))?;
container_typed.insert(typed_key, *value);
⋮----
Ok(container_typed)
⋮----
pub fn load_staked_nodes_overrides(
⋮----
debug!("Loading staked nodes overrides configuration from {path}");
if Path::new(&path).exists() {
⋮----
Ok(serde_yaml::from_reader(file)?)
⋮----
Err(format!("Staked nodes overrides provided '{path}' a non-existing file path.").into())
⋮----
mod tests {
⋮----
struct TestConfig {
⋮----
struct RpcHandler {
⋮----
impl RpcHandler {
fn _start() -> Self {
⋮----
fn start_with_config(config: TestConfig) -> Self {
⋮----
keypair.pubkey(),
⋮----
let validator_exit = create_validator_exit(exit);
let (bank_forks, vote_keypair) = new_bank_forks_with_config(BankTestConfig {
⋮----
account_indexes: Some(config.account_indexes),
⋮----
let vote_account = vote_keypair.pubkey();
⋮----
authorized_voter_keypairs: Arc::new(RwLock::new(vec![vote_keypair])),
⋮----
post_init: Arc::new(RwLock::new(Some(AdminRpcRequestMetadataPostInit {
⋮----
bank_forks: bank_forks.clone(),
⋮----
repair_socket: Arc::new(bind_to_localhost_unique().expect("should bind")),
⋮----
fn root_bank(&self) -> Arc<Bank> {
self.bank_forks.read().unwrap().root_bank()
⋮----
fn new_bank_forks_with_config(
⋮----
} = create_genesis_config(1_000_000_000);
⋮----
fn test_secondary_index_key_sizes() {
⋮----
let bank = rpc.root_bank();
⋮----
let req = format!(
⋮----
let res = io.handle_request_sync(&req, meta.clone());
let result: Value = serde_json::from_str(&res.expect("actual response"))
.expect("actual response deserialization");
⋮----
serde_json::from_value(result["result"].clone()).unwrap();
assert!(sizes.is_empty());
⋮----
assert_eq!(sizes.len(), 1);
⋮----
*sizes.get(&RpcAccountIndex::ProgramId).unwrap();
⋮----
bank.store_account(&wallet1_pubkey, &wallet1_account);
⋮----
bank.store_account(&wallet2_pubkey, &wallet2_account);
let mut account1_data = vec![0; TokenAccount::get_packed_len()];
⋮----
TokenAccount::pack(token_account1, &mut account1_data).unwrap();
⋮----
data: account1_data.to_vec(),
⋮----
bank.store_account(&token_account1_pubkey, &token_account1);
let mut mint1_data = vec![0; Mint::get_packed_len()];
⋮----
Mint::pack(mint1_state, &mut mint1_data).unwrap();
⋮----
data: mint1_data.to_vec(),
⋮----
bank.store_account(&mint1_pubkey, &mint_account1);
let mut account2_data = vec![0; TokenAccount::get_packed_len()];
⋮----
TokenAccount::pack(token_account2, &mut account2_data).unwrap();
⋮----
data: account2_data.to_vec(),
⋮----
bank.store_account(&token_account2_pubkey, &token_account2);
let mut account3_data = vec![0; TokenAccount::get_packed_len()];
⋮----
TokenAccount::pack(token_account3, &mut account3_data).unwrap();
⋮----
data: account3_data.to_vec(),
⋮----
bank.store_account(&token_account3_pubkey, &token_account3);
let mut mint2_data = vec![0; Mint::get_packed_len()];
⋮----
Mint::pack(mint2_state, &mut mint2_data).unwrap();
⋮----
data: mint2_data.to_vec(),
⋮----
bank.store_account(&mint2_pubkey, &mint_account2);
⋮----
assert_eq!(*sizes.get(&RpcAccountIndex::SplTokenOwner).unwrap(), 1);
⋮----
assert_eq!(*sizes.get(&RpcAccountIndex::SplTokenOwner).unwrap(), 2);
⋮----
assert_eq!(*sizes.get(&RpcAccountIndex::SplTokenMint).unwrap(), 2);
⋮----
assert_eq!(*sizes.get(&RpcAccountIndex::SplTokenMint).unwrap(), 1);
⋮----
assert_eq!(
⋮----
fn test_set_identity() {
⋮----
let validator_id_bytes = format!("{:?}", expected_validator_id.to_bytes());
let set_id_request = format!(
⋮----
let response = io.handle_request_sync(&set_id_request, meta.clone());
⋮----
serde_json::from_str(&response.expect("actual response"))
⋮----
.expect("Failed to parse expected response");
assert_eq!(actual_parsed_response, expected_parsed_response);
⋮----
r#"{"jsonrpc":"2.0","id":1,"method":"contactInfo","params":[]}"#.to_string();
let response = io.handle_request_sync(&contact_info_request, meta.clone());
let parsed_response: Value = serde_json::from_str(&response.expect("actual response"))
⋮----
.as_str()
.expect("Expected a string");
⋮----
struct TestValidatorWithAdminRpc {
⋮----
impl TestValidatorWithAdminRpc {
fn new() -> Self {
⋮----
let leader_node = Node::new_localhost_with_pubkey(&leader_keypair.pubkey());
⋮----
let validator_node = Node::new_localhost_with_pubkey(&validator_keypair.pubkey());
⋮----
create_genesis_config_with_leader(10_000, &leader_keypair.pubkey(), 1000)
⋮----
let (validator_ledger_path, _blockhash) = create_new_tmp_ledger!(&genesis_config);
⋮----
let voting_pubkey = voting_keypair.pubkey();
let authorized_voter_keypairs = Arc::new(RwLock::new(vec![voting_keypair]));
⋮----
rpc_addrs: Some((
validator_node.info.rpc().unwrap(),
validator_node.info.rpc_pubsub().unwrap(),
⋮----
rpc_addr: validator_config.rpc_addrs.map(|(rpc_addr, _)| rpc_addr),
⋮----
start_progress: start_progress.clone(),
validator_exit: validator_config.validator_exit.clone(),
⋮----
authorized_voter_keypairs: authorized_voter_keypairs.clone(),
⋮----
post_init: post_init.clone(),
⋮----
vec![leader_node.info],
⋮----
start_progress.clone(),
⋮----
post_init.clone(),
⋮----
.expect("assume successful validator start");
⋮----
let post_init = post_init.read().unwrap();
assert!(post_init.is_some());
let post_init = post_init.as_ref().unwrap();
let notifies = post_init.notifies.read().unwrap();
⋮----
notifies.into_iter().map(|(key, _)| key.clone()).collect();
⋮----
for key in required_updater_keys.iter() {
assert!(updater_keys.contains(key));
⋮----
fn handle_request(&self, request: &str) -> Option<String> {
self.io.handle_request_sync(request, self.meta.clone())
⋮----
impl Drop for TestValidatorWithAdminRpc {
fn drop(&mut self) {
remove_dir_all(self.validator_ledger_path.clone()).unwrap();
⋮----
fn test_set_identity_with_validator() {
⋮----
let response = test_validator.handle_request(&set_id_request);
⋮----
let response = test_validator.handle_request(&contact_info_request);
⋮----
r#"{"jsonrpc":"2.0","id":1,"method":"exit","params":[]}"#.to_string();
let exit_response = test_validator.handle_request(&contact_info_request);
⋮----
serde_json::from_str(&exit_response.expect("actual response"))
⋮----
fn test_set_bam_url() {
⋮----
let response = test_validator.handle_request(set_initial_bam_url_request);
⋮----
let response = test_validator.handle_request(set_bad_string_bam_url_request);
⋮----
.expect("Failed to parse expected error response");
⋮----
assert_eq!(actual_error_response, expected_error_response);
⋮----
let response = test_validator.handle_request(disable_bam_url_request);

================
File: validator/src/bootstrap.rs
================
pub struct RpcBootstrapConfig {
⋮----
fn verify_reachable_ports(
⋮----
addr.as_ref()
.map(|addr| socket_addr_space.check(addr))
.unwrap_or_default()
⋮----
let mut udp_sockets = vec![&node.sockets.repair];
udp_sockets.extend(node.sockets.gossip.iter());
if verify_address(&node.info.serve_repair(Protocol::UDP)) {
udp_sockets.push(&node.sockets.serve_repair);
⋮----
if verify_address(&node.info.tpu(Protocol::UDP)) {
udp_sockets.extend(node.sockets.tpu.iter());
udp_sockets.extend(&node.sockets.tpu_quic);
⋮----
if verify_address(&node.info.tpu_forwards(Protocol::UDP)) {
udp_sockets.extend(node.sockets.tpu_forwards.iter());
udp_sockets.extend(&node.sockets.tpu_forwards_quic);
⋮----
if verify_address(&node.info.tpu_vote(Protocol::UDP)) {
udp_sockets.extend(node.sockets.tpu_vote.iter());
⋮----
if verify_address(&node.info.tvu(Protocol::UDP)) {
udp_sockets.extend(node.sockets.tvu.iter());
udp_sockets.extend(node.sockets.broadcast.iter());
udp_sockets.extend(node.sockets.retransmit_sockets.iter());
⋮----
&cluster_entrypoint.gossip().unwrap(),
⋮----
let mut tcp_listeners = vec![];
⋮----
("RPC", rpc_addr, node.info.rpc()),
("RPC pubsub", rpc_pubsub_addr, node.info.rpc_pubsub()),
⋮----
if verify_address(public_addr) {
tcp_listeners.push(TcpListener::bind(bind_addr).unwrap_or_else(|err| {
error!("Unable to bind to tcp {bind_addr:?} for {purpose}: {err}");
exit(1);
⋮----
let ip_echo = ip_echo.try_clone().expect("unable to clone tcp_listener");
tcp_listeners.push(ip_echo);
⋮----
solana_net_utils::verify_all_reachable_tcp(&cluster_entrypoint.gossip().unwrap(), tcp_listeners)
⋮----
fn is_known_validator(id: &Pubkey, known_validators: &Option<HashSet<Pubkey>>) -> bool {
⋮----
known_validators.contains(id)
⋮----
fn start_gossip_node(
⋮----
identity_keypair.pubkey(),
⋮----
cluster_info.set_entrypoints(cluster_entrypoints.to_vec());
cluster_info.restore_contact_info(ledger_path, 0);
⋮----
gossip_exit_flag.clone(),
⋮----
fn get_rpc_peers(
⋮----
.unwrap_or_else(|| cluster_info.my_shred_version());
info!(
⋮----
let mut rpc_peers = cluster_info.rpc_peers();
⋮----
rpc_peers.retain(|rpc_peer| {
is_known_validator(rpc_peer.pubkey(), &validator_config.known_validators)
⋮----
let rpc_peers_total = rpc_peers.len();
⋮----
.into_iter()
.filter(|rpc_peer| !blacklisted_rpc_nodes.contains(rpc_peer.pubkey()))
.collect();
let rpc_peers_blacklisted = rpc_peers_total - rpc_peers.len();
⋮----
.iter()
.filter(|rpc_peer| {
⋮----
.count();
⋮----
*retry_reason = if !blacklisted_rpc_nodes.is_empty()
&& blacklist_timeout.elapsed() > BLACKLIST_CLEAR_THRESHOLD
⋮----
blacklisted_rpc_nodes.clear();
Some("Blacklist timeout expired".to_owned())
⋮----
Some("Wait for known rpc peers".to_owned())
⋮----
return vec![];
⋮----
fn check_vote_account(
⋮----
.get_account_with_commitment(vote_account_address, CommitmentConfig::confirmed())
.map_err(|err| format!("failed to fetch vote account: {err}"))?
⋮----
.ok_or_else(|| format!("vote account does not exist: {vote_account_address}"))?;
⋮----
return Err(format!(
⋮----
.get_account_with_commitment(identity_pubkey, CommitmentConfig::confirmed())
.map_err(|err| format!("failed to fetch identity account: {err}"))?
⋮----
.ok_or_else(|| format!("identity account does not exist: {identity_pubkey}"))?;
let vote_state = VoteStateV4::deserialize(vote_account.data(), vote_account_address).ok();
⋮----
if vote_state.authorized_voters.is_empty() {
return Err("Vote account not yet initialized".to_string());
⋮----
for (_, vote_account_authorized_voter_pubkey) in vote_state.authorized_voters.iter() {
if !authorized_voter_pubkeys.contains(vote_account_authorized_voter_pubkey) {
⋮----
Ok(())
⋮----
pub enum GetRpcNodeError {
⋮----
struct GetRpcNodeResult {
⋮----
struct PeerSnapshotHash {
⋮----
pub struct SnapshotHash {
⋮----
pub fn fail_rpc_node(
⋮----
warn!("{err}");
⋮----
if known_validators.contains(rpc_id) {
⋮----
info!("Excluding {rpc_id} as a future RPC candidate");
blacklisted_rpc_nodes.insert(*rpc_id);
⋮----
fn shutdown_gossip_service(gossip: (Arc<ClusterInfo>, Arc<AtomicBool>, GossipService)) {
⋮----
cluster_info.save_contact_info();
gossip_exit_flag.store(true, Ordering::Relaxed);
gossip_service.join().unwrap();
⋮----
pub fn attempt_download_genesis_and_snapshot(
⋮----
download_then_check_genesis_hash(
⋮----
.rpc()
.ok_or_else(|| String::from("Invalid RPC address"))?,
⋮----
if let Some(gossip) = gossip.take() {
shutdown_gossip_service(gossip);
⋮----
.get_slot_with_commitment(CommitmentConfig::finalized())
.map_err(|err| format!("Failed to get RPC node slot: {err}"))?;
info!("RPC node root slot: {rpc_client_slot}");
download_snapshots(
⋮----
if let Some(url) = bootstrap_config.check_vote_account.as_ref() {
⋮----
check_vote_account(
⋮----
&identity_keypair.pubkey(),
⋮----
.read()
.unwrap()
⋮----
.map(|k| k.pubkey())
⋮----
.unwrap_or_else(|err| {
error!("{err}");
⋮----
fn ping(addr: &SocketAddr) -> Option<Duration> {
⋮----
Ok(_) => Some(start.elapsed()),
⋮----
fn get_vetted_rpc_nodes(
⋮----
while vetted_rpc_nodes.is_empty() {
let rpc_node_details = match get_rpc_nodes(
⋮----
error!(
⋮----
vetted_rpc_nodes.extend(
⋮----
.into_par_iter()
.filter_map(|rpc_node_details| {
⋮----
let rpc_addr = rpc_contact_info.rpc()?;
let ping_time = ping(&rpc_addr);
⋮----
Some((rpc_contact_info, snapshot_hash, rpc_client, ping_time))
⋮----
.filter(
⋮----
.get_version()
⋮----
fail_rpc_node(
"Failed to ping RPC".to_string(),
⋮----
rpc_contact_info.pubkey(),
&mut newly_blacklisted_rpc_nodes.write().unwrap(),
⋮----
format!("Failed to get RPC node version: {err}"),
⋮----
.sorted_by_key(|(_, _, _, ping_time)| ping_time.unwrap())
.map(|(rpc_contact_info, snapshot_hash, rpc_client, _)| {
⋮----
blacklisted_rpc_nodes.extend(newly_blacklisted_rpc_nodes.into_inner().unwrap());
⋮----
pub fn rpc_bootstrap(
⋮----
let mut order: Vec<_> = (0..cluster_entrypoints.len()).collect();
order.shuffle(&mut rng());
if order.into_iter().all(|i| {
!verify_reachable_ports(
⋮----
let mut vetted_rpc_nodes = vec![];
⋮----
if gossip.is_none() {
*start_progress.write().unwrap() = ValidatorStartProgress::SearchingForRpcService;
gossip = Some(start_gossip_node(
identity_keypair.clone(),
⋮----
.gossip()
.expect("Operator must spin up node with valid gossip address"),
node.sockets.gossip.clone(),
⋮----
.expect("expected_shred_version should not be None"),
validator_config.gossip_validators.clone(),
⋮----
get_vetted_rpc_nodes(
⋮----
&gossip.as_ref().unwrap().0,
⋮----
let (rpc_contact_info, snapshot_hash, rpc_client) = vetted_rpc_nodes.pop().unwrap();
get_rpc_nodes_time += get_rpc_nodes_start.elapsed();
⋮----
let download_result = attempt_download_genesis_and_snapshot(
⋮----
authorized_voter_keypairs.clone(),
⋮----
snapshot_download_time += snapshot_download_start.elapsed();
⋮----
datapoint_info!(
⋮----
fn get_rpc_nodes(
⋮----
info!("\n{}", cluster_info.rpc_info_trace());
let rpc_peers = get_rpc_peers(
⋮----
if rpc_peers.is_empty() {
if get_rpc_peers_timout.elapsed() > GET_RPC_PEERS_TIMEOUT {
return Err(GetRpcNodeError::NoRpcPeersFound);
⋮----
let random_peer = &rpc_peers[rng().random_range(0..rpc_peers.len())];
return Ok(vec![GetRpcNodeResult {
⋮----
.as_ref()
.map(|timer: &Instant| timer.elapsed() < WAIT_FOR_ALL_KNOWN_VALIDATORS)
.unwrap_or(true)
⋮----
let peer_snapshot_hashes = get_peer_snapshot_hashes(
⋮----
validator_config.known_validators.as_ref(),
⋮----
if peer_snapshot_hashes.is_empty() {
⋮----
None => newer_cluster_snapshot_timeout = Some(Instant::now()),
⋮----
if newer_cluster_snapshot_timeout.elapsed() > NEWER_SNAPSHOT_THRESHOLD {
return Err(GetRpcNodeError::NoNewerSnapshots);
⋮----
retry_reason = Some("No snapshots available".to_owned());
⋮----
.map(|peer_snapshot_hash| peer_snapshot_hash.rpc_contact_info.pubkey())
⋮----
.map(|peer_snapshot_hash| GetRpcNodeResult {
rpc_contact_info: peer_snapshot_hash.rpc_contact_info.clone(),
snapshot_hash: Some(peer_snapshot_hash.snapshot_hash),
⋮----
.take(MAX_RPC_CONNECTIONS_EVALUATED_PER_ITERATION)
⋮----
return Ok(rpc_node_results);
⋮----
/// Get the Slot and Hash of the local snapshot with the highest slot.  Can be either a full
/// snapshot or an incremental snapshot.
⋮----
/// snapshot or an incremental snapshot.
fn get_highest_local_snapshot_hash(
⋮----
fn get_highest_local_snapshot_hash(
⋮----
.and_then(|full_snapshot_info| {
⋮----
full_snapshot_info.slot(),
⋮----
.map(|incremental_snapshot_info| {
⋮----
incremental_snapshot_info.slot(),
*incremental_snapshot_info.hash(),
⋮----
.or_else(|| Some((full_snapshot_info.slot(), *full_snapshot_info.hash())))
⋮----
.map(|(slot, snapshot_hash)| (slot, snapshot_hash.0))
⋮----
/// Get peer snapshot hashes
///
⋮----
///
/// The result is a vector of peers with snapshot hashes that:
⋮----
/// The result is a vector of peers with snapshot hashes that:
/// 1. match a snapshot hash from the known validators
⋮----
/// 1. match a snapshot hash from the known validators
/// 2. have the highest incremental snapshot slot
⋮----
/// 2. have the highest incremental snapshot slot
/// 3. have the highest full snapshot slot of (2)
⋮----
/// 3. have the highest full snapshot slot of (2)
fn get_peer_snapshot_hashes(
⋮----
fn get_peer_snapshot_hashes(
⋮----
let mut peer_snapshot_hashes = get_eligible_peer_snapshot_hashes(cluster_info, rpc_peers);
⋮----
let known_snapshot_hashes = get_snapshot_hashes_from_known_validators(
⋮----
retain_peer_snapshot_hashes_that_match_known_snapshot_hashes(
⋮----
// Only filter by highest incremental snapshot slot if we're actually going to download an
// incremental snapshot.  Otherwise this could remove higher full snapshot slots from
// being selected.  For example, if there are two peer snapshot hashes:
// (A) full snapshot slot: 100, incremental snapshot slot: 160
// (B) full snapshot slot: 150, incremental snapshot slot: None
// Then (A) has the highest overall snapshot slot.  But if we're not downloading and
// incremental snapshot, (B) should be selected since it's full snapshot of 150 is highest.
retain_peer_snapshot_hashes_with_highest_incremental_snapshot_slot(
⋮----
retain_peer_snapshot_hashes_with_highest_full_snapshot_slot(&mut peer_snapshot_hashes);
⋮----
/// Map full snapshot hashes to a set of incremental snapshot hashes.  Each full snapshot hash
/// is treated as the base for its set of incremental snapshot hashes.
⋮----
/// is treated as the base for its set of incremental snapshot hashes.
type KnownSnapshotHashes = HashMap<(Slot, Hash), HashSet<(Slot, Hash)>>;
⋮----
type KnownSnapshotHashes = HashMap<(Slot, Hash), HashSet<(Slot, Hash)>>;
/// Get the snapshot hashes from known validators.
///
⋮----
///
/// The snapshot hashes are put into a map from full snapshot hash to a set of incremental
⋮----
/// The snapshot hashes are put into a map from full snapshot hash to a set of incremental
/// snapshot hashes.  This map will be used as the "known snapshot hashes"; when peers are
⋮----
/// snapshot hashes.  This map will be used as the "known snapshot hashes"; when peers are
fn get_snapshot_hashes_from_known_validators(
⋮----
fn get_snapshot_hashes_from_known_validators(
⋮----
let get_snapshot_hashes_for_node = |node| get_snapshot_hashes_for_node(cluster_info, node);
if !do_known_validators_have_all_snapshot_hashes(
⋮----
debug!(
⋮----
build_known_snapshot_hashes(known_validators, get_snapshot_hashes_for_node)
⋮----
fn do_known_validators_have_all_snapshot_hashes<'a>(
⋮----
let node_has_snapshot_hashes = |node| get_snapshot_hashes_for_node(node).is_some();
⋮----
KnownValidatorsToWaitFor::All => known_validators.into_iter().all(node_has_snapshot_hashes),
KnownValidatorsToWaitFor::Any => known_validators.into_iter().any(node_has_snapshot_hashes),
⋮----
/// When waiting for snapshot hashes from the known validators, should we wait for *all* or *any*
/// of them?
⋮----
/// of them?
#[derive(Debug, Copy, Clone, Eq, PartialEq)]
enum KnownValidatorsToWaitFor {
⋮----
/// Build the known snapshot hashes from a set of nodes.
///
⋮----
///
/// The `get_snapshot_hashes_for_node` parameter is a function that map a pubkey to its snapshot
⋮----
/// The `get_snapshot_hashes_for_node` parameter is a function that map a pubkey to its snapshot
/// hashes.  This parameter exist to provide a way to test the inner algorithm without needing
⋮----
/// hashes.  This parameter exist to provide a way to test the inner algorithm without needing
/// runtime information such as the ClusterInfo or ValidatorConfig.
⋮----
/// runtime information such as the ClusterInfo or ValidatorConfig.
fn build_known_snapshot_hashes<'a>(
⋮----
fn build_known_snapshot_hashes<'a>(
⋮----
fn is_any_same_slot_and_different_hash<'a>(
⋮----
.any(|hay| needle.0 == hay.0 && needle.1 != hay.1)
⋮----
}) = get_snapshot_hashes_for_node(node)
⋮----
if is_any_same_slot_and_different_hash(&full_snapshot_hash, known_snapshot_hashes.keys()) {
warn!(
⋮----
// Insert a new full snapshot hash into the known snapshot hashes IFF an entry
// doesn't already exist.  This is to ensure we don't overwrite existing
⋮----
known_snapshot_hashes.entry(full_snapshot_hash).or_default();
⋮----
if is_any_same_slot_and_different_hash(
⋮----
known_incremental_snapshot_hashes.iter(),
⋮----
known_incremental_snapshot_hashes.insert(incremental_snapshot_hash);
⋮----
trace!("known snapshot hashes: {known_snapshot_hashes:?}");
⋮----
/// Get snapshot hashes from all eligible peers.
///
⋮----
///
/// This fn will get only one snapshot hash per peer (the one with the highest slot).
⋮----
/// This fn will get only one snapshot hash per peer (the one with the highest slot).
/// This may be just a full snapshot hash, or a combo full snapshot hash and
⋮----
/// This may be just a full snapshot hash, or a combo full snapshot hash and
/// incremental snapshot hash.
⋮----
/// incremental snapshot hash.
fn get_eligible_peer_snapshot_hashes(
⋮----
fn get_eligible_peer_snapshot_hashes(
⋮----
.flat_map(|rpc_peer| {
get_snapshot_hashes_for_node(cluster_info, rpc_peer.pubkey()).map(|snapshot_hash| {
⋮----
rpc_contact_info: rpc_peer.clone(),
⋮----
trace!("peer snapshot hashes: {peer_snapshot_hashes:?}");
⋮----
/// Retain the peer snapshot hashes that match a snapshot hash from the known snapshot hashes
fn retain_peer_snapshot_hashes_that_match_known_snapshot_hashes(
⋮----
fn retain_peer_snapshot_hashes_that_match_known_snapshot_hashes(
⋮----
peer_snapshot_hashes.retain(|peer_snapshot_hash| {
⋮----
.get(&peer_snapshot_hash.snapshot_hash.full)
.map(|known_incremental_hashes| {
if peer_snapshot_hash.snapshot_hash.incr.is_none() {
// If the peer's full snapshot hashes match, but doesn't have any
⋮----
.contains(peer_snapshot_hash.snapshot_hash.incr.as_ref().unwrap())
⋮----
.unwrap_or(false)
⋮----
trace!(
⋮----
fn retain_peer_snapshot_hashes_with_highest_full_snapshot_slot(
⋮----
.map(|peer_snapshot_hash| peer_snapshot_hash.snapshot_hash.full)
.max_by_key(|(slot, _hash)| *slot);
⋮----
trace!("retain peer snapshot hashes with highest full snapshot slot: {peer_snapshot_hashes:?}");
⋮----
fn retain_peer_snapshot_hashes_with_highest_incremental_snapshot_slot(
⋮----
.flat_map(|peer_snapshot_hash| peer_snapshot_hash.snapshot_hash.incr)
⋮----
fn download_snapshots(
⋮----
if snapshot_hash.is_none() {
return Ok(());
⋮----
} = snapshot_hash.unwrap();
⋮----
if should_use_local_snapshot(
⋮----
.any(|snapshot_archive| {
snapshot_archive.slot() == full_snapshot_hash.0
&& snapshot_archive.hash().0 == full_snapshot_hash.1
⋮----
download_snapshot(
⋮----
snapshot_archive.slot() == incremental_snapshot_hash.0
&& snapshot_archive.hash().0 == incremental_snapshot_hash.1
&& snapshot_archive.base_slot() == full_snapshot_hash.0
⋮----
fn download_snapshot(
⋮----
*start_progress.write().unwrap() = ValidatorStartProgress::DownloadingSnapshot {
⋮----
download_snapshot_archive(
⋮----
&mut Some(Box::new(|download_progress: &DownloadProgressRecord| {
debug!("Download progress: {download_progress:?}");
⋮----
if known_validators.contains(rpc_contact_info.pubkey())
&& known_validators.len() == 1
⋮----
fn should_use_local_snapshot(
⋮----
.map(|(slot, _)| slot)
.unwrap_or(full_snapshot_hash.0);
match get_highest_local_snapshot_hash(
⋮----
>= cluster_snapshot_slot.saturating_sub(maximum_local_snapshot_age)
⋮----
fn get_snapshot_hashes_for_node(cluster_info: &ClusterInfo, node: &Pubkey) -> Option<SnapshotHash> {
cluster_info.get_snapshot_hashes_for_node(node).map(
⋮----
let highest_incremental_snapshot_hash = incremental.into_iter().max();
⋮----
mod tests {
⋮----
impl PeerSnapshotHash {
fn new(
⋮----
fn default_contact_info_for_tests() -> ContactInfo {
⋮----
fn test_build_known_snapshot_hashes() {
⋮----
(full_snapshot_hash1, Some(incremental_snapshot_hash1)),
(full_snapshot_hash1, Some(incremental_snapshot_hash2)),
⋮----
(full_snapshot_hash2, Some(incremental_snapshot_hash1)),
(full_snapshot_hash2, Some(incremental_snapshot_hash2)),
⋮----
oracle.insert(Pubkey::new_unique(), Some(SnapshotHash { full, incr }));
⋮----
oracle.insert(Pubkey::new_unique(), None);
⋮----
let node_to_snapshot_hashes = |node| *oracle.get(node).unwrap();
⋮----
build_known_snapshot_hashes(oracle.keys(), node_to_snapshot_hashes);
let known_full_snapshot_hashes = known_snapshot_hashes.keys();
assert_eq!(known_full_snapshot_hashes.len(), 1);
let known_full_snapshot_hash = known_full_snapshot_hashes.into_iter().next().unwrap();
⋮----
known_snapshot_hashes.get(known_full_snapshot_hash).unwrap();
assert_eq!(known_incremental_snapshot_hashes.len(), 1);
⋮----
known_incremental_snapshot_hashes.iter().next().unwrap();
assert!(
⋮----
fn test_retain_peer_snapshot_hashes_that_match_known_snapshot_hashes() {
⋮----
.cloned()
.collect(),
⋮----
let known_snapshot_hash = known_snapshot_hashes.iter().next().unwrap();
⋮----
let known_incremental_snapshot_hash = known_snapshot_hash.1.iter().next().unwrap();
let contact_info = default_contact_info_for_tests();
let peer_snapshot_hashes = vec![
⋮----
let expected = vec![
⋮----
assert_eq!(expected, actual);
⋮----
fn test_retain_peer_snapshot_hashes_with_highest_full_snapshot_slot() {
⋮----
retain_peer_snapshot_hashes_with_highest_full_snapshot_slot(&mut actual);
⋮----
fn test_retain_peer_snapshot_hashes_with_highest_incremental_snapshot_slot_some() {
⋮----
let expected = vec![PeerSnapshotHash::new(
⋮----
retain_peer_snapshot_hashes_with_highest_incremental_snapshot_slot(&mut actual);
⋮----
fn test_retain_peer_snapshot_hashes_with_highest_incremental_snapshot_slot_none() {
⋮----
let expected = peer_snapshot_hashes.clone();
⋮----
fn test_retain_peer_snapshot_hashes_with_highest_slot_empty() {
⋮----
let mut actual = vec![];
let expected = actual.clone();

================
File: validator/src/cli.rs
================
pub mod thread_args;
⋮----
pub fn app<'a>(version: &'a str, default_args: &'a DefaultArgs) -> App<'a, 'a> {
let app = App::new(crate_name!())
.about(crate_description!())
.version(version)
.global_setting(AppSettings::ColoredHelp)
.global_setting(AppSettings::InferSubcommands)
.global_setting(AppSettings::UnifiedHelpMessage)
.global_setting(AppSettings::VersionlessSubcommands)
.subcommand(commands::exit::command())
.subcommand(commands::authorized_voter::command())
.subcommand(commands::contact_info::command())
.subcommand(commands::repair_shred_from_peer::command())
.subcommand(commands::repair_whitelist::command())
.subcommand(
SubCommand::with_name("init").about("Initialize the ledger directory then exit"),
⋮----
.subcommand(commands::monitor::command())
.subcommand(SubCommand::with_name("run").about("Run the validator"))
.subcommand(commands::plugin::command())
.subcommand(commands::set_identity::command())
.subcommand(commands::set_log_filter::command())
.subcommand(commands::staked_nodes_overrides::command())
.subcommand(commands::wait_for_restart_window::command())
.subcommand(commands::set_public_address::command())
.subcommand(commands::manage_block_production::command(default_args))
// bam subcommands
.subcommand(commands::bam::command(default_args))
// jito subcommands
.subcommand(commands::block_engine::command(default_args))
.subcommand(commands::relayer::command(default_args))
.subcommand(commands::shred::shred_receiver_command(default_args))
.subcommand(commands::shred::shred_retransmit_receiver_command(
⋮----
.args(&thread_args(&default_args.thread_args))
.args(&get_deprecated_arguments())
.after_help("The default subcommand is run")
⋮----
/// Deprecated argument description should be moved into the [`deprecated_arguments()`] function,
/// expressed as an instance of this type.
⋮----
/// expressed as an instance of this type.
struct DeprecatedArg {
⋮----
struct DeprecatedArg {
/// Deprecated argument description, moved here as is.
    ///
⋮----
///
    /// `hidden` property will be modified by [`deprecated_arguments()`] to only show this argument
⋮----
/// `hidden` property will be modified by [`deprecated_arguments()`] to only show this argument
    /// if [`hidden_unless_forced()`] says they should be displayed.
⋮----
/// if [`hidden_unless_forced()`] says they should be displayed.
    arg: Arg<'static, 'static>,
/// If simply replaced by a different argument, this is the name of the replacement.
    ///
⋮----
///
    /// Content should be an argument name, as presented to users.
⋮----
/// Content should be an argument name, as presented to users.
    replaced_by: Option<&'static str>,
⋮----
fn deprecated_arguments() -> Vec<DeprecatedArg> {
let mut res = vec![];
// This macro reduces indentation and removes some noise from the argument declaration list.
macro_rules! add_arg {
⋮----
add_arg!(
// deprecated in v3.1.1
⋮----
// deprecated in v3.1.3
⋮----
// deprecated in v3.1.0
⋮----
// Helper to add arguments that are no longer used but are being kept around to avoid breaking
// validator startup commands.
fn get_deprecated_arguments() -> Vec<Arg<'static, 'static>> {
deprecated_arguments()
.into_iter()
.map(|info| {
⋮----
// Hide all deprecated arguments by default.
arg.hidden(hidden_unless_forced())
⋮----
.collect()
⋮----
pub fn warn_for_deprecated_arguments(matches: &ArgMatches) {
⋮----
} in deprecated_arguments().into_iter()
⋮----
if matches.is_present(arg.b.name) {
let mut msg = format!("--{} is deprecated", arg.b.name.replace('_', "-"));
⋮----
msg.push_str(&format!(", please use --{replaced_by}"));
⋮----
msg.push('.');
⋮----
msg.push_str(&format!("  {usage_warning}"));
if !msg.ends_with('.') {
⋮----
eprintln!("{msg}");
⋮----
pub struct DefaultArgs {
⋮----
impl DefaultArgs {
pub fn new() -> Self {
⋮----
bind_address: "0.0.0.0".to_string(),
ledger_path: "ledger".to_string(),
dynamic_port_range: format!("{}-{}", VALIDATOR_PORT_RANGE.0, VALIDATOR_PORT_RANGE.1),
maximum_local_snapshot_age: "2500".to_string(),
tower_storage: "file".to_string(),
⋮----
.to_string(),
⋮----
DEFAULT_MAX_INCREMENTAL_SNAPSHOT_ARCHIVES_TO_RETAIN.to_string(),
snapshot_packager_niceness_adjustment: "0".to_string(),
⋮----
.get()
⋮----
min_snapshot_download_speed: DEFAULT_MIN_SNAPSHOT_DOWNLOAD_SPEED.to_string(),
max_snapshot_download_abort: MAX_SNAPSHOT_DOWNLOAD_ABORT.to_string(),
snapshot_archive_format: DEFAULT_ARCHIVE_COMPRESSION.to_string(),
snapshot_zstd_compression_level: "1".to_string(),
contact_debug_interval: "120000".to_string(),
⋮----
accounts_shrink_ratio: DEFAULT_ACCOUNTS_SHRINK_RATIO.to_string(),
tpu_connection_pool_size: DEFAULT_TPU_CONNECTION_POOL_SIZE.to_string(),
⋮----
DEFAULT_MAX_CONNECTIONS_PER_IPADDR_PER_MINUTE.to_string(),
vote_use_quic: DEFAULT_VOTE_USE_QUIC.to_string(),
⋮----
tpu_max_staked_connections: DEFAULT_MAX_STAKED_CONNECTIONS.to_string(),
tpu_max_unstaked_connections: DEFAULT_MAX_UNSTAKED_CONNECTIONS.to_string(),
⋮----
.saturating_add(DEFAULT_MAX_UNSTAKED_CONNECTIONS)
⋮----
tpu_max_fwd_unstaked_connections: 0.to_string(),
tpu_max_streams_per_ms: DEFAULT_MAX_STREAMS_PER_MS.to_string(),
num_quic_endpoints: DEFAULT_QUIC_ENDPOINTS.to_string(),
banking_trace_dir_byte_limit: BANKING_TRACE_DIR_DEFAULT_BYTE_LIMIT.to_string(),
⋮----
wen_restart_path: "wen_restart_progress.proto".to_string(),
⋮----
relayer_max_failed_heartbeats: DEFAULT_RELAYER_MAX_FAILED_HEARTBEATS.to_string(),
⋮----
impl Default for DefaultArgs {
fn default() -> Self {
⋮----
pub fn port_validator(port: String) -> Result<(), String> {
⋮----
.map(|_| ())
.map_err(|e| format!("{e:?}"))
⋮----
pub fn port_range_validator(port_range: String) -> Result<(), String> {
⋮----
Err(format!(
⋮----
Ok(())
⋮----
Err("Invalid port range".to_string())
⋮----
pub(crate) fn hash_validator(hash: String) -> Result<(), String> {
⋮----
pub fn test_app<'a>(version: &'a str, default_args: &'a DefaultTestArgs) -> App<'a, 'a> {
⋮----
.about("Test Validator")
⋮----
.arg({
⋮----
.short("C")
.long("config")
.value_name("PATH")
.takes_value(true)
.help("Configuration file to use");
⋮----
arg.default_value(config_file)
⋮----
.arg(
⋮----
.short("u")
.long("url")
.value_name("URL_OR_MONIKER")
⋮----
.validator(is_url_or_moniker)
.help(
⋮----
.long("mint")
.value_name("PUBKEY")
.validator(is_pubkey)
⋮----
.short("l")
.long("ledger")
.value_name("DIR")
⋮----
.required(true)
.default_value("test-ledger")
.help("Use DIR as ledger location"),
⋮----
.short("r")
.long("reset")
.takes_value(false)
⋮----
.short("q")
.long("quiet")
⋮----
.conflicts_with("log")
.help("Quiet mode: suppress normal output"),
⋮----
.long("log")
⋮----
.conflicts_with("quiet")
.help("Log mode: stream the validator log"),
⋮----
.long("account-index")
⋮----
.multiple(true)
.possible_values(&["program-id", "spl-token-owner", "spl-token-mint"])
.value_name("INDEX")
.help("Enable an accounts index, indexed by the selected account field"),
⋮----
.long("faucet-port")
.value_name("PORT")
⋮----
.default_value(&default_args.faucet_port)
.validator(port_validator)
.help("Enable the faucet on this port"),
⋮----
.long("rpc-port")
⋮----
.default_value(&default_args.rpc_port)
⋮----
.help("Enable JSON RPC on this port, and the next port for the RPC websocket"),
⋮----
.long("enable-rpc-bigtable-ledger-storage")
⋮----
.hidden(hidden_unless_forced())
⋮----
.long("enable-bigtable-ledger-upload")
⋮----
.help("Upload new confirmed blocks into a BigTable instance"),
⋮----
.long("rpc-bigtable-instance")
.value_name("INSTANCE_NAME")
⋮----
.default_value("solana-ledger")
.help("Name of BigTable instance to target"),
⋮----
.long("rpc-bigtable-app-profile-id")
.value_name("APP_PROFILE_ID")
⋮----
.default_value(solana_storage_bigtable::DEFAULT_APP_PROFILE_ID)
.help("Application profile id to use in Bigtable requests"),
⋮----
.long("bpf-program")
.value_names(&["ADDRESS_OR_KEYPAIR", "SBF_PROGRAM.SO"])
⋮----
.number_of_values(2)
⋮----
.long("upgradeable-program")
.value_names(&["ADDRESS_OR_KEYPAIR", "SBF_PROGRAM.SO", "UPGRADE_AUTHORITY"])
⋮----
.number_of_values(3)
⋮----
.long("account")
.value_names(&["ADDRESS", "DUMP.JSON"])
⋮----
.allow_hyphen_values(true)
⋮----
.long("account-dir")
.value_name("DIRECTORY")
.validator(|value| {
⋮----
.map_err(|err| format!("error parsing '{value}': {err}"))
.and_then(|path| {
if path.exists() && path.is_dir() {
⋮----
.long("ticks-per-slot")
.value_name("TICKS")
⋮----
.and_then(|ticks| {
⋮----
Err(format!("value must be >= {MINIMUM_TICKS_PER_SLOT}"))
⋮----
.help("The number of ticks in a slot"),
⋮----
.long("slots-per-epoch")
.value_name("SLOTS")
⋮----
.and_then(|slot| {
⋮----
Err(format!("value must be >= {MINIMUM_SLOTS_PER_EPOCH}"))
⋮----
.long("inflation-fixed")
.value_name("RATE")
⋮----
.and_then(|rate| match rate.partial_cmp(&0.0) {
Some(Ordering::Greater) | Some(Ordering::Equal) => Ok(()),
Some(Ordering::Less) | None => Err(String::from("value must be >= 0")),
⋮----
.long("gossip-port")
⋮----
.help("Gossip port number for the validator"),
⋮----
.long("dynamic-port-range")
.value_name("MIN_PORT-MAX_PORT")
⋮----
.validator(port_range_validator)
.help("Range to use for dynamically assigned ports [default: 1024-65535]"),
⋮----
.long("bind-address")
.value_name("HOST")
⋮----
.validator(solana_net_utils::is_host)
.default_value("127.0.0.1")
⋮----
.long("advertised-ip")
⋮----
.long("clone")
.short("c")
.value_name("ADDRESS")
⋮----
.validator(is_pubkey_or_keypair)
⋮----
.requires("json_rpc_url")
⋮----
.long("deep-clone-address-lookup-table")
⋮----
.long("maybe-clone")
⋮----
.long("clone-upgradeable-program")
⋮----
.required(false)
.long("warp-slot")
.short("w")
⋮----
.value_name("WARP_SLOT")
.validator(is_slot)
.min_values(0)
.max_values(1)
⋮----
.long("limit-ledger-size")
.value_name("SHRED_COUNT")
⋮----
.default_value(default_args.limit_ledger_size.as_str())
.help("Keep this amount of shreds in root slots."),
⋮----
.long("faucet-sol")
⋮----
.value_name("SOL")
.default_value(default_args.faucet_sol.as_str())
⋮----
.long("faucet-time-slice-secs")
⋮----
.value_name("SECS")
.default_value(default_args.faucet_time_slice_secs.as_str())
.help("Time slice (in secs) over which to limit faucet requests"),
⋮----
.long("faucet-per-time-sol-cap")
⋮----
.help("Per-time slice limit for faucet requests, in SOL"),
⋮----
.long("faucet-per-request-sol-cap")
⋮----
.help("Per-request limit for faucet requests, in SOL"),
⋮----
.long("geyser-plugin-config")
.alias("accountsdb-plugin-config")
.value_name("FILE")
⋮----
.help("Specify the configuration file for the Geyser plugin."),
⋮----
.long("enable-scheduler-bindings")
⋮----
.help("Enables external processes to connect and manage block production"),
⋮----
.long("deactivate-feature")
⋮----
.value_name("FEATURE_PUBKEY")
⋮----
.help("deactivate this feature in genesis."),
⋮----
.long("compute-unit-limit")
.alias("max-compute-units")
.value_name("COMPUTE_UNITS")
.validator(is_parsable::<u64>)
⋮----
.help("Override the runtime's compute unit limit per transaction"),
⋮----
.long("log-messages-bytes-limit")
.value_name("BYTES")
.validator(is_parsable::<usize>)
⋮----
.help("Maximum number of bytes written to the program log before truncation"),
⋮----
.long("transaction-account-lock-limit")
.value_name("NUM_ACCOUNTS")
⋮----
.help("Override the runtime's account lock limit per transaction"),
⋮----
.long("clone-feature-set")
⋮----
.args(&pub_sub_config::args( true))
.arg(commands::bam::argument())
⋮----
pub struct DefaultTestArgs {
⋮----
impl DefaultTestArgs {
⋮----
rpc_port: 8899.to_string(),
faucet_port: FAUCET_PORT.to_string(),
limit_ledger_size: 10_000.to_string(),
faucet_sol: (1_000_000.).to_string(),
faucet_time_slice_secs: (faucet::TIME_SLICE).to_string(),
⋮----
impl Default for DefaultTestArgs {
⋮----
mod test {
⋮----
fn make_sure_deprecated_arguments_are_sorted_alphabetically() {
let deprecated = deprecated_arguments();
for i in 0..deprecated.len().saturating_sub(1) {
⋮----
assert!(

================
File: validator/src/dashboard.rs
================
pub struct Dashboard {
⋮----
impl Dashboard {
pub fn new(
⋮----
println_name_value("Ledger location:", &format!("{}", ledger_path.display()));
⋮----
println_name_value("Log:", &format!("{}", log_path.display()));
⋮----
let progress_bar = new_spinner_progress_bar();
progress_bar.set_message("Initializing...");
⋮----
let exit = exit.clone();
validator_exit.register_exit(Box::new(move || exit.store(true, Ordering::Relaxed)));
⋮----
ledger_path: ledger_path.to_path_buf(),
⋮----
pub fn run(self, refresh_interval: Duration) {
⋮----
drop(progress_bar);
⋮----
while !exit.load(Ordering::Relaxed) {
⋮----
progress_bar.set_message("Connecting...");
let Some((rpc_addr, start_time)) = runtime.block_on(wait_for_validator_startup(
⋮----
let mut identity = match rpc_client.get_identity() {
⋮----
println!("Failed to get validator identity over RPC: {err}");
⋮----
println_name_value("Identity:", &identity.to_string());
if let Ok(genesis_hash) = rpc_client.get_genesis_hash() {
println_name_value("Genesis Hash:", &genesis_hash.to_string());
⋮----
if let Some(contact_info) = get_contact_info(&rpc_client, &identity) {
println_name_value(
⋮----
&contact_info.version.unwrap_or_else(|| "?".to_string()),
⋮----
println_name_value("Shred Version:", &shred_version.to_string());
⋮----
println_name_value("Gossip Address:", &gossip.to_string());
⋮----
println_name_value("TPU Address:", &tpu.to_string());
⋮----
println_name_value("JSON RPC URL:", &format!("http://{rpc}"));
⋮----
println_name_value("WebSocket PubSub URL:", &format!("ws://{pubsub}"));
⋮----
if exit.load(Ordering::Relaxed) {
⋮----
snapshot_slot_info = rpc_client.get_highest_snapshot_slot().ok();
⋮----
let new_identity = rpc_client.get_identity().unwrap_or(identity);
⋮----
progress_bar.println(format_name_value("Identity:", &identity.to_string()));
⋮----
match get_validator_stats(&rpc_client, &identity) {
⋮----
chrono::Duration::from_std(start_time.elapsed().unwrap()).unwrap();
format!(
⋮----
progress_bar.set_message(format!(
⋮----
progress_bar.abandon_with_message(format!("RPC connection failure: {err}"));
⋮----
async fn wait_for_validator_startup(
⋮----
if admin_client.is_none() {
⋮----
Ok(new_admin_client) => admin_client = Some(new_admin_client),
⋮----
progress_bar.set_message(format!("Unable to connect to validator: {err}"));
⋮----
match admin_client.as_ref().unwrap().start_progress().await {
⋮----
let admin_client = admin_client.take().unwrap();
⋮----
let rpc_addr = admin_client.rpc_addr().await?;
let start_time = admin_client.start_time().await?;
⋮----
Ok((None, _)) => progress_bar.set_message("RPC service not available"),
Ok((Some(rpc_addr), start_time)) => return Some((rpc_addr, start_time)),
⋮----
.set_message(format!("Failed to get validator info: {err}"));
⋮----
progress_bar.set_message(format!("Validator startup: {start_progress:?}..."));
⋮----
progress_bar.set_message(format!("Failed to get validator start progress: {err}"));
⋮----
fn get_contact_info(rpc_client: &RpcClient, identity: &Pubkey) -> Option<RpcContactInfo> {
⋮----
.get_cluster_nodes()
.ok()
.unwrap_or_default()
.into_iter()
.find(|node| node.pubkey == identity.to_string())
⋮----
fn get_validator_stats(
⋮----
let finalized_slot = rpc_client.get_slot_with_commitment(CommitmentConfig::finalized())?;
let confirmed_slot = rpc_client.get_slot_with_commitment(CommitmentConfig::confirmed())?;
let processed_slot = rpc_client.get_slot_with_commitment(CommitmentConfig::processed())?;
⋮----
rpc_client.get_transaction_count_with_commitment(CommitmentConfig::processed())?;
⋮----
.get_balance_with_commitment(identity, CommitmentConfig::confirmed())?
⋮----
let health = match rpc_client.get_health() {
Ok(()) => "ok".to_string(),
⋮----
}) = err.kind()
⋮----
format!("{num_slots_behind} slots behind")
⋮----
"health unknown".to_string()
⋮----
Ok((
⋮----
Sol(identity_balance),

================
File: validator/src/lib.rs
================
pub mod admin_rpc_service;
pub mod bootstrap;
pub mod cli;
pub mod commands;
pub mod dashboard;
pub fn format_name_value(name: &str, value: &str) -> String {
format!("{} {}", style(name).bold(), value)
⋮----
pub fn println_name_value(name: &str, value: &str) {
println!("{}", format_name_value(name, value));
⋮----
pub fn new_spinner_progress_bar() -> ProgressBar {
⋮----
progress_bar.set_draw_target(ProgressDrawTarget::stdout());
progress_bar.set_style(
⋮----
.template("{spinner:.green} {wide_msg}")
.expect("ProgresStyle::template direct input to be correct"),
⋮----
progress_bar.enable_steady_tick(Duration::from_millis(100));
⋮----
is_term: console::Term::stdout().is_term(),
⋮----
pub struct ProgressBar {
⋮----
impl ProgressBar {
pub fn set_message<T: Into<Cow<'static, str>> + Display>(&self, msg: T) {
⋮----
self.progress_bar.set_message(msg);
⋮----
println!("{msg}");
⋮----
pub fn println<I: AsRef<str>>(&self, msg: I) {
self.progress_bar.println(msg);
⋮----
pub fn abandon_with_message<T: Into<Cow<'static, str>> + Display>(&self, msg: T) {
⋮----
self.progress_bar.abandon_with_message(msg);
⋮----
pub fn ledger_lockfile(ledger_path: &Path) -> RwLock<File> {
let lockfile = ledger_path.join("ledger.lock");
⋮----
.write(true)
.create(true)
.truncate(false)
.open(lockfile)
.unwrap(),
⋮----
pub fn lock_ledger<'lock>(
⋮----
ledger_lockfile.try_write().unwrap_or_else(|_| {
println!(
⋮----
exit(1);

================
File: validator/src/main.rs
================
use jemallocator::Jemalloc;
⋮----
pub fn main() {
⋮----
let cli_app = app(solana_version, &default_args);
let matches = cli_app.get_matches();
warn_for_deprecated_arguments(&matches);
let ledger_path = PathBuf::from(matches.value_of("ledger_path").unwrap());
match matches.subcommand() {
⋮----
.inspect_err(|err| error!("Failed to initialize validator: {err}"))
.map_err(commands::Error::Dynamic),
⋮----
.inspect_err(|err| error!("Failed to start validator: {err}"))
⋮----
_ => unreachable!(),
⋮----
.unwrap_or_else(|err| {
println!("Validator command failed: {err}");
exit(1);

================
File: validator/tests/cli.rs
================
fn test_use_the_same_path_for_accounts_and_snapshots() {
let temp_dir = TempDir::new().unwrap();
let temp_dir_path = temp_dir.path();
let id_json_path = temp_dir_path.join("id.json");
let id_json_str = id_json_path.to_str().unwrap();
⋮----
write_keypair_file(&keypair, id_json_str).unwrap();
let temp_dir_str = temp_dir_path.to_str().unwrap();
let mut cmd = Command::cargo_bin(env!("CARGO_PKG_NAME")).unwrap();
cmd.args([
⋮----
cmd.assert().failure().stderr(predicates::str::contains(

================
File: validator/.gitignore
================
/target/
/farf/
/test-ledger/

================
File: validator/Cargo.toml
================
[package]
name = "agave-validator"
readme = "../README.md"
documentation = "https://docs.rs/agave-validator"
default-run = "agave-validator"
version = { workspace = true }
authors = { workspace = true }
description = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
agave-unstable-api = []

[dependencies]
agave-geyser-plugin-interface = { workspace = true }
agave-logger = { workspace = true }
agave-snapshots = { workspace = true }
arc-swap = { workspace = true }
chrono = { workspace = true, features = ["default", "serde"] }
clap = { workspace = true }
console = { workspace = true }
core_affinity = { workspace = true }
crossbeam-channel = { workspace = true }
fd-lock = { workspace = true }
indicatif = { workspace = true }
itertools = { workspace = true }
jsonrpc-core = { workspace = true }
jsonrpc-core-client = { workspace = true, features = ["ipc"] }
jsonrpc-derive = { workspace = true }
jsonrpc-ipc-server = { workspace = true }
libc = { workspace = true }
libloading = { workspace = true }
log = { workspace = true }
num_cpus = { workspace = true }
qualifier_attr = { workspace = true }
rand = { workspace = true }
rayon = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
serde_yaml = { workspace = true }
solana-account = { workspace = true }
solana-accounts-db = { workspace = true }
solana-clap-utils = { workspace = true }
solana-cli-config = { workspace = true }
solana-cli-output = { workspace = true }
solana-clock = { workspace = true }
solana-commitment-config = { workspace = true }
solana-core = { workspace = true }
solana-download-utils = { workspace = true }
solana-entry = { workspace = true }
solana-epoch-schedule = { workspace = true }
solana-faucet = { workspace = true }
solana-genesis-utils = { workspace = true }
solana-geyser-plugin-manager = { workspace = true }
solana-gossip = { workspace = true, features = ["agave-unstable-api"] }
solana-hash = { workspace = true }
solana-inflation = { workspace = true }
solana-keypair = { workspace = true }
solana-ledger = { workspace = true }
solana-metrics = { workspace = true }
solana-native-token = { workspace = true }
solana-net-utils = { workspace = true }
solana-perf = { workspace = true }
solana-poh = { workspace = true }
solana-program-runtime = { workspace = true }
solana-pubkey = { workspace = true }
solana-rayon-threadlimit = { workspace = true }
solana-rent = { workspace = true }
solana-rpc = { workspace = true }
solana-rpc-client = { workspace = true }
solana-rpc-client-api = { workspace = true }
solana-runtime = { workspace = true }
solana-sdk-ids = { workspace = true }
solana-send-transaction-service = { workspace = true }
solana-signer = { workspace = true }
solana-storage-bigtable = { workspace = true }
solana-streamer = { workspace = true }
solana-system-interface = { workspace = true }
solana-test-validator = { workspace = true }
solana-tpu-client = { workspace = true }
solana-turbine = { workspace = true }
solana-unified-scheduler-pool = { workspace = true }
solana-validator-exit = { workspace = true }
solana-version = { workspace = true }
solana-vote-program = { workspace = true }
symlink = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
tonic = { workspace = true, features = ["tls", "tls-roots", "tls-webpki-roots"] }
url = { workspace = true }

[target.'cfg(not(any(target_env = "msvc", target_os = "freebsd")))'.dependencies]
jemallocator = { workspace = true }

[target."cfg(unix)".dependencies]
libc = { workspace = true }

[dev-dependencies]
assert_cmd = { workspace = true }
predicates = { workspace = true }
pretty_assertions = { workspace = true }
scopeguard = { workspace = true }
solana-account-decoder = { workspace = true }
solana-core = { workspace = true, features = ["dev-context-only-utils"] }
solana-program-option = { workspace = true }
solana-program-pack = { workspace = true }
solana-runtime = { workspace = true, features = ["dev-context-only-utils"] }
solana-time-utils = { workspace = true }
spl-generic-token = { workspace = true }
spl-token-2022-interface = { workspace = true }
tempfile = { workspace = true }
test-case = { workspace = true }

================
File: validator/solana-test-validator
================
#!/usr/bin/env bash

here="$(dirname "$0")"
set -x
exec cargo run --manifest-path="$here"/Cargo.toml --bin solana-test-validator -- "$@"

================
File: vercel.json
================
{
  "github": {
    "silent": true
  }
}

================
File: verified-packet-receiver/src/lib.rs
================
pub mod receiver;

================
File: verified-packet-receiver/src/receiver.rs
================
pub struct VerifiedPacketReceiver {
⋮----
impl VerifiedPacketReceiver {
pub fn new(
⋮----
.into_iter()
.enumerate()
.map(|(i, socket)| {
⋮----
format!("solVtxRcvr{i:02}"),
⋮----
exit.clone(),
sender.clone(),
recycler.clone(),
tpu_stats.clone(),
⋮----
in_vote_only_mode.clone(),
⋮----
.collect();
⋮----
pub fn join(self) -> thread::Result<()> {
⋮----
thread_hdl.join()?;
⋮----
Ok(())

================
File: verified-packet-receiver/Cargo.toml
================
[package]
name = "agave-verified-packet-receiver"
description = "Agave Verified Packet Receiver Receiver"
documentation = "https://docs.rs/agave-verified-packet-receiver"
publish = true
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[lib]
crate-type = ["lib"]
name = "agave_verified_packet_receiver"

[features]
agave-unstable-api = []

[dependencies]
solana-perf = { workspace = true }
solana-streamer = { workspace = true }

[dev-dependencies]
assert_matches = { workspace = true }
solana-streamer = { workspace = true, features = ["dev-context-only-utils"] }

================
File: verified-packet-receiver/Readme.md
================
# Introduction
The Vortexor is a service that can offload the tasks of receiving transactions
from the public, performing signature verification, and deduplication from the
core validator, enabling it to focus on processing and executing the
transactions. The verified and filtered transactions will then be forwarded to
the validators linked with the Vortexor. This setup makes the TPU transaction
ingestion and verification more scalable compared to a single-node solution.

This module implements the VerifiedPacketReceiver in the below architecture
which encapsulates the functionality of receiving the verified packet batches
from the vortexor. In the first impelementation, we use UDP to receive the
verified packets from the vortexor. It is designed to support other protocol
option such as using QUIC.

# Architecture
Figure 1 describes the architecture diagram of the Vortexor and its
relationship with the validator.

                     +---------------------+
                     |   Solana            |
                     |   RPC / Web Socket  |
                     |   Service           |
                     +---------------------+
                                |
                                v
                    +--------------------- VORTEXOR ------------------------+
                    |           |                                           |
                    |   +------------------+                                |
                    |   | StakedKeyUpdater |                                |
                    |   +------------------+                                |
                    |           |                                           |
                    |           v                                           |
                    |   +-------------+        +--------------------+       |
        TPU -->     |   | TPU Streamer| -----> | SigVerifier/Dedup  |       |
        /QUIC       |   +-------------+        +--------------------+       |
                    |        |                          |                   |
                    |        v                          v                   |
                    |  +----------------+     +------------------------+    |
                    |  | Subscription   |<----| VerifiedPacketForwarder|    |
                    |  | Management     |     +------------------------+    |
                    |  +----------------+            |                      |
                    +--------------------------------|----------------------+
                                ^                    | (UDP/QUIC)
    Heartbeat/subscriptions     |                    |
                                |                    v
                    +-------------------- AGAVE VALIDATOR ------------------+
                    |                                                       |
                    |  +----------------+      +-----------------------+    |
          Config->  |  | Subscription   |      | VerifiedPacketReceiver|    |
      Admin RPC     |  | Management     |      |                       |    |
                    |  +----------------+      +-----------------------+    |
                    |        |                           |                  |
                    |        |                           v                  |
                    |        v                      +-----------+           |
                    |  +--------------------+       | Banking   |           |
    Gossip <--------|--| Gossip/Contact Info|       | Stage     |           |
                    |  +--------------------+       +-----------+           |
                    +-------------------------------------------------------+

                                       Figure 1.

================
File: version/src/legacy.rs
================
pub struct LegacyVersion1 {
⋮----
impl Sanitize for LegacyVersion1 {}
⋮----
pub struct LegacyVersion2 {
⋮----
impl Default for LegacyVersion2 {
fn default() -> Self {
⋮----
u32::from_le_bytes(agave_feature_set::ID.as_ref()[..4].try_into().unwrap());
⋮----
major: env!("CARGO_PKG_VERSION_MAJOR").parse().unwrap(),
minor: env!("CARGO_PKG_VERSION_MINOR").parse().unwrap(),
patch: env!("CARGO_PKG_VERSION_PATCH").parse().unwrap(),
commit: compute_commit(option_env!("CI_COMMIT")),
⋮----
fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
write!(
⋮----
impl Sanitize for LegacyVersion2 {}

================
File: version/src/lib.rs
================
extern crate solana_frozen_abi_macro;
mod legacy;
⋮----
pub enum ClientId {
⋮----
pub struct Version {
⋮----
impl Version {
pub fn as_semver_version(&self) -> semver::Version {
⋮----
pub fn client(&self) -> ClientId {
⋮----
fn compute_commit(sha1: Option<&'static str>) -> Option<u32> {
u32::from_str_radix(sha1?.get(..8)?, /*radix:*/ 16).ok()
⋮----
impl Default for Version {
fn default() -> Self {
⋮----
u32::from_le_bytes(agave_feature_set::ID.as_ref()[..4].try_into().unwrap());
⋮----
major: env!("CARGO_PKG_VERSION_MAJOR").parse().unwrap(),
minor: env!("CARGO_PKG_VERSION_MINOR").parse().unwrap(),
patch: env!("CARGO_PKG_VERSION_PATCH").parse().unwrap(),
commit: compute_commit(option_env!("CI_COMMIT"))
.or(compute_commit(option_env!("AGAVE_GIT_COMMIT_HASH")))
.unwrap_or_else(|| rng().random::<u32>()),
⋮----
// Other client implementations need to modify this line.
client: u16::try_from(ClientId::JitoLabs).unwrap(),
⋮----
fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
write!(f, "{}.{}.{}", self.major, self.minor, self.patch,)
⋮----
write!(
⋮----
impl Sanitize for Version {}
⋮----
fn from(client: u16) -> Self {
⋮----
type Error = String;
fn try_from(client: ClientId) -> Result<Self, Self::Error> {
⋮----
ClientId::SolanaLabs => Ok(0u16),
ClientId::JitoLabs => Ok(1u16),
ClientId::Frankendancer => Ok(2u16),
ClientId::Agave => Ok(3u16),
ClientId::AgavePaladin => Ok(4u16),
ClientId::Firedancer => Ok(5u16),
ClientId::AgaveBam => Ok(6u16),
ClientId::Sig => Ok(7u16),
ClientId::Unknown(client @ 0u16..=7u16) => Err(format!("Invalid client: {client}")),
ClientId::Unknown(client) => Ok(client),
⋮----
macro_rules! semver {
⋮----
macro_rules! version {
⋮----
mod test {
⋮----
fn test_compute_commit() {
assert_eq!(compute_commit(None), None);
assert_eq!(compute_commit(Some("1234567890")), Some(0x1234_5678));
assert_eq!(compute_commit(Some("HEAD")), None);
assert_eq!(compute_commit(Some("garbagein")), None);
⋮----
fn test_client_id() {
assert_eq!(ClientId::from(0u16), ClientId::SolanaLabs);
assert_eq!(ClientId::from(1u16), ClientId::JitoLabs);
assert_eq!(ClientId::from(2u16), ClientId::Frankendancer);
assert_eq!(ClientId::from(3u16), ClientId::Agave);
assert_eq!(ClientId::from(4u16), ClientId::AgavePaladin);
assert_eq!(ClientId::from(5u16), ClientId::Firedancer);
assert_eq!(ClientId::from(6u16), ClientId::AgaveBam);
assert_eq!(ClientId::from(7u16), ClientId::Sig);
⋮----
assert_eq!(ClientId::from(client), ClientId::Unknown(client));
⋮----
assert_eq!(u16::try_from(ClientId::SolanaLabs), Ok(0u16));
assert_eq!(u16::try_from(ClientId::JitoLabs), Ok(1u16));
assert_eq!(u16::try_from(ClientId::Frankendancer), Ok(2u16));
assert_eq!(u16::try_from(ClientId::Agave), Ok(3u16));
assert_eq!(u16::try_from(ClientId::AgavePaladin), Ok(4u16));
assert_eq!(u16::try_from(ClientId::Firedancer), Ok(5u16));
assert_eq!(u16::try_from(ClientId::AgaveBam), Ok(6u16));
assert_eq!(u16::try_from(ClientId::Sig), Ok(7u16));
⋮----
assert_eq!(
⋮----
assert_eq!(u16::try_from(ClientId::Unknown(client)), Ok(client));

================
File: version/.gitignore
================
/target/
/farf/

================
File: version/build.rs
================
use std::process::Command;
fn main() {
if let Ok(git_output) = Command::new("git").args(["rev-parse", "HEAD"]).output() {
if git_output.status.success() {
⋮----
let trimmed_hash = git_commit_hash.trim().to_string();
println!("cargo:rustc-env=AGAVE_GIT_COMMIT_HASH={trimmed_hash}");

================
File: version/Cargo.toml
================
[package]
name = "solana-version"
description = "Solana Version"
documentation = "https://docs.rs/solana-version"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[lib]
name = "solana_version"

[features]
agave-unstable-api = []
dummy-for-ci-check = []
frozen-abi = ["dep:solana-frozen-abi", "dep:solana-frozen-abi-macro"]

[dependencies]
agave-feature-set = { workspace = true }
rand = { workspace = true }
semver = { workspace = true }
serde = { workspace = true }
solana-frozen-abi = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-frozen-abi-macro = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-sanitize = { workspace = true }
solana-serde-varint = { workspace = true }

[lints]
workspace = true

================
File: vortexor/src/cli.rs
================
fn parse_port_range(port_range: &str) -> Result<(u16, u16), String> {
⋮----
if end.saturating_sub(start) < MINIMUM_VALIDATOR_PORT_RANGE_WIDTH {
Err(format!(
⋮----
Ok((start, end))
⋮----
Err("Invalid port range".to_string())
⋮----
fn get_version() -> &'static str {
⋮----
let version_static: &'static str = Box::leak(version.to_string().into_boxed_str());
⋮----
fn get_default_port_range() -> &'static str {
let range = format!("{}-{}", VALIDATOR_PORT_RANGE.0, VALIDATOR_PORT_RANGE.1);
let range: &'static str = Box::leak(range.into_boxed_str());
⋮----
fn parse_url_with_scheme(expected_schemes: &'static [&'static str]) -> ValueParser {
⋮----
let parsed_url = Url::parse(input).map_err(|e| format!("Invalid URL '{input}': {e}"))?;
if expected_schemes.contains(&parsed_url.scheme()) {
Ok(parsed_url)
⋮----
pub struct Cli {

================
File: vortexor/src/lib.rs
================
pub mod cli;
pub mod rpc_load_balancer;
pub mod sender;
pub mod stake_updater;
pub mod vortexor;

================
File: vortexor/src/main.rs
================
pub fn main() {
⋮----
let identity_keypair = read_keypair_file(identity).unwrap_or_else(|error| {
⋮----
format!("The --identity <KEYPAIR> argument is required, error: {error}"),
⋮----
.exit();
⋮----
.unwrap_or_else(|| format!("solana-vortexor-{}.log", identity_keypair.pubkey()));
⋮----
println!("log file: {logfile}");
Some(PathBuf::from(logfile))
⋮----
let _logger_thread = redirect_stderr_to_file(logfile);
info!("{} {solana_version}", crate_name!());
info!(
⋮----
let (tpu_sender, tpu_receiver) = bounded(DEFAULT_CHANNEL_SIZE);
let (tpu_fwd_sender, _tpu_fwd_receiver) = bounded(DEFAULT_CHANNEL_SIZE);
⋮----
.unwrap();
⋮----
bind_in_range_with_config(*bind_address, dynamic_port_range, config).unwrap();
let (non_vote_sender, non_vote_receiver) = banking_tracer.create_channel_non_vote();
⋮----
if rpc_servers.len() != websocket_servers.len() {
⋮----
.into_iter()
.zip(websocket_servers)
⋮----
destinations.clone(),
⋮----
info!("Creating the SigVerifier");
⋮----
exit.clone(),
rpc_load_balancer.clone(),
staked_nodes.clone(),
⋮----
let tpu_public_address = tpu_sockets.tpu_quic[0].local_addr().unwrap();
let tpu_fwd_public_address = tpu_sockets.tpu_quic_fwd[0].local_addr().unwrap();
for destination in destinations.read().unwrap().iter() {
⋮----
cancel.clone(),
⋮----
vortexor.join().unwrap();
sigverify_stage.join().unwrap();
packet_sender.join().unwrap();
staked_nodes_updater_service.join().unwrap();

================
File: vortexor/src/rpc_load_balancer.rs
================
type AtomicSlot = AtomicU64;
type ServerSlotInfo = Arc<(Url, AtomicSlot)>;
⋮----
pub struct RpcLoadBalancer {
⋮----
impl RpcLoadBalancer {
⋮----
pub fn new(
⋮----
.iter()
.map(|(_, ws)| Arc::new((ws.clone(), AtomicSlot::new(0)))),
⋮----
let server_to_rpc_client = HashMap::from_iter(servers.iter().map(|(rpc_url, ws)| {
⋮----
if let Err(e) = rpc_client.get_slot() {
error!("error warming up rpc: {rpc_url}. error: {e}");
⋮----
(ws.clone(), rpc_client)
⋮----
Self::start_subscription_threads(servers, slot_sender, server_to_slot.clone(), exit);
⋮----
fn start_subscription_threads(
⋮----
info!("start_subscription_threads for servers: {servers:?}");
⋮----
.enumerate()
.map(|(i, (_, websocket_url))| {
⋮----
.as_str()
.split('/')
.nth(2)
.unwrap_or_default()
.to_string();
let exit = exit.clone();
let websocket_url = websocket_url.clone();
let server_to_slot = server_to_slot[i].clone();
let slot_sender = slot_sender.clone();
let highest_slot = highest_slot.clone();
⋮----
.name(format!(
⋮----
.spawn(move || {
while !exit.load(Ordering::Relaxed) {
info!("running slot_subscribe() with url: {websocket_url}");
⋮----
match PubsubClient::slot_subscribe(websocket_url.as_str()) {
⋮----
match receiver.recv_timeout(Duration::from_millis(100)) {
⋮----
.store(slot.slot, Ordering::Relaxed);
datapoint_info!(
⋮----
.fetch_max(slot.slot, Ordering::Relaxed);
⋮----
if let Err(e) = slot_sender.send(slot.slot)
⋮----
error!("error sending slot: {e}");
⋮----
if last_slot_update.elapsed()
⋮----
datapoint_error!(
⋮----
warn!(
⋮----
error!(
⋮----
sleep(SLOT_REFRESH_INTERVAL);
⋮----
.unwrap()
⋮----
.collect()
⋮----
pub fn rpc_client(&self) -> Arc<RpcClient> {
let (highest_server, _) = self.get_highest_slot();
⋮----
.get(highest_server)
⋮----
.to_owned()
⋮----
fn get_highest_slot(&self) -> (&Url, Slot) {
⋮----
.max_by(|lhs, rhs| {
⋮----
.load(Ordering::Relaxed)
.cmp(&rhs.1.load(Ordering::Relaxed))
⋮----
.unwrap();
(&highest.0, highest.1.load(Ordering::Relaxed))
⋮----
pub fn join(self) -> thread::Result<()> {
⋮----
s.join()?;
⋮----
Ok(())

================
File: vortexor/src/sender.rs
================
pub struct PacketBatchSender {
⋮----
impl PacketBatchSender {
pub fn new(
⋮----
.map(|thread_id| {
let packet_batch_receiver = packet_batch_receiver.clone();
let destinations = destinations.clone();
let send_sock = send_sock.try_clone().unwrap();
⋮----
.name(format!("vtxSdr{thread_id}"))
.spawn(move || {
⋮----
.unwrap()
⋮----
.collect();
⋮----
pub fn join(self) -> thread::Result<()> {
⋮----
thread_hdl.join()?;
⋮----
Ok(())
⋮----
fn recv_send(
⋮----
let destinations = destinations.read().expect("Expected to get destinations");
match Self::receive_until(packet_batch_receiver.clone(), recv_timeout, batch_size) {
⋮----
trace!("Received packet counts: {packet_count}");
⋮----
for packet_batch in batch.iter() {
⋮----
if let Some(data) = packet.data(0..) {
packets.push(data);
⋮----
for destination in destinations.iter() {
⋮----
packets.iter().map(|data| (*data, destination)).collect();
let _result = batch_send(&send_sock, packet_refs.into_iter());
⋮----
info!("Exiting the recv_sender as channel is disconnected.");
⋮----
fn receive_until(
⋮----
let message = packet_batch_receiver.recv_timeout(recv_timeout)?;
⋮----
.iter()
.map(|batch| batch.len())
⋮----
let mut messages = vec![message];
while let Ok(message) = packet_batch_receiver.try_recv() {
⋮----
trace!(
⋮----
.checked_add(
⋮----
.unwrap();
messages.push(message);
if start.elapsed() >= recv_timeout || num_packets_received >= batch_size {
⋮----
Ok((num_packets_received, messages))

================
File: vortexor/src/stake_updater.rs
================
pub struct StakeUpdater {
⋮----
impl StakeUpdater {
pub fn new(
⋮----
info!("Starting stake updater thread");
⋮----
.name("stkUpdtr".to_string())
.spawn(move || {
⋮----
while !exit.load(Ordering::Relaxed) {
⋮----
warn!("Failed to refresh pubkey to stake map! Error: {err:?}");
sleep(refresh_sleep_duration);
⋮----
.unwrap();
⋮----
fn try_refresh_stake_info(
⋮----
if last_refresh.is_none() || last_refresh.unwrap().elapsed() > STAKE_REFRESH_INTERVAL {
let client = rpc_load_balancer.rpc_client();
let vote_accounts = client.get_vote_accounts()?;
⋮----
.iter()
.chain(vote_accounts.delinquent.iter())
.filter_map(|vote_account| {
Some((
Pubkey::from_str(&vote_account.node_pubkey).ok()?,
⋮----
*last_refresh = Some(Instant::now());
⋮----
.write()
.unwrap()
.update_stake_map(stake_map);
⋮----
sleep(*refresh_sleep_duration);
⋮----
Ok(())
⋮----
pub fn join(self) -> thread::Result<()> {
self.thread_hdl.join()

================
File: vortexor/src/vortexor.rs
================
pub struct TpuSockets {
⋮----
pub struct Vortexor {
⋮----
struct KeyUpdateNotifier {
⋮----
impl KeyUpdateNotifier {
fn new(key_updaters: Vec<Arc<EndpointKeyUpdater>>) -> Self {
⋮----
impl NotifyKeyUpdate for KeyUpdateNotifier {
fn update_key(&self, key: &Keypair) -> Result<(), Box<dyn std::error::Error>> {
let updaters = self.key_updaters.lock().unwrap();
for updater in updaters.iter() {
updater.update_key(key)?
⋮----
Ok(())
⋮----
impl Vortexor {
pub fn create_tpu_sockets(
⋮----
let tpu_quic = bind_sockets(
⋮----
let tpu_quic_fwd = bind_sockets(
⋮----
pub fn create_sigverify_stage(
⋮----
pub fn create_vortexor(
⋮----
let mut quic_fwd_server_params = quic_server_params.clone();
⋮----
let tpu_result = spawn_stake_wighted_qos_server(
⋮----
tpu_sender.clone(),
staked_nodes.clone(),
⋮----
cancel.clone(),
⋮----
.unwrap();
⋮----
let tpu_fwd_result = spawn_stake_wighted_qos_server(
⋮----
thread_handles: vec![tpu_result.thread, tpu_fwd_result.thread],
key_update_notifier: Arc::new(KeyUpdateNotifier::new(vec![
⋮----
pub fn get_key_update_notifier(&self) -> Arc<dyn NotifyKeyUpdate + Sync + Send> {
self.key_update_notifier.clone()
⋮----
pub fn join(self) -> thread::Result<()> {
⋮----
t.join()?
⋮----
fn bind_sockets(
⋮----
.map(|addr| (addr.ip(), (addr.port(), addr.port().saturating_add(1))))
.unwrap_or((bind_address, port_range));
⋮----
multi_bind_in_range_with_config(bind_address, port_range, quic_config, num_quic_endpoints)
.expect("expected bind to succeed");

================
File: vortexor/tests/vortexor.rs
================
async fn test_vortexor() {
⋮----
let bind_address = solana_net_utils::parse_host("127.0.0.1").expect("invalid bind_address");
⋮----
let (tpu_sender, tpu_receiver) = unbounded();
let (tpu_fwd_sender, tpu_fwd_receiver) = unbounded();
⋮----
let tpu_address = tpu_sockets.tpu_quic[0].local_addr().unwrap();
let tpu_fwd_address = tpu_sockets.tpu_quic_fwd[0].local_addr().unwrap();
let stakes = HashMap::from([(keypair.pubkey(), 10000)]);
⋮----
DEFAULT_MAX_STAKED_CONNECTIONS.saturating_add(DEFAULT_MAX_UNSTAKED_CONNECTIONS),
⋮----
cancel.clone(),
⋮----
check_multiple_streams(tpu_receiver, tpu_address, Some(&keypair)).await;
check_multiple_streams(tpu_fwd_receiver, tpu_fwd_address, Some(&keypair)).await;
cancel.cancel();
vortexor.join().unwrap();
⋮----
fn get_server_urls(validator: &ClusterValidatorInfo) -> (Url, Url) {
let rpc_addr = validator.info.contact_info.rpc().unwrap();
let rpc_pubsub_addr = validator.info.contact_info.rpc_pubsub().unwrap();
let rpc_url = Url::parse(format!("http://{rpc_addr}").as_str()).unwrap();
let ws_url = Url::parse(format!("ws://{rpc_pubsub_addr}").as_str()).unwrap();
⋮----
fn test_stake_update() {
⋮----
info!(
⋮----
assert_eq!(cluster.validators.len(), 3);
let pubkey = cluster.entry_point_info.pubkey();
⋮----
let mut servers = vec![get_server_urls(validator)];
for validator in cluster.validators.values() {
if validator.info.keypair.pubkey() != *pubkey {
servers.push(get_server_urls(validator));
⋮----
.recv_timeout(slot_receive_timeout)
.unwrap_or_else(|_| panic!("Expected a slot within {slot_receive_timeout:?}"));
⋮----
info!("Received a slot update: {slot}");
⋮----
exit.clone(),
rpc_load_balancer.clone(),
shared_staked_nodes.clone(),
⋮----
let stakes = shared_staked_nodes.read().unwrap();
if let Some(stake) = stakes.get_node_stake(pubkey) {
info!("Stake for {pubkey}: {stake}");
assert_eq!(stake, default_node_stake);
let total_stake = stakes.total_stake();
info!("total_stake: {total_stake}");
assert!(total_stake >= default_node_stake);
⋮----
info!("Waiting for stake map to be populated for {pubkey:?}...");
drop(stakes);
⋮----
if start_of_stake_updater.elapsed() > stake_updater_timeout {
panic!("Timeout waiting for stake map to be populated");
⋮----
info!("Test done, exiting stake updater service");
exit.store(true, Ordering::Relaxed);
staked_nodes_updater_service.join().unwrap();
info!("Stake updater service exited successfully, shutting down cluster");
cluster.exit();
info!("Cluster exited successfully");

================
File: vortexor/Cargo.toml
================
[package]
name = "solana-vortexor"
description = "Solana TPU Vortexor"
documentation = "https://docs.rs/solana-vortexor"
default-run = "solana-vortexor"
publish = false
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[lib]
crate-type = ["lib"]
name = "solana_vortexor"

[features]
default = ["agave-unstable-api"]
agave-unstable-api = []
dev-context-only-utils = []

[dependencies]
agave-banking-stage-ingress-types = { workspace = true }
agave-logger = { workspace = true }
bytes = { workspace = true }
clap = { version = "4.5.31", features = ["cargo", "derive", "error-context"] }
crossbeam-channel = { workspace = true }
dashmap = { workspace = true }
futures  = { workspace = true }
futures-util = { workspace = true }
histogram = { workspace = true }
indexmap = { workspace = true }
itertools = { workspace = true }
libc = { workspace = true }
log = { workspace = true }
nix = { workspace = true, features = ["net"] }
pem = { workspace = true }
percentage = { workspace = true }
quinn = { workspace = true }
quinn-proto = { workspace = true }
rustls = { workspace = true }
signal-hook = { workspace = true }
smallvec = { workspace = true }
socket2 = { workspace = true }
solana-clap-utils = { workspace = true }
solana-client = { workspace = true }
solana-clock = { workspace = true }
solana-commitment-config = { workspace = true }
solana-core = { workspace = true }
solana-keypair = { workspace = true }
solana-measure = { workspace = true }
solana-metrics = { workspace = true }
solana-net-utils = { workspace = true }
solana-perf = { workspace = true }
solana-pubkey = { workspace = true }
solana-quic-definitions = { workspace = true }
solana-signer = { workspace = true }
solana-streamer = { workspace = true }
solana-transaction-metrics-tracker = { workspace = true }
solana-version = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true, features = ["full"] }
tokio-util = { workspace = true }
url = { workspace = true }
x509-parser = { workspace = true }

[dev-dependencies]
assert_matches = { workspace = true }
solana-local-cluster = { workspace = true, features = ["dev-context-only-utils"] }
solana-native-token = { workspace = true }
solana-streamer = { workspace = true, features = ["dev-context-only-utils"] }

================
File: vortexor/README.md
================
> **Note:** Vortexor is under active development.
> For the quick instruction to pair a validator and vortexor, please read [Pair a Vortexor and Validator](#pair-a-vortexor-and-validator).

# Introduction
The Vortexor is a service that can offload the tasks of receiving transactions
from the public, performing signature verification, and deduplication from the
core validator, enabling it to focus on processing and executing the
transactions. The verified and filtered transactions will then be forwarded to
the validators linked with the Vortexor. This setup makes the TPU transaction
ingestion and verification more scalable compared to a single-node solution.

# Architecture
Figure 1 describes the architecture diagram of the Vortexor and its
relationship with the validator.

                     +---------------------+
                     |   Solana            |
                     |   RPC / Web Socket  |
                     |   Service           |
                     +---------------------+
                                |
                                v
                    +--------------------- VORTEXOR ------------------------+
                    |           |                                           |
                    |   +------------------+                                |
                    |   | StakedKeyUpdater |                                |
                    |   +------------------+                                |
                    |           |                                           |
                    |           v                                           |
                    |   +-------------+        +--------------------+       |
        TPU -->     |   | TPU Streamer| -----> | SigVerifier/Dedup  |       |
        /QUIC       |   +-------------+        +--------------------+       |
                    |        |                          |                   |
                    |        v                          v                   |
                    |  +----------------+     +------------------------+    |
                    |  | Subscription   |<----| VerifiedPacketForwarder|    |
                    |  | Management     |     +------------------------+    |
                    |  +----------------+            |                      |
                    +--------------------------------|----------------------+
                                ^                    | (UDP/QUIC)
    Heartbeat/subscriptions     |                    |
                                |                    v
                    +-------------------- AGAVE VALIDATOR ------------------+
                    |                                                       |
                    |  +----------------+      +-----------------------+    |
          Config->  |  | Subscription   |      | VerifiedPacketReceiver|    |
      Admin RPC     |  | Management     |      |                       |    |
                    |  +----------------+      +-----------------------+    |
                    |        |                           |                  |
                    |        |                           v                  |
                    |        v                      +-----------+           |
                    |  +--------------------+       | Banking   |           |
    Gossip <--------|--| Gossip/Contact Info|       | Stage     |           |
                    |  +--------------------+       +-----------+           |
                    +-------------------------------------------------------+

                                       Figure 1.

The Vortexor is a new executable that can be deployed on nodes separate from
the core Agave validator. It can also be deployed on the same node as the core
validator if the node has sufficient performance bandwidth.

It has the following major components:

1. **The TPU Streamer** – This is built from the existing QUIC-based TPU streamer.
2. **The SigVerify/Dedup** – This is refactored from the existing SigVerify component.
3. **Subscription Management** – Responsible for managing subscriptions
   from the validator. Actions include subscribing to transactions and canceling subscriptions.
4. **VerifiedPacketForwarder** – Responsible for forwarding verified
   transaction packets to subscribed validators. It uses UDP/QUIC to send transactions.
   Validators can bind to private addresses for receiving the verified packets.
   Firewalls can also restrict transactions to the chosen Vortexor.
5. **The Vortexor StakedKeyUpdater** – Retrieves the stake map from the network and makes
   it available to the TPU streamer for stake-weighted QoS.

Validators include a new component that receives verified packets sent from
the Vortexor and directly sends them to the banking stage. The validator's
Admin RPC is enhanced to configure peering with the Vortexor. The ContactInfo of
the validator updates with the Vortexor's address when linked.

# Relationship of Validator and Vortexor
The validator broadcasts one TPU address served by a Vortexor. A validator can
switch its paired Vortexor to another. A Vortexor, depending on its performance,
can serve one or more validators. The architecture also supports multiple
Vortexors sharing the TPU address behind a load balancer for scalability:

                            Load Balancer
                                 |
                                 v
                     __________________________
                     |           |            |
                     |           |            |
                 Vortexor       Vortexor     Vortexor
                     |           |            |
                     |           |            |
                     __________________________
                                 |
                                 v
                              Validator

                              Figure 2.

When the validator is in 'Paired' mode, receiving active transactions or
heartbeat messages from the Vortexor, it receives TPU transactions solely from
the Vortexor. It publishes the TPU address via gossip. The regular TPU and TPU
forward services are disabled for security and performance reasons.

The design assumes a trust relationship between the Vortexor and the validator,
achieved through a private network, firewall rules, or TLS verification. QUIC,
used for the VerifiedPacketReceiver, supports QoS to prioritize Vortexor traffic.

Heartbeat messages from the Vortexor inform the validator of its status. If no
transactions or heartbeats are received within a configurable timeout, the
validator may switch to another Vortexor or revert to its built-in TPU streamer.

# Deployment Considerations
Using a Vortexor enhances validator scalability but introduces complexities:

1. **Deployment Complexity**: For validators not using a Vortexor, there is no
   impact. For those using a Vortexor, additional setup is required. To minimize
   complexity, the Vortexor and validator require minimal configuration changes
   and provide clear documentation for pairing. Automatic fallback ensures
   continued operation if the connection between the Vortexor and validator
   breaks.

2. **Latency**: An additional hop exists between the original client and the
   leader validator. Latency is minimized by deploying the Vortexor on a node
   with low-latency connections to the validator. UDP forwarding is supported
   for speed.

3. **Security**: The implicit trust between the validator and Vortexor is
   safeguarded by private networks, firewalls, and QUIC with public key-based
   rules. Validators can optionally enforce re-verification of transactions.

4. **Compatibility**: The solution is compatible with existing setups, such as
   jito-relayers. The Vortexor CLI mimics jito-relayer's CLI to reduce friction
   for migrating users.

5. **Networking**: The Vortexor can be exposed directly to the internet or
   placed behind a load balancer. Communication with the validator is
   encouraged via private networks for security and performance.

# Upgrade Considerations
Operators can decide whether to adopt Vortexors without concerns about network
protocol changes. Upgrading involves specifying the Vortexor's TPU address and
verified packet receiver network address via CLI or Admin RPC. The transition is
designed to be seamless for operators.

# Pair a Vortexor and Validator

To pair a validator and Vortexor, follow these steps:


### Step 1: Determine the validator's receiver address and RPC/Web Socket Addresses
The validator's receiver address should be first determined as the IP:port.
For example, if there are multiple network interfaces, and the vortexor and validators
can can communicate on the private network, the IP address can be of the private
interface's address if the validator. The port should be free of collision from
other ports used on the system.

The RPC/Web socket server can be any available servers in the network. It does
NOT need to be the pairing validator. There must be equal number of RPC and Web
socket servers specified.

### Step 2: Run the Vortexor
Run the Vortexor using the following command:

```bash
solana-vortexor --identity /path/to/id.json \
    --destination <validator_receiver_address> \
    --dynamic-port-range <port_range> \
    --rpc-server <rpc_server_address> \
    --websocket-server <websocket_server_address>
```

**Parameters:**
- `--identity`: Path to the identity keypair file for the Vortexor.
- `--destination`: The validator's receiver address where verified packets will be sent (e.g., `10.138.0.136:8100`).
- `--dynamic-port-range`: The port range used by the Vortexor for TPU traffic (e.g., `9200-9300`).
- `--rpc-server`: The RPC server address to fetch cluster information (e.g., `http://10.138.0.137:8899`).
- `--websocket-server`: The WebSocket server address to fetch stake information (e.g., `ws://10.138.0.137:8900`).

**Example:**

In the example below, we are pairing the vortexor with the validator running on 10.138.0.136 and we use
the RPC node 10.138.0.137 for RPC and websocket service:

```bash
solana-vortexor --identity /home/solana/.config/solana/id.json \
    --destination 10.138.0.136:8100 \
    --dynamic-port-range 9200-9300 \
    --rpc-server http://10.138.0.137:8899 \
    --websocket-server ws://10.138.0.137:8900
```

---

### Step 3: Find the Vortexor's TPU and Forward Addresses
The Vortexor's TPU and forward addresses can be found in its log file. For example:

```
[2025-04-24T17:40:13.098760226Z INFO  solana_vortexor] Creating the Vortexor. The tpu socket is: Ok(0.0.0.0:9200), tpu_fwd: Ok(0.0.0.0:9201)
```

---

### Step 4: Configure the Validator
Run the validator with the following additional parameters to pair it with the Vortexor:

```bash
--tpu-vortexor-receiver-address <vortexor_receiver_address> \
--public-tpu-address <vortexor_tpu_address> \
--public-tpu-forwards-address <vortexor_tpu_forward_address>
```

**Parameters:**
- `--tpu-vortexor-receiver-address`: The address where the validator receives verified packets from the Vortexor (e.g., `10.138.0.136:8100`).
- `--public-tpu-address`: The TPU address of the Vortexor for receiving TPU traffic from the network (e.g., `10.138.0.131:9194`).
- `--public-tpu-forwards-address`: The TPU forward address of the Vortexor for receiving TPU forward traffic (e.g., `10.138.0.131:9195`).

**Example:**

In the example below, we are pairing the validator running on 10.138.0.136 with the
vortexor running on node 10.138.0.131:
```bash
--tpu-vortexor-receiver-address 10.138.0.136:8100 \
--public-tpu-address 10.138.0.131:9194 \
--public-tpu-forwards-address 10.138.0.131:9195
```

================
File: vote/benches/vote_account.rs
================
fn new_rand_vote_account<R: Rng>(
⋮----
node_pubkey: node_pubkey.unwrap_or_else(Pubkey::new_unique),
⋮----
commission: rng.random(),
⋮----
slot: rng.random(),
epoch_start_timestamp: rng.random(),
epoch: rng.random(),
leader_schedule_epoch: rng.random(),
unix_timestamp: rng.random(),
⋮----
rng.random(),
&VoteStateVersions::new_v4(vote_state.clone()),
⋮----
.unwrap();
⋮----
fn bench_vote_account_try_from(b: &mut Bencher) {
⋮----
let (account, vote_state) = new_rand_vote_account(&mut rng, None);
b.iter(|| {
let vote_account = VoteAccount::try_from(account.clone()).unwrap();
let vote_state_view = vote_account.vote_state_view();
assert_eq!(&vote_state.node_pubkey, vote_state_view.node_pubkey());
assert_eq!(
⋮----
assert_eq!(vote_state.last_timestamp, vote_state_view.last_timestamp());
assert_eq!(vote_state.root_slot, vote_state_view.root_slot());
⋮----
fn bench_staked_nodes_compute(b: &mut Bencher) {
⋮----
let (account, _) = new_rand_vote_account(&mut rng, None);
let vote_account = VoteAccount::try_from(account).unwrap();
let stake: u64 = rng.random_range(1_000_000..100_000_000);
vote_accounts_map.insert(Pubkey::new_unique(), (stake, vote_account));
⋮----
vote_accounts_map.insert(Pubkey::new_unique(), (0, vote_account));
⋮----
let staked_nodes = vote_accounts.staked_nodes();
assert!(!staked_nodes.is_empty());
⋮----
benchmark_group!(
⋮----
benchmark_main!(benches);

================
File: vote/src/vote_state_view/field_frames.rs
================
pub(super) trait ListFrame {
⋮----
fn item_size(&self) -> usize {
⋮----
unsafe fn read_item<'a>(&self, item_data: &'a [u8]) -> &'a Self::Item {
unsafe { &*(item_data.as_ptr() as *const Self::Item) }
⋮----
fn total_size(&self) -> usize {
core::mem::size_of::<u64>() /* len */ + self.total_item_size()
⋮----
fn total_item_size(&self) -> usize {
self.len() * self.item_size()
⋮----
pub(super) enum VotesFrame {
⋮----
impl ListFrame for VotesFrame {
type Item = LockoutItem;
⋮----
fn len(&self) -> usize {
⋮----
Self::Lockout(frame) => frame.len(),
Self::Landed(frame) => frame.len(),
⋮----
Self::Lockout(frame) => frame.item_size(),
Self::Landed(frame) => frame.item_size(),
⋮----
Self::Lockout(frame) => frame.read_item(item_data),
Self::Landed(frame) => frame.read_item(item_data),
⋮----
pub(super) struct LockoutItem {
⋮----
impl LockoutItem {
⋮----
pub(super) fn slot(&self) -> Slot {
⋮----
pub(super) fn confirmation_count(&self) -> u32 {
⋮----
pub(super) struct LockoutListFrame {
⋮----
impl LockoutListFrame {
pub(super) fn read(cursor: &mut std::io::Cursor<&[u8]>) -> Result<Self> {
⋮----
.map_err(|_err| VoteStateViewError::AccountDataTooSmall)? as usize;
let len = u8::try_from(len).map_err(|_| VoteStateViewError::InvalidVotesLength)?;
⋮----
cursor.consume(frame.total_item_size());
Ok(frame)
⋮----
impl ListFrame for LockoutListFrame {
⋮----
pub(super) struct BlsPubkeyCompressedView<'a> {
⋮----
pub(super) fn new(frame: BlsPubkeyCompressedFrame, buffer: &'a [u8]) -> Self {
⋮----
pub(super) fn pubkey(&self) -> Option<[u8; BLS_PUBLIC_KEY_COMPRESSED_SIZE]> {
⋮----
cursor.consume(1);
⋮----
cursor.read_exact(&mut buf).unwrap();
Some(buf)
⋮----
pub(super) struct BlsPubkeyCompressedFrame {
⋮----
impl BlsPubkeyCompressedFrame {
pub(super) fn total_size(&self) -> usize {
1 + self.size()
⋮----
pub(super) fn size(&self) -> usize {
⋮----
.map_err(|_err| VoteStateViewError::AccountDataTooSmall)?;
⋮----
0 => Ok(false),
1 => Ok(true),
_ => Err(VoteStateViewError::InvalidBlsPubkeyCompressedOption),
⋮----
cursor.consume(frame.size());
⋮----
pub(super) struct LandedVotesListFrame {
⋮----
impl LandedVotesListFrame {
⋮----
pub(super) struct LandedVoteItem {
⋮----
impl ListFrame for LandedVotesListFrame {
⋮----
unsafe { &*(item_data[1..].as_ptr() as *const LockoutItem) }
⋮----
pub(super) struct AuthorizedVotersListFrame {
⋮----
impl AuthorizedVotersListFrame {
⋮----
u8::try_from(len).map_err(|_| VoteStateViewError::InvalidAuthorizedVotersLength)?;
⋮----
pub(super) struct AuthorizedVoterItem {
⋮----
impl ListFrame for AuthorizedVotersListFrame {
type Item = AuthorizedVoterItem;
⋮----
pub(super) fn get_authorized_voter(self, epoch: Epoch) -> Option<&'a Pubkey> {
for item in self.into_iter().rev() {
⋮----
return Some(&item.voter);
⋮----
pub struct EpochCreditsItem {
⋮----
pub(super) struct EpochCreditsListFrame {
⋮----
impl EpochCreditsListFrame {
⋮----
let len = u8::try_from(len).map_err(|_| VoteStateViewError::InvalidEpochCreditsLength)?;
⋮----
impl ListFrame for EpochCreditsListFrame {
type Item = EpochCreditsItem;
⋮----
impl EpochCreditsItem {
⋮----
pub fn epoch(&self) -> u64 {
⋮----
pub fn credits(&self) -> u64 {
⋮----
pub fn prev_credits(&self) -> u64 {
⋮----
fn from(item: &EpochCreditsItem) -> Self {
(item.epoch(), item.credits(), item.prev_credits())
⋮----
pub(super) struct CommissionView<'a> {
⋮----
pub(super) fn new(frame: CommissionFrame, buffer: &'a [u8]) -> Self {
⋮----
pub(super) fn commission_percent(&self) -> u8 {
⋮----
let data = unsafe { *(self.buffer.as_ptr() as *const [u8; 2]) };
⋮----
let percent = (bps / 100).min(u8::MAX as u16);
⋮----
pub(super) fn commission_bps(&self) -> u16 {
⋮----
pub(super) struct CommissionFrame {
⋮----
impl CommissionFrame {
pub(super) const fn new_percent() -> Self {
⋮----
pub(super) const fn new_bps() -> Self {
⋮----
pub(super) struct PendingDelegatorRewardsView<'a> {
⋮----
pub(super) fn new(buffer: &'a [u8]) -> Self {
⋮----
pub(super) fn value(&self) -> u64 {
let data = unsafe { *(self.buffer.as_ptr() as *const [u8; 8]) };
⋮----
pub(super) struct RootSlotView<'a> {
⋮----
pub(super) fn new(frame: RootSlotFrame, buffer: &'a [u8]) -> Self {
⋮----
pub(super) fn root_slot(&self) -> Option<Slot> {
⋮----
solana_serialize_utils::cursor::read_u64(&mut cursor).unwrap()
⋮----
Some(root_slot)
⋮----
pub(super) struct RootSlotFrame {
⋮----
impl RootSlotFrame {
⋮----
_ => Err(VoteStateViewError::InvalidRootSlotOption),
⋮----
pub(super) struct PriorVotersFrame;
impl PriorVotersFrame {
pub(super) const fn total_size() -> usize {
⋮----
pub(super) fn read(cursor: &mut std::io::Cursor<&[u8]>) {
cursor.consume(PriorVotersFrame::total_size());
⋮----
mod tests {
⋮----
fn test_bls_pubkey_view() {
⋮----
assert!(view.pubkey().is_some());
⋮----
assert!(view.pubkey().is_none());
⋮----
fn test_prior_voters_total_size() {
⋮----
pub(super) struct PriorVotersItem {
⋮----
let prior_voters_len = CircBuf::<()>::default().buf().len();
⋮----
assert_eq!(PriorVotersFrame::total_size(), expected_total_size);
⋮----
fn test_commission_view() {
⋮----
assert_eq!(commission_view.commission_percent(), 0);
⋮----
let buffer = 100u16.to_le_bytes();
⋮----
assert_eq!(commission_view.commission_percent(), 1);
⋮----
let buffer = 101u16.to_le_bytes();
⋮----
let buffer = u16::MAX.to_le_bytes();
⋮----
assert_eq!(commission_view.commission_percent(), u8::MAX);

================
File: vote/src/vote_state_view/frame_v1_14_11.rs
================
pub(super) struct VoteStateFrameV1_14_11 {
⋮----
impl VoteStateFrameV1_14_11 {
pub(super) fn try_new(bytes: &[u8]) -> Result<Self> {
⋮----
cursor.set_position(votes_offset as u64);
⋮----
cursor.consume(core::mem::size_of::<BlockTimestamp>());
if cursor.position() as usize <= bytes.len() {
Ok(Self {
⋮----
Err(VoteStateViewError::AccountDataTooSmall)
⋮----
pub(super) fn field_offset(&self, field: Field) -> usize {
⋮----
Field::RootSlot => self.root_slot_offset(),
Field::AuthorizedVoters => self.authorized_voters_offset(),
Field::EpochCredits => self.epoch_credits_offset(),
Field::LastTimestamp => self.last_timestamp_offset(),
⋮----
const fn node_pubkey_offset() -> usize {
⋮----
const fn authorized_withdrawer_offset() -> usize {
⋮----
const fn commission_offset() -> usize {
⋮----
const fn votes_offset() -> usize {
⋮----
fn root_slot_offset(&self) -> usize {
Self::votes_offset() + self.votes_frame.total_size()
⋮----
fn authorized_voters_offset(&self) -> usize {
self.root_slot_offset() + self.root_slot_frame.total_size()
⋮----
fn prior_voters_offset(&self) -> usize {
self.authorized_voters_offset() + self.authorized_voters_frame.total_size()
⋮----
fn epoch_credits_offset(&self) -> usize {
self.prior_voters_offset() + PriorVotersFrame::total_size()
⋮----
fn last_timestamp_offset(&self) -> usize {
self.epoch_credits_offset() + self.epoch_credits_frame.total_size()
⋮----
mod tests {
⋮----
fn test_try_new_zeroed() {
⋮----
let mut bytes = bincode::serialize(&target_vote_state_versions).unwrap();
for i in 0..bytes.len() {
⋮----
assert_eq!(
⋮----
bytes.extend_from_slice(&[0; 42]);
⋮----
fn test_try_new_simple() {
⋮----
target_vote_state.root_slot = Some(42);
target_vote_state.epoch_credits.push((1, 2, 3));
target_vote_state.votes.push_back(LandedVote {
⋮----
VoteStateVersions::V1_14_11(Box::new(target_vote_state.into()));
⋮----
fn test_try_new_invalid_values() {
let mut bytes = vec![0; VoteStateFrameV1_14_11::votes_offset()];
⋮----
let mut bytes = bytes.clone();
bytes.extend_from_slice(&(256u64.to_le_bytes()));
⋮----
bytes.extend_from_slice(&[0; core::mem::size_of::<u64>()]);
⋮----
bytes.extend_from_slice(&(2u8.to_le_bytes()));
⋮----
bytes.extend_from_slice(&[0; 1]);
⋮----
bytes.extend_from_slice(&[0; PriorVotersFrame::total_size()]);

================
File: vote/src/vote_state_view/frame_v3.rs
================
pub(super) struct VoteStateFrameV3 {
⋮----
impl VoteStateFrameV3 {
pub(super) fn try_new(bytes: &[u8]) -> Result<Self> {
⋮----
cursor.set_position(votes_offset as u64);
⋮----
cursor.consume(core::mem::size_of::<BlockTimestamp>());
if cursor.position() as usize <= bytes.len() {
Ok(Self {
⋮----
Err(VoteStateViewError::AccountDataTooSmall)
⋮----
pub(super) fn field_offset(&self, field: Field) -> usize {
⋮----
Field::RootSlot => self.root_slot_offset(),
Field::AuthorizedVoters => self.authorized_voters_offset(),
Field::EpochCredits => self.epoch_credits_offset(),
Field::LastTimestamp => self.last_timestamp_offset(),
⋮----
const fn node_pubkey_offset() -> usize {
⋮----
const fn authorized_withdrawer_offset() -> usize {
⋮----
const fn commission_offset() -> usize {
⋮----
const fn votes_offset() -> usize {
⋮----
fn root_slot_offset(&self) -> usize {
Self::votes_offset() + self.votes_frame.total_size()
⋮----
fn authorized_voters_offset(&self) -> usize {
self.root_slot_offset() + self.root_slot_frame.total_size()
⋮----
fn prior_voters_offset(&self) -> usize {
self.authorized_voters_offset() + self.authorized_voters_frame.total_size()
⋮----
fn epoch_credits_offset(&self) -> usize {
self.prior_voters_offset() + PriorVotersFrame::total_size()
⋮----
fn last_timestamp_offset(&self) -> usize {
self.epoch_credits_offset() + self.epoch_credits_frame.total_size()
⋮----
mod tests {
⋮----
fn test_try_new_zeroed() {
⋮----
let mut bytes = bincode::serialize(&target_vote_state_versions).unwrap();
for i in 0..bytes.len() {
⋮----
assert_eq!(
⋮----
bytes.extend_from_slice(&[0; 42]);
⋮----
fn test_try_new_simple() {
⋮----
target_vote_state.root_slot = Some(42);
target_vote_state.epoch_credits.push((1, 2, 3));
target_vote_state.votes.push_back(LandedVote {
⋮----
fn test_try_new_invalid_values() {
let mut bytes = vec![0; VoteStateFrameV3::votes_offset()];
⋮----
let mut bytes = bytes.clone();
bytes.extend_from_slice(&(256u64.to_le_bytes()));
⋮----
bytes.extend_from_slice(&[0; core::mem::size_of::<u64>()]);
⋮----
bytes.extend_from_slice(&(2u8.to_le_bytes()));
⋮----
bytes.extend_from_slice(&[0; 1]);
⋮----
bytes.extend_from_slice(&[0; PriorVotersFrame::total_size()]);

================
File: vote/src/vote_state_view/frame_v4.rs
================
pub(crate) struct VoteStateFrameV4 {
⋮----
impl VoteStateFrameV4 {
pub(crate) fn try_new(bytes: &[u8]) -> Result<Self> {
⋮----
cursor.set_position(bls_pubkey_offset as u64);
⋮----
cursor.consume(core::mem::size_of::<BlockTimestamp>());
if cursor.position() as usize <= bytes.len() {
Ok(Self {
⋮----
Err(VoteStateViewError::AccountDataTooSmall)
⋮----
pub(super) fn field_offset(&self, field: Field) -> usize {
⋮----
Field::Votes => self.votes_offset(),
Field::RootSlot => self.root_slot_offset(),
Field::AuthorizedVoters => self.authorized_voters_offset(),
Field::EpochCredits => self.epoch_credits_offset(),
Field::LastTimestamp => self.last_timestamp_offset(),
⋮----
pub(super) fn simd185_field_offset(&self, field: Simd185Field) -> usize {
⋮----
const fn node_pubkey_offset() -> usize {
⋮----
const fn authorized_withdrawer_offset() -> usize {
⋮----
const fn inflation_rewards_collector_offset() -> usize {
⋮----
const fn block_revenue_collector_offset() -> usize {
⋮----
const fn inflation_rewards_commission_offset() -> usize {
⋮----
const fn block_revenue_commission_offset() -> usize {
⋮----
const fn pending_delegator_rewards_offset() -> usize {
⋮----
const fn bls_pubkey_compressed_offset() -> usize {
⋮----
fn votes_offset(&self) -> usize {
Self::bls_pubkey_compressed_offset() + self.bls_pubkey_compressed_frame.total_size()
⋮----
fn root_slot_offset(&self) -> usize {
self.votes_offset() + self.votes_frame.total_size()
⋮----
fn authorized_voters_offset(&self) -> usize {
self.root_slot_offset() + self.root_slot_frame.total_size()
⋮----
fn epoch_credits_offset(&self) -> usize {
self.authorized_voters_offset() + self.authorized_voters_frame.total_size()
⋮----
fn last_timestamp_offset(&self) -> usize {
self.epoch_credits_offset() + self.epoch_credits_frame.total_size()
⋮----
mod tests {
⋮----
enum TestVoteStateVersions {
⋮----
fn test_try_new_zeroed() {
⋮----
let mut bytes = bincode::serialize(&target_vote_state_versions).unwrap();
for i in 0..bytes.len() {
⋮----
assert_eq!(
⋮----
bytes.extend_from_slice(&[0; 42]);
⋮----
fn test_try_new_simple() {
⋮----
epoch_credits: vec![(1, 2, 3)],
bls_pubkey_compressed: Some([42; BLS_PUBLIC_KEY_COMPRESSED_SIZE]),
⋮----
root_slot: Some(42),
⋮----
fn test_try_new_invalid_values() {
let mut bytes = vec![0; VoteStateFrameV4::bls_pubkey_compressed_offset()];
⋮----
let mut bytes = bytes.clone();
bytes.extend_from_slice(&(2u8.to_le_bytes()));
⋮----
bytes.extend_from_slice(&[0; 1]);
⋮----
bytes.extend_from_slice(&(256u64.to_le_bytes()));
⋮----
bytes.extend_from_slice(&[0; core::mem::size_of::<u64>()]);

================
File: vote/src/vote_state_view/list_view.rs
================
pub(super) struct ListView<'a, F> {
⋮----
pub(super) fn new(frame: F, buffer: &'a [u8]) -> Self {
⋮----
pub(super) fn len(&self) -> usize {
self.frame.len()
⋮----
pub(super) fn last(&self) -> Option<&F::Item> {
let len = self.len();
⋮----
self.item(len - 1)
⋮----
fn item(&self, index: usize) -> Option<&'a F::Item> {
if index >= self.len() {
⋮----
let offset = index * self.frame.item_size();
let item_data = &self.item_buffer[offset..offset + self.frame.item_size()];
Some(unsafe { self.frame.read_item(item_data) })
⋮----
pub(super) struct ListViewIter<'a, F> {
⋮----
impl<'a, F: ListFrame> Iterator for ListViewIter<'a, F>
⋮----
type Item = &'a F::Item;
fn next(&mut self) -> Option<Self::Item> {
let item_data = self.buffer.next()?;
⋮----
fn size_hint(&self) -> (usize, Option<usize>) {
self.buffer.size_hint()
⋮----
fn count(self) -> usize {
self.buffer.count()
⋮----
fn nth(&mut self, n: usize) -> Option<Self::Item> {
let item_data = self.buffer.nth(n)?;
⋮----
fn last(mut self) -> Option<Self::Item> {
self.next_back()
⋮----
impl<'a, F: ListFrame> DoubleEndedIterator for ListViewIter<'a, F>
⋮----
fn next_back(&mut self) -> Option<Self::Item> {
let item_data = self.buffer.next_back()?;
// SAFETY: `item_data` is chunked by `self.frame.item_size()`
⋮----
impl<'a, F: ListFrame> IntoIterator for ListView<'a, F>
⋮----
type IntoIter = ListViewIter<'a, F>;
fn into_iter(self) -> Self::IntoIter {
let item_size = self.frame.item_size();
let total_bytes = self.frame.len() * item_size;
⋮----
buffer: slice.chunks_exact(item_size),
⋮----
mod tests {
⋮----
fn build_lockout_buffer(len: usize, make: impl Fn(usize) -> (u64, u32)) -> Vec<u8> {
⋮----
buf.extend_from_slice(&(len as u64).to_le_bytes());
⋮----
let (slot, count) = make(i);
buf.extend_from_slice(&slot.to_le_bytes());
buf.extend_from_slice(&count.to_le_bytes());
⋮----
fn build_landed_buffer(len: usize, make: impl Fn(usize) -> (u8, u64, u32)) -> Vec<u8> {
⋮----
let (latency, slot, count) = make(i);
buf.push(latency);
⋮----
fn iter_lockout_forward_and_rev() {
⋮----
let buffer = build_lockout_buffer(len, |i| (i as u64, (10 + i) as u32));
⋮----
.into_iter()
.map(|it| (it.slot(), it.confirmation_count()))
.collect();
assert_eq!(
⋮----
.rev()
⋮----
fn iter_lockout_mixed_front_back() {
⋮----
let buffer = build_lockout_buffer(len, |i| (i as u64, (100 + i) as u32));
⋮----
let mut it = ListView::new(frame, &buffer).into_iter();
⋮----
(it.next().map(|x| (x.slot(), x.confirmation_count()))).unwrap(),
(it.next_back().map(|x| (x.slot(), x.confirmation_count()))).unwrap(),
⋮----
assert!(it.next().is_none());
⋮----
assert_eq!(out, expected);
⋮----
fn iter_landed_stride_and_rev() {
⋮----
build_landed_buffer(len, |i| ((200 + i) as u8, (10 + i) as u64, (20 + i) as u32));
⋮----
fn size_hint_decreases() {
⋮----
let buffer = build_lockout_buffer(len, |i| (i as u64, i as u32));
⋮----
assert_eq!(it.size_hint(), (3, Some(3)));
assert!(it.next().is_some());
assert_eq!(it.size_hint(), (2, Some(2)));
assert!(it.next_back().is_some());
assert_eq!(it.size_hint(), (1, Some(1)));
⋮----
assert_eq!(it.size_hint(), (0, Some(0)));
⋮----
assert!(it.next_back().is_none());

================
File: vote/src/lib.rs
================
pub mod vote_account;
pub mod vote_parser;
pub mod vote_state_view;
pub mod vote_transaction;
⋮----
extern crate solana_frozen_abi_macro;

================
File: vote/src/vote_account.rs
================
pub struct VoteAccount(Arc<VoteAccountInner>);
⋮----
pub enum Error {
⋮----
struct VoteAccountInner {
⋮----
pub type VoteAccountsHashMap = HashMap<Pubkey, ( u64, VoteAccount)>;
⋮----
pub struct VoteAccounts {
⋮----
impl Clone for VoteAccounts {
fn clone(&self) -> Self {
⋮----
impl VoteAccount {
pub fn account(&self) -> &AccountSharedData {
⋮----
pub fn lamports(&self) -> u64 {
self.0.account.lamports()
⋮----
pub fn owner(&self) -> &Pubkey {
self.0.account.owner()
⋮----
pub fn vote_state_view(&self) -> &VoteStateView {
⋮----
pub fn node_pubkey(&self) -> &Pubkey {
self.0.vote_state_view.node_pubkey()
⋮----
pub fn new_random() -> VoteAccount {
⋮----
commission: rng.random(),
⋮----
slot: rng.random(),
epoch_start_timestamp: rng.random(),
epoch: rng.random(),
leader_schedule_epoch: rng.random(),
unix_timestamp: rng.random(),
⋮----
rng.random(),
&VoteStateVersions::new_v4(vote_state.clone()),
⋮----
.unwrap();
VoteAccount::try_from(account).unwrap()
⋮----
impl VoteAccounts {
pub fn len(&self) -> usize {
self.vote_accounts.len()
⋮----
pub fn is_empty(&self) -> bool {
self.vote_accounts.is_empty()
⋮----
pub fn staked_nodes(&self) -> Arc<HashMap< Pubkey,  u64>> {
⋮----
.get_or_init(|| {
⋮----
.values()
.filter(|(stake, _)| *stake != 0)
.count();
⋮----
for (stake, vote_account) in self.vote_accounts.values() {
⋮----
*staked_nodes.entry(*vote_account.node_pubkey()).or_default() += *stake;
⋮----
.clone()
⋮----
pub fn get(&self, pubkey: &Pubkey) -> Option<&VoteAccount> {
let (_stake, vote_account) = self.vote_accounts.get(pubkey)?;
Some(vote_account)
⋮----
pub fn get_delegated_stake(&self, pubkey: &Pubkey) -> u64 {
⋮----
.get(pubkey)
.map(|(stake, _vote_account)| *stake)
.unwrap_or_default()
⋮----
pub fn iter(&self) -> impl Iterator<Item = (&Pubkey, &VoteAccount)> {
⋮----
.iter()
.map(|(vote_pubkey, (_stake, vote_account))| (vote_pubkey, vote_account))
⋮----
pub fn delegated_stakes(&self) -> impl Iterator<Item = (&Pubkey, u64)> {
⋮----
.map(|(vote_pubkey, (stake, _vote_account))| (vote_pubkey, *stake))
⋮----
pub fn find_max_by_delegated_stake(&self) -> Option<&VoteAccount> {
⋮----
let (_pubkey, (_stake, vote_account)) = self.vote_accounts.iter().max_by_key(key)?;
⋮----
pub fn insert(
⋮----
match vote_accounts.entry(pubkey) {
⋮----
let (stake, old_vote_account) = entry.get_mut();
if let Some(staked_nodes) = self.staked_nodes.get_mut() {
let old_node_pubkey = old_vote_account.node_pubkey();
let new_node_pubkey = new_vote_account.node_pubkey();
⋮----
Some(mem::replace(old_vote_account, new_vote_account))
⋮----
let (stake, vote_account) = entry.insert((calculate_stake(), new_vote_account));
⋮----
Self::do_add_node_stake(staked_nodes, *stake, *vote_account.node_pubkey());
⋮----
pub fn remove(&mut self, pubkey: &Pubkey) -> Option<(u64, VoteAccount)> {
⋮----
let entry = vote_accounts.remove(pubkey);
⋮----
self.sub_node_stake(stake, vote_account);
⋮----
pub fn add_stake(&mut self, pubkey: &Pubkey, delta: u64) {
⋮----
if let Some((stake, vote_account)) = vote_accounts.get_mut(pubkey) {
⋮----
let vote_account = vote_account.clone();
self.add_node_stake(delta, &vote_account);
⋮----
pub fn sub_stake(&mut self, pubkey: &Pubkey, delta: u64) {
⋮----
.checked_sub(delta)
.expect("subtraction value exceeds account's stake");
⋮----
self.sub_node_stake(delta, &vote_account);
⋮----
fn add_node_stake(&mut self, stake: u64, vote_account: &VoteAccount) {
let Some(staked_nodes) = self.staked_nodes.get_mut() else {
⋮----
VoteAccounts::do_add_node_stake(staked_nodes, stake, *vote_account.node_pubkey());
⋮----
fn do_add_node_stake(
⋮----
.entry(node_pubkey)
.and_modify(|s| *s += stake)
.or_insert(stake);
⋮----
fn sub_node_stake(&mut self, stake: u64, vote_account: &VoteAccount) {
⋮----
VoteAccounts::do_sub_node_stake(staked_nodes, stake, vote_account.node_pubkey());
⋮----
fn do_sub_node_stake(
⋮----
.get_mut(node_pubkey)
.expect("this should not happen");
match (*current_stake).cmp(&stake) {
Ordering::Less => panic!("subtraction value exceeds node's stake"),
⋮----
staked_nodes.remove(node_pubkey);
⋮----
impl Serialize for VoteAccount {
fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
⋮----
self.0.account.serialize(serializer)
⋮----
fn from(account: &'a VoteAccount) -> Self {
account.0.account.clone()
⋮----
fn from(account: VoteAccount) -> Self {
⋮----
type Error = Error;
fn try_from(account: AccountSharedData) -> Result<Self, Self::Error> {
if !solana_sdk_ids::vote::check_id(account.owner()) {
return Err(Error::InvalidOwner(*account.owner()));
⋮----
Ok(Self(Arc::new(VoteAccountInner {
vote_state_view: VoteStateView::try_new(account.data_clone())
.map_err(|_| Error::InstructionError(InstructionError::InvalidAccountData))?,
⋮----
fn eq(&self, other: &Self) -> bool {
⋮----
impl Default for VoteAccounts {
fn default() -> Self {
⋮----
fn from(vote_accounts: Arc<VoteAccountsHashMap>) -> Self {
⋮----
fn as_ref(&self) -> &VoteAccountsHashMap {
⋮----
fn from(vote_accounts: &VoteAccounts) -> Self {
⋮----
impl FromIterator<(Pubkey, (/*stake:*/ u64, VoteAccount))> for VoteAccounts {
fn from_iter<I>(iter: I) -> Self
⋮----
// This custom deserializer is needed to ensure compatibility at snapshot loading with versions
// before https://github.com/anza-xyz/agave/pull/2659 which would theoretically allow invalid vote
// accounts in VoteAccounts.
//
// In the (near) future we should remove this custom deserializer and make it a hard error when we
// find invalid vote accounts in snapshots.
fn deserialize_accounts_hash_map<'de, D>(
⋮----
struct VoteAccountsVisitor;
⋮----
type Value = Arc<VoteAccountsHashMap>;
fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
formatter.write_str("a map of vote accounts")
⋮----
fn visit_map<M>(self, mut access: M) -> Result<Self::Value, M::Error>
⋮----
accounts.insert(pubkey, (stake, vote_account));
⋮----
Ok(Arc::new(accounts))
⋮----
deserializer.deserialize_map(VoteAccountsVisitor)
⋮----
mod tests {
⋮----
fn new_rand_vote_account<R: Rng>(
⋮----
node_pubkey: node_pubkey.unwrap_or_else(Pubkey::new_unique),
⋮----
.unwrap()
⋮----
fn new_rand_vote_accounts<R: Rng>(
⋮----
let nodes: Vec<_> = repeat_with(Pubkey::new_unique).take(num_nodes).collect();
repeat_with(move || {
let node = nodes[rng.random_range(0..nodes.len())];
let account = new_rand_vote_account(rng, Some(node));
let stake = rng.random_range(0..997);
let vote_account = VoteAccount::try_from(account).unwrap();
⋮----
fn staked_nodes<'a, I>(vote_accounts: I) -> HashMap<Pubkey, u64>
⋮----
.into_iter()
.filter(|(_, (stake, _))| *stake != 0)
⋮----
.entry(*vote_account.node_pubkey())
.and_modify(|s| *s += *stake)
.or_insert(*stake);
⋮----
fn test_vote_account_try_from() {
⋮----
let account = new_rand_vote_account(&mut rng, None);
let lamports = account.lamports();
let vote_account = VoteAccount::try_from(account.clone()).unwrap();
assert_eq!(lamports, vote_account.lamports());
assert_eq!(&account, vote_account.account());
⋮----
fn test_vote_account_try_from_invalid_owner() {
⋮----
let mut account = new_rand_vote_account(&mut rng, None);
account.set_owner(Pubkey::new_unique());
VoteAccount::try_from(account).unwrap();
⋮----
fn test_vote_account_try_from_invalid_account() {
⋮----
account.set_owner(solana_sdk_ids::vote::id());
⋮----
fn test_vote_account_serialize() {
⋮----
// Assert that VoteAccount has the same wire format as Account.
assert_eq!(
⋮----
fn test_vote_accounts_serialize() {
⋮----
new_rand_vote_accounts(&mut rng, 64).take(1024).collect();
let vote_accounts = VoteAccounts::from(Arc::new(vote_accounts_hash_map.clone()));
assert!(vote_accounts.staked_nodes().len() > 32);
⋮----
fn test_vote_accounts_deserialize() {
⋮----
let data = bincode::serialize(&vote_accounts_hash_map).unwrap();
let vote_accounts: VoteAccounts = bincode::deserialize(&data).unwrap();
⋮----
assert_eq!(*vote_accounts.vote_accounts, vote_accounts_hash_map);
⋮----
.serialize(&vote_accounts_hash_map)
⋮----
let vote_accounts: VoteAccounts = bincode::options().deserialize(&data).unwrap();
⋮----
fn test_vote_accounts_deserialize_invalid_account() {
⋮----
// we'll populate the map with 1 valid and 2 invalid accounts, then ensure that we only get
⋮----
let valid_account = new_rand_vote_account(&mut rng, None);
vote_accounts_hash_map.insert(Pubkey::new_unique(), (0xAA, valid_account.clone()));
⋮----
AccountSharedData::new_data(42, &vec![0xFF; 42], &solana_sdk_ids::vote::id()).unwrap();
vote_accounts_hash_map.insert(Pubkey::new_unique(), (0xBB, invalid_account_data));
⋮----
AccountSharedData::new_data(42, &valid_account.data().to_vec(), &Pubkey::new_unique())
⋮----
vote_accounts_hash_map.insert(Pubkey::new_unique(), (0xCC, invalid_account_key));
⋮----
.with_fixint_encoding()
.allow_trailing_bytes();
⋮----
let vote_accounts = deserialize_accounts_hash_map(&mut deserializer).unwrap();
assert_eq!(vote_accounts.len(), 1);
let (stake, _account) = vote_accounts.values().next().unwrap();
assert_eq!(*stake, 0xAA);
⋮----
fn test_staked_nodes() {
⋮----
let mut accounts: Vec<_> = new_rand_vote_accounts(&mut rng, 64).take(1024).collect();
⋮----
for (k, (pubkey, (stake, vote_account))) in accounts.iter().enumerate() {
vote_accounts.insert(*pubkey, vote_account.clone(), || *stake);
⋮----
let index = rng.random_range(0..accounts.len());
let (pubkey, (_, _)) = accounts.swap_remove(index);
vote_accounts.remove(&pubkey);
⋮----
assert_eq!(staked_nodes(&accounts), *vote_accounts.staked_nodes());
⋮----
let new_stake = rng.random_range(0..997);
⋮----
vote_accounts.sub_stake(pubkey, *stake - new_stake);
⋮----
vote_accounts.add_stake(pubkey, new_stake - *stake);
⋮----
while !accounts.is_empty() {
⋮----
if accounts.len() % 32 == 0 {
⋮----
assert!(vote_accounts.staked_nodes.get().unwrap().is_empty());
⋮----
fn test_staked_nodes_update() {
⋮----
let account1 = new_rand_vote_account(&mut rng, Some(node_pubkey));
let vote_account1 = VoteAccount::try_from(account1).unwrap();
let ret = vote_accounts.insert(pubkey, vote_account1.clone(), || 42);
assert_eq!(ret, None);
assert_eq!(vote_accounts.get_delegated_stake(&pubkey), 42);
assert_eq!(vote_accounts.staked_nodes().get(&node_pubkey), Some(&42));
let ret = vote_accounts.insert(pubkey, vote_account1.clone(), || {
panic!("should not be called")
⋮----
assert_eq!(ret, Some(vote_account1.clone()));
assert_eq!(vote_accounts.get(&pubkey), Some(&vote_account1));
⋮----
let account2 = new_rand_vote_account(&mut rng, Some(node_pubkey));
let vote_account2 = VoteAccount::try_from(account2).unwrap();
let ret = vote_accounts.insert(pubkey, vote_account2.clone(), || {
⋮----
assert_eq!(vote_accounts.get(&pubkey), Some(&vote_account2));
⋮----
let account3 = new_rand_vote_account(&mut rng, Some(new_node_pubkey));
let vote_account3 = VoteAccount::try_from(account3).unwrap();
let ret = vote_accounts.insert(pubkey, vote_account3.clone(), || {
⋮----
assert_eq!(ret, Some(vote_account2.clone()));
assert_eq!(vote_accounts.staked_nodes().get(&node_pubkey), None);
⋮----
fn test_staked_nodes_zero_stake() {
⋮----
assert!(vote_accounts.staked_nodes().is_empty());
let ret = vote_accounts.insert(pubkey, vote_account1.clone(), || 0);
⋮----
assert_eq!(vote_accounts.get_delegated_stake(&pubkey), 0);
⋮----
let account2 = new_rand_vote_account(&mut rng, Some(new_node_pubkey));
⋮----
assert_eq!(ret, Some(vote_account1));
⋮----
assert_eq!(vote_accounts.staked_nodes().get(&new_node_pubkey), None);
⋮----
fn test_staked_nodes_cow() {
⋮----
let mut accounts = new_rand_vote_accounts(&mut rng, 64);
⋮----
for (pubkey, (stake, vote_account)) in (&mut accounts).take(1024) {
vote_accounts.insert(pubkey, vote_account, || stake);
⋮----
let staked_nodes = vote_accounts.staked_nodes();
⋮----
accounts.find(|(_, (stake, _))| *stake != 0).unwrap();
let node_pubkey = *vote_account.node_pubkey();
vote_accounts.insert(pubkey, vote_account, || more_stake);
assert_ne!(staked_nodes, vote_accounts.staked_nodes());
⋮----
for (pubkey, stake) in vote_accounts.staked_nodes().iter() {
⋮----
assert_eq!(*stake, staked_nodes[pubkey]);
⋮----
fn test_vote_accounts_cow() {
⋮----
assert_eq!(vote_accounts_hashmap, vote_accounts.vote_accounts);
assert!(Arc::ptr_eq(
⋮----
vote_accounts.insert(pubkey, vote_account.clone(), || more_stake);
assert!(!Arc::ptr_eq(
⋮----
assert_ne!(vote_accounts_hashmap, vote_accounts.vote_accounts);
⋮----
for (pk, value) in vote_accounts.vote_accounts.iter() {
⋮----
assert_eq!(value, &vote_accounts_hashmap[pk]);
⋮----
assert_eq!(value, &other);

================
File: vote/src/vote_parser.rs
================
pub type ParsedVote = (Pubkey, VoteTransaction, Option<Hash>, Signature);
pub fn parse_sanitized_vote_transaction(tx: &impl SVMTransaction) -> Option<ParsedVote> {
let (program_id, first_instruction) = tx.program_instructions_iter().next()?;
⋮----
let first_account = usize::from(*first_instruction.accounts.first()?);
let key = tx.account_keys().get(first_account)?;
let (vote, switch_proof_hash) = parse_vote_instruction_data(first_instruction.data)?;
let signature = tx.signatures().first().cloned().unwrap_or_default();
Some((*key, vote, switch_proof_hash, signature))
⋮----
pub fn parse_vote_transaction(tx: &Transaction) -> Option<ParsedVote> {
let message = tx.message();
let first_instruction = message.instructions.first()?;
⋮----
let program_id = message.account_keys.get(program_id_index)?;
⋮----
let key = message.account_keys.get(first_account)?;
let (vote, switch_proof_hash) = parse_vote_instruction_data(&first_instruction.data)?;
let signature = tx.signatures.first().cloned().unwrap_or_default();
⋮----
fn parse_vote_instruction_data(
⋮----
match limited_deserialize(
⋮----
.ok()?
⋮----
VoteInstruction::Vote(vote) => Some((VoteTransaction::from(vote), None)),
VoteInstruction::VoteSwitch(vote, hash) => Some((VoteTransaction::from(vote), Some(hash))),
⋮----
Some((VoteTransaction::from(vote_state_update), None))
⋮----
Some((VoteTransaction::from(vote_state_update), Some(hash)))
⋮----
VoteInstruction::TowerSync(tower_sync) => Some((VoteTransaction::from(tower_sync), None)),
⋮----
Some((VoteTransaction::from(tower_sync), Some(hash)))
⋮----
mod test {
⋮----
fn new_vote_transaction(
⋮----
&vote_keypair.pubkey(),
&authorized_voter_keypair.pubkey(),
⋮----
let mut vote_tx = Transaction::new_with_payer(&[vote_ix], Some(&node_keypair.pubkey()));
vote_tx.partial_sign(&[node_keypair], blockhash);
vote_tx.partial_sign(&[authorized_voter_keypair], blockhash);
⋮----
fn run_test_parse_vote_transaction(input_hash: Option<Hash>) {
⋮----
let vote_tx = new_vote_transaction(
vec![42],
⋮----
let (key, vote, hash, signature) = parse_vote_transaction(&vote_tx).unwrap();
assert_eq!(hash, input_hash);
assert_eq!(vote, VoteTransaction::from(Vote::new(vec![42], bank_hash)));
assert_eq!(key, vote_keypair.pubkey());
assert_eq!(signature, vote_tx.signatures[0]);
⋮----
&auth_voter_keypair.pubkey(),
Vote::new(vec![1, 2], Hash::default()),
⋮----
let vote_tx = Transaction::new_with_payer(&[vote_ix], Some(&node_keypair.pubkey()));
assert!(parse_vote_transaction(&vote_tx).is_none());
⋮----
fn test_parse_vote_transaction() {
run_test_parse_vote_transaction(None);
run_test_parse_vote_transaction(Some(hash(&[42u8])));

================
File: vote/src/vote_state_view.rs
================
mod field_frames;
mod frame_v1_14_11;
mod frame_v3;
mod frame_v4;
mod list_view;
⋮----
pub enum VoteStateViewError {
⋮----
pub type Result<T> = core::result::Result<T, VoteStateViewError>;
enum Field {
⋮----
enum Simd185Field {
⋮----
pub struct VoteStateView {
⋮----
impl VoteStateView {
pub fn try_new(data: Arc<Vec<u8>>) -> Result<Self> {
let frame = VoteStateFrame::try_new(data.as_ref())?;
Ok(Self { data, frame })
⋮----
pub fn node_pubkey(&self) -> &Pubkey {
let offset = self.frame.offset(Field::NodePubkey);
unsafe { &*(self.data.as_ptr().add(offset) as *const Pubkey) }
⋮----
pub fn commission(&self) -> u8 {
self.inflation_rewards_commission_view()
.commission_percent()
⋮----
pub fn block_revenue_collector(&self) -> Option<&Pubkey> {
⋮----
.simd185_field_offset(Simd185Field::BlockRevenueCollector)?;
unsafe { Some(&*(self.data.as_ptr().add(offset) as *const Pubkey)) }
⋮----
pub fn inflation_rewards_collector(&self) -> Option<&Pubkey> {
⋮----
.simd185_field_offset(Simd185Field::InflationRewardsCollector)?;
⋮----
pub fn inflation_rewards_commission(&self) -> u16 {
self.inflation_rewards_commission_view().commission_bps()
⋮----
pub fn block_revenue_commission(&self) -> u16 {
self.block_revenue_commission_view()
.map(|view| view.commission_bps())
.unwrap_or(10_000)
⋮----
pub fn pending_delegator_rewards(&self) -> u64 {
self.pending_delegator_rewards_view()
.map(|view| view.value())
.unwrap_or(0)
⋮----
pub fn bls_pubkey_compressed(&self) -> Option<[u8; BLS_PUBLIC_KEY_COMPRESSED_SIZE]> {
self.bls_pubkey_compressed_view()
.and_then(|view| view.pubkey())
⋮----
pub fn votes_iter(&self) -> impl Iterator<Item = Lockout> + '_ {
self.votes_view().into_iter().map(|vote| {
Lockout::new_with_confirmation_count(vote.slot(), vote.confirmation_count())
⋮----
pub fn votes_len(&self) -> usize {
self.votes_view().len()
⋮----
pub fn last_lockout(&self) -> Option<Lockout> {
self.votes_view().last().map(|item| {
Lockout::new_with_confirmation_count(item.slot(), item.confirmation_count())
⋮----
pub fn last_voted_slot(&self) -> Option<Slot> {
self.votes_view().last().map(|item| item.slot())
⋮----
pub fn root_slot(&self) -> Option<Slot> {
self.root_slot_view().root_slot()
⋮----
pub fn get_authorized_voter(&self, epoch: Epoch) -> Option<&Pubkey> {
self.authorized_voters_view().get_authorized_voter(epoch)
⋮----
pub fn num_epoch_credits(&self) -> usize {
self.epoch_credits_view().len()
⋮----
pub fn epoch_credits_iter(&self) -> impl Iterator<Item = &EpochCreditsItem> + '_ {
self.epoch_credits_view().into_iter()
⋮----
pub fn credits(&self) -> u64 {
self.epoch_credits_view()
.last()
.map(|item| item.credits())
⋮----
pub fn last_timestamp(&self) -> BlockTimestamp {
let offset = self.frame.offset(Field::LastTimestamp);
⋮----
slot: solana_serialize_utils::cursor::read_u64(&mut cursor).unwrap(),
timestamp: solana_serialize_utils::cursor::read_i64(&mut cursor).unwrap(),
⋮----
fn inflation_rewards_commission_view(&self) -> CommissionView<'_> {
let offset = self.frame.offset(Field::Commission);
// SAFETY: `frame` was created from `data`.
CommissionView::new(self.frame.commission_frame(), &self.data[offset..])
⋮----
fn block_revenue_commission_view(&self) -> Option<CommissionView<'_>> {
⋮----
.simd185_field_offset(Simd185Field::BlockRevenueCommission)?;
Some(CommissionView::new(
⋮----
fn pending_delegator_rewards_view(&self) -> Option<PendingDelegatorRewardsView<'_>> {
⋮----
.simd185_field_offset(Simd185Field::PendingDelegatorRewards)?;
⋮----
Some(PendingDelegatorRewardsView::new(&self.data[offset..]))
⋮----
fn bls_pubkey_compressed_view(&self) -> Option<BlsPubkeyCompressedView<'_>> {
⋮----
.simd185_field_offset(Simd185Field::BlsPubkeyCompressed)?;
let frame = self.frame.bls_pubkey_compressed_frame()?;
Some(BlsPubkeyCompressedView::new(frame, &self.data[offset..]))
⋮----
fn votes_view(&self) -> ListView<'_, VotesFrame> {
let offset = self.frame.offset(Field::Votes);
⋮----
ListView::new(self.frame.votes_frame(), &self.data[offset..])
⋮----
fn root_slot_view(&self) -> RootSlotView<'_> {
let offset = self.frame.offset(Field::RootSlot);
RootSlotView::new(self.frame.root_slot_frame(), &self.data[offset..])
⋮----
fn authorized_voters_view(&self) -> ListView<'_, AuthorizedVotersListFrame> {
let offset = self.frame.offset(Field::AuthorizedVoters);
⋮----
ListView::new(self.frame.authorized_voters_frame(), &self.data[offset..])
⋮----
fn epoch_credits_view(&self) -> ListView<'_, EpochCreditsListFrame> {
let offset = self.frame.offset(Field::EpochCredits);
ListView::new(self.frame.epoch_credits_frame(), &self.data[offset..])
⋮----
fn from(vote_state: VoteStateV3) -> Self {
let vote_account_data = bincode::serialize(&VoteStateVersions::new_v3(vote_state)).unwrap();
VoteStateView::try_new(Arc::new(vote_account_data)).unwrap()
⋮----
fn from(vote_state: VoteStateV4) -> Self {
let vote_account_data = bincode::serialize(&VoteStateVersions::new_v4(vote_state)).unwrap();
⋮----
enum VoteStateFrame {
⋮----
impl VoteStateFrame {
fn try_new(bytes: &[u8]) -> Result<Self> {
⋮----
.map_err(|_err| VoteStateViewError::AccountDataTooSmall)?
⋮----
Ok(match version {
0 => return Err(VoteStateViewError::OldVersion),
⋮----
_ => return Err(VoteStateViewError::UnsupportedVersion),
⋮----
fn offset(&self, field: Field) -> usize {
⋮----
Self::V1_14_11(frame) => frame.field_offset(field),
Self::V3(frame) => frame.field_offset(field),
Self::V4(frame) => frame.field_offset(field),
⋮----
fn simd185_field_offset(&self, field: Simd185Field) -> Option<usize> {
⋮----
Self::V4(frame) => Some(frame.simd185_field_offset(field)),
⋮----
fn commission_frame(&self) -> CommissionFrame {
⋮----
fn bls_pubkey_compressed_frame(&self) -> Option<BlsPubkeyCompressedFrame> {
⋮----
Self::V4(frame) => Some(frame.bls_pubkey_compressed_frame),
⋮----
fn votes_frame(&self) -> VotesFrame {
⋮----
fn root_slot_frame(&self) -> RootSlotFrame {
⋮----
fn authorized_voters_frame(&self) -> AuthorizedVotersListFrame {
⋮----
fn epoch_credits_frame(&self) -> EpochCreditsListFrame {
⋮----
mod tests {
⋮----
enum TestVoteStateVersions {
⋮----
fn new_test_vote_state_v4() -> VoteStateV4 {
⋮----
.map(|i| LandedVote {
⋮----
.collect();
⋮----
bls_pubkey_compressed: Some([42; BLS_PUBLIC_KEY_COMPRESSED_SIZE]),
⋮----
root_slot: Some(42),
⋮----
epoch_credits: vec![(42, 42, 42)],
⋮----
fn new_test_vote_state_v3() -> VoteStateV3 {
⋮----
.set_new_authorized_voter(
⋮----
|_| Ok(()),
⋮----
.unwrap();
target_vote_state.root_slot = Some(42);
target_vote_state.epoch_credits.push((42, 42, 42));
⋮----
target_vote_state.votes.push_back(LandedVote {
⋮----
fn test_vote_state_view_v4() {
let target_vote_state = new_test_vote_state_v4();
⋮----
TestVoteStateVersions::V4(Box::new(target_vote_state.clone()));
let vote_state_buf = bincode::serialize(&target_vote_state_versions).unwrap();
let vote_state_view = VoteStateView::try_new(Arc::new(vote_state_buf)).unwrap();
assert_eq_vote_state_v4(&vote_state_view, &target_vote_state);
⋮----
fn test_vote_state_view_v4_default() {
⋮----
fn test_vote_state_view_v4_arbitrary() {
⋮----
let raw_data: Vec<u8> = (0..struct_bytes_x4).map(|_| rand::random::<u8>()).collect();
⋮----
let mut target_vote_state = VoteStateV4::arbitrary(&mut unstructured).unwrap();
target_vote_state.votes.truncate(MAX_LOCKOUT_HISTORY);
⋮----
.truncate(MAX_EPOCH_CREDITS_HISTORY);
if target_vote_state.authorized_voters.len() >= u8::MAX as usize {
⋮----
fn test_vote_state_view_v3() {
let target_vote_state = new_test_vote_state_v3();
let target_vote_state_versions = VoteStateVersions::V3(Box::new(target_vote_state.clone()));
⋮----
assert_eq_vote_state_v3(&vote_state_view, &target_vote_state);
⋮----
fn test_vote_state_view_v3_default() {
⋮----
fn test_vote_state_view_v3_arbitrary() {
⋮----
let mut target_vote_state = VoteStateV3::arbitrary(&mut unstructured).unwrap();
⋮----
if target_vote_state.authorized_voters().len() >= u8::MAX as usize {
⋮----
VoteStateVersions::V3(Box::new(target_vote_state.clone()));
⋮----
fn test_vote_state_view_1_14_11() {
let target_vote_state: VoteState1_14_11 = new_test_vote_state_v3().into();
⋮----
VoteStateVersions::V1_14_11(Box::new(target_vote_state.clone()));
⋮----
assert_eq_vote_state_1_14_11(&vote_state_view, &target_vote_state);
⋮----
fn test_vote_state_view_1_14_11_default() {
⋮----
fn test_vote_state_view_1_14_11_arbitrary() {
⋮----
let mut target_vote_state = VoteState1_14_11::arbitrary(&mut unstructured).unwrap();
⋮----
let (&first, &voter) = target_vote_state.authorized_voters.first().unwrap();
⋮----
for (epoch, pubkey) in target_vote_state.authorized_voters.iter().skip(1).take(10) {
authorized_voters.insert(*epoch, *pubkey);
⋮----
fn assert_eq_vote_state_v4(vote_state_view: &VoteStateView, vote_state: &VoteStateV4) {
assert_eq!(vote_state_view.node_pubkey(), &vote_state.node_pubkey);
assert_eq!(
⋮----
let view_votes = vote_state_view.votes_iter().collect::<Vec<_>>();
⋮----
.iter()
.map(|vote| vote.lockout)
⋮----
assert_eq!(view_votes, state_votes);
assert_eq!(vote_state_view.root_slot(), vote_state.root_slot);
if let Some((first_voter_epoch, first_voter)) = vote_state.authorized_voters.first() {
⋮----
let (last_voter_epoch, last_voter) = vote_state.authorized_voters.last().unwrap();
⋮----
assert_eq!(vote_state_view.get_authorized_voter(u64::MAX), None);
⋮----
.epoch_credits_iter()
.map(Into::into)
⋮----
assert_eq!(view_credits, vote_state.epoch_credits);
⋮----
assert_eq!(vote_state_view.last_timestamp(), vote_state.last_timestamp);
⋮----
fn assert_eq_vote_state_v3(vote_state_view: &VoteStateView, vote_state: &VoteStateV3) {
⋮----
assert_eq!(vote_state_view.commission(), vote_state.commission);
⋮----
if let Some((first_voter_epoch, first_voter)) = vote_state.authorized_voters().first() {
⋮----
let (last_voter_epoch, last_voter) = vote_state.authorized_voters().last().unwrap();
⋮----
fn assert_eq_vote_state_1_14_11(
⋮----
let view_votes = vote_state_view.votes_iter().collect::<VecDeque<_>>();
assert_eq!(view_votes, vote_state.votes);
⋮----
fn test_vote_state_view_too_small() {
⋮----
let vote_data = Arc::new(vec![0; i]);
let vote_state_view_err = VoteStateView::try_new(vote_data).unwrap_err();
assert_eq!(vote_state_view_err, VoteStateViewError::AccountDataTooSmall);
⋮----
fn test_vote_state_view_old_version() {
let vote_data = Arc::new(0u32.to_le_bytes().to_vec());
⋮----
assert_eq!(vote_state_view_err, VoteStateViewError::OldVersion);
⋮----
fn test_vote_state_view_unsupported_version() {
let vote_data = Arc::new(4u32.to_le_bytes().to_vec());
⋮----
assert_eq!(vote_state_view_err, VoteStateViewError::UnsupportedVersion);

================
File: vote/src/vote_transaction.rs
================
pub enum VoteTransaction {
⋮----
impl VoteTransaction {
pub fn slots(&self) -> Vec<Slot> {
⋮----
VoteTransaction::Vote(vote) => vote.slots.clone(),
VoteTransaction::VoteStateUpdate(vote_state_update) => vote_state_update.slots(),
VoteTransaction::CompactVoteStateUpdate(vote_state_update) => vote_state_update.slots(),
VoteTransaction::TowerSync(tower_sync) => tower_sync.slots(),
⋮----
pub fn slot(&self, i: usize) -> Slot {
⋮----
vote_state_update.lockouts[i].slot()
⋮----
VoteTransaction::TowerSync(tower_sync) => tower_sync.lockouts[i].slot(),
⋮----
pub fn len(&self) -> usize {
⋮----
VoteTransaction::Vote(vote) => vote.slots.len(),
⋮----
vote_state_update.lockouts.len()
⋮----
VoteTransaction::TowerSync(tower_sync) => tower_sync.lockouts.len(),
⋮----
pub fn is_empty(&self) -> bool {
⋮----
VoteTransaction::Vote(vote) => vote.slots.is_empty(),
⋮----
vote_state_update.lockouts.is_empty()
⋮----
VoteTransaction::TowerSync(tower_sync) => tower_sync.lockouts.is_empty(),
⋮----
pub fn hash(&self) -> Hash {
⋮----
pub fn timestamp(&self) -> Option<UnixTimestamp> {
⋮----
pub fn set_timestamp(&mut self, ts: Option<UnixTimestamp>) {
⋮----
pub fn last_voted_slot(&self) -> Option<Slot> {
⋮----
VoteTransaction::Vote(vote) => vote.last_voted_slot(),
⋮----
vote_state_update.last_voted_slot()
⋮----
VoteTransaction::TowerSync(tower_sync) => tower_sync.last_voted_slot(),
⋮----
pub fn last_voted_slot_hash(&self) -> Option<(Slot, Hash)> {
Some((self.last_voted_slot()?, self.hash()))
⋮----
pub fn is_full_tower_vote(&self) -> bool {
matches!(
⋮----
fn from(vote: Vote) -> Self {
⋮----
fn from(vote_state_update: VoteStateUpdate) -> Self {
⋮----
fn from(tower_sync: TowerSync) -> Self {
⋮----
pub fn new_vote_transaction(
⋮----
&vote_keypair.pubkey(),
&authorized_voter_keypair.pubkey(),
⋮----
let mut vote_tx = Transaction::new_with_payer(&[vote_ix], Some(&node_keypair.pubkey()));
vote_tx.partial_sign(&[node_keypair], blockhash);
vote_tx.partial_sign(&[authorized_voter_keypair], blockhash);
⋮----
pub fn new_vote_state_update_transaction(
⋮----
pub fn new_compact_vote_state_update_transaction(
⋮----
pub fn new_tower_sync_transaction(

================
File: vote/Cargo.toml
================
[package]
name = "solana-vote"
description = "Solana vote"
documentation = "https://docs.rs/solana-vote"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[lib]
crate-type = ["lib"]
name = "solana_vote"

[features]
agave-unstable-api = []
dev-context-only-utils = ["dep:rand", "dep:bincode"]
frozen-abi = [
    "dep:solana-frozen-abi",
    "dep:solana-frozen-abi-macro",
    "solana-vote-interface/frozen-abi",
]

[dependencies]
bincode = { workspace = true, optional = true }
itertools = { workspace = true }
log = { workspace = true }
rand = { version = "0.9.2", optional = true }
serde = { workspace = true, features = ["rc"] }
solana-account = { workspace = true, features = ["bincode"] }
solana-bincode = { workspace = true }
solana-clock = { workspace = true }
solana-frozen-abi = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-frozen-abi-macro = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-hash = { workspace = true }
solana-instruction = { workspace = true }
solana-keypair = { workspace = true }
solana-packet = { workspace = true }
solana-pubkey = { workspace = true }
solana-sdk-ids = { workspace = true }
solana-serialize-utils = { workspace = true }
solana-signature = { workspace = true }
solana-signer = { workspace = true }
solana-svm-transaction = { workspace = true }
solana-transaction = { workspace = true, features = ["bincode"] }
solana-vote-interface = { workspace = true, features = ["bincode"] }
thiserror = { workspace = true }

[dev-dependencies]
agave-logger = { workspace = true }
arbitrary = { workspace = true }
bencher = { workspace = true }
bincode = { workspace = true }
rand = { workspace = true }
solana-keypair = { workspace = true }
solana-sha256-hasher = { workspace = true }
solana-signer = { workspace = true }
solana-transaction = { workspace = true, features = ["bincode"] }
solana-vote = { path = ".", features = ["agave-unstable-api"] }
solana-vote-interface = { workspace = true, features = ["bincode", "dev-context-only-utils"] }
static_assertions = { workspace = true }

[[bench]]
name = "vote_account"
harness = false

[lints]
workspace = true

================
File: votor/src/consensus_pool/certificate_builder.rs
================
pub(super) enum AggregateError {
⋮----
pub(crate) enum BuildError {
⋮----
fn default_bitvec() -> BitVec<u8, Lsb0> {
⋮----
fn build_cert_from_bitmap(
⋮----
let new_len = bitmap.last_one().map_or(0, |i| i.saturating_add(1));
debug_assert!(new_len <= MAXIMUM_VALIDATORS);
⋮----
return Err(BuildError::InvalidRank(new_len));
⋮----
bitmap.resize(new_len, false);
let bitmap = encode_base2(&bitmap).map_err(BuildError::Encode)?;
Ok(Certificate {
⋮----
signature: signature.into(),
⋮----
fn build_cert_from_bitmaps(
⋮----
let last_one_0 = bitmap0.last_one().map_or(0, |i| i.saturating_add(1));
let last_one_1 = bitmap1.last_one().map_or(0, |i| i.saturating_add(1));
let new_len = last_one_0.max(last_one_1);
⋮----
bitmap0.resize(new_len, false);
bitmap1.resize(new_len, false);
let bitmap = encode_base3(&bitmap0, &bitmap1).map_err(BuildError::Encode)?;
⋮----
fn try_set_bitmap(bitmap: &mut BitVec<u8, Lsb0>, rank: u16) -> Result<(), AggregateError> {
⋮----
.get_mut(rank as usize)
.ok_or(AggregateError::InvalidRank(rank))?;
⋮----
return Err(AggregateError::ValidatorAlreadyIncluded);
⋮----
Ok(())
⋮----
enum BuilderType {
⋮----
impl BuilderType {
fn new(cert_type: &CertificateType) -> Self {
⋮----
bitmap0: default_bitvec(),
⋮----
bitmap: default_bitvec(),
⋮----
fn aggregate(
⋮----
let (_, vote, fallback_vote) = certificate_limits_and_votes(cert_type);
⋮----
debug_assert!(fallback_vote.is_some());
⋮----
return Err(AggregateError::InvalidVoteTypes);
⋮----
try_set_bitmap(bitmap0, msg.rank)?;
⋮----
debug_assert_eq!(msg.vote, fallback_vote);
⋮----
Some(bitmap) => try_set_bitmap(bitmap, msg.rank)?,
⋮----
let mut bitmap = default_bitvec();
try_set_bitmap(&mut bitmap, msg.rank)?;
*bitmap1 = Some(bitmap);
⋮----
Ok(signature.aggregate_with(msgs.iter().map(|m| &m.signature))?)
⋮----
debug_assert!(fallback_vote.is_none());
if fallback_vote.is_some() {
⋮----
debug_assert_eq!(msg.vote, vote);
⋮----
try_set_bitmap(bitmap, msg.rank)?;
⋮----
fn build(self, cert_type: CertificateType) -> Result<Certificate, BuildError> {
⋮----
build_cert_from_bitmap(cert_type, signature, bitmap)
⋮----
None => build_cert_from_bitmap(cert_type, signature, bitmap0),
Some(bitmap1) => build_cert_from_bitmaps(cert_type, signature, bitmap0, bitmap1),
⋮----
pub(super) struct CertificateBuilder {
⋮----
impl CertificateBuilder {
pub(super) fn new(cert_type: CertificateType) -> Self {
⋮----
pub(super) fn aggregate(&mut self, msgs: &[VoteMessage]) -> Result<(), AggregateError> {
self.builder_type.aggregate(&self.cert_type, msgs)
⋮----
pub(super) fn build(self) -> Result<Certificate, BuildError> {
self.builder_type.build(self.cert_type)
⋮----
mod tests {
⋮----
fn test_normal_build() {
⋮----
.iter()
.map(|&rank| {
⋮----
let signature = keypair.sign(b"fake_vote_message");
⋮----
.aggregate(&messages_1)
.expect("Failed to aggregate notarization votes");
⋮----
let signature = keypair.sign(b"fake_vote_message_2");
⋮----
.aggregate(&messages_2)
.expect("Failed to aggregate notarization fallback votes");
let cert = builder.build().expect("Failed to build certificate");
assert_eq!(cert.cert_type, cert_type);
match decode(&cert.bitmap, MAXIMUM_VALIDATORS).expect("Failed to decode bitmap") {
⋮----
assert_eq!(bitmap1.len(), 8);
assert_eq!(bitmap2.len(), 8);
⋮----
assert!(bitmap1[i as usize]);
⋮----
assert_eq!(bitmap1.count_ones(), 3);
⋮----
assert!(bitmap2[i as usize]);
⋮----
assert_eq!(bitmap2.count_ones(), 4);
⋮----
_ => panic!("Expected Base3 encoding"),
⋮----
assert_eq!(bitmap1.len(), 7);
⋮----
_ => panic!("Expected Base2 encoding"),
⋮----
assert_eq!(bitmap1.count_ones(), 0);
⋮----
fn test_builder_with_errors() {
⋮----
let rank_out_of_bounds = MAXIMUM_VALIDATORS.saturating_add(1);
⋮----
assert_eq!(
⋮----
let messages_1 = vec![VoteMessage {
⋮----
let messages_2 = vec![VoteMessage {
⋮----
fn test_certificate_verification_base2_encoding() {
⋮----
let serialized_vote = bincode::serialize(&vote).unwrap();
⋮----
let signature = keypair.sign(&serialized_vote);
vote_messages.push(VoteMessage {
⋮----
keypairs.push(keypair);
⋮----
.aggregate(&vote_messages)
.expect("Failed to aggregate votes");
let certificate_message = builder.build().expect("Failed to build certificate");
let aggregate_pubkey = BLSPubkeyProjective::aggregate(keypairs.iter().map(|kp| &kp.public))
.expect("Failed to aggregate public keys");
⋮----
aggregate_pubkey.verify_signature(&certificate_message.signature, &serialized_vote);
assert!(
⋮----
fn test_certificate_verification_base3_encoding() {
⋮----
let serialized_notarize_vote = bincode::serialize(&notarize_vote).unwrap();
⋮----
let signature = keypair.sign(&serialized_notarize_vote);
all_vote_messages.push(VoteMessage {
⋮----
all_pubkeys.push(keypair.public);
all_messages.push(serialized_notarize_vote.clone());
⋮----
let serialized_fallback_vote = bincode::serialize(&notarize_fallback_vote).unwrap();
⋮----
let signature = keypair.sign(&serialized_fallback_vote);
⋮----
all_messages.push(serialized_fallback_vote.clone());
⋮----
.aggregate(&all_vote_messages)
⋮----
decode(&certificate_message.bitmap, MAXIMUM_VALIDATORS).expect("Failed to decode");
⋮----
panic!("Expected Base3 encoding, but got Base2 encoding");
⋮----
assert!(bitmap1[0] && bitmap1[1] && bitmap1[2]);
assert_eq!(bitmap2.count_ones(), 3);
assert!(bitmap2[3] && bitmap2[4] && bitmap2[5]);
⋮----
all_pubkeys.iter(),
⋮----
all_messages.iter().map(Vec::as_slice),
⋮----
.unwrap();

================
File: votor/src/consensus_pool/parent_ready_tracker.rs
================
pub(crate) enum BlockProductionParent {
⋮----
pub(crate) struct ParentReadyTracker {
⋮----
struct ParentReadyStatus {
⋮----
impl ParentReadyTracker {
pub(super) fn new(cluster_info: Arc<ClusterInfo>, root_block @ (root_slot, _): Block) -> Self {
⋮----
slot_statuses.insert(
⋮----
notar_fallbacks: vec![root_block],
parents_ready: vec![],
⋮----
root_slot.saturating_add(1),
⋮----
notar_fallbacks: vec![],
parents_ready: vec![root_block],
⋮----
highest_with_parent_ready: root_slot.saturating_add(1),
⋮----
pub(super) fn add_new_notar_fallback_or_stronger(
⋮----
let status = self.slot_statuses.entry(slot).or_default();
if status.notar_fallbacks.contains(&block) {
⋮----
trace!(
⋮----
status.notar_fallbacks.push(block);
assert!(status.notar_fallbacks.len() <= MAX_ENTRIES_PER_PUBKEY_FOR_NOTARIZE_LITE);
for s in slot.saturating_add(1).. {
⋮----
let status = self.slot_statuses.entry(s).or_default();
if !status.parents_ready.contains(&block) {
status.parents_ready.push(block);
⋮----
events.push(VotorEvent::ParentReady {
⋮----
self.highest_with_parent_ready = s.max(self.highest_with_parent_ready);
⋮----
pub(super) fn add_new_skip(&mut self, slot: Slot, events: &mut Vec<VotorEvent>) {
⋮----
trace!("{}: Adding new skip for {slot:?}", self.cluster_info.id());
⋮----
let mut future_slots = vec![];
⋮----
future_slots.push(s);
if !self.slot_statuses.get(&s).is_some_and(|ss| ss.skip) {
⋮----
let mut potential_parents = vec![];
let Some(status) = self.slot_statuses.get(&(slot.saturating_sub(1))) else {
⋮----
potential_parents.push(*nf);
⋮----
potential_parents.push(*parent);
⋮----
if potential_parents.is_empty() {
⋮----
if status.parents_ready.contains(&block) {
⋮----
fn parent_ready(&self, slot: Slot, parent: Block) -> bool {
⋮----
.get(&slot)
.is_some_and(|ss| ss.parents_ready.contains(&parent))
⋮----
pub(crate) fn block_production_parent(&self, slot: Slot) -> BlockProductionParent {
if self.highest_parent_ready() > slot {
⋮----
.and_then(|ss| ss.parents_ready.iter().min().copied())
⋮----
fn highest_parent_ready(&self) -> Slot {
⋮----
pub(super) fn set_root(&mut self, root: Slot) {
⋮----
self.slot_statuses.retain(|&s, _| s >= root);
⋮----
mod tests {
⋮----
fn new_cluster_info() -> Arc<ClusterInfo> {
⋮----
let contact_info = ContactInfo::new_localhost(&keypair.pubkey(), 0);
⋮----
fn basic() {
⋮----
let mut tracker = ParentReadyTracker::new(new_cluster_info(), genesis);
let mut events = vec![];
⋮----
tracker.add_new_notar_fallback_or_stronger(block, &mut events);
assert_eq!(tracker.highest_parent_ready(), i + 1);
assert!(tracker.parent_ready(i + 1, block));
⋮----
fn skips() {
⋮----
tracker.add_new_skip(1, &mut events);
tracker.add_new_skip(2, &mut events);
tracker.add_new_skip(3, &mut events);
assert!(tracker.parent_ready(4, block));
assert!(tracker.parent_ready(4, genesis));
assert_eq!(tracker.highest_parent_ready(), 4);
⋮----
fn out_of_order() {
⋮----
assert!(!tracker.parent_ready(4, genesis));
⋮----
fn snapshot_wfsm() {
⋮----
let mut tracker = ParentReadyTracker::new(new_cluster_info(), root_block);
⋮----
assert!(tracker.parent_ready(root_slot + 1, root_block));
assert_eq!(tracker.highest_parent_ready(), root_slot + 1);
tracker.add_new_skip(root_slot, &mut events);
⋮----
tracker.add_new_skip(root_slot + 1, &mut events);
tracker.add_new_skip(root_slot + 2, &mut events);
assert!(tracker.parent_ready(root_slot + 3, root_block));
assert_eq!(tracker.highest_parent_ready(), root_slot + 3);
⋮----
assert!(tracker.parent_ready(root_slot + 5, block));
assert_eq!(tracker.highest_parent_ready(), root_slot + 5);
⋮----
fn highest_parent_ready_out_of_order() {
⋮----
assert_eq!(tracker.highest_parent_ready(), 1);
⋮----
assert_eq!(
⋮----
fn missed_window() {
⋮----
tracker.add_new_notar_fallback_or_stronger((4, Hash::new_unique()), &mut events);
assert_eq!(tracker.highest_parent_ready(), 5);
⋮----
tracker.add_new_notar_fallback_or_stronger((64, Hash::new_unique()), &mut events);
assert_eq!(tracker.highest_parent_ready(), 65);
⋮----
fn pick_more_skips() {
⋮----
tracker.add_new_skip(i, &mut vec![]);
tracker.add_new_notar_fallback_or_stronger((i, Hash::new_unique()), &mut vec![]);
⋮----
tracker.add_new_skip(11, &mut events);
assert_eq!(12, tracker.highest_parent_ready(),);
⋮----
.into_iter()
.map(|event| match event {
⋮----
assert!(slot == 12);
⋮----
_ => panic!("Invalid event"),
⋮----
.sorted()
.collect();
assert_eq!(parent_readys, (0..=10).collect::<Vec<Slot>>());

================
File: votor/src/consensus_pool/slot_stake_counters.rs
================
pub(crate) struct SlotStakeCounters {
⋮----
impl SlotStakeCounters {
pub fn new(total_stake: Stake) -> Self {
⋮----
pub fn add_vote(
⋮----
.insert(vote.block_id, entry_stake)
.unwrap_or(0);
⋮----
.saturating_sub(old_entry_stake)
.saturating_add(entry_stake);
self.top_notarized_stake = self.top_notarized_stake.max(entry_stake);
⋮----
if self.my_first_vote.is_none() && is_my_own_vote {
self.my_first_vote = Some(*vote);
⋮----
if self.my_first_vote.is_none() {
⋮----
let slot = vote.slot();
⋮----
if !self.safe_to_notar_sent.contains(block_id) && self.is_safe_to_notar(block_id, stake)
⋮----
events.push(VotorEvent::SafeToNotar((slot, *block_id)));
stats.event_safe_to_notarize = stats.event_safe_to_notarize.saturating_add(1);
self.safe_to_notar_sent.push(*block_id);
⋮----
if !self.safe_to_skip_sent && self.is_safe_to_skip() {
events.push(VotorEvent::SafeToSkip(slot));
⋮----
stats.event_safe_to_skip = stats.event_safe_to_skip.saturating_add(1);
⋮----
fn is_safe_to_notar(&self, block_id: &Hash, stake: &Stake) -> bool {
if let Some(Vote::Notarize(my_vote)) = self.my_first_vote.as_ref() {
⋮----
trace!("safe_to_notar {block_id:?} {skip_ratio} {notarized_ratio}");
⋮----
fn is_safe_to_skip(&self) -> bool {
if let Some(Vote::Notarize(_)) = self.my_first_vote.as_ref() {
trace!(
⋮----
.saturating_add(self.notarize_total.saturating_sub(self.top_notarized_stake))
⋮----
mod tests {
⋮----
fn test_safe_to_notar() {
⋮----
let mut events = vec![];
⋮----
counters.add_vote(
⋮----
assert!(events.is_empty());
assert_eq!(stats.event_safe_to_notarize, 0);
⋮----
assert_eq!(events.len(), 1);
assert!(
⋮----
assert_eq!(stats.event_safe_to_notarize, 1);
events.clear();
⋮----
fn test_safe_to_skip() {
⋮----
assert_eq!(stats.event_safe_to_skip, 0);
⋮----
assert!(matches!(events[0], VotorEvent::SafeToSkip(s) if s == slot));
assert_eq!(stats.event_safe_to_skip, 1);

================
File: votor/src/consensus_pool/stats.rs
================
struct CertificateStats {
⋮----
impl CertificateStats {
fn increment(&mut self, cert_type: &CertificateType) {
⋮----
CertificateType::Finalize(_) => self.finalize = self.finalize.saturating_add(1),
⋮----
self.finalize_fast = self.finalize_fast.saturating_add(1)
⋮----
CertificateType::Notarize(_, _) => self.notarize = self.notarize.saturating_add(1),
⋮----
self.notarize_fallback = self.notarize_fallback.saturating_add(1)
⋮----
CertificateType::Skip(_) => self.skip = self.skip.saturating_add(1),
⋮----
fn report(&self, header: &'static str) {
datapoint_info!(
⋮----
struct VoteStats {
⋮----
impl VoteStats {
fn increment(&mut self, vote: &Vote) {
⋮----
Vote::Notarize(_) => self.notarize = self.notarize.saturating_add(1),
⋮----
Vote::Skip(_) => self.skip = self.skip.saturating_add(1),
Vote::SkipFallback(_) => self.skip_fallback = self.skip_fallback.saturating_add(1),
Vote::Finalize(_) => self.finalize = self.finalize.saturating_add(1),
⋮----
fn report(&self) {
⋮----
pub(crate) struct ConsensusPoolStats {
⋮----
impl Default for ConsensusPoolStats {
fn default() -> Self {
⋮----
impl ConsensusPoolStats {
pub fn new() -> Self {
⋮----
pub fn incr_ingested_vote(&mut self, vote: &Vote) {
self.ingested_votes.increment(vote);
⋮----
pub fn incr_cert_type(&mut self, cert_type: &CertificateType, is_generated: bool) {
⋮----
self.new_certs_generated.increment(cert_type);
⋮----
self.new_certs_ingested.increment(cert_type);
⋮----
self.ingested_votes.report();
⋮----
.report("consensus_pool_generated_certs");
⋮----
.report("consensus_pool_ingested_certs");
⋮----
pub fn maybe_report(&mut self) {
if self.last_request_time.elapsed() >= STATS_REPORT_INTERVAL {
self.report();

================
File: votor/src/consensus_pool/vote_pool.rs
================
pub(crate) enum AddVoteError {
⋮----
fn insert_vote(
⋮----
match map.entry(voter) {
Entry::Occupied(_) => Err(AddVoteError::Duplicate),
⋮----
e.insert(vote);
Ok(())
⋮----
struct InternalVotePool {
⋮----
impl InternalVotePool {
fn new(slot: Slot) -> Self {
⋮----
fn add_vote(&mut self, voter: Pubkey, vote: VoteMessage) -> Result<(), AddVoteError> {
debug_assert_eq!(self.slot, vote.vote.slot());
⋮----
if self.skip.contains_key(&voter) {
return Err(AddVoteError::Invalid);
⋮----
match self.notar.entry(voter) {
⋮----
if e.get().vote.block_id().unwrap() == &notar.block_id {
Err(AddVoteError::Duplicate)
⋮----
Err(AddVoteError::Invalid)
⋮----
if self.finalize.contains_key(&voter) {
⋮----
match self.notar_fallback.entry(voter) {
⋮----
e.insert(BTreeMap::from([(notar_fallback.block_id, vote)]));
⋮----
let map = e.get_mut();
let map_len = map.len();
match map.entry(notar_fallback.block_id) {
⋮----
map_e.insert(vote);
⋮----
if self.notar.contains_key(&voter) || self.finalize.contains_key(&voter) {
⋮----
insert_vote(&mut self.skip, voter, vote)
⋮----
insert_vote(&mut self.skip_fallback, voter, vote)
⋮----
if self.skip.contains_key(&voter) || self.skip_fallback.contains_key(&voter) {
⋮----
if let Some(map) = self.notar_fallback.get(&voter) {
debug_assert!(!map.is_empty());
⋮----
insert_vote(&mut self.finalize, voter, vote)
⋮----
fn get_votes(&self, vote: &Vote) -> Vec<VoteMessage> {
⋮----
Vote::Finalize(_) => self.finalize.values().cloned().collect(),
⋮----
.values()
.filter(|vote| {
vote.vote.block_id().unwrap() == &notar.block_id
⋮----
.cloned()
.collect(),
⋮----
.filter_map(|map| map.get(&nf.block_id))
⋮----
Vote::Skip(_) => self.skip.values().cloned().collect(),
Vote::SkipFallback(_) => self.skip_fallback.values().cloned().collect(),
⋮----
struct Stakes {
⋮----
impl Stakes {
⋮----
fn add_stake(&mut self, voter_stake: Stake, vote: &Vote) -> Stake {
debug_assert_eq!(self.slot, vote.slot());
⋮----
let stake = self.notar.entry(notar.block_id).or_default();
*stake = (*stake).saturating_add(voter_stake);
⋮----
let stake = self.notar_fallback.entry(nf.block_id).or_default();
⋮----
self.skip = self.skip.saturating_add(voter_stake);
⋮----
self.skip_fallback = self.skip_fallback.saturating_add(voter_stake);
⋮----
self.finalize = self.finalize.saturating_add(voter_stake);
⋮----
fn get_stake(&self, vote: &Vote) -> Stake {
⋮----
Vote::Notarize(notar) => *self.notar.get(&notar.block_id).unwrap_or(&0),
Vote::NotarizeFallback(nf) => *self.notar_fallback.get(&nf.block_id).unwrap_or(&0),
⋮----
pub(super) struct VotePool {
⋮----
impl VotePool {
pub(super) fn new(slot: Slot) -> Self {
⋮----
pub(super) fn add_vote(
⋮----
debug_assert_eq!(self.slot, msg.vote.slot());
⋮----
self.votes.add_vote(voter, msg)?;
Ok(self.stakes.add_stake(voter_stake, &vote))
⋮----
pub(super) fn get_stake(&self, vote: &Vote) -> Stake {
self.stakes.get_stake(vote)
⋮----
pub(super) fn get_votes(&self, vote: &Vote) -> Vec<VoteMessage> {
self.votes.get_votes(vote)
⋮----
mod test {
⋮----
fn test_notar_failures() {
⋮----
votes.add_vote(voter, skip).unwrap();
⋮----
assert!(matches!(
⋮----
votes.add_vote(voter, notar).unwrap();
⋮----
votes.add_vote(voter, notar.clone()).unwrap();
⋮----
fn test_notar_fallback_failures() {
⋮----
votes.add_vote(voter, finalize).unwrap();
⋮----
votes.add_vote(voter, nf).unwrap();
⋮----
votes.add_vote(voter, nf.clone()).unwrap();
⋮----
fn test_skip_failures() {
⋮----
votes.add_vote(voter, skip.clone()).unwrap();
⋮----
fn test_skip_fallback_failures() {
⋮----
votes.add_vote(voter, sf.clone()).unwrap();
⋮----
fn test_finalize_failures() {
⋮----
votes.add_vote(voter, sf).unwrap();
⋮----
votes.add_vote(voter, finalize.clone()).unwrap();
⋮----
fn test_stakes() {
⋮----
assert_eq!(stakes.add_stake(stake, &vote), stake);
assert_eq!(stakes.get_stake(&vote), stake);
⋮----
assert_eq!(stakes.add_stake(stake0, &vote0), stake0);
assert_eq!(stakes.add_stake(stake1, &vote1), stake1);
assert_eq!(stakes.get_stake(&vote0), stake0);
assert_eq!(stakes.get_stake(&vote1), stake1);
⋮----
fn test_vote_pool() {
⋮----
assert_eq!(
⋮----
assert_eq!(vote_pool.get_stake(&vote), stake);
let returned_votes = vote_pool.get_votes(&vote);
assert_eq!(returned_votes.len(), 1);
assert_eq!(returned_votes[0], vote_message);

================
File: votor/src/consensus_pool_service/stats.rs
================
pub(super) struct Stats {
⋮----
impl Default for Stats {
fn default() -> Self {
⋮----
add_message_failed: Saturating(0),
certificates_sent: Saturating(0),
certificates_dropped: Saturating(0),
new_finalized_slot: Saturating(0),
parent_ready_missed_window: Saturating(0),
parent_ready_produce_window: Saturating(0),
received_votes: Saturating(0),
received_certificates: Saturating(0),
⋮----
prune_old_state_called: Saturating(0),
⋮----
impl Stats {
fn report(&self) {
⋮----
datapoint_info!(
⋮----
pub(super) fn maybe_report(&mut self) {
if self.last_request_time.elapsed() >= STATS_REPORT_INTERVAL {
self.report();

================
File: votor/src/event_handler/stats.rs
================
struct SlotTracking {
⋮----
impl Default for SlotTracking {
fn default() -> Self {
⋮----
impl SlotTracking {
fn finalized_elapsed_micros(&self) -> Option<i64> {
self.finalized.map(|(t, _fast_finalize)| t)
⋮----
fn is_fast_finalized(&self) -> Option<bool> {
self.finalized.map(|(_t, fast_finalize)| fast_finalize)
⋮----
fn report(&self, slot: Slot) {
datapoint_info!(
⋮----
pub enum StatsEvent {
⋮----
struct EventCountAndTime {
⋮----
struct ReceivedEventsStats {
⋮----
impl ReceivedEventsStats {
fn incr_event_with_timing(&mut self, stats_event: StatsEvent, time_us: u64) {
⋮----
self.block.count = self.block.count.saturating_add(1);
self.block.time_us = self.block.time_us.saturating_add(time_us);
⋮----
self.block_notarized.count = self.block_notarized.count.saturating_add(1);
self.block_notarized.time_us = self.block_notarized.time_us.saturating_add(time_us);
⋮----
self.first_shred.count = self.first_shred.count.saturating_add(1);
self.first_shred.time_us = self.first_shred.time_us.saturating_add(time_us);
⋮----
self.parent_ready.count = self.parent_ready.count.saturating_add(1);
self.parent_ready.time_us = self.parent_ready.time_us.saturating_add(time_us);
⋮----
self.timeout_crashed_leader.count.saturating_add(1);
⋮----
self.timeout_crashed_leader.time_us.saturating_add(time_us);
⋮----
self.timeout.count = self.timeout.count.saturating_add(1);
self.timeout.time_us = self.timeout.time_us.saturating_add(time_us);
⋮----
self.safe_to_notar.count = self.safe_to_notar.count.saturating_add(1);
self.safe_to_notar.time_us = self.safe_to_notar.time_us.saturating_add(time_us);
⋮----
self.safe_to_skip.count = self.safe_to_skip.count.saturating_add(1);
self.safe_to_skip.time_us = self.safe_to_skip.time_us.saturating_add(time_us);
⋮----
self.produce_window.count = self.produce_window.count.saturating_add(1);
self.produce_window.time_us = self.produce_window.time_us.saturating_add(time_us);
⋮----
self.finalized.count = self.finalized.count.saturating_add(1);
self.finalized.time_us = self.finalized.time_us.saturating_add(time_us);
⋮----
self.standstill.count = self.standstill.count.saturating_add(1);
self.standstill.time_us = self.standstill.time_us.saturating_add(time_us);
⋮----
self.set_identity.count = self.set_identity.count.saturating_add(1);
self.set_identity.time_us = self.set_identity.time_us.saturating_add(time_us);
⋮----
fn report(&self) {
⋮----
struct SentVoteStats {
⋮----
impl SentVoteStats {
fn incr_vote(&mut self, vote_type: VoteType) {
⋮----
VoteType::Finalize => self.finalize = self.finalize.saturating_add(1),
VoteType::Notarize => self.notarize = self.notarize.saturating_add(1),
⋮----
self.notarize_fallback = self.notarize_fallback.saturating_add(1)
⋮----
VoteType::Skip => self.skip = self.skip.saturating_add(1),
VoteType::SkipFallback => self.skip_fallback = self.skip_fallback.saturating_add(1),
⋮----
pub(crate) struct EventHandlerStats {
⋮----
impl Default for EventHandlerStats {
⋮----
impl StatsEvent {
pub fn new(event: &VotorEvent) -> Self {
⋮----
impl EventHandlerStats {
pub fn new() -> Self {
⋮----
fn reset(&mut self, root_slot: Slot, slot_tracking_map: BTreeMap<Slot, SlotTracking>) {
⋮----
pub fn handle_event_arrival(&mut self, event: &VotorEvent) -> StatsEvent {
⋮----
let entry = self.slot_tracking_map.entry(*slot).or_default();
entry.first_shred = Some(
⋮----
.saturating_duration_since(entry.start)
.as_micros() as i64,
⋮----
entry.parent_ready = Some(
⋮----
if entry.finalized.is_none() {
entry.finalized = Some((
⋮----
entry.finalized = Some((instant, true));
⋮----
pub fn set_root(&mut self, new_root: Slot) {
⋮----
self.set_root_count = self.set_root_count.saturating_add(1);
⋮----
pub fn incr_event_with_timing(&mut self, stats_event: StatsEvent, time_us: u64) {
⋮----
.incr_event_with_timing(stats_event, time_us);
⋮----
pub fn incr_vote(&mut self, bls_op: &BLSOp) {
⋮----
warn!("Unexpected BLS operation: {bls_op:?}");
⋮----
warn!("Unexpected BLS message type: {message:?}");
⋮----
self.sent_votes.incr_vote(vote_type);
⋮----
let entry = self.slot_tracking_map.entry(vote.vote.slot()).or_default();
entry.vote_notarize = Some(
⋮----
entry.vote_skip = Some(
⋮----
pub fn maybe_report(&mut self) {
⋮----
if now.duration_since(self.last_report_time) < STATS_REPORT_INTERVAL {
⋮----
self.received_events_stats.report();
self.sent_votes.report();
let split_off_map = self.slot_tracking_map.split_off(&self.root_slot);
⋮----
tracking.report(*slot);
⋮----
self.reset(self.root_slot, split_off_map);

================
File: votor/src/timer_manager/stats.rs
================
pub(crate) struct TimerManagerStats {
⋮----
impl TimerManagerStats {
pub fn new() -> Self {
⋮----
pub fn max_heap_size(&self) -> u64 {
⋮----
pub fn set_timeout_count(&self) -> u64 {
⋮----
pub fn set_timeout_succeed_count(&self) -> u64 {
⋮----
pub fn incr_timeout_count_with_heap_size(&mut self, size: usize, new_timer_inserted: bool) {
self.set_timeout_count = self.set_timeout_count.saturating_add(1);
self.max_heap_size = self.max_heap_size.max(size as u64);
⋮----
self.set_timeout_succeed_count = self.set_timeout_succeed_count.saturating_add(1);
⋮----
self.maybe_report();
⋮----
fn maybe_report(&mut self) {
if self.last_report.elapsed() < STATS_REPORT_INTERVAL {
⋮----
datapoint_info!(

================
File: votor/src/timer_manager/timers.rs
================
enum TimerState {
⋮----
impl TimerState {
fn new(slot: Slot, delta_timeout: Duration, now: Instant) -> (Self, Instant) {
let window = (slot..=last_of_consecutive_leader_slots(slot)).collect::<VecDeque<_>>();
assert!(!window.is_empty());
let timeout = now.checked_add(delta_timeout).unwrap();
⋮----
fn progress(&mut self, delta_block: Duration, now: Instant) -> Option<VotorEvent> {
⋮----
let slot = *window.front().unwrap();
let timeout = now.checked_add(delta_block).unwrap();
⋮----
window: window.to_owned(),
⋮----
Some(VotorEvent::TimeoutCrashedLeader(slot))
⋮----
let ret = Some(VotorEvent::Timeout(window.pop_front().unwrap()));
match window.front() {
⋮----
*timeout = now.checked_add(delta_block).unwrap();
⋮----
fn next_fire(&self) -> Option<Instant> {
⋮----
| Self::WaitDeltaBlock { window: _, timeout } => Some(*timeout),
⋮----
pub(super) struct Timers {
⋮----
impl Timers {
pub(super) fn new(
⋮----
pub(super) fn set_timeouts(&mut self, slot: Slot, now: Instant) {
assert_eq!(self.heap.len(), self.timers.len());
⋮----
self.timers.entry(slot).or_insert_with(|| {
self.heap.push(Reverse((next_fire, slot)));
⋮----
.incr_timeout_count_with_heap_size(self.heap.len(), new_timer_inserted);
⋮----
pub(super) fn progress(&mut self, now: Instant) -> Option<Instant> {
⋮----
match self.heap.pop() {
⋮----
Some(ret_timeout.map_or(next_fire, |r| std::cmp::min(r, next_fire)));
⋮----
let mut timer = self.timers.remove(&slot).unwrap();
if let Some(event) = timer.progress(self.delta_block, now) {
self.event_sender.send(event).unwrap();
⋮----
if let Some(next_fire) = timer.next_fire() {
⋮----
assert!(self.timers.insert(slot, timer).is_none());
⋮----
pub(super) fn stats(&self) -> TimerManagerStats {
self.stats.clone()
⋮----
pub(super) fn is_timeout_set(&self, slot: Slot) -> bool {
self.timers.contains_key(&slot)
⋮----
mod tests {
⋮----
fn timer_state_machine() {
⋮----
assert!(matches!(
⋮----
assert!(timer_state.next_fire().is_none());
⋮----
fn timers_progress() {
⋮----
let (sender, receiver) = unbounded();
⋮----
assert!(timers.progress(now).is_none());
assert!(receiver.try_recv().unwrap_err().is_empty());
timers.set_timeouts(0, now);
while timers.progress(now).is_some() {
now = now.checked_add(one_micro).unwrap();
⋮----
let mut events = receiver.try_iter().collect::<Vec<_>>();
⋮----
assert!(matches!(events.remove(0), VotorEvent::Timeout(0)));
assert!(matches!(events.remove(0), VotorEvent::Timeout(1)));
assert!(matches!(events.remove(0), VotorEvent::Timeout(2)));
assert!(matches!(events.remove(0), VotorEvent::Timeout(3)));
assert!(events.is_empty());
let stats = timers.stats();
assert_eq!(stats.set_timeout_count(), 1);
assert_eq!(stats.set_timeout_succeed_count(), 1);
assert_eq!(stats.max_heap_size(), 1);

================
File: votor/src/commitment.rs
================
pub enum CommitmentError {
⋮----
pub enum CommitmentType {
⋮----
pub struct CommitmentAggregationData {
⋮----
pub fn update_commitment_cache(
⋮----
match commitment_sender.try_send(CommitmentAggregationData {
⋮----
info!("commitment_sender has disconnected");
return Err(CommitmentError::ChannelDisconnected);
⋮----
Err(TrySendError::Full(_)) => error!("commitment_sender is backed up, something is wrong"),
⋮----
Ok(())
⋮----
mod tests {
⋮----
fn test_update_commitment_cache() {
let (commitment_sender, commitment_receiver) = unbounded();
⋮----
update_commitment_cache(commitment_type, slot, &commitment_sender)
.expect("Failed to send commitment data");
⋮----
.try_recv()
.expect("Failed to receive commitment data");
assert_eq!(
⋮----
drop(commitment_receiver);
let result = update_commitment_cache(CommitmentType::Notarize, 7, &commitment_sender);
assert!(matches!(result, Err(CommitmentError::ChannelDisconnected)));

================
File: votor/src/common.rs
================
pub type Stake = u64;
⋮----
pub enum VoteType {
⋮----
impl VoteType {
pub fn get_type(vote: &Vote) -> VoteType {
⋮----
pub fn is_notarize_type(&self) -> bool {
matches!(self, Self::Notarize | Self::NotarizeFallback)
⋮----
pub(crate) fn certificate_limits_and_votes(
⋮----
Some(Vote::new_notarization_fallback_vote(*slot, *block_id)),
⋮----
Some(Vote::new_skip_fallback_vote(*slot)),
⋮----
pub fn vote_to_certificate_ids(vote: &Vote) -> Vec<CertificateType> {
⋮----
Vote::Notarize(vote) => vec![
⋮----
vec![CertificateType::NotarizeFallback(vote.slot, vote.block_id)]
⋮----
Vote::Finalize(vote) => vec![CertificateType::Finalize(vote.slot)],
Vote::Skip(vote) => vec![CertificateType::Skip(vote.slot)],
Vote::SkipFallback(vote) => vec![CertificateType::Skip(vote.slot)],
⋮----
pub(crate) const DELTA_TIMEOUT: Duration = DELTA.checked_mul(3).unwrap();
⋮----
pub fn skip_timeout(leader_block_index: usize) -> Duration {
⋮----
.saturating_add(
⋮----
.saturating_mul(leader_block_index as u32)
.saturating_add(DELTA_TIMEOUT),
⋮----
.saturating_add(DELTA)
⋮----
pub fn block_timeout(leader_block_index: usize) -> Duration {
DELTA_BLOCK.saturating_mul((leader_block_index as u32).saturating_add(1))

================
File: votor/src/consensus_metrics.rs
================
pub enum ConsensusMetricsEvent {
⋮----
pub type ConsensusMetricsEventSender = Sender<(Instant, Vec<ConsensusMetricsEvent>)>;
pub type ConsensusMetricsEventReceiver = Receiver<(Instant, Vec<ConsensusMetricsEvent>)>;
fn build_histogram() -> Histogram {
⋮----
.max_value(10_000_000)
.build()
.unwrap()
⋮----
struct NodeVoteMetrics {
⋮----
impl Default for NodeVoteMetrics {
fn default() -> Self {
let histogram = build_histogram();
⋮----
notar: histogram.clone(),
notar_fallback: histogram.clone(),
skip: histogram.clone(),
skip_fallback: histogram.clone(),
⋮----
impl NodeVoteMetrics {
fn record_vote(&mut self, vote: &Vote, elapsed: Duration) {
let elapsed = elapsed.as_micros();
let elapsed = match elapsed.try_into() {
⋮----
warn!(
⋮----
Vote::Notarize(_) => self.notar.increment(elapsed),
Vote::NotarizeFallback(_) => self.notar_fallback.increment(elapsed),
Vote::Skip(_) => self.skip.increment(elapsed),
Vote::SkipFallback(_) => self.skip_fallback.increment(elapsed),
Vote::Finalize(_) => self.final_.increment(elapsed),
⋮----
pub enum RecordVoteError {
⋮----
pub enum RecordBlockHashError {
⋮----
pub struct ConsensusMetrics {
⋮----
impl ConsensusMetrics {
fn new(epoch: Epoch, receiver: ConsensusMetricsEventReceiver) -> Self {
⋮----
pub(crate) fn start_metrics_loop(
⋮----
.name("solConsMetrics".into())
.spawn(move || {
info!("ConsensusMetricsService has started");
⋮----
metrics.run(exit);
info!("ConsensusMetricsService has stopped");
⋮----
.expect("Failed to start consensus metrics thread")
⋮----
fn run(&mut self, exit: Arc<AtomicBool>) {
while !exit.load(Ordering::Relaxed) {
match self.receiver.recv_timeout(Duration::from_secs(1)) {
⋮----
self.record_vote(id, &vote, recorded);
⋮----
self.record_block_hash_seen(leader, slot, recorded);
⋮----
self.maybe_new_epoch(epoch);
⋮----
self.record_start_of_slot(slot, recorded);
⋮----
RecvTimeoutError::Timeout => trace!("ConsensusMetricsEventReceiver timeout"),
⋮----
warn!("ConsensusMetricsEventReceiver disconnected, exiting loop");
⋮----
fn record_vote(&mut self, id: Pubkey, vote: &Vote, recorded: Instant) {
let Some(start) = self.start_of_slot.get(&vote.slot()) else {
self.metrics_recording_failed = self.metrics_recording_failed.saturating_add(1);
⋮----
let node = self.node_metrics.entry(id).or_default();
let elapsed = recorded.duration_since(*start);
node.record_vote(vote, elapsed);
⋮----
fn record_block_hash_seen(&mut self, leader: Pubkey, slot: Slot, recorded: Instant) {
let Some(start) = self.start_of_slot.get(&slot) else {
⋮----
let elapsed = recorded.duration_since(*start).as_micros();
⋮----
.entry(leader)
.or_insert_with(build_histogram);
match histogram.increment(elapsed) {
⋮----
fn record_start_of_slot(&mut self, slot: Slot, recorded: Instant) {
self.start_of_slot.entry(slot).or_insert(recorded);
⋮----
fn end_of_epoch_reporting(&mut self) {
⋮----
let addr = addr.to_string();
datapoint_info!("votor_consensus_metrics",
⋮----
self.node_metrics.clear();
self.leader_metrics.clear();
self.start_of_slot.clear();
⋮----
fn maybe_new_epoch(&mut self, epoch: Epoch) {
assert!(epoch >= self.current_epoch);
⋮----
self.end_of_epoch_reporting();

================
File: votor/src/consensus_pool_service.rs
================
mod stats;
pub(crate) struct ConsensusPoolContext {
⋮----
pub(crate) struct ConsensusPoolService {
⋮----
enum ServiceError {
⋮----
impl ConsensusPoolService {
pub(crate) fn new(mut ctx: ConsensusPoolContext) -> Self {
⋮----
.name("solCnsPoolIngst".to_string())
.spawn(move || {
info!("ConsensusPoolService has started");
⋮----
ctx.exit.store(true, Ordering::Relaxed);
error!("ConsensusPoolService exited with error: {e}");
⋮----
info!("ConsensusPoolService has stopped");
⋮----
.unwrap();
⋮----
fn maybe_update_root_and_send_new_certificates(
⋮----
if new_finalized_slot.is_some() {
⋮----
let root_bank = sharable_banks.root();
consensus_pool.prune_old_state(root_bank.slot());
⋮----
fn send_certificates(
⋮----
let certs_len = certs.len();
for (i, certificate) in certs.into_iter().enumerate() {
match bls_sender.try_send(BLSOp::PushCertificate { certificate }) {
⋮----
return Err(ServiceError::ChannelDisconnected(
"VotingService".to_string(),
⋮----
stats.certificates_dropped += certs_len.saturating_sub(i);
return Err(ServiceError::ChannelFull);
⋮----
Ok(())
⋮----
fn process_consensus_message(
⋮----
let root_bank = ctx.sharable_banks.root();
⋮----
fn consensus_pool_ingest_loop(ctx: &mut ConsensusPoolContext) -> Result<(), ServiceError> {
let mut events = vec![];
let mut my_pubkey = ctx.cluster_info.id();
⋮----
ConsensusPool::new_from_root_bank(ctx.cluster_info.clone(), &root_bank);
info!("{my_pubkey}: Consensus pool loop initialized, waiting for Alpenglow migration");
⋮----
info!("{my_pubkey}: Consensus pool loop starting");
⋮----
let root_block = (root_bank.slot(), root_bank.block_id().unwrap_or_default());
let mut highest_parent_ready = root_bank.slot();
events.push(VotorEvent::ParentReady {
slot: root_bank.slot().checked_add(1).unwrap(),
⋮----
while !ctx.exit.load(Ordering::Relaxed) {
let new_pubkey = ctx.cluster_info.id();
⋮----
info!("Consensus pool pubkey updated to {my_pubkey}");
⋮----
if standstill_timer.elapsed() > ctx.delta_standstill {
events.push(VotorEvent::Standstill(
consensus_pool.highest_finalized_slot(),
⋮----
consensus_pool.get_certs_for_standstill(),
⋮----
return Err(ServiceError::ChannelDisconnected(channel_name));
⋮----
trace!("{my_pubkey}: unable to push standstill certificates into pool {e}");
⋮----
.drain(..)
.try_for_each(|event| ctx.event_sender.send(event))
.map_err(|_| {
ServiceError::ChannelDisconnected("Votor event receiver".to_string())
⋮----
let consensus_message_receiver = ctx.consensus_message_receiver.clone();
let messages = match consensus_message_receiver.recv_timeout(Duration::from_secs(1)) {
⋮----
std::iter::once(first_message).chain(consensus_message_receiver.try_iter())
⋮----
"BLS receiver".to_string(),
⋮----
return Err(ServiceError::ChannelDisconnected(n));
⋮----
warn!("{my_pubkey}: process_consensus_message() failed with {e}");
⋮----
stats.maybe_report();
consensus_pool.maybe_report();
⋮----
fn add_message_and_maybe_update_commitment(
⋮----
let (new_finalized_slot, new_certificates_to_send) = consensus_pool.add_message(
root_bank.epoch_schedule(),
root_bank.epoch_stakes_map(),
root_bank.slot(),
⋮----
return Ok((None, new_certificates_to_send));
⋮----
trace!("{my_pubkey}: new finalization certificate for {new_finalized_slot}");
update_commitment_cache(
⋮----
.map_err(|e| match e {
⋮----
ServiceError::ChannelDisconnected("CommitmentSender".to_string())
⋮----
Ok((Some(new_finalized_slot), new_certificates_to_send))
⋮----
fn add_produce_block_event(
⋮----
.iter()
.filter_map(|event| match event {
VotorEvent::ParentReady { slot, .. } => Some(slot),
⋮----
.max()
.copied()
⋮----
return Ok(());
⋮----
.slot_leader_at(*highest_parent_ready, Some(&root_bank))
⋮----
return Err(ServiceError::FailedToAddBlockEvent(format!(
⋮----
let end_slot = last_of_consecutive_leader_slots(start_slot);
if (start_slot..=end_slot).any(|s| ctx.blockstore.has_existing_shreds_for_slot(s)) {
warn!(
⋮----
.block_production_parent(start_slot)
⋮----
return Err(ServiceError::FailedToAddBlockEvent(
"Must have a block production parent".to_string(),
⋮----
events.push(VotorEvent::ProduceWindow(LeaderWindowInfo {
⋮----
pub(crate) fn join(self) -> thread::Result<()> {
self.t_ingest.join()
⋮----
mod tests {
⋮----
struct ConsensusPoolServiceTestComponents {
⋮----
fn setup(delta_standstill: Option<Duration>) -> ConsensusPoolServiceTestComponents {
⋮----
.map(|_| ValidatorVoteKeypairs::new_rand())
⋮----
let stake = (0..validator_keypairs.len())
.rev()
.map(|i| (i.saturating_add(5).saturating_mul(100)) as u64)
⋮----
let genesis = create_genesis_config_with_alpenglow_vote_accounts(
⋮----
let my_keypair = validator_keypairs[0].node_keypair.insecure_clone();
let contact_info = ContactInfo::new_localhost(&my_keypair.pubkey(), 0);
⋮----
let ledger_path = get_tmp_ledger_path_auto_delete!();
let blockstore = Blockstore::open(ledger_path.path()).unwrap();
let sharable_banks = bank_forks.read().unwrap().sharable_banks();
⋮----
Arc::new(LeaderScheduleCache::new_from_bank(&sharable_banks.root()));
⋮----
exit: exit.clone(),
⋮----
sharable_banks: sharable_banks.clone(),
leader_schedule_cache: leader_schedule_cache.clone(),
⋮----
delta_standstill: delta_standstill.unwrap_or(DELTA_STANDSTILL),
⋮----
fn wait_for_event<T>(receiver: &Receiver<T>, condition: impl Fn(&T) -> bool) {
⋮----
while start.elapsed() < Duration::from_secs(5) {
let res = receiver.recv_timeout(Duration::from_millis(500));
⋮----
if condition(&event) {
⋮----
assert!(event_received);
⋮----
fn test_send_and_receive<T>(
⋮----
consensus_message_sender.send(message).unwrap();
⋮----
wait_for_event(receiver, condition);
⋮----
fn test_receive_and_send_consensus_message() {
⋮----
let setup_result = setup(None);
⋮----
.map(|my_rank| {
⋮----
BLSKeypair::derive_from_signer(vote_keypair, BLS_KEYPAIR_DERIVE_SEED).unwrap();
let vote_serialized = bincode::serialize(&notarize_vote).unwrap();
⋮----
signature: bls_keypair.sign(&vote_serialized).into(),
⋮----
.collect();
test_send_and_receive(
⋮----
assert_eq!(certificate.cert_type.slot(), target_slot);
⋮----
assert!(matches!(
⋮----
wait_for_event(&setup_result.event_receiver, |event| {
⋮----
assert_eq!(*slot, target_slot);
assert_eq!(*receivied_block_id, block_id);
assert!(*is_fast_finalized);
⋮----
wait_for_event(
⋮----
assert_eq!(*commitment_type, CommitmentType::Finalized);
⋮----
bitmap: vec![],
⋮----
vec![ConsensusMessage::Certificate(skip_certificate)],
⋮----
matches!(certificate.cert_type, CertificateType::Skip(slot) if slot == target_slot)
⋮----
setup_result.exit.store(true, Ordering::Relaxed);
setup_result.consensus_pool_service.join().unwrap();
⋮----
fn test_send_produce_block_event() {
⋮----
let my_pubkey = setup_result.validator_keypairs[0].node_keypair.pubkey();
⋮----
.next_leader_slot(
⋮----
&setup_result.sharable_banks.root(),
⋮----
.expect("Should find a leader slot");
⋮----
.map(|slot| {
⋮----
assert_eq!(*start_slot, next_leader_slot.0);
⋮----
fn test_send_standstill() {
⋮----
let setup_result = setup(Some(delta_standstill_for_test));
⋮----
|event| matches!(event, VotorEvent::Standstill(slot) if *slot == 0),
⋮----
fn test_channel_disconnection(channel_name: &str) {
⋮----
.send(ConsensusMessage::Certificate(finalize_certificate))
⋮----
drop(setup_result.consensus_message_sender);
⋮----
drop(setup_result.bls_receiver);
⋮----
drop(setup_result.event_receiver);
⋮----
drop(setup_result.commitment_receiver);
⋮----
_ => panic!("Unknown channel name"),
⋮----
while !setup_result.exit.load(Ordering::Relaxed) && start.elapsed() < Duration::from_secs(5)
⋮----
assert!(setup_result.exit.load(Ordering::Relaxed));

================
File: votor/src/consensus_pool.rs
================
mod certificate_builder;
pub(crate) mod parent_ready_tracker;
mod slot_stake_counters;
mod stats;
mod vote_pool;
⋮----
enum AddVoteError {
⋮----
enum AddCertError {
⋮----
pub(crate) enum AddMessageError {
⋮----
fn get_key_and_stakes(
⋮----
let epoch = epoch_schedule.get_epoch(slot);
⋮----
.get(&epoch)
.ok_or(AddVoteError::EpochStakesNotFound(epoch))?;
⋮----
.bls_pubkey_to_rank_map()
.get_pubkey(rank as usize)
⋮----
return Err(AddVoteError::InvalidRank(rank));
⋮----
let stake = epoch_stakes.vote_account_stake(vote_key);
⋮----
panic!("Validator stake is zero for pubkey: {vote_key}");
⋮----
Ok((*vote_key, stake, epoch_stakes.total_stake()))
⋮----
pub(crate) struct ConsensusPool {
⋮----
impl ConsensusPool {
pub(crate) fn new_from_root_bank(cluster_info: Arc<ClusterInfo>, bank: &Bank) -> Self {
let root_block = (bank.slot(), bank.block_id().unwrap_or_default());
let parent_ready_tracker = ParentReadyTracker::new(cluster_info.clone(), root_block);
⋮----
fn build_certs(
⋮----
let Some(vote_pool) = self.vote_pools.get(&vote.slot()) else {
return Ok(vec![]);
⋮----
for cert_type in vote_to_certificate_ids(vote) {
if self.completed_certificates.contains_key(&cert_type) {
⋮----
let (limit, vote, fallback_vote) = certificate_limits_and_votes(&cert_type);
⋮----
.get_stake(&vote)
.saturating_add(fallback_vote.map_or(0, |v| vote_pool.get_stake(&v)));
⋮----
cert_builder.aggregate(&vote_pool.get_votes(&vote)).unwrap();
⋮----
cert_builder.aggregate(&vote_pool.get_votes(&v)).unwrap();
⋮----
let new_cert = Arc::new(cert_builder.build()?);
self.stats.incr_cert_type(&new_cert.cert_type, true);
new_certificates_to_send.push(new_cert);
⋮----
Ok(new_certificates_to_send)
⋮----
fn insert_certificate(&mut self, cert: Arc<Certificate>, events: &mut Vec<VotorEvent>) {
⋮----
trace!(
⋮----
self.completed_certificates.insert(cert_type, cert);
⋮----
.add_new_notar_fallback_or_stronger((slot, block_id), events);
⋮----
CertificateType::Skip(slot) => self.parent_ready_tracker.add_new_skip(slot, events),
⋮----
events.push(VotorEvent::BlockNotarized((slot, block_id)));
⋮----
if self.is_finalized(slot) {
events.push(VotorEvent::Finalized((slot, block_id), false));
⋮----
.is_none_or(|(s, _)| s < slot)
⋮----
self.highest_finalized_with_notarize = Some((slot, false));
⋮----
if let Some(block) = self.get_notarized_block(slot) {
events.push(VotorEvent::Finalized(block, false));
⋮----
if self.highest_finalized_slot.is_none_or(|s| s < slot) {
self.highest_finalized_slot = Some(slot);
⋮----
events.push(VotorEvent::Finalized((slot, block_id), true));
⋮----
.is_none_or(|(s, _)| s <= slot)
⋮----
self.highest_finalized_with_notarize = Some((slot, true));
⋮----
pub(crate) fn add_message(
⋮----
.add_vote(
⋮----
.map_err(|e| AddMessageError::Internal(e.to_string()))?,
⋮----
.add_certificate(root_slot, cert, events)
⋮----
Ok((new_finalized_slot, new_certficates_to_send))
⋮----
fn add_vote(
⋮----
let vote_slot = vote.slot();
⋮----
get_key_and_stakes(epoch_schedule, epoch_stakes_map, vote_slot, rank)?;
assert_ne!(
⋮----
self.stats.incoming_votes = self.stats.incoming_votes.saturating_add(1);
⋮----
self.stats.out_of_range_votes = self.stats.out_of_range_votes.saturating_add(1);
return Err(AddVoteError::UnrootedSlot);
⋮----
.entry(vote_slot)
.or_insert(VotePool::new(vote_slot))
.add_vote(validator_vote_key, validator_stake, vote_message)
⋮----
.or_insert_with(|| SlotStakeCounters::new(total_stake));
fallback_vote_counters.add_vote(
⋮----
self.stats.exist_votes = self.stats.exist_votes.saturating_add(1);
⋮----
self.stats.invalid_votes = self.stats.invalid_votes.saturating_add(1);
return Err(e.into());
⋮----
self.stats.incr_ingested_vote(&vote);
self.build_certs(&vote, total_stake).inspect(|certs| {
⋮----
self.insert_certificate(cert.clone(), events)
⋮----
fn add_certificate(
⋮----
self.stats.incoming_certs = self.stats.incoming_certs.saturating_add(1);
if cert_type.slot() < root_slot {
self.stats.out_of_range_certs = self.stats.out_of_range_certs.saturating_add(1);
return Err(AddCertError::UnrootedSlot);
⋮----
if self.completed_certificates.contains_key(cert_type) {
self.stats.exist_certs = self.stats.exist_certs.saturating_add(1);
⋮----
self.stats.incr_cert_type(cert_type, false);
⋮----
self.insert_certificate(cert.clone(), events);
Ok(vec![cert])
⋮----
fn get_notarized_block(&self, slot: Slot) -> Option<Block> {
⋮----
.iter()
.find_map(|(cert_type, _)| match cert_type {
CertificateType::Notarize(s, block_id) if slot == *s => Some((*s, *block_id)),
⋮----
fn highest_notarized_slot(&self) -> Slot {
⋮----
.filter_map(|(cert_type, _)| match cert_type {
CertificateType::Notarize(s, _) => Some(s),
CertificateType::NotarizeFallback(s, _) => Some(s),
⋮----
.max()
.copied()
.unwrap_or(0)
⋮----
fn highest_skip_slot(&self) -> Slot {
⋮----
CertificateType::Skip(s) => Some(s),
⋮----
pub(crate) fn highest_finalized_slot(&self) -> Slot {
⋮----
CertificateType::Finalize(s) => Some(s),
CertificateType::FinalizeFast(s, _) => Some(s),
⋮----
fn is_finalized(&self, slot: Slot) -> bool {
self.completed_certificates.keys().any(|cert_type| {
matches!(cert_type, CertificateType::Finalize(s) | CertificateType::FinalizeFast(s, _) if *s == slot)
⋮----
fn slot_has_notarized_fallback(&self, slot: Slot) -> bool {
self.completed_certificates.iter().any(
|(cert_type, _)| matches!(cert_type, CertificateType::NotarizeFallback(s,_) if *s == slot),
⋮----
fn skip_certified(&self, slot: Slot) -> bool {
⋮----
.contains_key(&CertificateType::Skip(slot))
⋮----
fn make_start_leader_decision(
⋮----
&& !self.slot_has_notarized_fallback(parent_slot)
&& !self.is_finalized(parent_slot)
⋮----
error!("Missing notarization certificate {parent_slot}");
⋮----
my_leader_slot != parent_slot.saturating_add(1);
⋮----
let begin_skip_slot = first_alpenglow_slot.max(parent_slot.saturating_add(1));
⋮----
if !self.skip_certified(slot) {
error!(
⋮----
pub(crate) fn prune_old_state(&mut self, root_slot: Slot) {
⋮----
.retain(|cert_type, _| match cert_type {
⋮----
self.vote_pools = self.vote_pools.split_off(&root_slot);
self.slot_stake_counters_map = self.slot_stake_counters_map.split_off(&root_slot);
self.parent_ready_tracker.set_root(root_slot);
⋮----
pub(crate) fn maybe_report(&mut self) {
self.stats.maybe_report();
⋮----
pub(crate) fn get_certs_for_standstill(&self) -> Vec<Arc<Certificate>> {
⋮----
self.highest_finalized_with_notarize.unwrap_or((0, false));
⋮----
.filter_map(|(cert_type, cert)| {
⋮----
cert_type.slot().cmp(&highest_finalized_with_notarize_slot),
⋮----
Some(cert.clone())
⋮----
panic!("Should not happen while certificate pool is single threaded")
⋮----
if cert_to_send.is_some() {
⋮----
.collect()
⋮----
mod tests {
⋮----
fn new_cluster_info() -> Arc<ClusterInfo> {
⋮----
let contact_info = ContactInfo::new_localhost(&keypair.pubkey(), 0);
⋮----
fn dummy_vote_message(
⋮----
.unwrap();
⋮----
.sign(bincode::serialize(vote).unwrap().as_slice())
.into();
⋮----
fn create_bank(slot: Slot, parent: Arc<Bank>, pubkey: &Pubkey) -> Bank {
⋮----
fn create_bank_forks(validator_keypairs: &[ValidatorVoteKeypairs]) -> Arc<RwLock<BankForks>> {
let genesis = create_genesis_config_with_alpenglow_vote_accounts(
⋮----
vec![100; validator_keypairs.len()],
⋮----
fn create_initial_state() -> (
⋮----
.map(|_| ValidatorVoteKeypairs::new_rand())
⋮----
let bank_forks = create_bank_forks(&validator_keypairs);
let root_bank = bank_forks.read().unwrap().root_bank();
⋮----
ConsensusPool::new_from_root_bank(new_cluster_info(), &root_bank),
⋮----
pool.add_message(
bank.epoch_schedule(),
bank.epoch_stakes_map(),
bank.slot(),
⋮----
dummy_vote_message(validator_keypairs, &vote, rank),
&mut vec![],
⋮----
dummy_vote_message(validator_keypairs, &vote, 6),
⋮----
Vote::Notarize(vote) => assert_eq!(pool.highest_notarized_slot(), vote.slot),
Vote::NotarizeFallback(vote) => assert_eq!(pool.highest_notarized_slot(), vote.slot),
Vote::Skip(vote) => assert_eq!(pool.highest_skip_slot(), vote.slot),
Vote::SkipFallback(vote) => assert_eq!(pool.highest_skip_slot(), vote.slot),
Vote::Finalize(vote) => assert_eq!(pool.highest_finalized_slot(), vote.slot),
⋮----
fn add_skip_vote_range(
⋮----
root_bank.epoch_schedule(),
root_bank.epoch_stakes_map(),
root_bank.slot(),
⋮----
dummy_vote_message(keypairs, &vote, rank),
⋮----
fn test_make_decision_leader_does_not_start_if_notarization_missing() {
let (_, pool, _) = create_initial_state();
⋮----
pool.make_start_leader_decision(my_leader_slot, parent_slot, first_alpenglow_slot);
assert!(
⋮----
fn test_make_decision_first_alpenglow_slot_edge_case_1() {
⋮----
assert!(pool.make_start_leader_decision(my_leader_slot, parent_slot, first_alpenglow_slot));
⋮----
fn test_make_decision_first_alpenglow_slot_edge_case_2() {
let (validator_keypairs, mut pool, bank_forks) = create_initial_state();
⋮----
assert!(!pool.make_start_leader_decision(
⋮----
add_certificate(
⋮----
&bank_forks.read().unwrap().root_bank(),
⋮----
fn test_make_decision_first_alpenglow_slot_edge_case_3() {
⋮----
fn test_make_decision_first_alpenglow_slot_edge_case_4() {
⋮----
fn test_make_decision_first_alpenglow_slot_edge_case_5() {
⋮----
fn test_make_decision_first_alpenglow_slot_edge_case_6() {
⋮----
fn test_make_decision_leader_does_not_start_if_skip_certificate_missing() {
let (validator_keypairs, mut pool, _) = create_initial_state();
⋮----
let my_pubkey = validator_keypairs[0].vote_keypair.pubkey();
let bank = create_bank(5, bank_forks.read().unwrap().get(0).unwrap(), &my_pubkey);
bank.freeze();
bank_forks.write().unwrap().insert(bank);
⋮----
assert_eq!(pool.highest_notarized_slot(), 5);
⋮----
fn test_make_decision_leader_starts_when_no_skip_required() {
⋮----
fn test_make_decision_leader_starts_if_notarized_and_skips_valid() {
⋮----
fn test_make_decision_leader_starts_if_skip_range_superset() {
⋮----
fn test_add_vote_and_create_new_certificate_with_types() {
⋮----
let cert_types = vec![CertificateType::Finalize(slot)];
do_test_add_vote_and_create_new_certificate_with_types(vote, cert_types);
⋮----
let cert_types = vec![
⋮----
let cert_types = vec![CertificateType::NotarizeFallback(slot, block_id)];
⋮----
let cert_types = vec![CertificateType::Skip(slot)];
⋮----
fn do_test_add_vote_and_create_new_certificate_with_types(
⋮----
Vote::Finalize(_) => |pool: &ConsensusPool| pool.highest_finalized_slot(),
Vote::Notarize(_) => |pool: &ConsensusPool| pool.highest_notarized_slot(),
Vote::NotarizeFallback(_) => |pool: &ConsensusPool| pool.highest_notarized_slot(),
Vote::Skip(_) => |pool: &ConsensusPool| pool.highest_skip_slot(),
Vote::SkipFallback(_) => |pool: &ConsensusPool| pool.highest_skip_slot(),
⋮----
let bank = bank_forks.read().unwrap().root_bank();
⋮----
dummy_vote_message(&validator_keypairs, &vote, my_validator_ix),
⋮----
let slot = vote.slot();
assert!(highest_slot_fn(&pool) < slot);
⋮----
dummy_vote_message(&validator_keypairs, &vote, rank),
⋮----
.add_message(
⋮----
dummy_vote_message(&validator_keypairs, &vote, new_validator_ix),
⋮----
if vote.is_finalize() {
assert_eq!(new_finalized_slot, Some(slot));
⋮----
assert!(new_finalized_slot.is_none());
⋮----
assert!(certs_to_send
⋮----
assert_eq!(highest_slot_fn(&pool), slot);
⋮----
ConsensusMessage::Certificate((*cert).clone()),
⋮----
assert_eq!(certs_to_send, []);
⋮----
fn test_add_certificate_with_types(cert_type: CertificateType, vote: Vote) {
⋮----
let message = ConsensusMessage::Certificate(cert.clone());
⋮----
message.clone(),
⋮----
if matches!(cert_type, CertificateType::Finalize(_))
|| matches!(cert_type, CertificateType::FinalizeFast(_, _))
⋮----
assert_eq!(new_finalized_slot, Some(cert_type.slot()));
⋮----
assert_eq!(certs_to_send.len(), 1);
assert_eq!(*certs_to_send[0], cert);
⋮----
for rank in 0..validator_keypairs.len() {
⋮----
assert!(!certs_to_send
⋮----
fn test_add_vote_zero_stake() {
let (_, mut pool, bank_forks) = create_initial_state();
⋮----
.unwrap_err();
assert_eq!(
⋮----
fn assert_single_certificate_range(
⋮----
assert!(pool.skip_certified(i));
⋮----
fn test_consecutive_slots() {
⋮----
assert_eq!(pool.highest_skip_slot(), 15);
⋮----
for i in 0..validator_keypairs.len() {
let slot = (i as u64).saturating_add(16);
⋮----
dummy_vote_message(&validator_keypairs, &vote, i),
⋮----
assert_single_certificate_range(&pool, 15, 15);
⋮----
fn test_multi_skip_cert() {
⋮----
add_skip_vote_range(
⋮----
assert!(pool.skip_certified(slot));
⋮----
assert!(!pool.skip_certified(slot));
⋮----
fn test_add_multiple_votes() {
⋮----
assert_eq!(pool.highest_skip_slot(), 0);
⋮----
assert_single_certificate_range(&pool, 20, 30);
⋮----
fn test_add_multiple_disjoint_votes() {
⋮----
dummy_vote_message(&validator_keypairs, &vote, 6),
⋮----
assert_eq!(pool.highest_skip_slot(), 2);
assert_single_certificate_range(&pool, 2, 2);
⋮----
dummy_vote_message(&validator_keypairs, &vote, 7),
⋮----
assert_eq!(pool.highest_skip_slot(), 4);
⋮----
assert_single_certificate_range(&pool, 4, 4);
⋮----
dummy_vote_message(&validator_keypairs, &vote, 8),
⋮----
assert_single_certificate_range(&pool, 2, 4);
assert!(pool.skip_certified(3));
⋮----
assert_eq!(pool.highest_skip_slot(), 10);
assert_single_certificate_range(&pool, 2, 10);
assert!(pool.skip_certified(7));
⋮----
fn test_update_existing_singleton_vote() {
⋮----
assert_eq!(pool.highest_skip_slot(), 1);
⋮----
assert_eq!(pool.highest_skip_slot(), 6);
assert_single_certificate_range(&pool, 1, 6);
⋮----
fn test_update_existing_vote() {
⋮----
add_skip_vote_range(&mut pool, &bank, 10, 25, &validator_keypairs, rank);
⋮----
add_skip_vote_range(&mut pool, &bank, 10, 20, &validator_keypairs, 6);
assert_eq!(pool.highest_skip_slot(), 20);
assert_single_certificate_range(&pool, 10, 20);
⋮----
fn test_threshold_not_reached() {
⋮----
fn test_update_and_skip_range_certify() {
⋮----
assert_single_certificate_range(&pool, 10, 15);
⋮----
fn test_safe_to_notar() {
⋮----
get_key_and_stakes(bank.epoch_schedule(), bank.epoch_stakes_map(), 0, 0).unwrap();
⋮----
let mut new_events = vec![];
⋮----
dummy_vote_message(&validator_keypairs, &vote, 0),
⋮----
assert!(new_events.is_empty());
⋮----
assert_eq!(new_events.len(), 1);
⋮----
assert_eq!(block_id, event_block_id);
assert_eq!(slot, event_slot);
⋮----
panic!("Expected SafeToNotar event");
⋮----
new_events.clear();
⋮----
assert_eq!(new_events.len(), 2);
⋮----
panic!("Expected SafeToSkip event");
⋮----
_ => panic!("Expected SafeToNotar event"),
⋮----
assert_eq!(duplicate_block_id, event_block_id);
⋮----
fn test_safe_to_skip() {
⋮----
VotorEvent::SafeToSkip(event_slot) => assert_eq!(slot, event_slot),
_ => panic!("Expected SafeToSkip event"),
⋮----
fn test_handle_new_root() {
⋮----
new_cluster_info(),
⋮----
ConsensusMessage::Certificate(cert_1.clone()),
⋮----
ConsensusMessage::Certificate(cert_2.clone()),
⋮----
assert!(pool.skip_certified(1));
assert!(pool.is_finalized(2));
let new_bank = Arc::new(create_bank(2, root_bank, &Pubkey::new_unique()));
pool.prune_old_state(new_bank.slot());
assert!(!pool.skip_certified(1));
⋮----
let new_bank = Arc::new(create_bank(3, new_bank, &Pubkey::new_unique()));
⋮----
assert!(!pool.is_finalized(2));
⋮----
assert!(pool
⋮----
fn test_get_certs_for_standstill() {
⋮----
assert!(pool.get_certs_for_standstill().is_empty());
⋮----
ConsensusMessage::Certificate(cert_3.clone()),
⋮----
ConsensusMessage::Certificate(cert_4.clone()),
⋮----
let certs = pool.get_certs_for_standstill();
assert_eq!(certs.len(), 2);
assert!(certs.iter().any(|cert| cert.cert_type.slot() == 3
⋮----
assert!(certs.iter().any(|cert| cert.cert_type.slot() == 4
⋮----
ConsensusMessage::Certificate(cert_5.clone()),
⋮----
ConsensusMessage::Certificate(cert_5_finalize.clone()),
⋮----
assert_eq!(certs.len(), 1);
⋮----
ConsensusMessage::Certificate(cert_6.clone()),
⋮----
assert!(certs.iter().any(|cert| cert.cert_type.slot() == 5
⋮----
assert!(certs.iter().any(|cert| cert.cert_type.slot() == 6
⋮----
ConsensusMessage::Certificate(cert_6_finalize.clone()),
⋮----
ConsensusMessage::Certificate(cert_6_notarize_fallback.clone()),
⋮----
ConsensusMessage::Certificate(cert_7.clone()),
⋮----
assert_eq!(certs.len(), 3);
⋮----
assert!(certs
⋮----
assert!(certs.iter().any(|cert| cert.cert_type.slot() == 8
⋮----
fn test_new_parent_ready_with_certificates() {
⋮----
let mut events = vec![];
⋮----
error!("Events: {events:?}");
assert!(events
⋮----
events.clear();
⋮----
fn test_vote_message_signature_verification() {
let (validator_keypairs, _, _) = create_initial_state();
⋮----
let consensus_message = dummy_vote_message(&validator_keypairs, &vote, rank_to_test);
⋮----
panic!("Expected Vote message")
⋮----
let signed_message = bincode::serialize(&vote).unwrap();
⋮----
.verify(&bls_pubkey, &signed_message)
.expect("BLS signature verification failed for VoteMessage");

================
File: votor/src/event_handler.rs
================
mod stats;
pub(crate) type PendingBlocks = BTreeMap<Slot, Vec<(Block, Block)>>;
pub(crate) struct EventHandlerContext {
⋮----
enum EventLoopError {
⋮----
pub(crate) struct EventHandler {
⋮----
struct LocalContext {
⋮----
impl EventHandler {
pub(crate) fn new(ctx: EventHandlerContext) -> Self {
let exit = ctx.exit.clone();
⋮----
.name("solVotorEvLoop".to_string())
.spawn(move || {
info!("EventHandler has started");
⋮----
exit.store(true, Ordering::Relaxed);
error!("EventHandler exited with error: {e}");
⋮----
info!("EventHandler has stopped");
⋮----
.unwrap();
⋮----
fn event_loop(context: EventHandlerContext) -> Result<(), EventLoopError> {
⋮----
my_pubkey: ctx.cluster_info.keypair().pubkey(),
⋮----
info!("{}: Event loop initialized", local_context.my_pubkey);
⋮----
info!("{}: Event loop starting", local_context.my_pubkey);
while !exit.load(Ordering::Relaxed) {
⋮----
let event = match event_receiver.recv_timeout(Duration::from_secs(1)) {
⋮----
Err(e) => return Err(EventLoopError::ReceiverDisconnected(e)),
⋮----
receive_event_time.stop();
⋮----
.saturating_add(receive_event_time.as_us());
let root_bank = vctx.sharable_banks.root();
if event.should_ignore(root_bank.slot()) {
local_context.stats.ignored = local_context.stats.ignored.saturating_add(1);
⋮----
let stats_event = local_context.stats.handle_event_arrival(&event);
⋮----
event_processing_time.stop();
⋮----
.incr_event_with_timing(stats_event, event_processing_time.as_us());
⋮----
local_context.stats.incr_vote(&vote);
⋮----
.send(vote)
.map_err(|_| EventLoopError::SenderDisconnected)?;
⋮----
send_votes_batch_time.stop();
⋮----
.saturating_add(send_votes_batch_time.as_us());
local_context.stats.maybe_report();
⋮----
Ok(())
⋮----
fn handle_parent_ready_event(
⋮----
info!("{my_pubkey}: Parent ready {slot} {parent_block:?}");
let should_set_timeouts = vctx.vote_history.add_parent_ready(slot, parent_block);
⋮----
timer_manager.write().set_timeouts(slot);
local_context.stats.timeout_set = local_context.stats.timeout_set.saturating_add(1);
⋮----
.write()
⋮----
fn send_to_metrics(
⋮----
match consensus_metrics_sender.try_send((Instant::now(), consensus_metrics_events)) {
Ok(()) => Ok(()),
Err(TrySendError::Disconnected(_)) => Err(EventLoopError::SenderDisconnected),
⋮----
warn!("send_to_metrics failed: queue is full");
⋮----
fn handle_event(
⋮----
let mut votes = vec![];
⋮----
debug_assert!(bank.is_frozen());
⋮----
vec![ConsensusMetricsEvent::StartOfSlot { slot }];
if slot == first_of_consecutive_leader_slots(slot) {
consensus_metrics_events.push(ConsensusMetricsEvent::BlockHashSeen {
leader: *bank.collector_id(),
⋮----
consensus_metrics_events.push(ConsensusMetricsEvent::MaybeNewEpoch {
epoch: bank.epoch(),
⋮----
info!("{my_pubkey}: Block {block:?} parent {parent_block:?}");
⋮----
} else if !vctx.vote_history.voted(slot) {
⋮----
.entry(slot)
.or_default()
.push((block, parent_block));
⋮----
info!("{my_pubkey}: Block Notarized {block:?}");
vctx.vote_history.add_block_notarized(block);
⋮----
info!("{my_pubkey}: First shred {slot}");
received_shred.insert(slot);
⋮----
vec![ConsensusMetricsEvent::StartOfSlot { slot }],
⋮----
info!("{my_pubkey}: TimeoutCrashedLeader {slot}");
if vctx.vote_history.voted(slot) || received_shred.contains(&slot) {
return Ok(votes);
⋮----
info!("{my_pubkey}: Timeout {slot}");
if slot != last_of_consecutive_leader_slots(slot) {
⋮----
vec![ConsensusMetricsEvent::StartOfSlot {
⋮----
if vctx.vote_history.voted(slot) {
⋮----
info!("{my_pubkey}: SafeToNotar {block:?}");
⋮----
if vctx.vote_history.its_over(slot)
|| vctx.vote_history.voted_notar_fallback(slot, block_id)
⋮----
info!("{my_pubkey}: Voting notarize-fallback for {slot} {block_id}");
if let Some(bls_op) = generate_vote_message(
⋮----
votes.push(bls_op);
⋮----
info!("{my_pubkey}: SafeToSkip {slot}");
⋮----
if vctx.vote_history.its_over(slot) || vctx.vote_history.voted_skip_fallback(slot) {
⋮----
info!("{my_pubkey}: Voting skip-fallback for {slot}");
⋮----
generate_vote_message(Vote::new_skip_fallback_vote(slot), false, vctx)?
⋮----
info!("{my_pubkey}: ProduceWindow {window_info:?}");
let mut l_window_info = ctx.leader_window_notifier.window_info.lock().unwrap();
if let Some(old_window_info) = l_window_info.as_ref() {
stats.leader_window_replaced = stats.leader_window_replaced.saturating_add(1);
error!(
⋮----
*l_window_info = Some(window_info);
ctx.leader_window_notifier.window_notification.notify_one();
⋮----
info!("{my_pubkey}: Finalized {block:?} fast: {is_fast_finalization}");
finalized_blocks.insert(block);
⋮----
info!("{my_pubkey}: Standstill {highest_finalized_slot}");
⋮----
info!("{my_pubkey}: SetIdentity");
⋮----
return Err(EventLoopError::SetIdentityError(e));
⋮----
Ok(votes)
⋮----
fn add_missing_parent_ready(
⋮----
let first_slot_of_window = first_of_consecutive_leader_slots(slot);
⋮----
if vctx.vote_history.highest_parent_ready_slot() >= Some(first_slot_of_window)
|| !local_context.finalized_blocks.contains(&finalized_block)
⋮----
let bank = ctx.bank_forks.read().unwrap().get(slot)?;
if !bank.is_frozen() {
⋮----
if bank.block_id() != Some(block_id) {
⋮----
let parent_bank = bank.parent()?;
let parent_slot = parent_bank.slot();
let Some(parent_block_id) = parent_bank.block_id() else {
⋮----
info!(
⋮----
Some((slot, (parent_slot, parent_block_id)))
⋮----
fn handle_set_identity(
⋮----
let new_identity = ctx.cluster_info.keypair();
let new_pubkey = new_identity.pubkey();
⋮----
vctx.vote_history = VoteHistory::restore(ctx.vote_history_storage.as_ref(), my_pubkey)?;
vctx.identity_keypair = new_identity.clone();
warn!("set-identity: from {my_old_pubkey} to {my_pubkey}");
⋮----
fn get_block_parent_block(bank: &Bank) -> (Block, Block) {
let slot = bank.slot();
⋮----
bank.block_id().expect("Block id must be set upstream"),
⋮----
let parent_slot = bank.parent_slot();
let parent_block_id = bank.parent_block_id().unwrap_or_else(|| {
trace!("Using default block id for {slot} parent {parent_slot}");
⋮----
fn try_notar(
⋮----
if voting_context.vote_history.voted(slot) {
return Ok(false);
⋮----
if leader_slot_index(slot) == 0 || slot == 1 {
⋮----
.is_parent_ready(slot, &parent_block)
⋮----
if parent_slot.saturating_add(1) != slot {
⋮----
if voting_context.vote_history.voted_notar(parent_slot) != Some(parent_block_id) {
⋮----
info!("{my_pubkey}: Voting notarize for {slot} {block_id}");
⋮----
update_commitment_cache(
⋮----
pending_blocks.remove(&slot);
⋮----
Ok(true)
⋮----
fn check_pending_blocks(
⋮----
.values()
.flat_map(|blocks| blocks.iter())
.copied()
.collect();
⋮----
fn try_final(
⋮----
if !voting_context.vote_history.is_block_notarized(&block)
|| voting_context.vote_history.its_over(slot)
|| voting_context.vote_history.bad_window(slot)
⋮----
.voted_notar(slot)
.is_none_or(|bid| bid != block_id)
⋮----
info!("{my_pubkey}: Voting finalize for {slot}");
⋮----
generate_vote_message(Vote::new_finalization_vote(slot), false, voting_context)?
⋮----
fn try_skip_window(
⋮----
let root_bank = voting_context.sharable_banks.root();
let start = first_of_consecutive_leader_slots(slot)
.max(root_bank.slot())
.max(1);
for s in start..=last_of_consecutive_leader_slots(slot) {
if voting_context.vote_history.voted(s) {
⋮----
info!("{my_pubkey}: Voting skip for {s}");
⋮----
generate_vote_message(Vote::new_skip_vote(s), false, voting_context)?
⋮----
fn refresh_votes(
⋮----
.votes_cast_since(highest_finalized_slot)
⋮----
info!("{my_pubkey}: Refreshing vote {vote:?}");
if let Some(bls_op) = generate_vote_message(vote, true, voting_context)? {
⋮----
fn check_rootable_blocks(
⋮----
let bank_forks_r = ctx.bank_forks.read().unwrap();
let old_root = bank_forks_r.root();
⋮----
.iter()
.filter_map(|&(slot, block_id)| {
let bank = bank_forks_r.get(slot)?;
⋮----
&& vctx.vote_history.voted(slot)
&& bank.is_frozen()
&& bank.block_id().is_some_and(|bid| bid == block_id))
.then_some(slot)
⋮----
.max()
⋮----
return Ok(());
⋮----
drop(bank_forks_r);
⋮----
.map_err(EventLoopError::SetRoot);
if set_root_result.is_ok() {
stats.set_root(new_root)
⋮----
pub(crate) fn join(self) -> thread::Result<()> {
self.t_event_handler.join()
⋮----
mod tests {
⋮----
struct EventHandlerTestContext {
⋮----
impl EventHandlerTestContext {
fn setup() -> EventHandlerTestContext {
let (bls_sender, bls_receiver) = bounded(100);
let (commitment_sender, commitment_receiver) = bounded(100);
let (own_vote_sender, own_vote_receiver) = bounded(100);
let (drop_bank_sender, drop_bank_receiver) = bounded(100);
⋮----
let (event_sender, _event_receiver) = bounded(100);
let (consensus_metrics_sender, consensus_metrics_receiver) = bounded(100);
⋮----
event_sender.clone(),
exit.clone(),
⋮----
.map(|_| ValidatorVoteKeypairs::new(Keypair::new(), Keypair::new(), Keypair::new()))
⋮----
let stakes = (0..validator_keypairs.len())
.rev()
.map(|i| 100_u64.saturating_add(i as u64))
⋮----
let genesis = create_genesis_config_with_alpenglow_vote_accounts(
⋮----
let my_node_keypair = validator_keypairs[my_index].node_keypair.insecure_clone();
let my_vote_keypair = validator_keypairs[my_index].vote_keypair.insecure_clone();
⋮----
BLSKeypair::derive_from_signer(&my_vote_keypair, BLS_KEYPAIR_DERIVE_SEED).unwrap();
⋮----
let contact_info = ContactInfo::new_localhost(&my_node_keypair.pubkey(), 0);
⋮----
Arc::new(my_node_keypair.insecure_clone()),
⋮----
&get_tmp_ledger_path!(),
⋮----
.unwrap(),
⋮----
cluster_info: cluster_info.clone(),
bank_forks: bank_forks.clone(),
⋮----
leader_window_notifier: leader_window_notifier.clone(),
⋮----
let vote_history = VoteHistory::new(my_node_keypair.pubkey(), 0);
⋮----
identity_keypair: Arc::new(my_node_keypair.insecure_clone()),
sharable_banks: bank_forks.read().unwrap().sharable_banks(),
⋮----
vote_account_pubkey: my_vote_keypair.pubkey(),
⋮----
authorized_voter_keypairs: Arc::new(RwLock::new(vec![Arc::new(my_vote_keypair)])),
⋮----
&bank_forks.read().unwrap().root_bank(),
⋮----
my_pubkey: my_node_keypair.pubkey(),
⋮----
bls_ops: vec![],
⋮----
fn send_parent_ready_event(&mut self, slot: Slot, parent_block: Block) {
⋮----
self.bls_ops.append(&mut new_ops);
⋮----
fn send_timeout_event(&mut self, slot: Slot) {
⋮----
fn send_block_event(&mut self, slot: Slot, bank: Arc<Bank>) {
⋮----
fn send_block_notarized_event(&mut self, block: Block) {
⋮----
fn send_timeout_crashed_leader_event(&mut self, slot: Slot) {
⋮----
fn send_first_shred_event(&mut self, slot: Slot) {
⋮----
fn send_safe_to_notar_event(&mut self, block: Block) {
⋮----
fn send_safe_to_skip_event(&mut self, slot: Slot) {
⋮----
fn send_produce_window_event(
⋮----
fn send_finalized_event(&mut self, block: Block, is_fast_finalization: bool) {
⋮----
fn send_set_identity_event(&mut self) {
⋮----
fn send_standstill_event(&mut self, highest_finalized_slot: Slot) {
⋮----
fn create_block_only(&mut self, slot: Slot, parent_bank: Arc<Bank>) -> Arc<Bank> {
⋮----
bank.set_block_id(Some(Hash::new_unique()));
bank.freeze();
let mut bank_forks_w = self.bank_forks.write().unwrap();
bank_forks_w.insert(bank);
bank_forks_w.get(slot).unwrap()
⋮----
fn create_block_and_send_block_event(
⋮----
let bank = self.create_block_only(slot, parent_bank);
self.send_block_event(slot, bank.clone());
⋮----
fn check_for_votes(&mut self, expected_votes: &[Vote]) {
⋮----
let expected_vote_serialized = bincode::serialize(v).unwrap();
⋮----
self.my_bls_keypair.sign(&expected_vote_serialized).into();
⋮----
let prev_length = self.bls_ops.len();
self.bls_ops.retain(|bls_op| {
!matches!(bls_op, BLSOp::PushVote { message, .. } if **message == expected_message)
⋮----
assert!(
⋮----
fn check_for_vote(&mut self, expected_vote: &Vote) {
let expected_vote_serialized = bincode::serialize(expected_vote).unwrap();
⋮----
let own_vote = self.own_vote_receiver.try_recv().unwrap();
assert_eq!(own_vote, expected_message);
⋮----
fn check_for_commitment(&mut self, expected_type: CommitmentType, expected_slot: Slot) {
let commitment = self.commitment_receiver.try_recv().unwrap();
assert_eq!(commitment.commitment_type, expected_type);
assert_eq!(commitment.slot, expected_slot);
⋮----
fn check_no_vote_or_commitment(&self) {
assert_eq!(
⋮----
fn check_parent_ready_slot(&mut self, expected: (Slot, Block)) {
⋮----
self.check_timeout_set(slot);
⋮----
fn check_timeout_set(&mut self, expected_slot: Slot) {
assert!(self.timer_manager.read().is_timeout_set(expected_slot));
⋮----
fn check_for_metrics_event(&mut self, expected: ConsensusMetricsEvent) {
⋮----
.try_recv()
.expect("Should receive metrics event");
assert!(event.1.contains(&expected));
⋮----
fn create_vote_history_storage_and_switch_identity(
⋮----
SavedVoteHistory::new(&VoteHistory::new(new_identity.pubkey(), 0), &new_identity)
⋮----
assert!(file_vote_history_storage
⋮----
.set_keypair(Arc::new(new_identity.insecure_clone()));
self.send_set_identity_event();
file_vote_history_storage.filename(&new_identity.pubkey())
⋮----
fn test_received_block_event_and_parent_ready_event() {
⋮----
test_context.send_parent_ready_event(slot, (parent_slot, Hash::default()));
test_context.check_parent_ready_slot((slot, (parent_slot, Hash::default())));
⋮----
.read()
.unwrap()
.sharable_banks()
.root();
let bank1 = test_context.create_block_and_send_block_event(slot, root_bank);
let block_id_1 = bank1.block_id().unwrap();
test_context.check_for_metrics_event(ConsensusMetricsEvent::StartOfSlot { slot });
test_context.check_for_vote(&Vote::new_notarization_vote(slot, block_id_1));
test_context.check_for_commitment(CommitmentType::Notarize, slot);
test_context.send_block_event(1, bank1.clone());
test_context.check_no_vote_or_commitment();
⋮----
let bank2 = test_context.create_block_and_send_block_event(slot, bank1.clone());
let block_id_2 = bank2.block_id().unwrap();
test_context.check_for_vote(&Vote::new_notarization_vote(slot, block_id_2));
⋮----
let _ = test_context.create_block_and_send_block_event(3, bank1.clone());
⋮----
let bank4 = test_context.create_block_and_send_block_event(slot, bank2.clone());
let block_id_4 = bank4.block_id().unwrap();
⋮----
test_context.send_parent_ready_event(slot, (2, block_id_2));
test_context.check_parent_ready_slot((slot, (2, block_id_2)));
test_context.check_for_vote(&Vote::new_notarization_vote(slot, block_id_4));
⋮----
fn test_received_block_notarized_and_timeout() {
⋮----
let bank1 = test_context.create_block_and_send_block_event(1, root_bank);
⋮----
test_context.send_parent_ready_event(1, (0, Hash::default()));
test_context.check_parent_ready_slot((1, (0, Hash::default())));
test_context.check_for_vote(&Vote::new_notarization_vote(1, block_id_1));
test_context.check_for_commitment(CommitmentType::Notarize, 1);
test_context.send_block_notarized_event((1, block_id_1));
test_context.check_for_vote(&Vote::new_finalization_vote(1));
let bank2 = test_context.create_block_and_send_block_event(2, bank1.clone());
⋮----
test_context.check_for_vote(&Vote::new_notarization_vote(2, block_id_2));
test_context.check_for_commitment(CommitmentType::Notarize, 2);
test_context.send_block_notarized_event((2, block_id_2));
test_context.check_for_vote(&Vote::new_finalization_vote(2));
⋮----
let bank3 = test_context.create_block_only(slot, bank2.clone());
let block_id_3 = bank3.block_id().unwrap();
⋮----
test_context.send_block_notarized_event((slot, block_id_3));
⋮----
test_context.send_block_event(slot, bank3.clone());
test_context.check_for_vote(&Vote::new_notarization_vote(slot, block_id_3));
⋮----
test_context.check_for_vote(&Vote::new_finalization_vote(slot));
test_context.send_safe_to_skip_event(slot);
⋮----
let bank4 = test_context.create_block_only(slot, bank3.clone());
test_context.send_timeout_event(slot);
test_context.send_block_event(slot, bank4.clone());
test_context.check_for_vote(&Vote::new_skip_vote(slot));
test_context.check_for_vote(&Vote::new_skip_vote(slot + 1));
test_context.check_for_vote(&Vote::new_skip_vote(slot + 2));
test_context.check_for_vote(&Vote::new_skip_vote(slot + 3));
⋮----
let bank5 = test_context.create_block_only(slot, bank4.clone());
test_context.send_block_event(slot, bank5.clone());
⋮----
test_context.exit.store(true, Ordering::Relaxed);
⋮----
fn test_received_timeout_crashed_leader_and_first_shred() {
⋮----
test_context.send_timeout_crashed_leader_event(4);
test_context.check_for_vote(&Vote::new_skip_vote(4));
test_context.check_for_vote(&Vote::new_skip_vote(5));
test_context.check_for_vote(&Vote::new_skip_vote(6));
test_context.check_for_vote(&Vote::new_skip_vote(7));
test_context.send_first_shred_event(8);
test_context.send_timeout_crashed_leader_event(8);
⋮----
fn test_received_safe_to_notar() {
⋮----
let bank_1 = test_context.create_block_and_send_block_event(1, root_bank);
let block_id_1_old = bank_1.block_id().unwrap();
⋮----
test_context.check_for_vote(&Vote::new_notarization_vote(1, block_id_1_old));
⋮----
test_context.send_safe_to_notar_event((1, block_id_1_1));
test_context.check_for_vote(&Vote::new_skip_vote(2));
test_context.check_for_vote(&Vote::new_skip_vote(3));
test_context.check_for_vote(&Vote::new_notarization_fallback_vote(1, block_id_1_1));
⋮----
test_context.send_safe_to_notar_event((1, block_id_1_2));
test_context.check_for_vote(&Vote::new_notarization_fallback_vote(1, block_id_1_2));
⋮----
fn test_received_safe_to_skip() {
⋮----
let block_id_1 = bank_1.block_id().unwrap();
⋮----
test_context.send_safe_to_skip_event(1);
⋮----
test_context.check_for_vote(&Vote::new_skip_fallback_vote(1));
⋮----
fn test_received_produce_window() {
⋮----
test_context.send_produce_window_event(1, 3, (0, Hash::default()));
⋮----
.lock()
⋮----
let received_leader_window_info = guard.take().unwrap();
assert_eq!(received_leader_window_info.start_slot, 1);
assert_eq!(received_leader_window_info.end_slot, 3);
⋮----
drop(guard);
⋮----
test_context.send_produce_window_event(2, 3, (1, block_id_1));
⋮----
assert_eq!(received_leader_window_info.start_slot, 2);
⋮----
assert_eq!(received_leader_window_info.parent_block, (1, block_id_1));
⋮----
fn test_received_finalized() {
⋮----
test_context.send_finalized_event((1, block_id_1), true);
let dropped_banks = test_context.drop_bank_receiver.try_recv().unwrap();
assert_eq!(dropped_banks.len(), 1);
assert_eq!(dropped_banks[0].slot(), 0);
assert_eq!(test_context.bank_forks.read().unwrap().root(), 1);
⋮----
fn test_parent_ready_in_middle_of_window() {
⋮----
let bank4 = test_context.create_block_and_send_block_event(4, root_bank);
⋮----
let bank5 = test_context.create_block_and_send_block_event(5, bank4.clone());
let block_id_5 = bank5.block_id().unwrap();
test_context.send_finalized_event((5, block_id_5), true);
test_context.check_parent_ready_slot((5, (4, block_id_4)));
let bank9 = test_context.create_block_only(9, bank5.clone());
let block_id_9 = bank9.block_id().unwrap();
test_context.send_finalized_event((9, block_id_9), true);
test_context.send_block_event(9, bank9.clone());
test_context.check_parent_ready_slot((9, (5, block_id_5)));
⋮----
fn test_received_standstill() {
⋮----
test_context.send_timeout_event(2);
⋮----
test_context.send_standstill_event(0);
test_context.check_for_votes(&[
⋮----
test_context.bls_ops.clear();
test_context.send_standstill_event(1);
test_context.check_for_votes(&[Vote::new_skip_vote(2), Vote::new_skip_vote(3)]);
⋮----
fn test_received_set_identity() {
⋮----
let old_identity = test_context.cluster_info.keypair().insecure_clone();
⋮----
let mut files_to_remove = vec![];
⋮----
.push(test_context.create_vote_history_storage_and_switch_identity(&new_identity));
⋮----
let _ = test_context.create_block_and_send_block_event(1, root_bank.clone());
⋮----
.push(test_context.create_vote_history_storage_and_switch_identity(&old_identity));
⋮----
let bank4 = test_context.create_block_and_send_block_event(slot, root_bank);
⋮----
test_context.send_parent_ready_event(slot, (0, Hash::default()));
⋮----
let _ = remove_file(file);

================
File: votor/src/event.rs
================
pub struct CompletedBlock {
⋮----
pub struct LeaderWindowInfo {
⋮----
pub type VotorEventSender = Sender<VotorEvent>;
pub type VotorEventReceiver = Receiver<VotorEvent>;
⋮----
pub enum VotorEvent {
⋮----
impl VotorEvent {
pub(crate) fn should_ignore(&self, root: Slot) -> bool {

================
File: votor/src/lib.rs
================
extern crate log;
pub mod commitment;
pub mod common;
mod consensus_metrics;
pub mod consensus_pool;
mod consensus_pool_service;
pub mod event;
mod event_handler;
pub mod root_utils;
mod staked_validators_cache;
mod timer_manager;
pub mod vote_history;
pub mod vote_history_storage;
mod voting_service;
mod voting_utils;
⋮----
pub mod votor;
⋮----
extern crate solana_frozen_abi_macro;

================
File: votor/src/root_utils.rs
================
pub(crate) struct RootContext {
⋮----
pub enum SetRootError {
⋮----
pub(crate) fn set_root(
⋮----
info!("{my_pubkey}: setting root {new_root}");
vctx.vote_history.set_root(new_root);
pending_blocks.retain(|pending_block, _| *pending_block >= new_root);
finalized_blocks.retain(|(slot, _)| *slot >= new_root);
received_shred.retain(|slot| *slot >= new_root);
check_and_handle_new_root(
⋮----
rctx.snapshot_controller.as_deref(),
Some(new_root),
⋮----
ctx.rpc_subscriptions.as_deref(),
⋮----
let hash = ctx.bank_forks.read().unwrap().bank_hash(new_root).unwrap();
⋮----
.insert_optimistic_slot(new_root, &hash, timestamp().try_into().unwrap())?;
⋮----
.as_ref()
.map(|s| s.get_current_declared_work());
⋮----
.send((
⋮----
.map_err(|_| SendError(()))?;
⋮----
Ok(())
⋮----
pub fn check_and_handle_new_root<CB>(
⋮----
.read()
.unwrap()
.get(new_root)
.expect("Root bank doesn't exist");
let mut rooted_banks = root_bank.parents();
let oldest_parent = rooted_banks.last().map(|last| last.parent_slot());
rooted_banks.push(root_bank.clone());
let rooted_slots: Vec<_> = rooted_banks.iter().map(|bank| bank.slot()).collect();
⋮----
.is_some_and(|sender| sender.should_send_parents)
.then(|| {
let mut new_chain = rooted_slots.clone();
new_chain.push(oldest_parent.unwrap_or(parent_slot));
⋮----
leader_schedule_cache.set_root(rooted_banks.last().unwrap());
blockstore.set_roots(rooted_slots.iter())?;
set_bank_forks_root(
⋮----
blockstore.slots_stats.mark_rooted(new_root);
⋮----
rpc_subscriptions.notify_roots(rooted_slots);
⋮----
.send((BankNotification::NewRootBank(root_bank), dependency_work))
.unwrap_or_else(|err| warn!("bank_notification_sender failed: {err:?}"));
⋮----
.send((BankNotification::NewRootedChain(new_chain), dependency_work))
⋮----
info!("{my_pubkey}: new root {new_root}");
⋮----
pub fn set_bank_forks_root<CB>(
⋮----
bank_forks.read().unwrap().prune_program_cache(new_root);
let removed_banks = bank_forks.write().unwrap().set_root(
⋮----
.send(removed_banks)
.unwrap_or_else(|err| warn!("bank drop failed: {err:?}"));
let r_bank_forks = bank_forks.read().unwrap();
callback(&r_bank_forks);

================
File: votor/src/staked_validators_cache.rs
================
struct StakedValidatorsCacheEntry {
⋮----
pub struct StakedValidatorsCache {
⋮----
impl StakedValidatorsCache {
pub fn new(
⋮----
.read()
.unwrap()
.working_bank()
.epoch_schedule()
.clone();
⋮----
fn cur_epoch(&self, slot: Slot) -> Epoch {
self.epoch_schedule.get_epoch(slot)
⋮----
fn refresh_cache_entry(
⋮----
let bank_forks = self.bank_forks.read().unwrap();
[bank_forks.root_bank(), bank_forks.working_bank()]
⋮----
.iter()
.find_map(|bank| bank.epoch_staked_nodes(epoch))
.unwrap_or_else(|| {
error!(
⋮----
struct Node {
⋮----
.filter(|(pubkey, stake)| {
⋮----
let not_self = pubkey != &&cluster_info.id();
⋮----
.filter_map(|(pubkey, stake)| {
cluster_info.lookup_contact_info(pubkey, |node| {
node.alpenglow().map(|alpenglow_socket| Node {
⋮----
.collect();
nodes.dedup_by_key(|node| node.alpenglow_socket);
nodes.sort_unstable_by(|a, b| a.stake.cmp(&b.stake));
let mut alpenglow_sockets = Vec::with_capacity(nodes.len());
⋮----
.as_ref()
.map(|x| x.get_override_map());
⋮----
.get(&node.pubkey)
.cloned()
.unwrap_or(alpenglow_socket)
⋮----
alpenglow_sockets.push(socket);
⋮----
self.cache.push(
⋮----
pub fn get_staked_validators_by_slot(
⋮----
let epoch = self.cur_epoch(slot);
⋮----
if alpenglow_port_override.has_new_override(self.alpenglow_port_override_last_modified)
⋮----
alpenglow_port_override.last_modified();
trace!(
⋮----
self.refresh_cache_entry(epoch, cluster_info, access_time);
⋮----
self.get_staked_validators_by_epoch(epoch, cluster_info, access_time)
⋮----
fn get_staked_validators_by_epoch(
⋮----
.get(&epoch)
.map(|v| Some(access_time) > v.creation_time.checked_add(self.ttl))
.unwrap_or(true);
⋮----
.map(|v| &*v.alpenglow_sockets)
.unwrap(),
⋮----
pub fn len(&self) -> usize {
self.cache.len()
⋮----
pub fn is_empty(&self) -> bool {
self.cache.is_empty()
⋮----
mod tests {
⋮----
fn update_cluster_info(
⋮----
.keys()
.enumerate()
.map(|(node_ix, pubkey)| {
⋮----
.set_alpenglow((
⋮----
8080_u16.saturating_add(node_ix as u16),
⋮----
.unwrap();
⋮----
let node_pubkey = *contact_info.pubkey();
⋮----
assert_eq!(node_pubkey, entry.label().pubkey());
⋮----
let mut gossip_crds = cluster_info.gossip.crds.write().unwrap();
⋮----
.insert(entry, timestamp(), GossipRoute::LocalMessage)
⋮----
fn create_bank_forks_and_cluster_info(
⋮----
.map(|_| ValidatorVoteKeypairs::new(Keypair::new(), Keypair::new(), Keypair::new()))
⋮----
.last()
⋮----
.insecure_clone();
⋮----
.map(|v| (v.node_keypair.pubkey(), v.node_keypair.insecure_clone()))
⋮----
.map(|node_ix| {
⋮----
rng.random_range(1..997)
⋮----
let genesis = create_genesis_config_with_alpenglow_vote_accounts(
⋮----
let base_slot_epoch = bank0.epoch_schedule().get_epoch(base_slot);
bank0.set_epoch_stakes_for_test(base_slot_epoch, bank0.epoch_stakes(0).unwrap().clone());
⋮----
Node::new_localhost_with_pubkey(&my_keypair.pubkey()).info,
⋮----
update_cluster_info(&mut cluster_info, node_keypair_map);
⋮----
.map(|v| v.node_keypair.pubkey())
⋮----
fn test_detect_only_staked_nodes_and_refresh_after_ttl(
⋮----
create_bank_forks_and_cluster_info(num_nodes, num_zero_stake_nodes, slot_num);
⋮----
let (sockets, refreshed) = svc.get_staked_validators_by_slot(slot_num, &cluster_info, now);
assert!(refreshed);
assert_eq!(
⋮----
assert_eq!(1, svc.len());
let (sockets, refreshed) = svc.get_staked_validators_by_slot(
⋮----
now.checked_add(Duration::from_secs_f64(4.999)).unwrap(),
⋮----
assert!(!refreshed);
⋮----
now.checked_add(Duration::from_secs(5)).unwrap(),
⋮----
now.checked_add(Duration::from_secs_f64(5.001)).unwrap(),
⋮----
now.checked_add(Duration::from_secs(100)).unwrap(),
⋮----
fn test_cache_eviction() {
⋮----
let (bank_forks, cluster_info, _) = create_bank_forks_and_cluster_info(50, 7, base_slot);
⋮----
assert_eq!(0, svc.len());
assert!(svc.is_empty());
⋮----
let (_, refreshed) = svc.get_staked_validators_by_slot(
entry_ix.saturating_mul(base_slot),
⋮----
assert_eq!(entry_ix as usize, svc.len());
⋮----
let (_, refreshed) = svc.get_staked_validators_by_slot(6 * base_slot, &cluster_info, now);
⋮----
assert_eq!(5, svc.len());
assert!(!svc.cache.contains(&svc.cur_epoch(base_slot)));
⋮----
assert!(svc
⋮----
now.checked_add(Duration::from_secs(10)).unwrap(),
⋮----
fn test_only_update_once_per_epoch() {
⋮----
let (_, refreshed) = svc.get_staked_validators_by_slot(slot_num, &cluster_info, now);
⋮----
let (_, refreshed) = svc.get_staked_validators_by_slot(2 * slot_num, &cluster_info, now);
⋮----
fn test_exclude_self_from_cache(num_nodes: usize) {
⋮----
create_bank_forks_and_cluster_info(num_nodes, 0, slot_num);
let keypair = cluster_info.keypair().insecure_clone();
⋮----
.lookup_contact_info(&keypair.pubkey(), |node| node.alpenglow().unwrap())
⋮----
StakedValidatorsCache::new(bank_forks.clone(), Duration::from_secs(5), 5, true, None);
⋮----
svc.get_staked_validators_by_slot(slot_num, &cluster_info, Instant::now());
assert_eq!(sockets.len(), num_nodes);
assert!(sockets.contains(&my_socket_addr));
⋮----
StakedValidatorsCache::new(bank_forks.clone(), Duration::from_secs(5), 5, false, None);
⋮----
assert_eq!(sockets.len(), num_nodes.checked_sub(1).unwrap());
assert!(!sockets.contains(&my_socket_addr));
⋮----
fn test_alpenglow_port_override() {
⋮----
let (bank_forks, cluster_info, node_pubkeys) = create_bank_forks_and_cluster_info(3, 0, 1);
⋮----
let blackhole_addr: SocketAddr = "0.0.0.0:0".parse().unwrap();
⋮----
bank_forks.clone(),
⋮----
Some(alpenglow_port_override.clone()),
⋮----
let (sockets, _) = svc.get_staked_validators_by_slot(0, &cluster_info, Instant::now());
assert_eq!(sockets.len(), 2);
assert!(!sockets.contains(&blackhole_addr));
alpenglow_port_override.update_override(HashMap::from([(pubkey_b, blackhole_addr)]));
⋮----
let mut sockets: Vec<_> = sockets.to_vec();
sockets.sort();
assert_eq!(sockets[0], blackhole_addr);
assert_ne!(sockets[1], blackhole_addr);
alpenglow_port_override.clear();

================
File: votor/src/timer_manager.rs
================
mod stats;
mod timers;
⋮----
pub(crate) struct TimerManager {
⋮----
impl TimerManager {
pub(crate) fn new(event_sender: Sender<VotorEvent>, exit: Arc<AtomicBool>) -> Self {
⋮----
while !exit.load(Ordering::Relaxed) {
let duration = match timers.write().progress(Instant::now()) {
⋮----
Some(next_fire) => next_fire.duration_since(Instant::now()),
⋮----
pub(crate) fn set_timeouts(&self, slot: Slot) {
self.timers.write().set_timeouts(slot, Instant::now());
⋮----
pub(crate) fn join(self) {
self.handle.join().unwrap();
⋮----
pub(crate) fn is_timeout_set(&self, slot: Slot) -> bool {
self.timers.read().is_timeout_set(slot)
⋮----
mod tests {
⋮----
fn test_timer_manager() {
let (event_sender, event_receiver) = unbounded();
⋮----
let timer_manager = TimerManager::new(event_sender, exit.clone());
⋮----
timer_manager.set_timeouts(slot);
⋮----
while timeouts_received < 2 && Instant::now().duration_since(start) < Duration::from_secs(2)
⋮----
let res = event_receiver.recv_timeout(Duration::from_millis(200));
⋮----
assert_eq!(s, slot);
assert!(
⋮----
assert!(Instant::now().duration_since(start) >= DELTA_TIMEOUT);
⋮----
_ => panic!("Unexpected event: {event:?}"),
⋮----
exit.store(true, Ordering::Relaxed);
timer_manager.join();

================
File: votor/src/vote_history_storage.rs
================
pub type Result<T> = std::result::Result<T, VoteHistoryError>;
⋮----
pub enum SavedVoteHistoryVersions {
⋮----
impl SavedVoteHistoryVersions {
fn try_into_vote_history(&self, node_pubkey: &Pubkey) -> Result<VoteHistory> {
assert_eq!(self.pubkey(), Pubkey::default());
⋮----
if !t.signature.verify(node_pubkey.as_ref(), &t.data) {
return Err(VoteHistoryError::InvalidSignature);
⋮----
bincode::deserialize(&t.data).map(VoteHistoryVersions::Current)
⋮----
.map_err(|e| e.into())
.and_then(|vote_history: VoteHistoryVersions| {
let vote_history = vote_history.convert_to_current();
⋮----
return Err(VoteHistoryError::WrongVoteHistory(format!(
⋮----
Ok(vote_history)
⋮----
fn serialize_into(&self, file: &mut File) -> Result<()> {
bincode::serialize_into(file, self).map_err(|e| e.into())
⋮----
fn pubkey(&self) -> Pubkey {
⋮----
fn from(vote_history: SavedVoteHistory) -> SavedVoteHistoryVersions {
⋮----
pub struct SavedVoteHistory {
⋮----
impl SavedVoteHistory {
pub fn new<T: Signer>(vote_history: &VoteHistory, keypair: &T) -> Result<Self> {
let node_pubkey = keypair.pubkey();
⋮----
let signature = keypair.sign_message(&data);
Ok(Self {
⋮----
pub trait VoteHistoryStorage: Sync + Send {
⋮----
pub struct NullVoteHistoryStorage {}
impl VoteHistoryStorage for NullVoteHistoryStorage {
fn load(&self, _node_pubkey: &Pubkey) -> Result<VoteHistory> {
Err(VoteHistoryError::IoError(io::Error::other(
⋮----
fn store(&self, _saved_vote_history: &SavedVoteHistoryVersions) -> Result<()> {
Ok(())
⋮----
pub struct FileVoteHistoryStorage {
⋮----
impl FileVoteHistoryStorage {
pub fn new(vote_history_path: PathBuf) -> Self {
⋮----
pub fn filename(&self, node_pubkey: &Pubkey) -> PathBuf {
⋮----
.join(format!("vote_history-{node_pubkey}"))
.with_extension("bin")
⋮----
impl VoteHistoryStorage for FileVoteHistoryStorage {
fn load(&self, node_pubkey: &Pubkey) -> Result<VoteHistory> {
let filename = self.filename(node_pubkey);
trace!("load {}", filename.display());
fs::create_dir_all(filename.parent().unwrap())?;
⋮----
.and_then(|t: SavedVoteHistoryVersions| t.try_into_vote_history(node_pubkey))
⋮----
fn store(&self, saved_vote_history: &SavedVoteHistoryVersions) -> Result<()> {
let pubkey = saved_vote_history.pubkey();
let filename = self.filename(&pubkey);
trace!("store: {}", filename.display());
let new_filename = filename.with_extension("bin.new");
⋮----
saved_vote_history.serialize_into(&mut file)?;
⋮----
mod test {
⋮----
fn test_file_vote_history_storage() {
⋮----
let tmp_dir = TempDir::new().unwrap();
let storage = FileVoteHistoryStorage::new(tmp_dir.path().to_path_buf());
⋮----
let pubkey = keypair.pubkey();
assert_eq!(
⋮----
let saved_vote_history = SavedVoteHistory::new(&vote_history, &keypair).unwrap();
⋮----
storage.store(&saved_vote_history_versions).unwrap();
let restored_vote_history = storage.load(&pubkey).unwrap();
assert_eq!(restored_vote_history.root(), 0);
vote_history.set_root(1);
vote_history.add_vote(Vote::new_skip_vote(2));
⋮----
assert_eq!(restored_vote_history.root(), 1);
⋮----
let error = storage.load(&Pubkey::new_unique()).err().unwrap();
assert!(matches!(error, VoteHistoryError::IoError(_)));
let original_path = storage.filename(&pubkey);
⋮----
let new_path = storage.filename(&new_pubkey);
fs::copy(&original_path, &new_path).unwrap();
let error = storage.load(&new_pubkey).err().unwrap();
assert!(matches!(error, VoteHistoryError::InvalidSignature));
⋮----
fn test_null_vote_history_storage() {
⋮----
assert!(storage.load(&pubkey).is_err());

================
File: votor/src/vote_history.rs
================
pub enum VoteHistoryVersions {
⋮----
impl VoteHistoryVersions {
pub fn new_current(vote_history: VoteHistory) -> Self {
⋮----
pub fn convert_to_current(self) -> VoteHistory {
⋮----
pub struct VoteHistory {
⋮----
impl VoteHistory {
pub fn new(node_pubkey: Pubkey, root: Slot) -> Self {
⋮----
pub fn voted(&self, slot: Slot) -> bool {
assert!(slot >= self.root);
self.voted.contains(&slot)
⋮----
pub fn voted_notar(&self, slot: Slot) -> Option<Hash> {
⋮----
self.voted_notar.get(&slot).copied()
⋮----
pub fn voted_notar_fallback(&self, slot: Slot, block_id: Hash) -> bool {
⋮----
.get(&slot)
.is_some_and(|v| v.contains(&block_id))
⋮----
pub fn voted_skip_fallback(&self, slot: Slot) -> bool {
⋮----
self.voted_skip_fallback.contains(&slot)
⋮----
pub fn skipped(&self, slot: Slot) -> bool {
⋮----
self.skipped.contains(&slot)
⋮----
pub fn its_over(&self, slot: Slot) -> bool {
⋮----
self.its_over.contains(&slot)
⋮----
pub fn votes_cast_since(&self, slot: Slot) -> Vec<Vote> {
⋮----
.iter()
.filter(|(s, _)| s > &&slot)
.flat_map(|(_, votes)| votes.iter())
.cloned()
.collect()
⋮----
pub fn bad_window(&self, slot: Slot) -> bool {
⋮----
|| self.voted_notar_fallback.contains_key(&slot)
|| self.voted_skip_fallback.contains(&slot)
⋮----
pub fn is_block_notarized(&self, block: &Block) -> bool {
self.notarized_blocks.contains(block)
⋮----
pub fn is_parent_ready(&self, slot: Slot, parent: &Block) -> bool {
⋮----
.is_some_and(|ps| ps.contains(parent))
⋮----
pub fn root(&self) -> Slot {
⋮----
pub fn add_vote(&mut self, vote: Vote) {
assert!(vote.slot() >= self.root);
⋮----
assert!(self.voted.insert(vote.slot));
assert!(self.voted_notar.insert(vote.slot, vote.block_id).is_none());
⋮----
assert!(!self.skipped(vote.slot));
self.its_over.insert(vote.slot);
⋮----
self.voted.insert(vote.slot);
self.skipped.insert(vote.slot);
⋮----
assert!(self.voted(vote.slot));
assert!(!self.its_over(vote.slot));
⋮----
.entry(vote.slot)
.or_default()
.insert(vote.block_id);
⋮----
self.voted_skip_fallback.insert(vote.slot);
⋮----
self.votes_cast.entry(vote.slot()).or_default().push(vote);
⋮----
pub fn add_block_notarized(&mut self, block @ (slot, _): Block) {
⋮----
self.notarized_blocks.insert(block);
⋮----
pub fn add_parent_ready(&mut self, slot: Slot, parent: Block) -> bool {
⋮----
match self.parent_ready_slots.entry(slot) {
⋮----
entry.get_mut().insert(parent);
⋮----
entry.insert(HashSet::from([parent]));
⋮----
pub fn highest_parent_ready_slot(&self) -> Option<Slot> {
self.parent_ready_slots.keys().max().copied()
⋮----
pub fn set_root(&mut self, root: Slot) {
⋮----
self.voted.retain(|s| *s >= root);
self.voted_notar.retain(|s, _| *s >= root);
self.voted_notar_fallback.retain(|s, _| *s >= root);
self.voted_skip_fallback.retain(|s| *s >= root);
self.skipped.retain(|s| *s >= root);
self.its_over.retain(|s| *s >= root);
self.votes_cast.retain(|s, _| *s >= root);
self.notarized_blocks.retain(|(s, _)| *s >= root);
self.parent_ready_slots.retain(|s, _| *s >= root);
⋮----
pub fn save(
⋮----
vote_history_storage.store(&SavedVoteHistoryVersions::from(saved_vote_history))?;
Ok(())
⋮----
pub fn restore(
⋮----
vote_history_storage.load(node_pubkey)
⋮----
pub enum VoteHistoryError {
⋮----
impl VoteHistoryError {
pub fn is_file_missing(&self) -> bool {
⋮----
io_err.kind() == std::io::ErrorKind::NotFound
⋮----
mod test {
⋮----
fn check_votes_cast_since(vote_history: &VoteHistory, slot: Slot, expected_votes: Vec<Vote>) {
let votes = vote_history.votes_cast_since(slot);
assert_eq!(votes.len(), expected_votes.len());
⋮----
assert!(votes.contains(&vote));
⋮----
fn test_add_votes() {
⋮----
assert!(vote_history.votes_cast_since(0).is_empty());
⋮----
vote_history.add_vote(vote_notarize_1);
assert!(vote_history.voted(1));
assert!(!vote_history.its_over(1));
check_votes_cast_since(&vote_history, 0, vec![vote_notarize_1]);
assert_eq!(vote_history.voted_notar(1), Some(block_id_1));
assert!(!vote_history.skipped(1));
assert!(!vote_history.voted_notar_fallback(1, block_id_1));
assert!(!vote_history.bad_window(1));
⋮----
vote_history.add_vote(vote_finalize_1);
⋮----
assert!(vote_history.its_over(1));
check_votes_cast_since(&vote_history, 0, vec![vote_notarize_1, vote_finalize_1]);
⋮----
vote_history.add_vote(vote_skip_2);
assert!(vote_history.voted(2));
assert!(vote_history.skipped(2));
check_votes_cast_since(
⋮----
vec![vote_notarize_1, vote_finalize_1, vote_skip_2],
⋮----
assert_eq!(vote_history.voted_notar(2), None);
assert!(!vote_history.its_over(2));
assert!(vote_history.bad_window(2));
⋮----
vote_history.add_vote(vote_notarize_fallback_2);
⋮----
assert!(vote_history.voted_notar_fallback(2, block_id_2));
⋮----
vec![
⋮----
vote_history.add_vote(vote_notarize_3);
assert!(vote_history.voted(3));
assert!(!vote_history.skipped(3));
assert_eq!(vote_history.voted_notar(3), Some(block_id_3));
assert!(!vote_history.voted_notar_fallback(3, block_id_3));
⋮----
assert!(!vote_history.its_over(3));
assert!(!vote_history.bad_window(3));
⋮----
vote_history.add_vote(vote_skip_fallback_3);
⋮----
assert!(vote_history.skipped(3));
⋮----
assert!(vote_history.voted_skip_fallback(3));
⋮----
assert!(vote_history.bad_window(3));
vote_history.set_root(2);
assert_eq!(vote_history.root(), 2);
⋮----
fn test_add_notarized_blocks() {
⋮----
assert!(!vote_history.is_block_notarized(&block_1));
vote_history.add_block_notarized(block_1);
assert!(vote_history.is_block_notarized(&block_1));
⋮----
assert!(!vote_history.is_block_notarized(&block_2));
vote_history.add_block_notarized(block_2);
assert!(vote_history.is_block_notarized(&block_2));
⋮----
fn test_add_parent_ready() {
⋮----
assert_eq!(vote_history.highest_parent_ready_slot(), None);
⋮----
vote_history.add_parent_ready(1, block_id_0);
assert!(vote_history.is_parent_ready(1, &block_id_0));
assert_eq!(vote_history.highest_parent_ready_slot(), Some(1));
vote_history.set_root(1);
assert_eq!(vote_history.root(), 1);
⋮----
assert!(vote_history.add_parent_ready(2, block_id_2_0));
assert!(vote_history.is_parent_ready(2, &block_id_2_0));
assert_eq!(vote_history.highest_parent_ready_slot(), Some(2));
assert!(!vote_history.add_parent_ready(2, block_id_2_1));
assert!(vote_history.is_parent_ready(2, &block_id_2_1));
assert!(!vote_history.add_parent_ready(2, block_id_0));
assert!(vote_history.is_parent_ready(2, &block_id_0));
⋮----
assert!(!vote_history.is_parent_ready(1, &block_id_0));
⋮----
assert!(!vote_history.add_parent_ready(1, block_id_0));
⋮----
fn test_save_and_restore() {
⋮----
let mut vote_history = VoteHistory::new(node_keypair.pubkey(), 0);
let tmp_dir = TempDir::new().unwrap();
let vote_history_storage = FileVoteHistoryStorage::new(tmp_dir.path().to_path_buf());
⋮----
vote_history.add_vote(vote_1);
vote_history.add_vote(vote_2);
⋮----
.save(&vote_history_storage, &node_keypair)
.unwrap();
⋮----
VoteHistory::restore(&vote_history_storage, &node_keypair.pubkey())
.ok()
⋮----
check_votes_cast_since(&restored_vote_history, 0, vec![vote_1, vote_2]);
assert_eq!(restored_vote_history, vote_history);
⋮----
.save(&vote_history_storage, &Keypair::new())
.err()
⋮----
assert!(matches!(error, VoteHistoryError::WrongVoteHistory(_)));
assert!(!error.is_file_missing());
⋮----
assert!(matches!(error, VoteHistoryError::IoError(_)));
assert!(error.is_file_missing());

================
File: votor/src/voting_service.rs
================
enum SendVoteError {
⋮----
pub enum BLSOp {
⋮----
fn send_message(
⋮----
let client = connection_cache.get_connection(socket);
client.send_data_async(Arc::new(buf))
⋮----
pub struct VotingService {
⋮----
pub struct AlpenglowPortOverride {
⋮----
struct AlpenglowPortOverrideInner {
⋮----
impl Default for AlpenglowPortOverrideInner {
fn default() -> Self {
⋮----
impl AlpenglowPortOverride {
pub fn update_override(&self, new_override: HashMap<Pubkey, SocketAddr>) {
let mut inner = self.inner.write().unwrap();
⋮----
pub fn has_new_override(&self, previous: Instant) -> bool {
self.inner.read().unwrap().last_modified != previous
⋮----
pub fn last_modified(&self) -> Instant {
self.inner.read().unwrap().last_modified
⋮----
pub fn clear(&self) {
⋮----
inner.override_map.clear();
⋮----
pub fn get_override_map(&self) -> HashMap<Pubkey, SocketAddr> {
self.inner.read().unwrap().override_map.clone()
⋮----
pub struct VotingServiceOverride {
⋮----
impl VotingService {
pub fn new(
⋮----
}) => (additional_listeners, Some(alpenglow_port_override)),
⋮----
.name("solVotorVoteSvc".to_string())
.spawn(move || {
⋮----
bank_forks.clone(),
⋮----
info!("AlpenglowVotingService has started");
⋮----
let Ok(bls_op) = bls_receiver.recv() else {
⋮----
vote_history_storage.as_ref(),
⋮----
connection_cache.clone(),
⋮----
info!("AlpenglowVotingService has stopped");
⋮----
.unwrap();
⋮----
fn broadcast_consensus_message(
⋮----
let buf = match serialize(message) {
⋮----
error!("Failed to serialize alpenglow message: {err:?}");
⋮----
.get_staked_validators_by_slot(slot, cluster_info, Instant::now());
⋮----
.iter()
.chain(staked_validator_alpenglow_sockets.iter());
⋮----
if let Err(e) = send_message(buf.clone(), socket, &connection_cache) {
warn!("Failed to send alpenglow message to {socket}: {e:?}");
⋮----
fn handle_bls_op(
⋮----
if let Err(err) = vote_history_storage.store(&saved_vote_history) {
error!("Unable to save vote history to storage: {err:?}");
⋮----
measure.stop();
trace!("{measure}");
⋮----
let vote_slot = certificate.cert_type.slot();
let message = ConsensusMessage::Certificate((*certificate).clone());
⋮----
pub fn join(self) -> thread::Result<()> {
self.thread_hdl.join()
⋮----
mod tests {
⋮----
fn create_voting_service(
⋮----
.map(|_| ValidatorVoteKeypairs::new_rand())
⋮----
let genesis = create_genesis_config_with_alpenglow_vote_accounts(
⋮----
vec![100; validator_keypairs.len()],
⋮----
let contact_info = ContactInfo::new_localhost(&keypair.pubkey(), 0);
⋮----
Some(VotingServiceOverride {
additional_listeners: vec![listener],
⋮----
fn test_send_message(bls_op: BLSOp, expected_message: ConsensusMessage) {
⋮----
let socket = bind_to_localhost_unique().unwrap();
let listener_addr = socket.local_addr().unwrap();
let (_, validator_keypairs) = create_voting_service(bls_receiver, listener_addr);
bls_sender.send(bls_op).unwrap();
⋮----
.map(|x| (x.node_keypair.pubkey(), 100))
.collect();
⋮----
} = spawn_stake_wighted_qos_server(
⋮----
cancel_token.clone(),
⋮----
let packets = receiver.recv().unwrap();
let packet = packets.first().expect("No packets received");
⋮----
.unwrap_or_else(|err| {
panic!(
⋮----
assert_eq!(received_message, expected_message);
cancel_token.cancel();
quic_server_thread.join().unwrap();

================
File: votor/src/voting_utils.rs
================
pub enum GenerateVoteTxResult {
⋮----
impl GenerateVoteTxResult {
pub fn is_non_voting(&self) -> bool {
matches!(self, Self::NonVoting)
⋮----
pub fn is_hot_spare(&self) -> bool {
matches!(self, Self::HotSpare)
⋮----
pub fn is_invalid_config(&self) -> bool {
⋮----
pub fn is_transient_error(&self) -> bool {
⋮----
pub enum VoteError {
⋮----
pub struct VotingContext {
⋮----
fn get_bls_keypair(
⋮----
let pubkey = authorized_voter_keypair.pubkey();
if let Some(existing) = context.derived_bls_keypairs.get(&pubkey) {
return Ok(existing.clone());
⋮----
.insert(pubkey, bls_keypair.clone());
Ok(bls_keypair)
⋮----
fn generate_vote_tx(vote: &Vote, bank: &Bank, context: &mut VotingContext) -> GenerateVoteTxResult {
⋮----
let authorized_voter_keypairs = context.authorized_voter_keypairs.read().unwrap();
if authorized_voter_keypairs.is_empty() {
⋮----
if vote.slot() < slot {
⋮----
let Some(vote_account) = bank.get_vote_account(&vote_account_pubkey) else {
⋮----
let vote_state_view = vote_account.vote_state_view();
if vote_state_view.node_pubkey() != &context.identity_keypair.pubkey() {
info!(
⋮----
let Some(bls_pubkey_serialized) = vote_state_view.bls_pubkey_compressed() else {
panic!(
⋮----
(bincode::deserialize::<BLSPubkeyCompressed>(&bls_pubkey_serialized).unwrap())
.try_into()
.unwrap_or_else(|_| {
⋮----
let Some(authorized_voter_pubkey) = vote_state_view.get_authorized_voter(bank.epoch())
⋮----
return GenerateVoteTxResult::NoAuthorizedVoter(vote_account_pubkey, bank.epoch());
⋮----
.iter()
.find(|keypair| &keypair.pubkey() == authorized_voter_pubkey)
⋮----
warn!(
⋮----
authorized_voter_keypair = keypair.clone();
⋮----
let bls_keypair = get_bls_keypair(context, &authorized_voter_keypair)
.unwrap_or_else(|e| panic!("Failed to derive my own BLS keypair: {e:?}"));
⋮----
let vote_serialized = bincode::serialize(&vote).unwrap();
let epoch = bank.epoch_schedule().get_epoch(vote.slot());
let Some(epoch_stakes) = bank.epoch_stakes(epoch) else {
⋮----
.bls_pubkey_to_rank_map()
.get_rank(&my_bls_pubkey)
⋮----
signature: bls_keypair.sign(&vote_serialized).into(),
⋮----
fn insert_vote_and_create_bls_message(
⋮----
context.vote_history.add_vote(vote);
⋮----
let bank = context.sharable_banks.root();
let message = match generate_vote_tx(&vote, &bank, context) {
⋮----
if e.is_transient_error() {
return Err(VoteError::TransientError(Box::new(e)));
⋮----
return Err(VoteError::InvalidConfig(Box::new(e)));
⋮----
.send(message.clone())
.map_err(|_| SendError(()))?;
⋮----
Ok(BLSOp::PushVote {
⋮----
slot: vote.slot(),
⋮----
pub fn generate_vote_message(
⋮----
let bls_op = match insert_vote_and_create_bls_message(vote, is_refresh, vctx) {
⋮----
warn!("Failed to generate vote and push to votes: {e:?}");
return Ok(None);
⋮----
info!("Failed to generate vote and push to votes: {e:?}");
⋮----
Err(e) => return Err(e),
⋮----
Ok(Some(bls_op))
⋮----
mod tests {
⋮----
fn generate_expected_consensus_message(
⋮----
let signature = my_bls_keypair.sign(&vote_serialized);
⋮----
signature: signature.into(),
⋮----
fn setup_voting_context_and_bank_forks(
⋮----
let stakes: Vec<u64> = (1u64..=10).rev().map(|x| x.saturating_mul(100)).collect();
let genesis = create_genesis_config_with_alpenglow_vote_accounts(
⋮----
let sharable_banks = bank_forks.read().unwrap().sharable_banks();
let (bls_sender, _bls_receiver) = unbounded();
let (commitment_sender, _commitment_receiver) = unbounded();
let (consensus_metrics_sender, _consensus_metrics_receiver) = unbounded();
⋮----
vote_history: VoteHistory::new(my_keys.node_keypair.pubkey(), 0),
vote_account_pubkey: my_keys.vote_keypair.pubkey(),
identity_keypair: Arc::new(my_keys.node_keypair.insecure_clone()),
authorized_voter_keypairs: Arc::new(RwLock::new(vec![Arc::new(
⋮----
fn test_generate_own_vote_message() {
⋮----
.map(|_| ValidatorVoteKeypairs::new(Keypair::new(), Keypair::new(), Keypair::new()))
⋮----
setup_voting_context_and_bank_forks(own_vote_sender, &validator_keypairs, my_index);
⋮----
.unwrap();
⋮----
let result = generate_vote_message(vote, false, &mut voting_context)
.ok()
.unwrap()
⋮----
let expected_message = generate_expected_consensus_message(vote, &my_bls_keypair);
⋮----
assert_eq!(slot, &vote_slot);
assert_eq!(**message, expected_message);
assert_eq!(
⋮----
panic!("Expected BLSOp::PushVote, got {result:?}");
⋮----
let received_message = own_vote_receiver.recv().unwrap();
assert_eq!(received_message, expected_message);
⋮----
fn test_wait_to_vote_slot() {
⋮----
voting_context.wait_to_vote_slot = Some(4);
⋮----
assert!(generate_vote_message(vote, false, &mut voting_context)
⋮----
voting_context.wait_to_vote_slot = Some(1);
⋮----
fn test_non_voting_node() {
⋮----
voting_context.authorized_voter_keypairs = Arc::new(std::sync::RwLock::new(vec![]));
⋮----
voting_context.authorized_voter_keypairs = Arc::new(RwLock::new(vec![Arc::new(
⋮----
fn test_wrong_identity_keypair() {
⋮----
assert!(generate_vote_message(vote, true, &mut voting_context)
⋮----
Arc::new(validator_keypairs[my_index].node_keypair.insecure_clone());
⋮----
fn test_wrong_vote_account_pubkey() {
⋮----
voting_context.vote_account_pubkey = validator_keypairs[my_index].vote_keypair.pubkey();
⋮----
fn test_wrong_bls_pubkey() {
⋮----
voting_context.derived_bls_keypairs.insert(
validator_keypairs[my_index].vote_keypair.pubkey(),
⋮----
fn test_panic_on_future_slot() {
⋮----
let _ = generate_vote_message(vote, false, &mut voting_context);
⋮----
fn test_zero_staked_validator_fails_voting() {
⋮----
let bank = voting_context.sharable_banks.root();
assert_eq!(bank.epoch(), 0);
assert!(bank.epoch_stakes(2).is_none());
⋮----
.enumerate()
.map(|(i, keypairs)| {
⋮----
i.saturating_mul(100)
⋮----
let authorized_voter = keypairs.vote_keypair.pubkey();
let vote_account = bank.get_vote_account(&authorized_voter).unwrap();
⋮----
.collect();
⋮----
assert!(new_bank.epoch_stakes(2).is_none());
⋮----
new_bank.set_epoch_stakes_for_test(2, epoch2_epoch_stakes);
assert!(new_bank.epoch_stakes(2).is_some());
new_bank.freeze();
⋮----
voting_context.sharable_banks = bank_forks.read().unwrap().sharable_banks();
⋮----
.root()
.epoch_schedule()
.get_first_slot_in_epoch(1);
⋮----
.get_first_slot_in_epoch(2);

================
File: votor/src/votor.rs
================
pub struct LeaderWindowNotifier {
⋮----
pub struct VotorConfig {
⋮----
pub(crate) struct SharedContext {
⋮----
pub struct Votor {
⋮----
impl Votor {
pub fn new(config: VotorConfig) -> Self {
⋮----
let identity_keypair = cluster_info.keypair().clone();
⋮----
let sharable_banks = bank_forks.read().unwrap().sharable_banks();
⋮----
blockstore: blockstore.clone(),
bank_forks: bank_forks.clone(),
cluster_info: cluster_info.clone(),
⋮----
identity_keypair: identity_keypair.clone(),
⋮----
bls_sender: bls_sender.clone(),
commitment_sender: commitment_sender.clone(),
⋮----
sharable_banks: sharable_banks.clone(),
consensus_metrics_sender: consensus_metrics_sender.clone(),
⋮----
leader_schedule_cache: leader_schedule_cache.clone(),
⋮----
event_sender.clone(),
exit.clone(),
⋮----
exit: exit.clone(),
start: start.clone(),
⋮----
let root_epoch = sharable_banks.root().epoch();
⋮----
pub fn start_migration(&self) {
⋮----
let mut started = lock.lock().unwrap();
⋮----
cvar.notify_all();
⋮----
pub(crate) fn wait_for_migration_or_exit(
⋮----
if exit.load(Ordering::Relaxed) {
⋮----
(started, _) = cvar.wait_timeout(started, Duration::from_secs(1)).unwrap();
⋮----
pub fn join(self) -> thread::Result<()> {
self.consensus_pool_service.join()?;
⋮----
manager.into_inner().join();
⋮----
self.event_handler.join()?;
self.consensus_metrics_handle.join()

================
File: votor/Cargo.toml
================
[package]
name = "agave-votor"
documentation = "https://docs.rs/agave-votor"
version = { workspace = true }
authors = { workspace = true }
description = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []
dev-context-only-utils = ["solana-runtime/dev-context-only-utils"]
frozen-abi = [
    "dep:solana-frozen-abi",
    "dep:solana-frozen-abi-macro",
    "solana-accounts-db/frozen-abi",
    "solana-bloom/frozen-abi",
    "solana-ledger/frozen-abi",
    "solana-runtime/frozen-abi",
    "solana-signature/frozen-abi",
    "agave-votor-messages/frozen-abi",
]

[dependencies]
agave-logger = { workspace = true }
agave-votor-messages = { workspace = true }
anyhow = { workspace = true }
bincode = { workspace = true }
bitvec = { workspace = true }
bs58 = { workspace = true }
crossbeam-channel = { workspace = true }
dashmap = { workspace = true, features = ["rayon", "raw-api"] }
histogram = { workspace = true }
itertools = { workspace = true }
log = { workspace = true }
lru = { workspace = true }
parking_lot = { workspace = true }
qualifier_attr = { workspace = true }
rayon = { workspace = true }
serde = { workspace = true }
serde_bytes = { workspace = true }
solana-account = { workspace = true }
solana-accounts-db = { workspace = true }
solana-bloom = { workspace = true }
solana-bls-signatures = { workspace = true }
solana-client = { workspace = true }
solana-clock = { workspace = true }
solana-connection-cache = { workspace = true }
solana-entry = { workspace = true }
solana-epoch-schedule = { workspace = true }
solana-frozen-abi = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-frozen-abi-macro = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-genesis-config = { workspace = true }
solana-gossip = { workspace = true }
solana-hash = { workspace = true }
solana-keypair = { workspace = true }
solana-ledger = { workspace = true }
solana-measure = { workspace = true }
solana-metrics = { workspace = true }
solana-pubkey = { workspace = true }
solana-rpc = { workspace = true }
solana-runtime = { workspace = true }
solana-signature = { workspace = true }
solana-signer = { workspace = true }
solana-signer-store = { workspace = true }
solana-time-utils = { workspace = true }
solana-transaction = { workspace = true }
solana-transaction-error = { workspace = true }
solana-vote = { workspace = true }
solana-vote-program = { workspace = true }
thiserror = { workspace = true }

[dev-dependencies]
rand = { workspace = true }
solana-net-utils = { workspace = true }
solana-perf = { workspace = true, features = ["dev-context-only-utils"] }
solana-runtime = { workspace = true, features = ["dev-context-only-utils"] }
solana-sdk-ids = { workspace = true }
solana-streamer = { workspace = true, features = ["dev-context-only-utils"] }
tempfile = { workspace = true }
test-case = { workspace = true }
tokio-util = { workspace = true }

[lints]
workspace = true

================
File: votor-messages/src/consensus_message.rs
================
pub type Block = (Slot, Hash);
⋮----
pub struct VoteMessage {
⋮----
pub enum CertificateType {
⋮----
impl CertificateType {
pub fn slot(&self) -> Slot {
⋮----
pub fn to_block(self) -> Option<Block> {
⋮----
| Self::FinalizeFast(slot, block_id) => Some((slot, block_id)),
⋮----
pub struct Certificate {
⋮----
pub enum ConsensusMessage {
⋮----
impl ConsensusMessage {
pub fn new_vote(vote: Vote, signature: BLSSignature, rank: u16) -> Self {

================
File: votor-messages/src/lib.rs
================
pub mod consensus_message;
pub mod vote;
⋮----
extern crate solana_frozen_abi_macro;

================
File: votor-messages/src/vote.rs
================
pub enum Vote {
⋮----
impl Vote {
pub fn new_notarization_vote(slot: Slot, block_id: Hash) -> Self {
⋮----
pub fn new_finalization_vote(slot: Slot) -> Self {
⋮----
pub fn new_skip_vote(slot: Slot) -> Self {
⋮----
pub fn new_notarization_fallback_vote(slot: Slot, block_id: Hash) -> Self {
⋮----
pub fn new_skip_fallback_vote(slot: Slot) -> Self {
⋮----
pub fn slot(&self) -> Slot {
⋮----
pub fn block_id(&self) -> Option<&Hash> {
⋮----
Self::Notarize(vote) => Some(&vote.block_id),
Self::NotarizeFallback(vote) => Some(&vote.block_id),
⋮----
pub fn is_notarization(&self) -> bool {
matches!(self, Self::Notarize(_))
⋮----
pub fn is_finalize(&self) -> bool {
matches!(self, Self::Finalize(_))
⋮----
pub fn is_skip(&self) -> bool {
matches!(self, Self::Skip(_))
⋮----
pub fn is_notarize_fallback(&self) -> bool {
matches!(self, Self::NotarizeFallback(_))
⋮----
pub fn is_skip_fallback(&self) -> bool {
matches!(self, Self::SkipFallback(_))
⋮----
pub fn is_notarization_or_finalization(&self) -> bool {
matches!(self, Self::Notarize(_) | Self::Finalize(_))
⋮----
fn from(vote: NotarizationVote) -> Self {
⋮----
fn from(vote: FinalizationVote) -> Self {
⋮----
fn from(vote: SkipVote) -> Self {
⋮----
fn from(vote: NotarizationFallbackVote) -> Self {
⋮----
fn from(vote: SkipFallbackVote) -> Self {
⋮----
pub struct NotarizationVote {
⋮----
pub struct FinalizationVote {
⋮----
pub struct SkipVote {
⋮----
pub struct NotarizationFallbackVote {
⋮----
pub struct SkipFallbackVote {

================
File: votor-messages/Cargo.toml
================
[package]
name = "agave-votor-messages"
documentation = "https://docs.rs/agave-votor-messages"
version = { workspace = true }
authors = { workspace = true }
description = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[features]
agave-unstable-api = []
frozen-abi = [
    "dep:solana-frozen-abi",
    "dep:solana-frozen-abi-macro",
    "solana-hash/frozen-abi",
    "solana-bls-signatures/frozen-abi",
]

[dependencies]
agave-logger = { workspace = true }
serde = { workspace = true }
solana-bls-signatures = { workspace = true, features = [
    "bytemuck", "solana-signer-derive",
] }
solana-clock = { workspace = true }
solana-frozen-abi = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-frozen-abi-macro = { workspace = true, optional = true, features = [
    "frozen-abi",
] }
solana-hash = { workspace = true, features = ["serde"] }

[lints]
workspace = true

================
File: watchtower/src/main.rs
================
struct Config {
⋮----
fn get_config() -> Config {
let matches = App::new(crate_name!())
.about(crate_description!())
.version(solana_version::version!())
.after_help(
⋮----
.arg({
⋮----
.short("C")
.long("config")
.value_name("PATH")
.takes_value(true)
.global(true)
.help("Configuration file to use");
⋮----
arg.default_value(config_file)
⋮----
.arg(
⋮----
.long("url")
.value_name("URL")
⋮----
.validator(is_url)
.help("JSON RPC URL for the cluster (conflicts with --urls)"),
⋮----
.long("urls")
⋮----
.multiple(true)
.number_of_values(3)
.conflicts_with("json_rpc_url")
.help(
⋮----
.long("rpc-timeout")
.value_name("SECONDS")
⋮----
.default_value("30")
.help("Timeout value for RPC requests"),
⋮----
.long("interval")
⋮----
.default_value("60")
.help("Wait interval seconds between checking the cluster"),
⋮----
.long("unhealthy-threshold")
.value_name("COUNT")
⋮----
.default_value("1")
.help("How many consecutive failures must occur to trigger a notification"),
⋮----
.long("validator-identity")
.value_name("VALIDATOR IDENTITY PUBKEY")
⋮----
.validator(is_pubkey_or_keypair)
⋮----
.help("Validator identities to monitor for delinquency"),
⋮----
.long("minimum-validator-identity-balance")
.value_name("SOL")
⋮----
.default_value("10")
.validator(is_parsable::<f64>)
.help("Alert when the validator identity balance is less than this amount of SOL"),
⋮----
.long("no-duplicate-notifications")
.hidden(hidden_unless_forced()),
⋮----
.long("monitor-active-stake")
.takes_value(false)
⋮----
.long("active-stake-alert-threshold")
.value_name("PERCENTAGE")
⋮----
.validator(is_valid_percentage)
.default_value("80")
.help("Alert when the current stake for the cluster drops below this value"),
⋮----
.long("ignore-http-bad-gateway")
⋮----
.long("name-suffix")
.value_name("SUFFIX")
⋮----
.default_value("")
.help("Add this string into all notification messages after \"agave-watchtower\""),
⋮----
.long("acceptable-slot-range")
.value_name("RANGE")
⋮----
.default_value("50")
.validator(is_parsable::<u64>)
.help("Acceptable range of slots for endpoints, checked at watchtower startup"),
⋮----
.get_matches();
let config = if let Some(config_file) = matches.value_of("config_file") {
solana_cli_config::Config::load(config_file).unwrap_or_default()
⋮----
let interval = Duration::from_secs(value_t_or_exit!(matches, "interval", u64));
let unhealthy_threshold = value_t_or_exit!(matches, "unhealthy_threshold", usize);
⋮----
.value_of("minimum_validator_identity_balance")
.and_then(sol_str_to_lamports)
.unwrap();
let json_rpc_urls = values_t!(matches, "json_rpc_urls", String).unwrap_or_else(|_| {
vec![value_t!(matches, "json_rpc_url", String).unwrap_or_else(|_| config.json_rpc_url)]
⋮----
let rpc_timeout = value_t_or_exit!(matches, "rpc_timeout", u64);
⋮----
let validator_identity_pubkeys: Vec<_> = pubkeys_of(&matches, "validator_identities")
.unwrap_or_default()
.into_iter()
.collect();
let monitor_active_stake = matches.is_present("monitor_active_stake");
⋮----
value_t_or_exit!(matches, "active_stake_alert_threshold", u8);
let ignore_http_bad_gateway = matches.is_present("ignore_http_bad_gateway");
let name_suffix = value_t_or_exit!(matches, "name_suffix", String);
let acceptable_slot_range = value_t_or_exit!(matches, "acceptable_slot_range", u64);
⋮----
info!("RPC URLs: {:?}", config.json_rpc_urls);
info!(
⋮----
fn get_cluster_info(
⋮----
let transaction_count = rpc_client.get_transaction_count()?;
let recent_blockhash = rpc_client.get_latest_blockhash()?;
let vote_accounts = rpc_client.get_vote_accounts()?;
⋮----
validator_balances.insert(
⋮----
rpc_client.get_balance(validator_identity)?,
⋮----
Ok((
⋮----
struct EndpointData {
⋮----
fn query_endpoint(
⋮----
info!("Querying {}", endpoint.rpc_client.url());
match get_cluster_info(config, &endpoint.rpc_client) {
⋮----
info!("Current transaction count: {transaction_count}");
info!("Recent blockhash: {recent_blockhash}");
info!("Current validator count: {}", vote_accounts.current.len());
⋮----
let mut failures = vec![];
⋮----
.iter()
.map(|vote_account| vote_account.activated_stake)
.sum();
⋮----
failures.push((
⋮----
format!(
⋮----
format!("Unable to get new blockhash: {recent_blockhash}"),
⋮----
format!("Current stake is {current_stake_percent:.2}%"),
⋮----
let mut validator_errors = vec![];
for validator_identity in config.validator_identity_pubkeys.iter() {
⋮----
format_labeled_address(&validator_identity.to_string(), &config.address_labels);
⋮----
.any(|vai| vai.node_pubkey == *validator_identity.to_string())
⋮----
validator_errors.push(format!("{formatted_validator_identity} delinquent"));
⋮----
validator_errors.push(format!("{formatted_validator_identity} missing"));
⋮----
if let Some(balance) = validator_balances.get(validator_identity) {
⋮----
format!("{} has {}", formatted_validator_identity, Sol(*balance)),
⋮----
if !validator_errors.is_empty() {
failures.push(("delinquent", validator_errors.join(",")));
⋮----
error!("{} sanity failure: {}", failure.0, failure.1);
⋮----
Ok(failures.into_iter().next()) // Only report the first failure if any
⋮----
if let client_error::ErrorKind::Reqwest(reqwest_err) = err.kind() {
if let Some(client_error::reqwest::StatusCode::BAD_GATEWAY) = reqwest_err.status() {
⋮----
warn!("Error suppressed: {err}");
return Ok(None);
⋮----
warn!("rpc-error: {err}");
Err(err)
⋮----
fn validate_endpoints(
⋮----
info!("Validating endpoints...");
⋮----
let slot = endpoint.rpc_client.get_slot()?;
let genesis_hash = endpoint.rpc_client.get_genesis_hash()?;
info!("Genesis hash: {genesis_hash}");
info!("Current slot: {slot}");
max_slot = max_slot.max(slot);
min_slot = min_slot.min(slot);
⋮----
return Err(
"Endpoints don't agree on genesis hash, have you mixed up clusters?".into(),
⋮----
opt_common_genesis_hash = Some(genesis_hash);
⋮----
return Err(format!(
⋮----
.into());
⋮----
Ok(())
⋮----
fn main() -> Result<(), Box<dyn error::Error>> {
⋮----
let config = get_config();
⋮----
.map(|url| EndpointData {
⋮----
if let Err(err) = validate_endpoints(&config, &endpoints) {
error!("Endpoint validation failed: {err}");
⋮----
let min_agreeing_endpoints = endpoints.len() / 2 + 1;
⋮----
let mut last_notification_msg = "".into();
⋮----
let mut failures = HashMap::new(); // test_name -> message
⋮----
match query_endpoint(&config, endpoint) {
⋮----
// Collecting only one failure of each type
⋮----
.entry(failure_test_name)
.or_insert(failure_error_message.clone());
⋮----
failures.clear(); // Ignoring other failures when watchtower is unreliable
let watchtower_unreliable_msg = format!(
⋮----
failures.insert("watchtower-reliability", watchtower_unreliable_msg);
⋮----
if failures.len() > 1 {
failures.clear();
⋮----
.into();
⋮----
let (failure_test_name, failure_error_message) = failures.iter().next().unwrap();
let notification_msg = format!(
⋮----
datapoint_info!("watchtower-sanity", ("ok", false, bool));
⋮----
notifier.send(&notification_msg, &NotificationType::Trigger { incident });
⋮----
datapoint_error!(
⋮----
datapoint_info!("watchtower-sanity", ("ok", true, bool));
if !last_notification_msg.is_empty() {
let alarm_duration = Instant::now().duration_since(last_success);
⋮----
let alarm_duration = Duration::from_secs(alarm_duration.as_secs());
let all_clear_msg = format!(
⋮----
info!("{all_clear_msg}");
notifier.send(
&format!("agave-watchtower{}: {}", config.name_suffix, all_clear_msg),
⋮----
last_notification_msg = "".into();
⋮----
sleep(config.interval);

================
File: watchtower/.gitignore
================
/target/
/farf/

================
File: watchtower/Cargo.toml
================
[package]
name = "agave-watchtower"
documentation = "https://docs.rs/agave-watchtower"
version = { workspace = true }
authors = { workspace = true }
description = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[features]
agave-unstable-api = []

[dependencies]
agave-logger = { workspace = true }
clap = { workspace = true }
humantime = { workspace = true }
log = { workspace = true }
solana-clap-utils = { workspace = true }
solana-cli-config = { workspace = true }
solana-cli-output = { workspace = true }
solana-hash = "=3.1.0"
solana-metrics = { workspace = true }
solana-native-token = "=3.0.0"
solana-notifier = { workspace = true }
solana-pubkey = { version = "=3.0.0", default-features = false }
solana-rpc-client = { workspace = true }
solana-rpc-client-api = { workspace = true }
solana-version = { workspace = true }

================
File: watchtower/README.md
================
The `agave-watchtower` program is used to monitor the health of a cluster. It
periodically polls the cluster over an RPC API to confirm that the transaction
count is advancing, new blockhashes are available, and no validators are
delinquent. Results are reported as InfluxDB metrics, with an optional push
notification on sanity failure.

If you only care about the health of several specific validators, the
`--validator-identity` command-line argument can be used to restrict failure
notifications to issues only affecting that set of validators.

User can provide either 1 or 3 RPC URLs for the cluster via the `--url` or `--urls`
command-line arguments respectively. 2 URLs are not accepted because it's not enough
to have redundnacy, and more than 3 URLs are not accepted because there's little
benefit from having more than 3. If 3 URLs are provided, at least 2 of them have to
confirm health of a cluster.

### Metrics
#### `watchtower-sanity`
On every iteration this data point will be emitted indicating the overall result
using a boolean `ok` field.

#### `watchtower-sanity-failure`
On failure this data point contains details about the specific test that failed via
the following fields:
* `test`: name of the sanity test that failed
* `err`: exact sanity failure message

================
File: web3.js/README.md
================
# `@solana/web3.js`

Moved to its own repo @ https://github.com/solana-labs/solana-web3.js

================
File: wen-restart/proto/wen_restart.proto
================
syntax = "proto3";
package solana.wen_restart_proto;

enum State {
    INIT = 0;
    LAST_VOTED_FORK_SLOTS = 1;
    HEAVIEST_FORK = 2;
    GENERATE_SNAPSHOT = 3;
    DONE = 4;
}

message LastVotedForkSlotsRecord {
    repeated uint64 last_voted_fork_slots = 1;
    string last_vote_bankhash = 2;
    uint32 shred_version = 3;
    uint64 wallclock = 4;
}

message LastVotedForkSlotsAggregateRecord {
    map<string, LastVotedForkSlotsRecord> received = 1;
    optional LastVotedForkSlotsAggregateFinal final_result = 2;
}

message LastVotedForkSlotsEpochInfoRecord {
    uint64 epoch = 1;
    uint64 total_stake = 2;
    uint64 actively_voting_stake = 3;
    uint64 actively_voting_for_this_epoch_stake = 4;
}

message LastVotedForkSlotsAggregateFinal {
    map<uint64, uint64> slots_stake_map = 1;
    repeated LastVotedForkSlotsEpochInfoRecord epoch_infos = 2;
}

message HeaviestForkRecord {
    uint64 slot = 1;
    string bankhash = 2;
    uint64 total_active_stake = 3;
    uint32 shred_version = 4;
    uint64 wallclock = 5;
    string from = 6;
}

message HeaviestForkAggregateRecord {
    repeated HeaviestForkRecord received = 1;
    uint64 total_active_stake = 2;
}

message GenerateSnapshotRecord {
    string path = 1;
    uint64 slot = 2;
    string bankhash = 3;
    uint32 shred_version = 4;
}

message ConflictMessage {
    string old_message = 2;
    string new_message = 3;
}

message WenRestartProgress {
    State state = 1;
    optional LastVotedForkSlotsRecord my_last_voted_fork_slots = 2;
    optional LastVotedForkSlotsAggregateRecord last_voted_fork_slots_aggregate = 3;
    optional HeaviestForkRecord my_heaviest_fork = 4;
    optional HeaviestForkAggregateRecord heaviest_fork_aggregate = 5;
    optional HeaviestForkRecord coordinator_heaviest_fork = 6;
    optional GenerateSnapshotRecord my_snapshot = 7;
    map<string, ConflictMessage> conflict_message = 8;
}

================
File: wen-restart/src/heaviest_fork_aggregate.rs
================
pub(crate) struct HeaviestForkAggregate {
⋮----
pub enum HeaviestForkAggregateResult {
⋮----
impl HeaviestForkAggregate {
pub(crate) fn new(
⋮----
active_peers.insert(*my_pubkey);
⋮----
block_stake_map.insert(
⋮----
epoch_stakes.node_id_to_stake(my_pubkey).unwrap_or(0),
⋮----
epoch_stakes: epoch_stakes.clone(),
⋮----
pub(crate) fn aggregate_from_record(
⋮----
Ok(self.aggregate(restart_heaviest_fork))
⋮----
fn is_valid_change(
⋮----
current_heaviest_fork.clone(),
new_heaviest_fork.clone(),
⋮----
bankhash: new_heaviest_fork.last_slot_hash.to_string(),
⋮----
from: new_heaviest_fork.from.to_string(),
⋮----
pub(crate) fn aggregate(
⋮----
let sender_stake = self.epoch_stakes.node_id_to_stake(from).unwrap_or(0);
⋮----
warn!("Gossip should not accept zero-stake RestartLastVotedFork from {from:?}");
⋮----
warn!(
⋮----
let result = if let Some(old_heaviest_fork) = self.heaviest_forks.get(from) {
⋮----
.entry((
⋮----
.or_insert(0);
*entry = entry.saturating_add(sender_stake);
self.active_peers.insert(*from);
⋮----
bankhash: received_heaviest_fork.last_slot_hash.to_string(),
⋮----
from: from.to_string(),
⋮----
.insert(*from, received_heaviest_fork.clone());
⋮----
pub(crate) fn total_active_stake(&self) -> u64 {
self.active_peers.iter().fold(0, |sum: u64, pubkey| {
sum.saturating_add(self.epoch_stakes.node_id_to_stake(pubkey).unwrap_or(0))
⋮----
pub(crate) fn print_block_stake_map(&self) {
let total_stake = self.epoch_stakes.total_stake();
for ((slot, hash), stake) in self.block_stake_map.iter() {
info!(
⋮----
mod tests {
⋮----
struct TestAggregateInitResult {
⋮----
fn test_aggregate_init() -> TestAggregateInitResult {
⋮----
.map(|_| ValidatorVoteKeypairs::new_rand())
.collect();
let GenesisConfigInfo { genesis_config, .. } = create_genesis_config_with_vote_accounts(
⋮----
vec![100; validator_voting_keypairs.len()],
⋮----
let root_bank = bank_forks.read().unwrap().root_bank();
let heaviest_slot = root_bank.slot().saturating_add(3);
⋮----
root_bank.epoch_stakes(root_bank.epoch()).unwrap(),
⋮----
&validator_voting_keypairs[MY_INDEX].node_keypair.pubkey(),
⋮----
fn test_aggregate_from_gossip() {
let mut test_state = test_aggregate_init();
⋮----
let timestamp1 = timestamp();
⋮----
.iter()
.take(initial_num_active_validators)
⋮----
let pubkey = validator_voting_keypair.node_keypair.pubkey();
assert_eq!(
⋮----
.pubkey();
let now = timestamp();
⋮----
for validator_voting_keypair in test_state.validator_voting_keypairs.iter().take(13) {
⋮----
for validator_voting_keypair in test_state.validator_voting_keypairs.iter().take(14) {
⋮----
fn test_aggregate_from_record() {
⋮----
let time1 = timestamp();
⋮----
bankhash: test_state.heaviest_hash.to_string(),
⋮----
assert_eq!(test_state.heaviest_fork_aggregate.total_active_stake(), 100);
⋮----
assert_eq!(test_state.heaviest_fork_aggregate.total_active_stake(), 200);
⋮----
let time2 = timestamp();
⋮----
.pubkey(),
wallclock: timestamp(),
⋮----
fn test_aggregate_from_record_failures() {
⋮----
heaviest_fork_record.from = "invalid_pubkey".to_string();
assert!(test_state
⋮----
heaviest_fork_record.from = from.to_string();
heaviest_fork_record.bankhash.clear();

================
File: wen-restart/src/last_voted_fork_slots_aggregate.rs
================
pub(crate) struct LastVotedForkSlotsEpochInfo {
⋮----
pub(crate) struct LastVotedForkSlotsAggregate {
⋮----
pub struct LastVotedForkSlotsFinalResult {
⋮----
pub enum LastVotedForkSlotsAggregateResult {
⋮----
impl LastVotedForkSlotsAggregate {
pub(crate) fn new(
⋮----
let root_slot = root_bank.slot();
let root_epoch = root_bank.epoch();
⋮----
let epoch = root_bank.epoch_schedule().get_epoch(*slot);
if let Some(sender_stake) = root_bank.epoch_node_id_to_stake(epoch, my_pubkey) {
slots_stake_map.insert(*slot, sender_stake);
⋮----
warn!("The root bank {root_slot} does not have the stake for slot {slot}");
⋮----
.get_epoch_and_slot_index(
⋮----
.iter()
.max()
.expect("my voted slots should not be empty"),
⋮----
.checked_add(2)
.expect("root_epoch should not be so big"))
.map(|epoch| {
⋮----
.epoch_total_stake(epoch)
.expect("epoch stake not found");
⋮----
.epoch_node_id_to_stake(epoch, my_pubkey)
.unwrap_or(0);
⋮----
.collect();
⋮----
pub(crate) fn aggregate_from_record(
⋮----
Ok(self.aggregate(converted_record))
⋮----
pub(crate) fn aggregate(
⋮----
let root_slot = self.root_bank.slot();
let new_slots_vec = new_slots.to_slots(root_slot);
if new_slots_vec.is_empty() {
info!("The slots from {from} is older than root slot {root_slot}");
⋮----
if let Some(old_slots) = self.last_voted_fork_slots.get(from) {
if old_slots.to_slots(self.root_bank.slot()) == new_slots_vec {
⋮----
old_slots.clone(),
new_slots.clone(),
⋮----
self.last_voted_fork_slots.insert(*from, new_slots.clone());
⋮----
.get_epoch_and_slot_index(new_slots.last_voted_slot)
⋮----
self.update_epoch_info(from, last_vote_epoch);
self.insert_message(from, &new_slots_vec);
⋮----
last_vote_bankhash: new_slots.last_voted_hash.to_string(),
⋮----
fn insert_message(&mut self, from: &Pubkey, new_slots_vec: &Vec<Slot>) {
⋮----
let epoch = self.root_bank.epoch_schedule().get_epoch(*slot);
let entry = self.slots_stake_map.entry(*slot).or_insert(0);
if let Some(sender_stake) = self.root_bank.epoch_node_id_to_stake(epoch, from) {
*entry = entry.saturating_add(sender_stake);
let repair_threshold_stake = (self.root_bank.epoch_total_stake(epoch).unwrap()
⋮----
self.slots_to_repair.insert(*slot);
⋮----
fn update_epoch_info(&mut self, from: &Pubkey, last_vote_epoch: Epoch) {
for entry in self.epoch_info_vec.iter_mut() {
if let Some(stake) = self.root_bank.epoch_node_id_to_stake(entry.epoch, from) {
⋮----
entry.actively_voting_stake.checked_add(stake).unwrap();
⋮----
.checked_add(stake)
.unwrap();
⋮----
pub(crate) fn min_active_percent(&self) -> f64 {
⋮----
.filter(|info| {
⋮----
.map(|info| info.actively_voting_stake as f64 / info.total_stake as f64 * 100.0)
.min_by(|a, b| a.partial_cmp(b).unwrap())
.unwrap_or(0.0)
⋮----
pub(crate) fn slots_to_repair_iter(&self) -> impl Iterator<Item = &Slot> {
self.slots_to_repair.iter()
⋮----
pub(crate) fn get_final_result(self) -> LastVotedForkSlotsFinalResult {
⋮----
mod tests {
⋮----
struct TestAggregateInitResult {
⋮----
fn test_aggregate_init() -> TestAggregateInitResult {
⋮----
.map(|_| ValidatorVoteKeypairs::new_rand())
⋮----
let GenesisConfigInfo { genesis_config, .. } = create_genesis_config_with_vote_accounts(
⋮----
vec![100; validator_voting_keypairs.len()],
⋮----
let bank0 = bank_forks.read().unwrap().root_bank();
let bank1 = Bank::new_from_parent(bank0.clone(), &Pubkey::default(), 1);
bank_forks.write().unwrap().insert(bank1);
bank_forks.write().unwrap().set_root(1, None, None);
let root_bank = bank_forks.read().unwrap().root_bank();
⋮----
let last_voted_fork_slots = vec![
⋮----
&validator_voting_keypairs[MY_INDEX].node_keypair.pubkey(),
⋮----
fn test_aggregate_success() {
let mut test_state = test_aggregate_init();
⋮----
assert_eq!(test_state.slots_aggregate.min_active_percent(), 0.0);
⋮----
.take(initial_num_active_validators)
⋮----
let pubkey = validator_voting_keypair.node_keypair.pubkey();
let now = timestamp();
assert_eq!(
⋮----
assert!(test_state
⋮----
.pubkey();
let timestamp1 = timestamp();
⋮----
Vec::from_iter(test_state.slots_aggregate.slots_to_repair_iter().cloned());
actual_slots.sort();
assert_eq!(actual_slots, test_state.last_voted_fork_slots);
⋮----
fn test_aggregate_from_record_success() {
⋮----
let time1 = timestamp();
⋮----
last_voted_fork_slots: test_state.last_voted_fork_slots.clone(),
last_vote_bankhash: last_vote_bankhash.to_string(),
⋮----
assert_eq!(test_state.slots_aggregate.min_active_percent(), 40.0);
⋮----
let time2 = timestamp();
⋮----
vec![root_slot + 1, root_slot + 2, root_slot + 3, root_slot + 4];
⋮----
.pubkey(),
⋮----
fn test_aggregate_from_record_failures() {
⋮----
wallclock: timestamp(),
⋮----
last_voted_fork_slots_record.last_vote_bankhash.clear();
⋮----
last_voted_fork_slots_record.last_vote_bankhash.pop();
last_voted_fork_slots_record.last_vote_bankhash = last_vote_bankhash.to_string();
last_voted_fork_slots_record.last_voted_fork_slots.clear();
⋮----
fn test_aggregate_init_across_epoch() {
⋮----
let mut new_root_bank = Bank::new_from_parent(root_bank.clone(), &Pubkey::default(), 1);
⋮----
.enumerate()
.map(|(i, keypairs)| {
⋮----
let authorized_voter = keypairs.vote_keypair.pubkey();
let node_id = keypairs.node_keypair.pubkey();
⋮----
VoteAccount::try_from(create_v4_account_with_authorized(
⋮----
.unwrap(),
⋮----
new_root_bank.set_epoch_stakes_for_test(1, epoch1_epoch_stakes);
let last_voted_fork_slots = vec![root_bank.slot() + 1, root_bank.get_slots_in_epoch(0) + 1];

================
File: wen-restart/src/lib.rs
================
pub(crate) mod solana {
pub(crate) mod wen_restart_proto {
include!(concat!(env!("OUT_DIR"), "/solana.wen_restart_proto.rs"));
⋮----
pub(crate) mod heaviest_fork_aggregate;
pub(crate) mod last_voted_fork_slots_aggregate;
pub mod wen_restart;

================
File: wen-restart/src/wen_restart.rs
================
pub enum WenRestartError {
⋮----
fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
⋮----
write!(
⋮----
write!(f, "Block not found: {slot}")
⋮----
write!(f, "Block not full: {slot}")
⋮----
write!(f, "Block not frozen after replay: {slot} {err:?}")
⋮----
WenRestartError::Exiting => write!(f, "Exiting"),
⋮----
write!(f, "Generate snapshot when snapshots are disabled")
⋮----
write!(f, "Malformed last voted fork slots protobuf: {record:?}")
⋮----
write!(f, "Malformed progress: {state:?} missing {missing}")
⋮----
write!(f, "Missing last voted fork slots")
⋮----
write!(f, "Missing snapshot in protobuf")
⋮----
write!(f, "Unexpected state: {state:?}")
⋮----
// We need a WenRestartProgressInternalState so we can convert the protobuf written in file
// into internal data structure in the initialize function. It should be easily
// convertible to and from WenRestartProgress protobuf.
⋮----
pub(crate) enum WenRestartProgressInternalState {
⋮----
pub(crate) fn send_restart_last_voted_fork_slots(
⋮----
cluster_info.push_restart_last_voted_fork_slots(last_voted_fork_slots, last_vote_bankhash)?;
Ok(LastVotedForkSlotsRecord {
last_voted_fork_slots: last_voted_fork_slots.to_vec(),
last_vote_bankhash: last_vote_bankhash.to_string(),
shred_version: cluster_info.my_shred_version() as u32,
wallclock: timestamp(),
⋮----
pub(crate) fn aggregate_restart_last_voted_fork_slots(
⋮----
let root_bank = bank_forks.read().unwrap().root_bank();
let root_slot = root_bank.slot();
⋮----
root_bank.clone(),
⋮----
&cluster_info.id(),
⋮----
last_voted_fork_slots_aggregate.aggregate_from_record(key_string, message)
⋮----
error!("Failed to aggregate from record: {e:?}");
⋮----
progress.last_voted_fork_slots_aggregate = Some(LastVotedForkSlotsAggregateRecord {
⋮----
if exit.load(Ordering::Relaxed) {
return Err(WenRestartError::Exiting.into());
⋮----
let start = timestamp();
for new_last_voted_fork_slots in cluster_info.get_restart_last_voted_fork_slots(&mut cursor)
⋮----
let from = new_last_voted_fork_slots.from.to_string();
match last_voted_fork_slots_aggregate.aggregate(new_last_voted_fork_slots) {
⋮----
.as_mut()
.unwrap()
⋮----
.insert(from, record);
⋮----
info!(
⋮----
progress.conflict_message.insert(
⋮----
old_message: format!("{old_record:?}"),
new_message: format!("{new_record:?}"),
⋮----
// Because all operations on the aggregate are called from this single thread, we can
// fetch all results separately without worrying about them being out of sync. We can
// also use returned iterator without the vector changing underneath us.
let active_percent = last_voted_fork_slots_aggregate.min_active_percent();
⋮----
.slots_to_repair_iter()
.filter(|slot| {
if *slot <= &root_slot || is_full_slots.contains(*slot) {
⋮----
if blockstore.is_full(**slot) {
is_full_slots.insert(**slot);
⋮----
.cloned()
.collect();
⋮----
filtered_slots.sort();
⋮----
write_wen_restart_records(wen_restart_path, progress)?;
old_progress = progress.clone();
⋮----
if filtered_slots.is_empty()
⋮----
*wen_restart_repair_slots.write().unwrap() = vec![];
⋮----
*wen_restart_repair_slots.write().unwrap() = filtered_slots;
⋮----
let elapsed = timestamp().saturating_sub(start);
let time_left = GOSSIP_SLEEP_MILLIS.saturating_sub(elapsed);
⋮----
sleep(Duration::from_millis(time_left));
⋮----
Ok(last_voted_fork_slots_aggregate.get_final_result())
⋮----
fn is_over_stake_threshold(
⋮----
.iter()
.find(|info| info.epoch == epoch)
.is_some_and(|info| {
⋮----
.checked_sub((info.total_stake as f64 * HEAVIEST_FORK_THRESHOLD_DELTA) as u64)
.unwrap();
⋮----
// Verify that all blocks with at least (active_stake_percnet - 38%) of the stake form a
// single chain from the root, and use the highest slot in the blocks as the heaviest fork.
// Please see SIMD 46 "gossip current heaviest fork" for correctness proof.
pub(crate) fn find_heaviest_fork(
⋮----
.filter(|(slot, stake)| {
⋮----
&& is_over_stake_threshold(
⋮----
root_bank.epoch_schedule().get_epoch(**slot),
⋮----
.map(|(slot, _)| *slot)
⋮----
slots.sort();
// The heaviest slot we selected will always be the last of the slots list, or root if the list is empty.
let heaviest_fork_slot = slots.last().map_or(root_slot, |x| *x);
⋮----
if let Ok(Some(block_meta)) = blockstore.meta(*slot) {
if block_meta.parent_slot != Some(expected_parent) {
⋮----
error!(
⋮----
return Err(WenRestartError::BlockNotLinkedToExpectedParent(
⋮----
.into());
⋮----
if !block_meta.is_full() {
return Err(WenRestartError::BlockNotFull(*slot).into());
⋮----
return Err(WenRestartError::BlockNotFound(*slot).into());
⋮----
let heaviest_fork_bankhash = find_bankhash_of_heaviest_fork(
⋮----
blockstore.clone(),
bank_forks.clone(),
⋮----
info!("Heaviest fork found: slot: {heaviest_fork_slot}, bankhash: {heaviest_fork_bankhash:?}");
Ok((heaviest_fork_slot, heaviest_fork_bankhash))
⋮----
fn check_slot_smaller_than_intended_snapshot_slot(
⋮----
match slot.cmp(&intended_snapshot_slot) {
std::cmp::Ordering::Greater => Err(WenRestartError::FutureSnapshotExists(
⋮----
directory.to_string_lossy().to_string(),
⋮----
.into()),
std::cmp::Ordering::Equal => Err(WenRestartError::GenerateSnapshotWhenOneExists(
⋮----
std::cmp::Ordering::Less => Ok(()),
⋮----
// Given the agreed upon slot, add hard fork and rehash the corresponding bank, then
// generate new snapshot. Generate incremental snapshot if possible, but generate full
// snapshot if there is no full snapshot or snapshot generation is turned off (in this
// case the incremental snasphot based on the full snapshot is incorrect).
//
// We don't use set_root() explicitly, because it may kick off snapshot requests, we
pub(crate) fn generate_snapshot(
⋮----
let my_bank_forks = bank_forks.read().unwrap();
let old_root_bank = my_bank_forks.root_bank();
⋮----
.hard_forks()
⋮----
.any(|(slot, _)| slot == &my_heaviest_fork_slot)
⋮----
old_root_bank.register_hard_fork(my_heaviest_fork_slot);
⋮----
match my_bank_forks.get(my_heaviest_fork_slot) {
Some(bank) => new_root_bank = bank.clone(),
⋮----
return Err(WenRestartError::BlockNotFound(my_heaviest_fork_slot).into());
⋮----
let mut banks = vec![&new_root_bank];
let parents = new_root_bank.parents();
banks.extend(parents.iter());
⋮----
abs_status.stop();
info!("Waiting for AccountsBackgroundService to stop");
while abs_status.is_running() {
⋮----
let snapshot_config = snapshot_controller.snapshot_config();
⋮----
let full_snapshot_slot = if snapshot_config.should_generate_snapshots() {
get_highest_full_snapshot_archive_slot(directory)
⋮----
check_slot_smaller_than_intended_snapshot_slot(
⋮----
get_highest_incremental_snapshot_archive_slot(directory, full_snapshot_slot)
⋮----
bank_to_incremental_snapshot_archive(
⋮----
Some(snapshot_config.snapshot_version),
⋮----
.path()
.display()
.to_string()
⋮----
bank_to_full_snapshot_archive(
⋮----
compute_shred_version(&genesis_config_hash, Some(&new_root_bank.hard_forks()));
info!("wen_restart snapshot generated on {new_snapshot_path} base slot {full_snapshot_slot:?}");
purge_all_bank_snapshots(&snapshot_config.bank_snapshots_dir);
Ok(GenerateSnapshotRecord {
⋮----
bankhash: new_root_bank.hash().to_string(),
⋮----
pub(crate) fn find_bankhash_of_heaviest_fork(
⋮----
.read()
⋮----
.get(heaviest_fork_slot)
.map(|bank| bank.hash())
⋮----
return Ok(hash);
⋮----
.thread_name(|i| format!("solReplayTx{i:02}"))
.build()
.expect("new rayon threadpool");
⋮----
let saved_bank = bank_forks.read().unwrap().get_with_scheduler(slot);
let bank_with_scheduler = saved_bank.unwrap_or_else(|| {
⋮----
parent_bank.clone(),
⋮----
.slot_leader_at(slot, Some(&parent_bank))
.unwrap(),
⋮----
bank_forks.write().unwrap().insert_from_ledger(new_bank)
⋮----
let bank = if bank_with_scheduler.is_frozen() {
bank_with_scheduler.clone_without_scheduler()
⋮----
let mut progress = ConfirmationProgress::new(parent_bank.last_blockhash());
if let Err(e) = process_single_slot(
⋮----
return Err(
WenRestartError::BlockNotFrozenAfterReplay(slot, Some(e.to_string())).into(),
⋮----
.get(slot)
.expect("bank should have been just inserted");
⋮----
Ok(parent_bank.hash())
⋮----
pub(crate) fn aggregate_restart_heaviest_fork(
⋮----
if progress.my_heaviest_fork.is_none() {
return Err(WenRestartError::MalformedProgress(
⋮----
"my_heaviest_fork".to_string(),
⋮----
let my_heaviest_fork = progress.my_heaviest_fork.clone().unwrap();
⋮----
.epoch_stakes(root_bank.epoch_schedule().get_epoch(heaviest_fork_slot))
⋮----
let total_stake = epoch_stakes.total_stake();
⋮----
cluster_info.my_shred_version(),
⋮----
if let Err(e) = heaviest_fork_aggregate.aggregate_from_record(message) {
⋮----
progress.heaviest_fork_aggregate = Some(HeaviestForkAggregateRecord {
⋮----
return Ok(());
⋮----
for new_heaviest_fork in cluster_info.get_restart_heaviest_fork(&mut cursor) {
info!("Received new heaviest fork: {new_heaviest_fork:?}");
let from = new_heaviest_fork.from.to_string();
match heaviest_fork_aggregate.aggregate(new_heaviest_fork) {
⋮----
info!("Successfully aggregated new heaviest fork: {record:?}");
⋮----
.push(record);
⋮----
warn!(
⋮----
let current_total_active_stake = heaviest_fork_aggregate.total_active_stake();
⋮----
if stat_printed_at.elapsed() > Duration::from_secs(COORDINATOR_STAT_PRINT_INTERVAL_SECONDS)
⋮----
heaviest_fork_aggregate.print_block_stake_map();
⋮----
pub(crate) fn repair_heaviest_fork(
⋮----
let to_repair = if blockstore.meta(heaviest_slot).is_ok_and(|x| x.is_some()) {
⋮----
.take_while(|slot| *slot > my_heaviest_fork_slot)
.filter(|slot| !blockstore.is_full(*slot))
.collect()
⋮----
vec![heaviest_slot]
⋮----
info!("wen_restart repair slots: {to_repair:?}");
if to_repair.is_empty() {
⋮----
*wen_restart_repair_slots.write().unwrap() = to_repair;
sleep(Duration::from_millis(GOSSIP_SLEEP_MILLIS));
⋮----
pub(crate) fn verify_coordinator_heaviest_fork(
⋮----
repair_heaviest_fork(
⋮----
exit.clone(),
⋮----
wen_restart_repair_slots.clone(),
⋮----
let root_slot = bank_forks.read().unwrap().root_bank().slot();
⋮----
.take_while(|slot| slot >= &root_slot)
⋮----
coordinator_heaviest_slot_ancestors.sort();
if !coordinator_heaviest_slot_ancestors.contains(&root_slot) {
return Err(WenRestartError::HeaviestForkOnLeaderOnDifferentFork(
⋮----
&& !coordinator_heaviest_slot_ancestors.contains(&my_heaviest_fork_slot)
⋮----
.any(|slot| slot == coordinator_heaviest_slot)
⋮----
let my_bankhash = if !coordinator_heaviest_slot_ancestors.is_empty() {
find_bankhash_of_heaviest_fork(
⋮----
.get(coordinator_heaviest_slot)
⋮----
.hash()
⋮----
return Err(WenRestartError::BankHashMismatch(
⋮----
Ok(())
⋮----
pub(crate) fn receive_restart_heaviest_fork(
⋮----
progress.coordinator_heaviest_fork = Some(HeaviestForkRecord {
⋮----
bankhash: coordinator_heaviest_hash.to_string(),
⋮----
from: new_heaviest_fork.from.to_string(),
⋮----
return Ok((coordinator_heaviest_slot, coordinator_heaviest_hash));
⋮----
pub(crate) fn send_and_receive_heaviest_fork(
⋮----
if config.cluster_info.id() == config.wen_restart_coordinator {
pushfn(my_heaviest_fork_slot, my_heaviest_fork_hash);
Ok((my_heaviest_fork_slot, my_heaviest_fork_hash))
⋮----
let (coordinator_slot, coordinator_hash) = receive_restart_heaviest_fork(
⋮----
config.cluster_info.clone(),
config.exit.clone(),
⋮----
match verify_coordinator_heaviest_fork(
⋮----
config.bank_forks.clone(),
config.blockstore.clone(),
⋮----
config.wen_restart_repair_slots.clone().unwrap(),
⋮----
Ok(()) => pushfn(coordinator_slot, coordinator_hash),
⋮----
warn!("Failed to verify coordinator heaviest fork: {e:?}, exit soon");
⋮----
config.cluster_info.flush_push_queue();
⋮----
return Err(e);
⋮----
Ok((coordinator_slot, coordinator_hash))
⋮----
pub struct WenRestartConfig {
⋮----
pub fn wait_for_wen_restart(config: WenRestartConfig) -> Result<()> {
let (mut state, mut progress) = initialize(
⋮----
config.last_vote.clone(),
⋮----
progress.my_last_voted_fork_slots = Some(send_restart_last_voted_fork_slots(
⋮----
None => aggregate_restart_last_voted_fork_slots(
⋮----
aggregate_final_result: Some(final_result),
⋮----
let (slot, bankhash) = find_heaviest_fork(
aggregate_final_result.clone(),
⋮----
info!("Heaviest fork found: slot: {slot}, bankhash: {bankhash}");
⋮----
bankhash: bankhash.to_string(),
⋮----
shred_version: config.cluster_info.my_shred_version() as u32,
from: config.cluster_info.id().to_string(),
⋮----
my_heaviest_fork: Some(heaviest_fork),
⋮----
let (slot, hash) = send_and_receive_heaviest_fork(
⋮----
.push_restart_heaviest_fork(slot, hash, 0);
⋮----
Some(snapshot_controller) => generate_snapshot(
⋮----
Err(WenRestartError::GenerateSnapshotWhenDisabled.into())
⋮----
my_snapshot: Some(snapshot_record),
⋮----
aggregate_restart_heaviest_fork(
⋮----
state = increment_and_write_wen_restart_records(
⋮----
pub(crate) fn increment_and_write_wen_restart_records(
⋮----
progress.set_state(RestartState::LastVotedForkSlots);
⋮----
progress.set_state(RestartState::HeaviestFork);
if let Some(aggregate_record) = progress.last_voted_fork_slots_aggregate.as_mut() {
aggregate_record.final_result = Some(LastVotedForkSlotsAggregateFinal {
slots_stake_map: aggregate_final_result.slots_stake_map.clone(),
⋮----
.map(|info| LastVotedForkSlotsEpochInfoRecord {
⋮----
.collect(),
⋮----
WenRestartError::UnexpectedState(RestartState::LastVotedForkSlots).into(),
⋮----
progress.my_heaviest_fork = Some(my_heaviest_fork.clone());
⋮----
my_heaviest_fork_hash: Hash::from_str(&my_heaviest_fork.bankhash).unwrap(),
⋮----
return Err(WenRestartError::UnexpectedState(RestartState::HeaviestFork).into());
⋮----
progress.set_state(RestartState::GenerateSnapshot);
⋮----
progress.set_state(RestartState::Done);
progress.my_snapshot = Some(my_snapshot.clone());
⋮----
hash: Hash::from_str(&my_snapshot.bankhash).unwrap(),
⋮----
return Err(WenRestartError::MissingSnapshotInProtobuf.into());
⋮----
return Err(WenRestartError::UnexpectedState(RestartState::Done).into())
⋮----
write_wen_restart_records(records_path, progress)?;
Ok(new_state)
⋮----
pub(crate) fn initialize(
⋮----
let progress = match read_wen_restart_records(records_path) {
⋮----
if stdio_err.is_some_and(|e| e.kind() == std::io::ErrorKind::NotFound) {
info!("wen restart proto file not found at {records_path:?}, write init state");
⋮----
state: RestartState::Init.into(),
⋮----
write_wen_restart_records(records_path, &progress)?;
⋮----
match progress.state() {
⋮----
if let Some(my_snapshot) = progress.my_snapshot.as_ref() {
Ok((
⋮----
Err(WenRestartError::MissingSnapshotInProtobuf.into())
⋮----
last_voted_fork_slots = my_last_voted_fork_slots.last_voted_fork_slots.clone();
⋮----
Hash::from_str(&my_last_voted_fork_slots.last_vote_bankhash).unwrap();
⋮----
if let Some(last_vote_slot) = last_vote.last_voted_slot() {
last_vote_bankhash = last_vote.hash();
⋮----
.take(RestartLastVotedForkSlots::MAX_SLOTS)
⋮----
return Err(WenRestartError::MissingLastVotedForkSlots.into());
⋮----
if let Some(record) = progress.my_last_voted_fork_slots.as_ref() {
⋮----
last_voted_fork_slots: record.last_voted_fork_slots.clone(),
⋮----
.as_ref()
.and_then(|r| {
r.final_result.as_ref().map(|result| {
⋮----
slots_stake_map: result.slots_stake_map.clone(),
⋮----
.map(|info| LastVotedForkSlotsEpochInfo {
⋮----
Err(WenRestartError::MalformedLastVotedForkSlotsProtobuf(None).into())
⋮----
RestartState::HeaviestFork => Ok((
⋮----
.map(|result| LastVotedForkSlotsFinalResult {
⋮----
.ok_or(WenRestartError::MalformedProgress(
⋮----
"final_result in last_voted_fork_slots_aggregate".to_string(),
⋮----
my_heaviest_fork: progress.my_heaviest_fork.clone(),
⋮----
RestartState::GenerateSnapshot => Ok((
⋮----
my_snapshot: progress.my_snapshot.clone(),
⋮----
fn read_wen_restart_records(records_path: &PathBuf) -> Result<WenRestartProgress> {
let buffer = read(records_path)?;
⋮----
info!("read record {progress:?}");
Ok(progress)
⋮----
pub(crate) fn write_wen_restart_records(
⋮----
info!("writing new record {new_progress:?}");
let mut buf = Vec::with_capacity(new_progress.encoded_len());
new_progress.encode(&mut buf)?;
file.write_all(&buf)?;
⋮----
mod tests {
⋮----
fn push_restart_last_voted_fork_slots(
⋮----
*node.pubkey(),
⋮----
let entries = vec![
⋮----
let mut gossip_crds = cluster_info.gossip.crds.write().unwrap();
⋮----
assert!(gossip_crds
⋮----
fn push_restart_heaviest_fork(
⋮----
from: *node.pubkey(),
⋮----
assert!(cluster_info
⋮----
struct WenRestartTestInitResult {
⋮----
fn insert_slots_into_blockstore(
⋮----
last_hash = fill_blockstore_slot_with_ticks(
⋮----
fn wen_restart_test_init(ledger_path: &TempDir) -> WenRestartTestInitResult {
⋮----
.map(|_| ValidatorVoteKeypairs::new_rand())
⋮----
.insecure_clone(),
⋮----
.pubkey();
⋮----
ContactInfo::new_localhost(&node_keypair.pubkey(), timestamp());
contact_info.set_shred_version(SHRED_VERSION);
⋮----
node_keypair.clone(),
⋮----
} = create_genesis_config_with_vote_accounts(
⋮----
vec![100; validator_voting_keypairs.len()],
⋮----
let start_blockhash = create_new_ledger(
ledger_path.path(),
⋮----
let blockstore = Arc::new(Blockstore::open(ledger_path.path()).unwrap());
let (bank_forks, ..) = test_process_blockstore(
⋮----
.extend(last_parent..last_parent.saturating_add(EXPECTED_SLOTS).saturating_add(1));
last_blockhash = insert_slots_into_blockstore(
⋮----
last_voted_fork_slots.insert(0, 0);
last_voted_fork_slots.reverse();
let mut wen_restart_proto_path = ledger_path.path().to_path_buf();
wen_restart_proto_path.push("wen_restart_status.proto");
let _ = remove_file(&wen_restart_proto_path);
⋮----
genesis_config_hash: genesis_config.hash(),
⋮----
fn wait_on_expected_progress_with_timeout(
⋮----
if let Ok(new_progress) = read_wen_restart_records(&wen_restart_proto_path) {
⋮----
if let Some(record) = progress.my_last_voted_fork_slots.as_mut() {
⋮----
if timestamp().saturating_sub(start) > WAIT_FOR_THREAD_TIMEOUT {
assert_eq!(
⋮----
panic!(
⋮----
sleep(Duration::from_millis(10));
⋮----
fn wen_restart_test_succeed_after_failure(
⋮----
wen_restart_path: test_state.wen_restart_proto_path.clone(),
⋮----
last_vote: VoteTransaction::from(Vote::new(vec![last_vote_slot], last_vote_bankhash)),
blockstore: test_state.blockstore.clone(),
cluster_info: test_state.cluster_info.clone(),
bank_forks: test_state.bank_forks.clone(),
wen_restart_repair_slots: Some(Arc::new(RwLock::new(Vec::new()))),
⋮----
exit: exit.clone(),
⋮----
.name("solana-wen-restart".to_string())
.spawn(move || {
let _ = wait_for_wen_restart(wen_restart_config).is_ok();
⋮----
wait_on_expected_progress_with_timeout(
test_state.wen_restart_proto_path.clone(),
⋮----
exit.store(true, Ordering::Relaxed);
assert!(wen_restart_thread_handle.join().is_ok());
let _ = remove_file(&test_state.wen_restart_proto_path);
⋮----
fn test_wen_restart_normal_flow() {
let ledger_path = get_tmp_ledger_path_auto_delete!();
let wen_restart_repair_slots = Some(Arc::new(RwLock::new(Vec::new())));
let test_state = wen_restart_test_init(&ledger_path);
⋮----
(last_vote_slot + 1..last_vote_slot + 3).collect();
⋮----
let bank_snapshots_dir = tempfile::TempDir::new().unwrap();
let full_snapshot_archives_dir = tempfile::TempDir::new().unwrap();
let incremental_snapshot_archives_dir = tempfile::TempDir::new().unwrap();
⋮----
bank_snapshots_dir: bank_snapshots_dir.as_ref().to_path_buf(),
full_snapshot_archives_dir: full_snapshot_archives_dir.as_ref().to_path_buf(),
⋮----
.to_path_buf(),
⋮----
let old_root_bank = test_state.bank_forks.read().unwrap().root_bank();
assert!(bank_to_full_snapshot_archive(
⋮----
let (abs_request_sender, _abs_request_receiver) = unbounded();
⋮----
wen_restart_repair_slots: wen_restart_repair_slots.clone(),
⋮----
snapshot_controller: Some(Arc::new(snapshot_controller)),
⋮----
assert!(wait_for_wen_restart(wen_restart_config).is_ok());
⋮----
.try_into()
⋮----
let mut last_voted_fork_slots_from_others = test_state.last_voted_fork_slots.clone();
last_voted_fork_slots_from_others.reverse();
last_voted_fork_slots_from_others.append(&mut expected_slots_to_repair.clone());
⋮----
.take(validators_to_take)
⋮----
let node_pubkey = keypairs.node_keypair.pubkey();
let node = ContactInfo::new_rand(&mut rng, Some(node_pubkey));
⋮----
let now = timestamp();
push_restart_last_voted_fork_slots(
test_state.cluster_info.clone(),
⋮----
expected_received_last_voted_fork_slots.insert(
node_pubkey.to_string(),
⋮----
last_voted_fork_slots: last_voted_fork_slots_from_others.clone(),
last_vote_bankhash: last_vote_hash.to_string(),
⋮----
let _ = insert_slots_into_blockstore(
test_state.blockstore.clone(),
⋮----
.get(my_heaviest_fork_slot)
⋮----
if bank.is_frozen() {
my_heaviest_fork_bankhash = bank.hash();
⋮----
sleep(Duration::from_millis(100));
⋮----
.get(coordinator_heaviest_fork_slot)
⋮----
.hash();
⋮----
let node = ContactInfo::new_rand(&mut rng, Some(coordinator_keypair.pubkey()));
⋮----
push_restart_heaviest_fork(
⋮----
let progress = read_wen_restart_records(&test_state.wen_restart_proto_path).unwrap();
⋮----
.map(|slot| {
⋮----
expected_slots_stake_map.extend(
⋮----
.map(|slot| (*slot, stake_for_new_slots)),
⋮----
fn change_proto_file_readonly(wen_restart_proto_path: &PathBuf, readonly: bool) {
⋮----
.permissions();
perms.set_readonly(readonly);
std::fs::set_permissions(wen_restart_proto_path, perms).unwrap();
⋮----
fn test_wen_restart_divergence_across_epoch_boundary() {
⋮----
old_root_bank.clone(),
⋮----
assert_eq!(new_root_bank.epoch(), 1);
⋮----
.enumerate()
.map(|(i, keypairs)| {
⋮----
let authorized_voter = keypairs.vote_keypair.pubkey();
let node_id = keypairs.node_keypair.pubkey();
⋮----
VoteAccount::try_from(create_v4_account_with_authorized(
⋮----
new_root_bank.set_epoch_stakes_for_test(2, epoch2_epoch_stakes);
⋮----
old_root_bank.last_blockhash(),
⋮----
let mut progress = ConfirmationProgress::new(old_root_bank.last_blockhash());
let last_vote_bankhash = new_root_bank.hash();
⋮----
.write()
⋮----
.insert_from_ledger(new_root_bank);
⋮----
panic!("process_single_slot failed: {e:?}");
⋮----
let mut bank_forks = test_state.bank_forks.write().unwrap();
let _ = bank_forks.set_root(last_vote_slot + 1, None, Some(last_vote_slot + 1));
⋮----
.get(last_vote_slot + 1)
⋮----
new_root_bank.slot(),
⋮----
new_root_bank.last_blockhash(),
⋮----
let new_epoch_slot = new_root_bank.epoch_schedule().get_first_slot_in_epoch(2);
⋮----
.take(TOTAL_VALIDATOR_COUNT as usize - 1)
⋮----
vec![new_epoch_slot, my_heaviest_fork_slot, 0]
⋮----
vec![old_epoch_slot, my_heaviest_fork_slot, 0]
⋮----
fn test_wen_restart_initialize() {
⋮----
let mut last_voted_fork_slots = test_state.last_voted_fork_slots.clone();
⋮----
let mut file = File::create(&test_state.wen_restart_proto_path).unwrap();
file.write_all(b"garbage").unwrap();
⋮----
assert!(remove_file(&test_state.wen_restart_proto_path).is_ok());
⋮----
let empty_last_vote = VoteTransaction::from(Vote::new(vec![], last_vote_bankhash));
⋮----
assert!(write_wen_restart_records(
⋮----
state: RestartState::HeaviestFork.into(),
my_heaviest_fork: Some(HeaviestForkRecord {
⋮----
bankhash: Hash::new_unique().to_string(),
⋮----
from: Pubkey::new_unique().to_string(),
⋮----
state: RestartState::GenerateSnapshot.into(),
my_snapshot: Some(GenerateSnapshotRecord {
⋮----
path: "/path/to/snapshot".to_string(),
⋮----
let mut vote = TowerSync::from(vec![(test_state.last_voted_fork_slots[0], 1)]);
⋮----
my_last_voted_fork_slots: Some(LastVotedForkSlotsRecord {
last_voted_fork_slots: test_state.last_voted_fork_slots.clone(),
⋮----
assert!(write_wen_restart_records(&test_state.wen_restart_proto_path, &progress,).is_ok());
⋮----
state: RestartState::LastVotedForkSlots.into(),
⋮----
last_voted_fork_slots_aggregate: Some(LastVotedForkSlotsAggregateRecord {
⋮----
final_result: Some(LastVotedForkSlotsAggregateFinal {
⋮----
epoch_infos: vec![
⋮----
state: RestartState::Done.into(),
⋮----
bankhash: snapshot_slot_hash.to_string(),
⋮----
fn test_wen_restart_send_last_voted_fork_failures() {
⋮----
let original_progress = progress.clone();
⋮----
assert_eq!(progress, original_progress);
⋮----
let last_voted_fork_slots = test_state.last_voted_fork_slots.clone();
wen_restart_test_succeed_after_failure(
⋮----
fn test_write_wen_restart_records_failure() {
⋮----
assert!(write_wen_restart_records(&test_state.wen_restart_proto_path, &progress).is_ok());
change_proto_file_readonly(&test_state.wen_restart_proto_path, true);
⋮----
change_proto_file_readonly(&test_state.wen_restart_proto_path, false);
⋮----
fn test_wen_restart_aggregate_last_voted_fork_stop_and_restart() {
⋮----
let start_time = timestamp();
⋮----
let wen_restart_proto_path_clone = test_state.wen_restart_proto_path.clone();
let cluster_info_clone = test_state.cluster_info.clone();
let bank_forks_clone = test_state.bank_forks.clone();
let blockstore_clone = test_state.blockstore.clone();
⋮----
let exit_clone = exit.clone();
let mut progress_clone = progress.clone();
⋮----
assert!(aggregate_restart_last_voted_fork_slots(
⋮----
expected_messages.insert(
⋮----
received: expected_messages.clone(),
⋮----
let _ = wen_restart_thread_handle.join();
⋮----
fn test_increment_and_write_wen_restart_records() {
⋮----
let my_dir = TempDir::new().unwrap();
let mut wen_restart_proto_path = my_dir.path().to_path_buf();
⋮----
let my_last_voted_fork_slots = Some(LastVotedForkSlotsRecord {
last_voted_fork_slots: vec![0, 1],
⋮----
let last_voted_fork_slots_aggregate = Some(LastVotedForkSlotsAggregateRecord {
⋮----
slots_stake_map: vec![(0, 900), (1, 800)].into_iter().collect(),
epoch_infos: vec![LastVotedForkSlotsEpochInfoRecord {
⋮----
let my_heaviest_fork = Some(HeaviestForkRecord {
⋮----
bankhash: Hash::default().to_string(),
⋮----
from: my_pubkey.to_string(),
⋮----
let coordinator_heaviest_fork = Some(HeaviestForkRecord {
⋮----
let my_snapshot = Some(GenerateSnapshotRecord {
⋮----
bankhash: my_bankhash.to_string(),
path: "snapshot_1".to_string(),
⋮----
vec![(0, 900), (1, 800)].into_iter().collect();
⋮----
my_last_voted_fork_slots: my_last_voted_fork_slots.clone(),
⋮----
aggregate_final_result: Some(LastVotedForkSlotsFinalResult {
slots_stake_map: expected_slots_stake_map.clone(),
epoch_info_vec: vec![LastVotedForkSlotsEpochInfo {
⋮----
last_voted_fork_slots_aggregate: last_voted_fork_slots_aggregate.clone(),
⋮----
my_heaviest_fork: my_heaviest_fork.clone(),
⋮----
coordinator_heaviest_fork: coordinator_heaviest_fork.clone(),
⋮----
my_snapshot: my_snapshot.clone(),
⋮----
let state = increment_and_write_wen_restart_records(
⋮----
assert_eq!(&state, &exit_state);
assert_eq!(&progress, &exit_progress);
⋮----
fn test_find_heaviest_fork_failures() {
⋮----
let num_slots = (not_full_slot - parent_slot).max(1);
let mut entries = create_ticks(num_slots * TICKS_PER_SLOT, 0, test_state.last_blockhash);
assert!(entries.len() > 1);
entries.pop();
let shreds = entries_to_test_shreds(&entries, not_full_slot, parent_slot, false, 0);
⋮----
.insert_shreds(shreds, None, false)
⋮----
.map(|slot| (*slot, 900))
⋮----
slots_stake_map.insert(not_full_slot, 800);
⋮----
let missing_parent = last_vote_slot.saturating_add(1);
let new_slot = last_vote_slot.saturating_add(2);
let new_hash = insert_slots_into_blockstore(
⋮----
slots_stake_map.insert(missing_parent, 800);
slots_stake_map.insert(new_slot, 800);
⋮----
fn start_aggregate_heaviest_fork_thread(
⋮----
bankhash: heaviest_fork_bankhash.to_string(),
⋮----
.saturating_mul(TOTAL_VALIDATOR_COUNT as u64),
⋮----
from: test_state.cluster_info.id().to_string(),
⋮----
let wen_restart_path = test_state.wen_restart_proto_path.clone();
let cluster_info = test_state.cluster_info.clone();
let bank_forks = test_state.bank_forks.clone();
⋮----
.name("solana-wen-restart-aggregate-heaviest-fork".to_string())
⋮----
let result = aggregate_restart_heaviest_fork(
⋮----
&mut progress.clone(),
⋮----
assert!(result.is_ok());
⋮----
fn test_aggregate_heaviest_fork() {
⋮----
let thread = start_aggregate_heaviest_fork_thread(
⋮----
let node_pubkey = keypair.node_keypair.pubkey();
let node = ContactInfo::new_rand(&mut rand::thread_rng(), Some(node_pubkey));
⋮----
assert!(thread.join().is_ok());
⋮----
fn test_generate_snapshot() {
⋮----
let old_root_slot = old_root_bank.slot();
⋮----
let mut slots = test_state.last_voted_fork_slots.clone();
slots.reverse();
let old_last_vote_bankhash = find_bankhash_of_heaviest_fork(
⋮----
test_state.bank_forks.clone(),
⋮----
SnapshotController::new(abs_request_sender.clone(), snapshot_config, new_root_slot);
⋮----
let generated_record = generate_snapshot(
⋮----
assert!(Path::new(&generated_record.path).exists());
assert!(generated_record.path.starts_with(
⋮----
.get(new_root_slot)
⋮----
assert_ne!(old_last_vote_bankhash, new_root_bankhash);
⋮----
assert_ne!(new_shred_version, SHRED_VERSION as u32);
⋮----
.split('-')
.next_back()
⋮----
.split('.')
.next()
⋮----
fn test_return_ok_after_wait_is_done() {
⋮----
assert!(wait_for_wen_restart(config).is_ok());
⋮----
fn test_receive_restart_heaviest_fork() {
⋮----
let random_node = ContactInfo::new_rand(&mut rng, Some(random_keypair.pubkey()));
⋮----
cluster_info.clone(),
⋮----
timestamp(),
⋮----
let coordinator_node = ContactInfo::new_rand(&mut rng, Some(coordinator_keypair.pubkey()));
⋮----
fn test_repair_heaviest_fork() {
⋮----
let blockstore_clone = blockstore.clone();
let wen_restart_repair_slots_clone = wen_restart_repair_slots.clone();
⋮----
.name("solana-repair-heaviest-fork".to_string())
⋮----
assert!(repair_heaviest_fork(
⋮----
repair_heaviest_fork_thread_handle.join().unwrap();
⋮----
fn test_verify_coordinator_heaviest_fork() {
⋮----
root_bank = test_state.bank_forks.read().unwrap().root_bank().clone();
⋮----
let my_hash = root_bank.hash();
⋮----
fn test_send_and_receive_heaviest_fork() {
⋮----
let coordinator_hash = find_bankhash_of_heaviest_fork(
⋮----
wen_restart_coordinator: test_state.cluster_info.id(),
last_vote: VoteTransaction::from(Vote::new(vec![last_vote], Hash::default())),
⋮----
assert_eq!(pushed_slot, coordinator_slot);
assert_eq!(pushed_hash, coordinator_hash);
⋮----
config.wen_restart_coordinator = coordinator_keypair.pubkey();
⋮----
.get(my_slot)
⋮----
assert_eq!(pushed_slot, my_slot);
assert_eq!(pushed_hash, my_hash);
⋮----
fn run_and_check_find_bankhash_of_heaviest_fork(
⋮----
fn test_find_bankhash_of_heaviest_fork() {
⋮----
run_and_check_find_bankhash_of_heaviest_fork(&test_state, &slots, last_vote);
⋮----
slots.push(new_slot);
run_and_check_find_bankhash_of_heaviest_fork(&test_state, &slots, new_slot);
⋮----
test_state.bank_forks.read().unwrap().get(new_slot).unwrap(),
⋮----
.insert_from_ledger(new_bank);
run_and_check_find_bankhash_of_heaviest_fork(

================
File: wen-restart/build.rs
================
use std::io::Result;
fn main() -> Result<()> {
⋮----
if std::env::var(PROTOC_ENVAR).is_err() {
⋮----
let proto = proto_base_path.join("wen_restart.proto");
println!("cargo:rerun-if-changed={}", proto.display());
⋮----
Ok(())

================
File: wen-restart/Cargo.toml
================
[package]
name = "solana-wen-restart"
description = "Automatic repair and restart protocol"
documentation = "https://github.com/solana-foundation/solana-improvement-documents/pull/46"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }
publish = true

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu"]

[lib]
name = "solana_wen_restart"

[features]
agave-unstable-api = []

[dependencies]
agave-snapshots = { workspace = true }
anyhow = { workspace = true }
log = { workspace = true }
prost = { workspace = true }
prost-types = { workspace = true }
rayon = { workspace = true }
solana-clock = { workspace = true }
solana-entry = { workspace = true }
solana-genesis-utils = { workspace = true }
solana-gossip = { workspace = true }
solana-hash = { workspace = true }
solana-ledger = { workspace = true }
solana-net-utils = { workspace = true }
solana-pubkey = { workspace = true }
solana-runtime = { workspace = true }
solana-shred-version = { workspace = true }
solana-svm-timings = { workspace = true }
solana-time-utils = { workspace = true }
solana-vote = { workspace = true }
solana-vote-interface = { workspace = true }
solana-vote-program = { workspace = true }

[build-dependencies]
prost-build = { workspace = true }

# windows users should install the protobuf compiler manually and set the PROTOC
# envar to point to the installed binary
[target."cfg(not(windows))".build-dependencies]
protobuf-src = { workspace = true }

[dev-dependencies]
agave-logger = { workspace = true }
agave-snapshots = { workspace = true }
assert_matches = { workspace = true }
crossbeam-channel = { workspace = true }
rand = "0.8.5"
serial_test = { workspace = true }
solana-entry = { workspace = true }
solana-keypair = { workspace = true }
solana-ledger = { workspace = true, features = ["dev-context-only-utils"] }
solana-runtime = { workspace = true, features = ["dev-context-only-utils"] }
solana-signer = { workspace = true }
tempfile = { workspace = true }

================
File: xdp/src/device.rs
================
pub struct QueueId(pub u64);
pub struct NetworkDevice {
⋮----
impl NetworkDevice {
pub fn new(name: impl Into<String>) -> Result<Self, io::Error> {
let if_name = name.into();
let if_name_c = CString::new(if_name.as_bytes())
.map_err(|_| io::Error::new(ErrorKind::InvalidInput, "Invalid interface name"))?;
let if_index = unsafe { libc::if_nametoindex(if_name_c.as_ptr()) };
⋮----
return Err(io::Error::last_os_error());
⋮----
Ok(Self { if_index, if_name })
⋮----
pub fn new_from_index(if_index: u32) -> Result<Self, io::Error> {
⋮----
let ret = unsafe { libc::if_indextoname(if_index, buf.as_mut_ptr() as *mut c_char) };
if ret.is_null() {
⋮----
let if_name = String::from_utf8_lossy(cstr.to_bytes()).to_string();
⋮----
pub fn new_from_default_route() -> Result<Self, io::Error> {
⋮----
let default_route = router.default().unwrap();
⋮----
pub fn name(&self) -> &str {
⋮----
pub fn if_index(&self) -> u32 {
⋮----
pub fn mac_addr(&self) -> Result<MacAddress, io::Error> {
⋮----
let if_name = CString::new(self.if_name.as_bytes()).unwrap();
let if_name_bytes = if_name.as_bytes_with_nul();
let len = std::cmp::min(if_name_bytes.len(), IF_NAMESIZE);
⋮----
if_name_bytes.as_ptr() as *const c_char,
req.ifr_name.as_mut_ptr(),
⋮----
let result = unsafe { syscall(SYS_ioctl, fd.as_raw_fd(), SIOCGIFHWADDR, &mut req) };
⋮----
Ok(MacAddress(
⋮----
slice::from_raw_parts(req.ifr_ifru.ifru_hwaddr.sa_data.as_ptr() as *const u8, 6)
⋮----
.try_into()
.unwrap(),
⋮----
pub fn ipv4_addr(&self) -> Result<Ipv4Addr, io::Error> {
⋮----
let result = unsafe { syscall(SYS_ioctl, fd.as_raw_fd(), SIOCGIFADDR, &mut req) };
⋮----
Ipv4Addr::from(sin_addr.s_addr.to_ne_bytes())
⋮----
Ok(addr)
⋮----
pub fn driver(&self) -> io::Result<String> {
let path = format!("/sys/class/net/{}/device/driver", self.if_name);
let path = fs::read_link(path).map_err(|e| {
⋮----
e.kind(),
format!(
⋮----
Ok(path.file_name().unwrap().to_str().unwrap().into())
⋮----
pub fn open_queue(&self, queue_id: QueueId) -> Result<DeviceQueue, io::Error> {
let ring_sizes = Self::ring_sizes(&self.if_name).ok();
Ok(DeviceQueue::new(self.if_index, queue_id, ring_sizes))
⋮----
pub fn ring_sizes(if_name: &str) -> Result<RingSizes, io::Error> {
⋮----
struct EthtoolRingParam {
⋮----
let fd = unsafe { socket(AF_INET, SOCK_DGRAM, 0) };
⋮----
if_name.as_ptr() as *const c_char,
ifr.ifr_name.as_mut_ptr(),
if_name.len().min(IF_NAMESIZE),
⋮----
let res = unsafe { syscall(SYS_ioctl, fd.as_raw_fd(), SIOCETHTOOL, &ifr) };
⋮----
Ok(RingSizes {
⋮----
pub struct RingSizes {
⋮----
impl Default for RingSizes {
fn default() -> Self {
⋮----
pub struct DeviceQueue {
⋮----
impl DeviceQueue {
pub fn new(if_index: u32, queue_id: QueueId, ring_sizes: Option<RingSizes>) -> Self {
⋮----
pub fn id(&self) -> QueueId {
⋮----
pub fn tx_completion(&mut self) -> Option<&TxCompletionRing> {
self.completion.as_ref()
⋮----
pub fn ring_sizes(&self) -> Option<RingSizes> {
⋮----
pub(crate) struct RingConsumer {
⋮----
impl RingConsumer {
pub fn new(producer: *mut AtomicU32, consumer: *mut AtomicU32) -> Self {
⋮----
cached_producer: unsafe { (*producer).load(Ordering::Acquire) },
⋮----
cached_consumer: unsafe { (*consumer).load(Ordering::Relaxed) },
⋮----
pub fn available(&self) -> u32 {
self.cached_producer.wrapping_sub(self.cached_consumer)
⋮----
pub fn consume(&mut self) -> Option<u32> {
⋮----
self.cached_consumer = self.cached_consumer.wrapping_add(1);
Some(index)
⋮----
pub fn commit(&mut self) {
unsafe { (*self.consumer).store(self.cached_consumer, Ordering::Release) };
⋮----
pub fn sync(&mut self, commit: bool) {
⋮----
self.commit();
⋮----
self.cached_producer = unsafe { (*self.producer).load(Ordering::Acquire) };
⋮----
pub(crate) struct RingProducer {
⋮----
impl RingProducer {
pub fn new(producer: *mut AtomicU32, consumer: *mut AtomicU32, size: u32) -> Self {
⋮----
cached_producer: unsafe { (*producer).load(Ordering::Relaxed) },
⋮----
cached_consumer: unsafe { (*consumer).load(Ordering::Acquire) },
⋮----
.saturating_sub(self.cached_producer.wrapping_sub(self.cached_consumer))
⋮----
pub fn produce(&mut self) -> Option<u32> {
if self.available() == 0 {
⋮----
self.cached_producer = self.cached_producer.wrapping_add(1);
⋮----
unsafe { (*self.producer).store(self.cached_producer, Ordering::Release) };
⋮----
self.cached_consumer = unsafe { (*self.consumer).load(Ordering::Acquire) };
⋮----
pub(crate) struct XdpDesc {
⋮----
pub struct TxCompletionRing {
⋮----
impl TxCompletionRing {
pub(crate) fn new(mmap: RingMmap<u64>, size: u32) -> Self {
debug_assert!(size.is_power_of_two());
⋮----
pub fn read(&mut self) -> Option<FrameOffset> {
let index = self.consumer.consume()? & self.size.saturating_sub(1);
let index = unsafe { *self.mmap.desc.add(index as usize) } as usize;
Some(FrameOffset(index))
⋮----
self.consumer.commit();
⋮----
self.consumer.sync(commit);
⋮----
pub struct RxFillRing<F: Frame> {
⋮----
pub(crate) fn new(mmap: RingMmap<u64>, size: u32, fd: RawFd) -> Self {
⋮----
pub fn write(&mut self, frame: F) -> Result<(), io::Error> {
let Some(index) = self.producer.produce() else {
return Err(ErrorKind::StorageFull.into());
⋮----
let index = index & self.size.saturating_sub(1);
let desc = unsafe { self.mmap.desc.add(index as usize) };
⋮----
desc.write(frame.offset().0 as u64);
⋮----
Ok(())
⋮----
self.producer.commit();
⋮----
self.producer.sync(commit);
⋮----
pub struct RingMmap<T> {
⋮----
impl<T> Drop for RingMmap<T> {
fn drop(&mut self) {
⋮----
munmap(self.mmap as *mut _, self.mmap_len);
⋮----
pub(crate) unsafe fn mmap_ring<T>(
⋮----
let map_size = (offsets.desc as usize).saturating_add(size);
⋮----
mmap(
⋮----
let producer = map_addr.add(offsets.producer as usize) as *mut AtomicU32;
let consumer = map_addr.add(offsets.consumer as usize) as *mut AtomicU32;
let desc = map_addr.add(offsets.desc as usize) as *mut T;
let flags = map_addr.add(offsets.flags as usize) as *mut AtomicU32;
Ok(RingMmap {
⋮----
mod test {
⋮----
fn test_ring_producer() {
⋮----
assert_eq!(ring.available(), size);
⋮----
assert_eq!(ring.produce(), Some(i));
assert_eq!(ring.available(), size - i - 1);
⋮----
assert_eq!(ring.produce(), None);
consumer.store(1, Ordering::Release);
⋮----
ring.commit();
⋮----
ring.sync(true);
assert_eq!(ring.produce(), Some(16));
⋮----
consumer.store(2, Ordering::Release);
⋮----
assert_eq!(ring.produce(), Some(17));
⋮----
fn test_ring_producer_wrap_around() {
⋮----
assert_eq!(ring.available(), 0);
consumer.fetch_add(1, Ordering::Release);
⋮----
assert_eq!(ring.produce(), Some(u32::MAX - 1));
⋮----
assert_eq!(ring.produce(), Some(u32::MAX));
⋮----
assert_eq!(ring.produce(), Some(0));
⋮----
assert_eq!(ring.produce(), Some(1));
⋮----
fn test_ring_consumer() {
⋮----
producer.store(1, Ordering::Release);
⋮----
assert_eq!(ring.available(), 1);
producer.store(size, Ordering::Release);
⋮----
assert_eq!(ring.consume(), Some(i));
⋮----
assert_eq!(ring.consume(), None);
⋮----
fn test_ring_consumer_wrap_around() {
⋮----
producer.fetch_add(1, Ordering::Release);
⋮----
assert_eq!(ring.consume(), Some(u32::MAX - 1));
producer.store(0, Ordering::Release);
⋮----
assert_eq!(ring.consume(), Some(u32::MAX));
⋮----
assert_eq!(ring.consume(), Some(0));
⋮----
assert_eq!(ring.consume(), Some(1));

================
File: xdp/src/lib.rs
================
pub mod device;
⋮----
pub mod netlink;
⋮----
pub mod packet;
⋮----
mod program;
⋮----
pub mod route;
⋮----
pub mod socket;
⋮----
pub mod tx_loop;
⋮----
pub mod umem;
⋮----
pub use program::load_xdp_program;
use std::io;
⋮----
pub fn set_cpu_affinity(cpus: impl IntoIterator<Item = usize>) -> Result<(), io::Error> {
⋮----
Err(io::Error::last_os_error())
⋮----
Ok(())
⋮----
pub fn set_cpu_affinity(_cpus: impl IntoIterator<Item = usize>) -> Result<(), io::Error> {
unimplemented!()

================
File: xdp/src/netlink.rs
================
const NLA_HDR_LEN: usize = align_to(mem::size_of::<nlattr>(), NLA_ALIGNTO as usize);
pub struct NetlinkSocket {
⋮----
impl NetlinkSocket {
fn open() -> Result<Self, io::Error> {
let sock = unsafe { socket(AF_NETLINK, SOCK_RAW, NETLINK_ROUTE) };
⋮----
return Err(io::Error::last_os_error());
⋮----
setsockopt(
sock.as_raw_fd(),
⋮----
getsockname(
⋮----
Ok(Self {
⋮----
fn send(&self, msg: &[u8]) -> Result<(), io::Error> {
⋮----
send(
self.sock.as_raw_fd(),
msg.as_ptr() as *const _,
msg.len(),
⋮----
Ok(())
⋮----
fn recv(&self) -> Result<Vec<NetlinkMessage>, io::Error> {
⋮----
// Safety: libc wrapper
⋮----
recv(
⋮----
buf.as_mut_ptr() as *mut _,
buf.len(),
⋮----
offset += align_to(message.header.nlmsg_len as usize, NLMSG_ALIGNTO as usize);
⋮----
let err = message.error.unwrap();
⋮----
// this is an ACK
⋮----
return Err(io::Error::from_raw_os_error(-err.error));
⋮----
_ => messages.push(message),
⋮----
Ok(messages)
⋮----
pub struct NetlinkMessage {
⋮----
impl NetlinkMessage {
fn read(buf: &[u8]) -> Result<Self, io::Error> {
if mem::size_of::<nlmsghdr>() > buf.len() {
return Err(io::Error::other("buffer smaller than nlmsghdr"));
⋮----
let header = unsafe { ptr::read_unaligned(buf.as_ptr() as *const nlmsghdr) };
⋮----
if msg_len < mem::size_of::<nlmsghdr>() || msg_len > buf.len() {
return Err(io::Error::other("invalid nlmsg_len"));
⋮----
let data_offset = align_to(mem::size_of::<nlmsghdr>(), NLMSG_ALIGNTO as usize);
if data_offset >= buf.len() {
return Err(io::Error::other("need more data"));
⋮----
if data_offset + mem::size_of::<nlmsgerr>() > buf.len() {
return Err(io::Error::other(
⋮----
Some(unsafe {
ptr::read_unaligned(buf[data_offset..].as_ptr() as *const nlmsgerr)
⋮----
(buf[data_offset..msg_len].to_vec(), None)
⋮----
const fn align_to(v: usize, align: usize) -> usize {
⋮----
struct NlAttrsIterator<'a> {
⋮----
fn new(attrs: &'a [u8]) -> Self {
⋮----
impl<'a> Iterator for NlAttrsIterator<'a> {
type Item = Result<NlAttr<'a>, NlAttrError>;
fn next(&mut self) -> Option<Self::Item> {
⋮----
if buf.is_empty() {
⋮----
if NLA_HDR_LEN > buf.len() {
self.offset = buf.len();
return Some(Err(NlAttrError::InvalidBufferLength {
size: buf.len(),
⋮----
let attr = unsafe { ptr::read_unaligned(buf.as_ptr() as *const nlattr) };
⋮----
let align_len = align_to(len, NLA_ALIGNTO as usize);
⋮----
return Some(Err(NlAttrError::InvalidHeaderLength(len)));
⋮----
if align_len > buf.len() {
⋮----
Some(Ok(NlAttr { header: attr, data }))
⋮----
fn parse_attrs(buf: &[u8]) -> Result<HashMap<u16, NlAttr<'_>>, NlAttrError> {
⋮----
attrs.insert(attr.header.nla_type & NLA_TYPE_MASK as u16, attr);
⋮----
Ok(attrs)
⋮----
struct NlAttr<'a> {
⋮----
enum NlAttrError {
⋮----
fn from(e: NlAttrError) -> Self {
⋮----
fn bytes_of<T>(val: &T) -> &[u8] {
⋮----
unsafe { slice::from_raw_parts(slice::from_ref(val).as_ptr().cast(), size) }
⋮----
pub struct MacAddress(pub [u8; 6]);
impl MacAddress {
pub fn new(bytes: [u8; 6]) -> Self {
MacAddress(bytes)
⋮----
pub fn as_bytes(&self) -> &[u8; 6] {
⋮----
fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
write!(
⋮----
pub struct NeighborEntry {
⋮----
impl NeighborEntry {
pub fn is_valid(&self) -> bool {
self.lladdr.is_some() && (self.state & (NUD_REACHABLE | NUD_PERMANENT | NUD_STALE)) != 0
⋮----
struct ndmsg {
⋮----
struct NeighRequest {
⋮----
pub fn netlink_get_neighbors(
⋮----
sock.send(&bytes_of(&req)[..req.header.nlmsg_len as usize])?;
⋮----
for msg in sock.recv()? {
⋮----
if msg.data.len() < mem::size_of::<ndmsg>() {
⋮----
let Some(neighbor) = parse_rtm_newneigh(msg, if_index) else {
⋮----
neighbors.push(neighbor);
⋮----
Ok(neighbors)
⋮----
pub fn parse_rtm_newneigh(msg: NetlinkMessage, if_index: Option<i32>) -> Option<NeighborEntry> {
let nd_msg = unsafe { ptr::read_unaligned(msg.data.as_ptr() as *const ndmsg) };
⋮----
let Ok(attrs) = parse_attrs(&msg.data[mem::size_of::<ndmsg>()..]) else {
⋮----
if let Some(dst_attr) = attrs.get(&NDA_DST) {
neighbor.destination = parse_ip_address(dst_attr.data, nd_msg.ndm_family);
⋮----
if let Some(lladdr_attr) = attrs.get(&NDA_LLADDR) {
if lladdr_attr.data.len() >= 6 {
⋮----
mac.copy_from_slice(&lladdr_attr.data[0..6]);
neighbor.lladdr = Some(MacAddress(mac));
⋮----
Some(neighbor)
⋮----
pub struct RouteEntry {
⋮----
struct rtmsg {
⋮----
struct RouteRequest {
⋮----
fn parse_ip_address(data: &[u8], family: u8) -> Option<IpAddr> {
⋮----
AF_INET if data.len() == 4 => Some(IpAddr::V4(Ipv4Addr::new(
⋮----
AF_INET6 if data.len() == 16 => {
⋮----
Some(IpAddr::V6(Ipv6Addr::from(segments)))
⋮----
pub fn netlink_get_routes(family: u8) -> Result<Vec<RouteEntry>, io::Error> {
⋮----
if msg.data.len() < mem::size_of::<rtmsg>() {
⋮----
let Some(route) = parse_rtm_newroute(msg) else {
⋮----
routes.push(route);
⋮----
Ok(routes)
⋮----
pub fn parse_rtm_newroute(msg: NetlinkMessage) -> Option<RouteEntry> {
let rt_msg = unsafe { ptr::read_unaligned(msg.data.as_ptr() as *const rtmsg) };
let Ok(attrs) = parse_attrs(&msg.data[mem::size_of::<rtmsg>()..]) else {
⋮----
if let Some(dst_attr) = attrs.get(&RTA_DST) {
route.destination = parse_ip_address(dst_attr.data, rt_msg.rtm_family);
⋮----
if let Some(gateway_attr) = attrs.get(&RTA_GATEWAY) {
route.gateway = parse_ip_address(gateway_attr.data, rt_msg.rtm_family);
⋮----
data.get(..4)
.map(|data| u32::from_ne_bytes([data[0], data[1], data[2], data[3]]))
⋮----
if let Some(oif_attr) = attrs.get(&RTA_OIF) {
route.out_if_index = u32_from_ne_bytes(oif_attr.data).map(|i| i as i32);
⋮----
if let Some(iif_attr) = attrs.get(&RTA_IIF) {
route.in_if_index = u32_from_ne_bytes(iif_attr.data).map(|i| i as i32);
⋮----
if let Some(priority_attr) = attrs.get(&RTA_PRIORITY) {
route.priority = u32_from_ne_bytes(priority_attr.data);
⋮----
if let Some(table_attr) = attrs.get(&RTA_TABLE) {
route.table = u32_from_ne_bytes(table_attr.data);
⋮----
if let Some(prefsrc_attr) = attrs.get(&RTA_PREFSRC) {
route.pref_src = parse_ip_address(prefsrc_attr.data, rt_msg.rtm_family);
⋮----
Some(route)
⋮----
pub fn netlink_get_default_gateway(family: u8) -> Result<Option<RouteEntry>, io::Error> {
let routes = netlink_get_routes(family)?;
⋮----
(Some(IpAddr::V4(addr)), AF_INET) => addr.is_unspecified() && route.dst_len == 0,
(Some(IpAddr::V6(addr)), AF_INET6) => addr.is_unspecified() && route.dst_len == 0,
⋮----
if is_default_destination && route.gateway.is_some() {
return Ok(Some(route));
⋮----
Ok(None)

================
File: xdp/src/packet.rs
================
pub fn write_eth_header(packet: &mut [u8], src_mac: &[u8; 6], dst_mac: &[u8; 6]) {
packet[0..6].copy_from_slice(dst_mac);
packet[6..12].copy_from_slice(src_mac);
packet[12..14].copy_from_slice(&(ETH_P_IP as u16).to_be_bytes());
⋮----
pub fn write_ip_header(packet: &mut [u8], src_ip: &Ipv4Addr, dst_ip: &Ipv4Addr, udp_len: u16) {
⋮----
packet[2..4].copy_from_slice(&(total_len as u16).to_be_bytes());
packet[4..6].copy_from_slice(&0u16.to_be_bytes());
packet[6..8].copy_from_slice(&0u16.to_be_bytes());
⋮----
packet[10..12].copy_from_slice(&0u16.to_be_bytes());
packet[12..16].copy_from_slice(&src_ip.octets());
packet[16..20].copy_from_slice(&dst_ip.octets());
let checksum = calculate_ip_checksum(&packet[..IP_HEADER_SIZE]);
packet[10..12].copy_from_slice(&checksum.to_be_bytes());
⋮----
pub fn write_udp_header(
⋮----
packet[0..2].copy_from_slice(&src_port.to_be_bytes());
packet[2..4].copy_from_slice(&dst_port.to_be_bytes());
packet[4..6].copy_from_slice(&(udp_len as u16).to_be_bytes());
⋮----
let checksum = calculate_udp_checksum(&packet[..udp_len], src_ip, dst_ip);
packet[6..8].copy_from_slice(&checksum.to_be_bytes());
⋮----
fn calculate_udp_checksum(udp_packet: &[u8], src_ip: &Ipv4Addr, dst_ip: &Ipv4Addr) -> u16 {
let udp_len = udp_packet.len();
⋮----
let src_ip = src_ip.octets();
let dst_ip = dst_ip.octets();
⋮----
fn calculate_ip_checksum(header: &[u8]) -> u16 {
⋮----
for i in 0..header.len() / 2 {
⋮----
if header.len() % 2 == 1 {
sum += (header[header.len() - 1] as u32) << 8;

================
File: xdp/src/program.rs
================
macro_rules! write_fields {
⋮----
pub fn load_xdp_program(dev: &NetworkDevice) -> Result<Ebpf, Box<dyn std::error::Error>> {
⋮----
let broken_frags = dev.driver()? == "i40e";
⋮----
loader.set_global("AGAVE_XDP_DROP_MULTI_FRAGS", &1u8, true);
loader.load(&agave_xdp_ebpf::AGAVE_XDP_EBPF_PROGRAM)
⋮----
loader.load(&generate_xdp_elf())
⋮----
let p: &mut Xdp = ebpf.program_mut("agave_xdp").unwrap().try_into().unwrap();
p.load()?;
p.attach_to_if_index(dev.if_index(), aya::programs::xdp::XdpFlags::DRV_MODE)?;
Ok(ebpf)
⋮----
fn generate_xdp_elf() -> Vec<u8> {
let mut buffer = vec![0u8; 4096];
⋮----
cursor.set_position(xdp_off);
cursor.write_all(XDP_PROG).unwrap();
let xdp_size = cursor.position() - xdp_off;
let strtab_off = cursor.position();
cursor.write_all(STRTAB).unwrap();
let strtab_size = cursor.position() - strtab_off;
let symtab_off = align_cursor(&mut cursor, 8);
write_symbol(&mut cursor, 0, 0, 0, 0, 0, 0).unwrap();
write_symbol(
⋮----
XDP_PROG.len() as u64,
⋮----
.unwrap();
let symtab_size = cursor.position() - symtab_off;
let shdrs_off = align_cursor(&mut cursor, 8);
write_section_headers(
⋮----
cursor.set_position(0);
write_elf_header(&mut cursor, shdrs_off, SECTIONS, STRTAB_INDEX).unwrap();
⋮----
fn align_cursor(cursor: &mut Cursor<&mut Vec<u8>>, alignment: usize) -> u64 {
let pos = cursor.position() as usize;
⋮----
cursor.set_position((pos + padding) as u64);
cursor.position()
⋮----
fn write_elf_header(
⋮----
header[40..48].copy_from_slice(&sh_offset.to_le_bytes());
header[60..62].copy_from_slice(&sh_num.to_le_bytes());
header[62..64].copy_from_slice(&sh_strndx.to_le_bytes());
w.write_all(&header)
⋮----
fn write_section_header(
⋮----
write_fields!(w, name, type_, flags, addr, offset, size, link, info, addralign, entsize);
Ok(())
⋮----
fn write_symbol(
⋮----
write_fields!(
⋮----
fn write_section_headers(
⋮----
write_section_header(w, 0, SHT_NULL, 0, 0, 0, 0, 0, 0, 0, 0)?;
write_section_header(w, STRTAB_XDP_OFF, SHT_PROGBITS, SHF_ALLOC | SHF_EXECINSTR, 0, xdp_off, xdp_size, 0, 0, 0, 0)?;
write_section_header(w, STRTAB_STRTAB_OFF, SHT_STRTAB, 0, 0, strtab_off, strtab_size, 0, 0, 0, 0)?;
write_section_header(w, STRTAB_SYMTAB_OFF, SHT_SYMTAB, 0, 0, symtab_off, symtab_size, 2, 1, 0, 0)?;

================
File: xdp/src/route.rs
================
pub enum RouteError {
⋮----
pub struct NextHop {
⋮----
fn lookup_route(routes: &[RouteEntry], dest: IpAddr) -> Option<&RouteEntry> {
⋮----
for route in routes.iter().filter(|r| r.family == family) {
⋮----
if best_match.is_none() {
best_match = Some((route, 0));
⋮----
if !is_ipv4_match(dest_addr, route_addr, prefix_len) {
⋮----
if best_match.is_none() || prefix_len > best_match.unwrap().1 {
best_match = Some((route, prefix_len));
⋮----
if !is_ipv6_match(dest_addr, route_addr, prefix_len) {
⋮----
best_match.map(|(route, _)| route)
⋮----
fn is_ipv4_match(addr: Ipv4Addr, network: Ipv4Addr, prefix_len: u8) -> bool {
⋮----
let mask = 0xFFFFFFFF << 32u32.saturating_sub(prefix_len as u32);
⋮----
fn is_ipv6_match(addr: Ipv6Addr, network: Ipv6Addr, prefix_len: u8) -> bool {
⋮----
let addr_segments = addr.segments();
let network_segments = network.segments();
⋮----
if let Some(remaining_bits) = prefix_len.checked_rem(16).filter(|&b| b != 0) {
let mask = 0xFFFF_u16 << 16u16.saturating_sub(remaining_bits as u16);
⋮----
pub struct Router {
⋮----
impl Router {
pub fn new() -> Result<Self, io::Error> {
Ok(Self {
⋮----
routes: netlink_get_routes(AF_INET as u8)?,
⋮----
pub fn default(&self) -> Result<NextHop, RouteError> {
⋮----
.iter()
.find(|r| r.destination.is_none())
.ok_or(RouteError::NoRouteFound(IpAddr::V4(Ipv4Addr::UNSPECIFIED)))?;
⋮----
.ok_or(RouteError::MissingOutputInterface)? as u32;
⋮----
let mac_addr = self.arp_table.lookup(next_hop_ip).cloned();
Ok(NextHop {
⋮----
pub fn route(&self, dest_ip: IpAddr) -> Result<NextHop, RouteError> {
let route = lookup_route(&self.routes, dest_ip).ok_or(RouteError::NoRouteFound(dest_ip))?;
⋮----
struct ArpTable {
⋮----
impl ArpTable {
⋮----
let neighbors = netlink_get_neighbors(None, AF_INET as u8)?;
Ok(Self { neighbors })
⋮----
pub fn lookup(&self, ip: IpAddr) -> Option<&MacAddress> {
⋮----
.find(|n| n.destination == Some(ip))
.and_then(|n| n.lladdr.as_ref())
⋮----
mod tests {
⋮----
fn test_ipv4_match() {
assert!(is_ipv4_match(
⋮----
assert!(!is_ipv4_match(
⋮----
fn test_ipv6_match() {
assert!(is_ipv6_match(
⋮----
assert!(!is_ipv6_match(
⋮----
fn test_router() {
let router = Router::new().unwrap();
let next_hop = router.route("1.1.1.1".parse().unwrap()).unwrap();
eprintln!("{next_hop:?}");

================
File: xdp/src/socket.rs
================
pub struct Socket<U: Umem> {
⋮----
pub fn new(
⋮----
let fd = socket(AF_XDP, SOCK_RAW, 0);
⋮----
return Err(io::Error::last_os_error());
⋮----
addr: umem.as_ptr() as u64,
len: umem.len() as u64,
chunk_size: umem.frame_size() as u32,
⋮----
if setsockopt(
fd.as_raw_fd(),
⋮----
if getsockopt(
⋮----
mmap_ring(
⋮----
tx_completion_ring_size.saturating_mul(mem::size_of::<u64>()),
⋮----
rx_fill_ring_size.saturating_mul(mem::size_of::<u64>()),
⋮----
let Some(frame) = umem.reserve() else {
return Err(io::Error::other("Failed to reserve frame for RX fill ring"));
⋮----
rx_fill_ring.write(frame)?;
⋮----
rx_fill_ring.commit();
⋮----
let tx_ring = Some(TxRing::new(
⋮----
tx_ring_size.saturating_mul(mem::size_of::<XdpDesc>()),
⋮----
Some(RxRing::new(
⋮----
rx_ring_size.saturating_mul(mem::size_of::<XdpDesc>()),
⋮----
sxdp_ifindex: dev_queue.if_index(),
sxdp_queue_id: dev_queue.id().0 as u32,
⋮----
if bind(
⋮----
Ok((
⋮----
pub fn tx(
⋮----
.ring_sizes()
.ok_or_else(|| io::Error::other("zero copy requires a set ring size"))?
⋮----
Ok((socket, tx))
⋮----
pub fn rx(
⋮----
Ok((socket, rx))
⋮----
pub fn queue(&self) -> &DeviceQueue {
⋮----
pub fn umem(&mut self) -> &mut U {
⋮----
impl<U: Umem> AsFd for Socket<U> {
fn as_fd(&self) -> BorrowedFd<'_> {
self.fd.as_fd()
⋮----
pub struct Tx<F: Frame> {
⋮----
pub struct Rx<F: Frame> {
⋮----
pub struct TxRing<F: Frame> {
⋮----
pub struct RingFull<F: Frame>(pub F);
⋮----
fn new(mmap: RingMmap<XdpDesc>, size: u32, fd: RawFd) -> Self {
debug_assert!(size.is_power_of_two());
⋮----
pub fn write(&mut self, frame: F, options: u32) -> Result<(), RingFull<F>> {
let Some(index) = self.producer.produce() else {
return Err(RingFull(frame));
⋮----
let index = index & self.size.saturating_sub(1);
⋮----
let desc = self.mmap.desc.add(index as usize);
desc.write(XdpDesc {
addr: frame.offset().0 as u64,
len: frame.len() as u32,
⋮----
Ok(())
⋮----
pub fn needs_wakeup(&self) -> bool {
unsafe { (*self.mmap.flags).load(Ordering::Relaxed) & XDP_RING_NEED_WAKEUP != 0 }
⋮----
pub fn wake(&self) -> Result<u64, io::Error> {
let result = unsafe { sendto(self.fd, ptr::null(), 0, libc::MSG_DONTWAIT, ptr::null(), 0) };
⋮----
Ok(result as u64)
⋮----
pub fn capacity(&self) -> usize {
⋮----
pub fn available(&self) -> usize {
self.producer.available() as usize
⋮----
pub fn commit(&mut self) {
self.producer.commit();
⋮----
pub fn sync(&mut self, commit: bool) {
self.producer.sync(commit);
⋮----
pub struct RxRing {
⋮----
impl RxRing {
⋮----
self.consumer.available() as usize
⋮----
self.consumer.commit();
⋮----
self.consumer.sync(commit);

================
File: xdp/src/tx_loop.rs
================
pub fn tx_loop<T: AsRef<[u8]>, A: AsRef<[SocketAddr]>>(
⋮----
set_cpu_affinity([cpu_id]).unwrap();
let src_mac = src_mac.unwrap_or_else(|| {
dev.mac_addr()
.expect("no src_mac provided, device must have a MAC address")
⋮----
let src_ip = src_ip.unwrap_or_else(|| {
dev.ipv4_addr()
.expect("no src_ip provided, device must have an IPv4 address")
⋮----
let frame_size = unsafe { sysconf(_SC_PAGESIZE) } as usize;
⋮----
.open_queue(queue_id)
.expect("failed to open queue for AF_XDP socket");
⋮----
} = queue.ring_sizes().unwrap_or_else(|| {
⋮----
.or_else(|_| {
⋮----
.unwrap();
let umem = SliceUmem::new(&mut memory, frame_size as u32).unwrap();
⋮----
caps::raise(None, CapSet::Effective, cap).unwrap();
⋮----
panic!("failed to create AF_XDP socket on queue {queue_id:?}");
⋮----
let umem = socket.umem();
let umem_tx_capacity = umem.available();
⋮----
let mut ring = ring.unwrap();
let router = Router::new().expect("failed to create router");
⋮----
caps::drop(None, CapSet::Effective, cap).unwrap();
⋮----
match receiver.try_recv() {
⋮----
batched_packets += addrs.as_ref().len();
batched_items.push((addrs, payload));
⋮----
ring.commit();
kick(&ring);
⋮----
let mut chunk_remaining = BATCH_SIZE.min(batched_packets);
for (addrs, payload) in batched_items.drain(..) {
for addr in addrs.as_ref() {
if ring.available() == 0 || umem.available() == 0 {
⋮----
completion.sync(true);
ring.sync(false);
while let Some(frame_offset) = completion.read() {
umem.release(frame_offset);
⋮----
if ring.available() > 0 && umem.available() > 0 {
⋮----
let mut frame = umem.reserve().unwrap();
let IpAddr::V4(dst_ip) = addr.ip() else {
panic!("IPv6 not supported");
⋮----
let next_hop = router.route(addr.ip()).unwrap();
⋮----
umem.release(frame.offset());
⋮----
let len = payload.as_ref().len();
frame.set_len(PACKET_HEADER_SIZE + len);
let packet = umem.map_frame_mut(&frame);
packet[PACKET_HEADER_SIZE..][..len].copy_from_slice(payload.as_ref());
write_eth_header(packet, &src_mac.0, &dest_mac.0);
write_ip_header(
⋮----
write_udp_header(
⋮----
addr.port(),
⋮----
ring.write(frame, 0)
.map_err(|_| "ring full")
.expect("failed to write to ring");
⋮----
chunk_remaining = BATCH_SIZE.min(batched_packets);
⋮----
let _ = drop_sender.try_send((addrs, payload));
⋮----
debug_assert_eq!(batched_packets, 0);
⋮----
assert_eq!(batched_packets, 0);
while umem.available() < umem_tx_capacity || ring.available() < ring.capacity() {
⋮----
fn kick(ring: &TxRing<SliceUmemFrame<'_>>) {
if !ring.needs_wakeup() {
⋮----
if let Err(e) = ring.wake() {
kick_error(e);
⋮----
fn kick_error(e: std::io::Error) {
match e.raw_os_error() {

================
File: xdp/src/umem.rs
================
pub struct FrameOffset(pub(crate) usize);
pub trait Frame {
⋮----
fn is_empty(&self) -> bool {
self.len() == 0
⋮----
pub trait Umem {
⋮----
fn map_frame(&self, frame: &Self::Frame) -> &[u8] {
unsafe { slice::from_raw_parts(self.as_ptr().add(frame.offset().0), frame.len()) }
⋮----
fn map_frame_mut(&mut self, frame: &Self::Frame) -> &mut [u8] {
unsafe { slice::from_raw_parts_mut(self.as_mut_ptr().add(frame.offset().0), frame.len()) }
⋮----
pub struct SliceUmemFrame<'a> {
⋮----
pub fn set_len(&mut self, len: usize) {
⋮----
impl Frame for SliceUmemFrame<'_> {
fn offset(&self) -> FrameOffset {
FrameOffset(self.offset)
⋮----
fn len(&self) -> usize {
⋮----
pub struct SliceUmem<'a> {
⋮----
pub fn new(buffer: &'a mut [u8], frame_size: u32) -> Result<Self, io::Error> {
debug_assert!(frame_size.is_power_of_two());
let capacity = buffer.len() / frame_size as usize;
Ok(Self {
⋮----
pub fn capacity(&self) -> usize {
⋮----
pub fn available(&self) -> usize {
self.available_frames.len()
⋮----
impl<'a> Umem for SliceUmem<'a> {
type Frame = SliceUmemFrame<'a>;
fn as_ptr(&self) -> *const u8 {
self.buffer.as_ptr()
⋮----
fn as_mut_ptr(&mut self) -> *mut u8 {
self.buffer.as_mut_ptr()
⋮----
self.buffer.len()
⋮----
fn frame_size(&self) -> usize {
⋮----
fn reserve(&mut self) -> Option<SliceUmemFrame<'a>> {
let index = self.available_frames.pop()?;
Some(SliceUmemFrame {
⋮----
fn release(&mut self, frame: FrameOffset) {
⋮----
self.available_frames.push(index as u64);
⋮----
pub struct AllocError;
pub struct PageAlignedMemory {
⋮----
impl PageAlignedMemory {
pub fn alloc(frame_size: usize, frame_count: usize) -> Result<Self, AllocError> {
⋮----
unsafe { sysconf(_SC_PAGESIZE) as usize },
⋮----
pub fn alloc_with_page_size(
⋮----
debug_assert!(frame_count.is_power_of_two());
debug_assert!(page_size.is_power_of_two());
⋮----
return Err(AllocError);
⋮----
impl Drop for PageAlignedMemory {
fn drop(&mut self) {
⋮----
munmap(self.ptr as *mut c_void, self.len);
⋮----
impl Deref for PageAlignedMemory {
type Target = [u8];
fn deref(&self) -> &Self::Target {
⋮----
impl DerefMut for PageAlignedMemory {
fn deref_mut(&mut self) -> &mut Self::Target {

================
File: xdp/Cargo.toml
================
[package]
name = "agave-xdp"
description = "Agave XDP implementation"
version = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }
publish = true

[features]
agave-unstable-api = []

[dependencies]
crossbeam-channel = { workspace = true }
libc = { workspace = true }
log = { workspace = true }
thiserror = { workspace = true }

[target.'cfg(target_os = "linux")'.dependencies]
agave-xdp-ebpf = { workspace = true }
aya = { workspace = true }
caps = { workspace = true }

================
File: xdp-ebpf/src/bin/agave-xdp-prog.rs
================
pub fn agave_xdp(ctx: XdpContext) -> u32 {
if drop_frags() && has_frags(&ctx) {
⋮----
fn drop_frags() -> bool {
⋮----
fn has_frags(ctx: &XdpContext) -> bool {
⋮----
let linear_len = ctx.data_end() - ctx.data();
let buf_len = unsafe { bpf_xdp_get_buff_len(ctx.ctx) as usize };
⋮----
fn panic(_info: &core::panic::PanicInfo) -> ! {

================
File: xdp-ebpf/src/lib.rs
================
.len()] = unsafe {
⋮----
.as_ptr()
.cast(),

================
File: xdp-ebpf/Cargo.toml
================
[package]
name = "agave-xdp-ebpf"
version = { workspace = true }
authors = { workspace = true }
description = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }
include = ["Cargo.toml", "src/**", "README", "agave-xdp-prog"]

[[bin]]
name = "agave-xdp-prog"
path = "src/bin/agave-xdp-prog.rs"
required-features = ["ebpf"]

[features]
ebpf = []
agave-unstable-api = []

[target.'cfg(target_arch = "bpf")'.dependencies]
aya-ebpf = { workspace = true }

[target.'cfg(target_os = "linux")'.dependencies]
aya = { workspace = true }

[lints]
workspace = true

================
File: xdp-ebpf/README
================
# Overview

agave-xdp-ebpf is the eBPF XDP program loaded by Agave.

It's a lib AND bin package, where the bin package is used to build the eBPF
bytecode, and the lib package is used to bundle the eBPF bytecode in a host
crate and loaded as a regular dependency.

# Usage

To use the program you can depend on the `agave-xdp-ebpf` crate and load the
bytecode available at `agave_xdp_ebpf::AGAVE_XDP_EBPF_PROGRAM` using
`aya::Ebpf::load`.

# Building the eBPF XDP program

The eBPF program is prebuilt and saved in `./agave-xdp-prog`. This is done so
that the crate can be built from crates.io. To rebuild the program from the
monorepo root run:

    scripts/build-agave-xdp-ebpf.sh

The ebpf program must be rebuilt anytime the source changes (duh), or the
rust nightly version used by the monorepo is bumped.

# Verify the crates.io bytecode

To verify that the bytecode loaded by agave via crates.io matches the bytecode
generated by the source included in this package, from the monorepo root run:

    # This will rebuild and print whether the hashes have changed. If you haven't made any
    # modifications, the hashes must match.
    scripts/build-agave-xdp.sh

    # If the hashes match, build agave as usual and verify that the final code also matches
    scripts/elf-hash-symbol.sh target/release/agave-validator AGAVE_XDP_EBPF_PROGRAM

================
File: zk-keygen/README.md
================
# PLEASE READ: This repo no longer contains the Solana ZK-KEYGEN

The solana-zk-keygen is currently developed at <https://github.com/solana-program/zk-elgamal-proof>.

================
File: zk-sdk/README.md
================
# PLEASE READ: This repo no longer contains the Solana ZK-SDK

The solana-zk-sdk is currently developed at https://github.com/solana-program/zk-elgamal-proof.

================
File: zk-token-sdk/src/encryption/auth_encryption.rs
================
struct AuthenticatedEncryption;
impl AuthenticatedEncryption {
⋮----
fn keygen() -> AeKey {
AeKey(OsRng.gen::<[u8; AE_KEY_LEN]>())
⋮----
fn encrypt(key: &AeKey, balance: u64) -> AeCiphertext {
let mut plaintext = balance.to_le_bytes();
⋮----
let ciphertext = Aes128GcmSiv::new(&key.0.into())
.encrypt(&nonce.into(), plaintext.as_ref())
.expect("authenticated encryption");
plaintext.zeroize();
⋮----
ciphertext: ciphertext.try_into().unwrap(),
⋮----
fn decrypt(key: &AeKey, ciphertext: &AeCiphertext) -> Option<u64> {
let plaintext = Aes128GcmSiv::new(&key.0.into())
.decrypt(&ciphertext.nonce.into(), ciphertext.ciphertext.as_ref());
⋮----
let amount_bytes: [u8; 8] = plaintext.try_into().unwrap();
Some(u64::from_le_bytes(amount_bytes))
⋮----
pub struct AeKey([u8; AE_KEY_LEN]);
impl AeKey {
pub fn new_from_signer(
⋮----
pub fn seed_from_signer(
⋮----
let message = [b"AeKey", public_seed].concat();
let signature = signer.try_sign_message(&message)?;
if bool::from(signature.as_ref().ct_eq(Signature::default().as_ref())) {
return Err(SignerError::Custom("Rejecting default signature".into()));
⋮----
hasher.update(signature.as_ref());
let result = hasher.finalize();
Ok(result.to_vec())
⋮----
pub fn new_rand() -> Self {
⋮----
pub fn encrypt(&self, amount: u64) -> AeCiphertext {
⋮----
pub fn decrypt(&self, ciphertext: &AeCiphertext) -> Option<u64> {
⋮----
impl EncodableKey for AeKey {
fn read<R: Read>(reader: &mut R) -> Result<Self, Box<dyn error::Error>> {
⋮----
Ok(Self(bytes))
⋮----
fn write<W: Write>(&self, writer: &mut W) -> Result<String, Box<dyn error::Error>> {
⋮----
let json = serde_json::to_string(&bytes.to_vec())?;
writer.write_all(&json.clone().into_bytes())?;
Ok(json)
⋮----
impl SeedDerivable for AeKey {
fn from_seed(seed: &[u8]) -> Result<Self, Box<dyn error::Error>> {
⋮----
if seed.len() < MINIMUM_SEED_LEN {
return Err(AuthenticatedEncryptionError::SeedLengthTooShort.into());
⋮----
if seed.len() > MAXIMUM_SEED_LEN {
return Err(AuthenticatedEncryptionError::SeedLengthTooLong.into());
⋮----
hasher.update(seed);
⋮----
Ok(Self(result[..AE_KEY_LEN].try_into()?))
⋮----
fn from_seed_and_derivation_path(
⋮----
Err(AuthenticatedEncryptionError::DerivationMethodNotSupported.into())
⋮----
fn from_seed_phrase_and_passphrase(
⋮----
Self::from_seed(&generate_seed_from_seed_phrase_and_passphrase(
⋮----
fn from(bytes: [u8; AE_KEY_LEN]) -> Self {
Self(bytes)
⋮----
fn from(key: AeKey) -> Self {
⋮----
type Error = AuthenticatedEncryptionError;
fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
if bytes.len() != AE_KEY_LEN {
return Err(AuthenticatedEncryptionError::Deserialization);
⋮----
.try_into()
.map(Self)
.map_err(|_| AuthenticatedEncryptionError::Deserialization)
⋮----
type Nonce = [u8; NONCE_LEN];
type Ciphertext = [u8; CIPHERTEXT_LEN];
⋮----
pub struct AeCiphertext {
⋮----
impl AeCiphertext {
pub fn decrypt(&self, key: &AeKey) -> Option<u64> {
⋮----
pub fn to_bytes(&self) -> [u8; AE_CIPHERTEXT_LEN] {
⋮----
buf[..NONCE_LEN].copy_from_slice(&self.nonce);
buf[NONCE_LEN..].copy_from_slice(&self.ciphertext);
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<AeCiphertext> {
if bytes.len() != AE_CIPHERTEXT_LEN {
⋮----
let nonce = bytes[..NONCE_LEN].try_into().ok()?;
let ciphertext = bytes[NONCE_LEN..].try_into().ok()?;
Some(AeCiphertext { nonce, ciphertext })
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
write!(f, "{}", BASE64_STANDARD.encode(self.to_bytes()))
⋮----
mod tests {
⋮----
fn test_aes_encrypt_decrypt_correctness() {
⋮----
let ciphertext = key.encrypt(amount);
let decrypted_amount = ciphertext.decrypt(&key).unwrap();
assert_eq!(amount, decrypted_amount);
⋮----
fn test_aes_new() {
⋮----
assert_ne!(
⋮----
assert!(AeKey::new_from_signer(&null_signer, Pubkey::default().as_ref()).is_err());
⋮----
fn test_aes_key_from_seed() {
let good_seed = vec![0; 32];
assert!(AeKey::from_seed(&good_seed).is_ok());
let too_short_seed = vec![0; 15];
assert!(AeKey::from_seed(&too_short_seed).is_err());
let too_long_seed = vec![0; 65536];
assert!(AeKey::from_seed(&too_long_seed).is_err());
⋮----
fn test_aes_key_from() {
let key = AeKey::from_seed(&[0; 32]).unwrap();
let key_bytes: [u8; AE_KEY_LEN] = AeKey::from_seed(&[0; 32]).unwrap().into();
assert_eq!(key, AeKey::from(key_bytes));
⋮----
fn test_aes_key_try_from() {
⋮----
assert_eq!(key, AeKey::try_from(key_bytes.as_slice()).unwrap());
⋮----
fn test_aes_key_try_from_error() {
let too_many_bytes = vec![0_u8; 32];
assert!(AeKey::try_from(too_many_bytes.as_slice()).is_err());

================
File: zk-token-sdk/src/encryption/discrete_log.rs
================
use std::thread;
⋮----
pub enum DiscreteLogError {
⋮----
pub struct DiscreteLog {
⋮----
pub struct DecodePrecomputation(HashMap<[u8; RISTRETTO_POINT_LEN], u16>);
⋮----
fn decode_u32_precomputation(generator: RistrettoPoint) -> DecodePrecomputation {
⋮----
for (point, x_hi) in ristretto_iter.take(TWO16 as usize) {
let key = point.compress().to_bytes();
hashmap.insert(key, x_hi as u16);
⋮----
DecodePrecomputation(hashmap)
⋮----
include_bytes!("decode_u32_precomputation_for_G.bincode");
bincode::deserialize(DECODE_PRECOMPUTATION_FOR_G_BINCODE).unwrap_or_default()
⋮----
impl DiscreteLog {
pub fn new(generator: RistrettoPoint, target: RistrettoPoint) -> Self {
⋮----
range_bound: (TWO16 as usize).try_into().unwrap(),
⋮----
compression_batch_size: 32.try_into().unwrap(),
⋮----
pub fn num_threads(&mut self, num_threads: NonZeroUsize) -> Result<(), DiscreteLogError> {
if !num_threads.is_power_of_two() || num_threads.get() > MAX_THREAD {
return Err(DiscreteLogError::DiscreteLogThreads);
⋮----
self.num_threads = Some(num_threads);
⋮----
.checked_div(num_threads.get())
.and_then(|range_bound| range_bound.try_into().ok())
.unwrap();
self.step_point = Scalar::from(num_threads.get() as u64) * G;
Ok(())
⋮----
pub fn set_compression_batch_size(
⋮----
if compression_batch_size.get() >= TWO16 as usize {
return Err(DiscreteLogError::DiscreteLogBatchSize);
⋮----
pub fn decode_u32(self) -> Option<u64> {
⋮----
let handles = (0..num_threads.get())
.map(|i| {
⋮----
(-(&self.step_point), num_threads.get() as u64),
⋮----
.into_iter()
.map_while(|h| h.join().ok())
.find(|x| x.is_some())
.flatten()
⋮----
unreachable!()
⋮----
fn decode_range(
⋮----
.take(range_bound.get())
.chunks(compression_batch_size.get())
⋮----
.filter(|(point, index)| {
if point.is_identity() {
decoded = Some(*index);
⋮----
.unzip();
⋮----
for (point, x_lo) in batch_compressed.iter().zip(batch_indices.iter()) {
let key = point.to_bytes();
if hashmap.0.contains_key(&key) {
⋮----
decoded = Some(x_lo + TWO16 * x_hi as u64);
⋮----
struct RistrettoIterator {
⋮----
impl RistrettoIterator {
fn new(current: (RistrettoPoint, u64), step: (RistrettoPoint, u64)) -> Self {
⋮----
impl Iterator for RistrettoIterator {
type Item = (RistrettoPoint, u64);
fn next(&mut self) -> Option<Self::Item> {
⋮----
Some(r)
⋮----
mod tests {
⋮----
fn test_serialize_decode_u32_precomputation_for_G() {
let decode_u32_precomputation_for_G = decode_u32_precomputation(G);
⋮----
f.write_all(&bincode::serialize(&decode_u32_precomputation_for_G).unwrap())
⋮----
panic!("Rebuild and run this test again");
⋮----
fn test_decode_correctness() {
⋮----
let decoded = instance.decode_u32();
let computation_secs = start_computation.elapsed().as_secs_f64();
assert_eq!(amount, decoded.unwrap());
println!("single thread discrete log computation secs: {computation_secs:?} sec");
⋮----
fn test_decode_correctness_threaded() {
⋮----
instance.num_threads(4.try_into().unwrap()).unwrap();
⋮----
println!("4 thread discrete log computation: {computation_secs:?} sec");

================
File: zk-token-sdk/src/encryption/elgamal.rs
================
pub struct ElGamal;
impl ElGamal {
⋮----
fn keygen() -> ElGamalKeypair {
⋮----
s.zeroize();
⋮----
fn keygen_with_scalar(s: &Scalar) -> ElGamalKeypair {
let secret = ElGamalSecretKey(*s);
⋮----
fn encrypt<T: Into<Scalar>>(public: &ElGamalPubkey, amount: T) -> ElGamalCiphertext {
⋮----
let handle = public.decrypt_handle(&opening);
⋮----
fn encrypt_with<T: Into<Scalar>>(
⋮----
let handle = public.decrypt_handle(opening);
⋮----
pub fn encode<T: Into<Scalar>>(amount: T) -> ElGamalCiphertext {
⋮----
let handle = DecryptHandle(RistrettoPoint::identity());
⋮----
fn decrypt(secret: &ElGamalSecretKey, ciphertext: &ElGamalCiphertext) -> DiscreteLog {
⋮----
ciphertext.commitment.get_point() - &(&secret.0 * &ciphertext.handle.0),
⋮----
fn decrypt_u32(secret: &ElGamalSecretKey, ciphertext: &ElGamalCiphertext) -> Option<u64> {
⋮----
discrete_log_instance.decode_u32()
⋮----
pub struct ElGamalKeypair {
⋮----
impl ElGamalKeypair {
pub fn new_for_tests(public: ElGamalPubkey, secret: ElGamalSecretKey) -> Self {
⋮----
pub fn new_from_signer(
⋮----
Ok(ElGamalKeypair { public, secret })
⋮----
pub fn new_rand() -> Self {
⋮----
pub fn pubkey(&self) -> &ElGamalPubkey {
⋮----
pub fn secret(&self) -> &ElGamalSecretKey {
⋮----
pub fn to_bytes(&self) -> [u8; ELGAMAL_KEYPAIR_LEN] {
⋮----
bytes[..ELGAMAL_PUBKEY_LEN].copy_from_slice(&self.public.to_bytes());
bytes[ELGAMAL_PUBKEY_LEN..].copy_from_slice(self.secret.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<Self> {
if bytes.len() != ELGAMAL_KEYPAIR_LEN {
⋮----
Some(Self {
⋮----
secret: ElGamalSecretKey::from_bytes(bytes[ELGAMAL_PUBKEY_LEN..].try_into().ok()?)?,
⋮----
pub fn read_json<R: Read>(reader: &mut R) -> Result<Self, Box<dyn error::Error>> {
⋮----
Self::try_from(bytes.as_slice())
.ok()
.ok_or_else(|| std::io::Error::other("Invalid ElGamalKeypair").into())
⋮----
pub fn read_json_file<F: AsRef<Path>>(path: F) -> Result<Self, Box<dyn error::Error>> {
⋮----
pub fn write_json<W: Write>(&self, writer: &mut W) -> Result<String, Box<dyn error::Error>> {
⋮----
serde_json::to_string(&Into::<[u8; ELGAMAL_KEYPAIR_LEN]>::into(self).as_slice())?;
writer.write_all(&json.clone().into_bytes())?;
Ok(json)
⋮----
pub fn write_json_file<F: AsRef<Path>>(
⋮----
self.write_to_file(outfile)
⋮----
impl EncodableKey for ElGamalKeypair {
fn read<R: Read>(reader: &mut R) -> Result<Self, Box<dyn error::Error>> {
⋮----
fn write<W: Write>(&self, writer: &mut W) -> Result<String, Box<dyn error::Error>> {
self.write_json(writer)
⋮----
type Error = ElGamalError;
fn try_from(bytes: &[u8]) -> Result<Self, Self::Error> {
⋮----
return Err(ElGamalError::KeypairDeserialization);
⋮----
Ok(Self {
⋮----
fn from(keypair: ElGamalKeypair) -> Self {
⋮----
.copy_from_slice(&Into::<[u8; ELGAMAL_PUBKEY_LEN]>::into(keypair.public));
bytes[ELGAMAL_PUBKEY_LEN..].copy_from_slice(keypair.secret.as_bytes());
⋮----
fn from(keypair: &ElGamalKeypair) -> Self {
⋮----
impl SeedDerivable for ElGamalKeypair {
fn from_seed(seed: &[u8]) -> Result<Self, Box<dyn error::Error>> {
⋮----
fn from_seed_and_derivation_path(
⋮----
Err(ElGamalError::DerivationMethodNotSupported.into())
⋮----
fn from_seed_phrase_and_passphrase(
⋮----
Self::from_seed(&generate_seed_from_seed_phrase_and_passphrase(
⋮----
impl EncodableKeypair for ElGamalKeypair {
type Pubkey = ElGamalPubkey;
fn encodable_pubkey(&self) -> Self::Pubkey {
⋮----
pub struct ElGamalPubkey(RistrettoPoint);
impl ElGamalPubkey {
⋮----
pub fn new(secret: &ElGamalSecretKey) -> Self {
⋮----
assert_ne!(s, &Scalar::ZERO);
ElGamalPubkey(s.invert() * &(*H))
⋮----
pub fn get_point(&self) -> &RistrettoPoint {
⋮----
pub fn to_bytes(&self) -> [u8; ELGAMAL_PUBKEY_LEN] {
self.0.compress().to_bytes()
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<ElGamalPubkey> {
if bytes.len() != ELGAMAL_PUBKEY_LEN {
⋮----
compressed_ristretto.decompress().map(ElGamalPubkey)
⋮----
pub fn encrypt<T: Into<Scalar>>(&self, amount: T) -> ElGamalCiphertext {
⋮----
pub fn encrypt_with<T: Into<Scalar>>(
⋮----
pub fn decrypt_handle(self, opening: &PedersenOpening) -> DecryptHandle {
⋮----
impl EncodableKey for ElGamalPubkey {
⋮----
.ok_or_else(|| std::io::Error::other("Invalid ElGamalPubkey").into())
⋮----
let json = serde_json::to_string(&bytes.to_vec())?;
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
write!(
⋮----
return Err(ElGamalError::PubkeyDeserialization);
⋮----
Ok(ElGamalPubkey(
⋮----
.decompress()
.ok_or(ElGamalError::PubkeyDeserialization)?,
⋮----
fn from(pubkey: ElGamalPubkey) -> Self {
pubkey.0.compress().to_bytes()
⋮----
fn from(pubkey: &ElGamalPubkey) -> Self {
⋮----
pub struct ElGamalSecretKey(Scalar);
impl ElGamalSecretKey {
⋮----
Ok(key)
⋮----
pub fn seed_from_signer(
⋮----
let message = [b"ElGamalSecretKey", public_seed].concat();
let signature = signer.try_sign_message(&message)?;
if bool::from(signature.as_ref().ct_eq(Signature::default().as_ref())) {
return Err(SignerError::Custom("Rejecting default signatures".into()));
⋮----
hasher.update(signature.as_ref());
let result = hasher.finalize();
Ok(result.to_vec())
⋮----
ElGamalSecretKey(Scalar::random(&mut OsRng))
⋮----
pub fn from_seed(seed: &[u8]) -> Result<Self, ElGamalError> {
⋮----
if seed.len() < MINIMUM_SEED_LEN {
return Err(ElGamalError::SeedLengthTooShort);
⋮----
if seed.len() > MAXIMUM_SEED_LEN {
return Err(ElGamalError::SeedLengthTooLong);
⋮----
Ok(ElGamalSecretKey(Scalar::hash_from_bytes::<Sha3_512>(seed)))
⋮----
pub fn get_scalar(&self) -> &Scalar {
⋮----
pub fn decrypt(&self, ciphertext: &ElGamalCiphertext) -> DiscreteLog {
⋮----
pub fn decrypt_u32(&self, ciphertext: &ElGamalCiphertext) -> Option<u64> {
⋮----
pub fn as_bytes(&self) -> &[u8; ELGAMAL_SECRET_KEY_LEN] {
self.0.as_bytes()
⋮----
pub fn to_bytes(&self) -> [u8; ELGAMAL_SECRET_KEY_LEN] {
self.0.to_bytes()
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<ElGamalSecretKey> {
match bytes.try_into() {
⋮----
.map(ElGamalSecretKey)
.into(),
⋮----
impl EncodableKey for ElGamalSecretKey {
⋮----
.ok_or_else(|| std::io::Error::other("Invalid ElGamalSecretKey").into())
⋮----
impl SeedDerivable for ElGamalSecretKey {
⋮----
let key = Self::from_seed(&generate_seed_from_seed_phrase_and_passphrase(
⋮----
fn from(scalar: Scalar) -> ElGamalSecretKey {
ElGamalSecretKey(scalar)
⋮----
Ok(bytes) => Ok(ElGamalSecretKey::from(
⋮----
.into_option()
.ok_or(ElGamalError::SecretKeyDeserialization)?,
⋮----
_ => Err(ElGamalError::SecretKeyDeserialization),
⋮----
fn from(secret_key: ElGamalSecretKey) -> Self {
secret_key.0.to_bytes()
⋮----
fn from(secret_key: &ElGamalSecretKey) -> Self {
⋮----
impl Eq for ElGamalSecretKey {}
impl PartialEq for ElGamalSecretKey {
fn eq(&self, other: &Self) -> bool {
self.ct_eq(other).unwrap_u8() == 1u8
⋮----
impl ConstantTimeEq for ElGamalSecretKey {
fn ct_eq(&self, other: &Self) -> Choice {
self.0.ct_eq(&other.0)
⋮----
pub struct ElGamalCiphertext {
⋮----
impl ElGamalCiphertext {
pub fn add_amount<T: Into<Scalar>>(&self, amount: T) -> Self {
let point = amount.into() * &G;
⋮----
pub fn subtract_amount<T: Into<Scalar>>(&self, amount: T) -> Self {
⋮----
pub fn to_bytes(&self) -> [u8; ELGAMAL_CIPHERTEXT_LEN] {
⋮----
bytes[..PEDERSEN_COMMITMENT_LEN].copy_from_slice(&self.commitment.to_bytes());
bytes[PEDERSEN_COMMITMENT_LEN..].copy_from_slice(&self.handle.to_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<ElGamalCiphertext> {
if bytes.len() != ELGAMAL_CIPHERTEXT_LEN {
⋮----
Some(ElGamalCiphertext {
⋮----
pub fn decrypt(&self, secret: &ElGamalSecretKey) -> DiscreteLog {
⋮----
pub fn decrypt_u32(&self, secret: &ElGamalSecretKey) -> Option<u64> {
⋮----
write!(f, "{}", BASE64_STANDARD.encode(self.to_bytes()))
⋮----
type Output = ElGamalCiphertext;
fn add(self, ciphertext: &'b ElGamalCiphertext) -> ElGamalCiphertext {
⋮----
define_add_variants!(
⋮----
fn sub(self, ciphertext: &'b ElGamalCiphertext) -> ElGamalCiphertext {
⋮----
define_sub_variants!(
⋮----
fn mul(self, scalar: &'b Scalar) -> ElGamalCiphertext {
⋮----
define_mul_variants!(
⋮----
fn mul(self, ciphertext: &'b ElGamalCiphertext) -> ElGamalCiphertext {
⋮----
pub struct DecryptHandle(RistrettoPoint);
impl DecryptHandle {
pub fn new(public: &ElGamalPubkey, opening: &PedersenOpening) -> Self {
Self(&public.0 * opening.get_scalar())
⋮----
pub fn to_bytes(&self) -> [u8; DECRYPT_HANDLE_LEN] {
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<DecryptHandle> {
if bytes.len() != DECRYPT_HANDLE_LEN {
⋮----
compressed_ristretto.decompress().map(DecryptHandle)
⋮----
type Output = DecryptHandle;
fn add(self, handle: &'b DecryptHandle) -> DecryptHandle {
DecryptHandle(&self.0 + &handle.0)
⋮----
fn sub(self, handle: &'b DecryptHandle) -> DecryptHandle {
DecryptHandle(&self.0 - &handle.0)
⋮----
fn mul(self, scalar: &'b Scalar) -> DecryptHandle {
DecryptHandle(&self.0 * scalar)
⋮----
define_mul_variants!(LHS = DecryptHandle, RHS = Scalar, Output = DecryptHandle);
⋮----
fn mul(self, handle: &'b DecryptHandle) -> DecryptHandle {
DecryptHandle(self * &handle.0)
⋮----
define_mul_variants!(LHS = Scalar, RHS = DecryptHandle, Output = DecryptHandle);
⋮----
mod tests {
⋮----
fn test_encrypt_decrypt_correctness() {
⋮----
assert_eq!(expected_instance, ElGamal::decrypt(&secret, &ciphertext));
assert_eq!(57_u64, secret.decrypt_u32(&ciphertext).unwrap());
⋮----
fn test_encrypt_decrypt_correctness_multithreaded() {
⋮----
instance.num_threads(4.try_into().unwrap()).unwrap();
assert_eq!(57_u64, instance.decode_u32().unwrap());
⋮----
fn test_decrypt_handle() {
⋮----
let handle_0 = public_0.decrypt_handle(&opening);
let handle_1 = public_1.decrypt_handle(&opening);
⋮----
assert_eq!(expected_instance, secret_0.decrypt(&ciphertext_0));
assert_eq!(expected_instance, secret_1.decrypt(&ciphertext_1));
⋮----
fn test_homomorphic_addition() {
⋮----
assert_eq!(ciphertext_sum, ciphertext_0 + ciphertext_1);
⋮----
assert_eq!(ciphertext_sum, ciphertext.add_amount(amount_1));
⋮----
fn test_homomorphic_subtraction() {
⋮----
assert_eq!(ciphertext_sub, ciphertext_0 - ciphertext_1);
⋮----
assert_eq!(ciphertext_sub, ciphertext.subtract_amount(amount_1));
⋮----
fn test_homomorphic_multiplication() {
⋮----
assert_eq!(ciphertext_prod, ciphertext * scalar);
assert_eq!(ciphertext_prod, scalar * ciphertext);
⋮----
fn test_serde_ciphertext() {
⋮----
let ciphertext = public.encrypt(amount);
let encoded = bincode::serialize(&ciphertext).unwrap();
let decoded: ElGamalCiphertext = bincode::deserialize(&encoded).unwrap();
assert_eq!(ciphertext, decoded);
⋮----
fn test_serde_pubkey() {
⋮----
let encoded = bincode::serialize(&public).unwrap();
let decoded: ElGamalPubkey = bincode::deserialize(&encoded).unwrap();
assert_eq!(public, decoded);
⋮----
fn test_serde_secretkey() {
⋮----
let encoded = bincode::serialize(&secret).unwrap();
let decoded: ElGamalSecretKey = bincode::deserialize(&encoded).unwrap();
assert_eq!(secret, decoded);
⋮----
fn tmp_file_path(name: &str) -> String {
use std::env;
let out_dir = env::var("FARF_DIR").unwrap_or_else(|_| "farf".to_string());
⋮----
format!("{}/tmp/{}-{}", out_dir, name, keypair.public)
⋮----
fn test_write_keypair_file() {
let outfile = tmp_file_path("test_write_keypair_file.json");
⋮----
.write_json_file(&outfile)
.unwrap();
let keypair_vec: Vec<u8> = serde_json::from_str(&serialized_keypair).unwrap();
assert!(Path::new(&outfile).exists());
assert_eq!(
⋮----
use std::os::unix::fs::PermissionsExt;
⋮----
fs::remove_file(&outfile).unwrap();
⋮----
fn test_write_keypair_file_overwrite_ok() {
let outfile = tmp_file_path("test_write_keypair_file_overwrite_ok.json");
⋮----
fn test_write_keypair_file_truncate() {
let outfile = tmp_file_path("test_write_keypair_file_truncate.json");
⋮----
ElGamalKeypair::read_json_file(&outfile).unwrap();
⋮----
let mut f = File::create(&outfile).unwrap();
f.write_all(String::from_utf8([b'a'; 2048].to_vec()).unwrap().as_bytes())
⋮----
fn test_secret_key_new_from_signer() {
⋮----
assert_ne!(
⋮----
assert!(
⋮----
fn test_keypair_from_seed() {
let good_seed = vec![0; 32];
assert!(ElGamalKeypair::from_seed(&good_seed).is_ok());
let too_short_seed = vec![0; 31];
assert!(ElGamalKeypair::from_seed(&too_short_seed).is_err());
let too_long_seed = vec![0; 65536];
assert!(ElGamalKeypair::from_seed(&too_long_seed).is_err());
⋮----
fn test_keypair_from_seed_phrase_and_passphrase() {
⋮----
let expected_keypair = ElGamalKeypair::from_seed(seed.as_bytes()).unwrap();
⋮----
ElGamalKeypair::from_seed_phrase_and_passphrase(mnemonic.phrase(), passphrase).unwrap();
assert_eq!(keypair.public, expected_keypair.public);
⋮----
fn test_decrypt_handle_bytes() {
let handle = DecryptHandle(RistrettoPoint::default());
let encoded = handle.to_bytes();
let decoded = DecryptHandle::from_bytes(&encoded).unwrap();
assert_eq!(handle, decoded);
⋮----
fn test_serde_decrypt_handle() {
⋮----
let encoded = bincode::serialize(&handle).unwrap();
let decoded: DecryptHandle = bincode::deserialize(&encoded).unwrap();

================
File: zk-token-sdk/src/encryption/grouped_elgamal.rs
================
pub enum GroupedElGamalError {
⋮----
pub struct GroupedElGamal<const N: usize>;
⋮----
pub fn encrypt<T: Into<Scalar>>(
⋮----
.iter()
.map(|handle| handle.decrypt_handle(&opening))
⋮----
.try_into()
.unwrap();
⋮----
pub fn encrypt_with<T: Into<Scalar>>(
⋮----
.map(|handle| handle.decrypt_handle(opening))
⋮----
fn to_elgamal_ciphertext(
⋮----
.get(index)
.ok_or(GroupedElGamalError::IndexOutOfBounds)?;
Ok(ElGamalCiphertext {
⋮----
fn decrypt(
⋮----
.map(|ciphertext| ciphertext.decrypt(secret))
⋮----
fn decrypt_u32(
⋮----
.map(|ciphertext| ciphertext.decrypt_u32(secret))
⋮----
pub struct GroupedElGamalCiphertext<const N: usize> {
⋮----
pub fn decrypt(
⋮----
pub fn decrypt_u32(
⋮----
fn expected_byte_length() -> usize {
N.checked_add(1)
.and_then(|length| length.checked_mul(RISTRETTO_POINT_LEN))
.unwrap()
⋮----
pub fn to_bytes(&self) -> Vec<u8> {
⋮----
buf.extend_from_slice(&self.commitment.to_bytes());
⋮----
.for_each(|handle| buf.extend_from_slice(&handle.to_bytes()));
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<Self> {
if bytes.len() != Self::expected_byte_length() {
⋮----
let mut iter = bytes.chunks(RISTRETTO_POINT_LEN);
let commitment = PedersenCommitment::from_bytes(iter.next()?)?;
⋮----
handles.push(DecryptHandle::from_bytes(handle_bytes)?);
⋮----
Some(Self {
⋮----
handles: handles.try_into().unwrap(),
⋮----
mod tests {
⋮----
fn test_grouped_elgamal_encrypt_decrypt_correctness() {
⋮----
elgamal_keypair_0.pubkey(),
elgamal_keypair_1.pubkey(),
elgamal_keypair_2.pubkey(),
⋮----
assert_eq!(
⋮----
fn test_grouped_ciphertext_bytes() {
⋮----
let produced_bytes = grouped_ciphertext.to_bytes();
assert_eq!(produced_bytes.len(), 128);
⋮----
GroupedElGamalCiphertext::<3>::from_bytes(&produced_bytes).unwrap();

================
File: zk-token-sdk/src/encryption/mod.rs
================
pub mod auth_encryption;
pub mod discrete_log;
pub mod elgamal;
pub mod grouped_elgamal;
pub mod pedersen;

================
File: zk-token-sdk/src/encryption/pedersen.rs
================
use rand::rngs::OsRng;
⋮----
RistrettoPoint::hash_from_bytes::<Sha3_512>(RISTRETTO_BASEPOINT_COMPRESSED.as_bytes())
⋮----
pub struct Pedersen;
impl Pedersen {
⋮----
pub fn new<T: Into<Scalar>>(amount: T) -> (PedersenCommitment, PedersenOpening) {
⋮----
pub fn with<T: Into<Scalar>>(amount: T, opening: &PedersenOpening) -> PedersenCommitment {
let x: Scalar = amount.into();
let r = opening.get_scalar();
PedersenCommitment(RistrettoPoint::multiscalar_mul(&[x, *r], &[G, *H]))
⋮----
pub fn encode<T: Into<Scalar>>(amount: T) -> PedersenCommitment {
PedersenCommitment(amount.into() * &G)
⋮----
pub struct PedersenOpening(Scalar);
impl PedersenOpening {
pub fn new(scalar: Scalar) -> Self {
Self(scalar)
⋮----
pub fn get_scalar(&self) -> &Scalar {
⋮----
pub fn new_rand() -> Self {
PedersenOpening(Scalar::random(&mut OsRng))
⋮----
pub fn as_bytes(&self) -> &[u8; PEDERSEN_OPENING_LEN] {
self.0.as_bytes()
⋮----
pub fn to_bytes(&self) -> [u8; PEDERSEN_OPENING_LEN] {
self.0.to_bytes()
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<PedersenOpening> {
match bytes.try_into() {
⋮----
.map(PedersenOpening)
.into(),
⋮----
impl Eq for PedersenOpening {}
impl PartialEq for PedersenOpening {
fn eq(&self, other: &Self) -> bool {
self.ct_eq(other).unwrap_u8() == 1u8
⋮----
impl ConstantTimeEq for PedersenOpening {
fn ct_eq(&self, other: &Self) -> Choice {
self.0.ct_eq(&other.0)
⋮----
type Output = PedersenOpening;
fn add(self, opening: &'b PedersenOpening) -> PedersenOpening {
PedersenOpening(&self.0 + &opening.0)
⋮----
define_add_variants!(
⋮----
fn sub(self, opening: &'b PedersenOpening) -> PedersenOpening {
PedersenOpening(&self.0 - &opening.0)
⋮----
define_sub_variants!(
⋮----
fn mul(self, scalar: &'b Scalar) -> PedersenOpening {
PedersenOpening(&self.0 * scalar)
⋮----
define_mul_variants!(
⋮----
fn mul(self, opening: &'b PedersenOpening) -> PedersenOpening {
PedersenOpening(self * &opening.0)
⋮----
pub struct PedersenCommitment(RistrettoPoint);
impl PedersenCommitment {
pub fn new(point: RistrettoPoint) -> Self {
Self(point)
⋮----
pub fn get_point(&self) -> &RistrettoPoint {
⋮----
pub fn to_bytes(&self) -> [u8; PEDERSEN_COMMITMENT_LEN] {
self.0.compress().to_bytes()
⋮----
pub fn from_bytes(bytes: &[u8]) -> Option<PedersenCommitment> {
if bytes.len() != PEDERSEN_COMMITMENT_LEN {
⋮----
compressed_ristretto.decompress().map(PedersenCommitment)
⋮----
type Output = PedersenCommitment;
fn add(self, commitment: &'b PedersenCommitment) -> PedersenCommitment {
PedersenCommitment(&self.0 + &commitment.0)
⋮----
fn sub(self, commitment: &'b PedersenCommitment) -> PedersenCommitment {
PedersenCommitment(&self.0 - &commitment.0)
⋮----
fn mul(self, scalar: &'b Scalar) -> PedersenCommitment {
PedersenCommitment(scalar * &self.0)
⋮----
fn mul(self, commitment: &'b PedersenCommitment) -> PedersenCommitment {
PedersenCommitment(self * &commitment.0)
⋮----
mod tests {
⋮----
fn test_pedersen_homomorphic_addition() {
⋮----
let opening_0 = PedersenOpening(Scalar::random(rng));
let opening_1 = PedersenOpening(Scalar::random(rng));
⋮----
assert_eq!(commitment_addition, commitment_0 + commitment_1);
⋮----
fn test_pedersen_homomorphic_subtraction() {
⋮----
assert_eq!(commitment_addition, commitment_0 - commitment_1);
⋮----
fn test_pedersen_homomorphic_multiplication() {
⋮----
assert_eq!(commitment_addition, commitment * scalar);
assert_eq!(commitment_addition, scalar * commitment);
⋮----
fn test_pedersen_commitment_bytes() {
⋮----
let encoded = commitment.to_bytes();
let decoded = PedersenCommitment::from_bytes(&encoded).unwrap();
assert_eq!(commitment, decoded);
assert_eq!(PedersenCommitment::from_bytes(&[0; 33]), None);
⋮----
fn test_pedersen_opening_bytes() {
let opening = PedersenOpening(Scalar::random(&mut OsRng));
let encoded = opening.to_bytes();
let decoded = PedersenOpening::from_bytes(&encoded).unwrap();
assert_eq!(opening, decoded);
assert_eq!(PedersenOpening::from_bytes(&[0; 33]), None);
⋮----
fn test_serde_pedersen_commitment() {
⋮----
let encoded = bincode::serialize(&commitment).unwrap();
let decoded: PedersenCommitment = bincode::deserialize(&encoded).unwrap();
⋮----
fn test_serde_pedersen_opening() {
⋮----
let encoded = bincode::serialize(&opening).unwrap();
let decoded: PedersenOpening = bincode::deserialize(&encoded).unwrap();

================
File: zk-token-sdk/src/instruction/batched_grouped_ciphertext_validity/handles_2.rs
================
pub struct BatchedGroupedCiphertext2HandlesValidityProofData {
⋮----
pub struct BatchedGroupedCiphertext2HandlesValidityProofContext {
⋮----
impl BatchedGroupedCiphertext2HandlesValidityProofData {
pub fn new(
⋮----
let pod_destination_pubkey = pod::ElGamalPubkey(destination_pubkey.into());
let pod_auditor_pubkey = pod::ElGamalPubkey(auditor_pubkey.into());
let pod_grouped_ciphertext_lo = (*grouped_ciphertext_lo).into();
let pod_grouped_ciphertext_hi = (*grouped_ciphertext_hi).into();
⋮----
let mut transcript = context.new_transcript();
⋮----
.into();
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &BatchedGroupedCiphertext2HandlesValidityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let destination_pubkey = self.context.destination_pubkey.try_into()?;
let auditor_pubkey = self.context.auditor_pubkey.try_into()?;
⋮----
self.context.grouped_ciphertext_lo.try_into()?;
⋮----
self.context.grouped_ciphertext_hi.try_into()?;
let destination_handle_lo = grouped_ciphertext_lo.handles.first().unwrap();
let auditor_handle_lo = grouped_ciphertext_lo.handles.get(1).unwrap();
let destination_handle_hi = grouped_ciphertext_hi.handles.first().unwrap();
let auditor_handle_hi = grouped_ciphertext_hi.handles.get(1).unwrap();
let proof: BatchedGroupedCiphertext2HandlesValidityProof = self.proof.try_into()?;
⋮----
.verify(
⋮----
.map_err(|e| e.into())
⋮----
impl BatchedGroupedCiphertext2HandlesValidityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"destination-pubkey", &self.destination_pubkey);
transcript.append_pubkey(b"auditor-pubkey", &self.auditor_pubkey);
transcript.append_grouped_ciphertext_2_handles(
⋮----
mod test {
⋮----
fn test_ciphertext_validity_proof_instruction_correctness() {
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/batched_grouped_ciphertext_validity/handles_3.rs
================
pub struct BatchedGroupedCiphertext3HandlesValidityProofData {
⋮----
pub struct BatchedGroupedCiphertext3HandlesValidityProofContext {
⋮----
impl BatchedGroupedCiphertext3HandlesValidityProofData {
pub fn new(
⋮----
let pod_source_pubkey = pod::ElGamalPubkey(source_pubkey.into());
let pod_destination_pubkey = pod::ElGamalPubkey(destination_pubkey.into());
let pod_auditor_pubkey = pod::ElGamalPubkey(auditor_pubkey.into());
let pod_grouped_ciphertext_lo = (*grouped_ciphertext_lo).into();
let pod_grouped_ciphertext_hi = (*grouped_ciphertext_hi).into();
⋮----
let mut transcript = context.new_transcript();
⋮----
.into();
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &BatchedGroupedCiphertext3HandlesValidityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let source_pubkey = self.context.source_pubkey.try_into()?;
let destination_pubkey = self.context.destination_pubkey.try_into()?;
let auditor_pubkey = self.context.auditor_pubkey.try_into()?;
⋮----
self.context.grouped_ciphertext_lo.try_into()?;
⋮----
self.context.grouped_ciphertext_hi.try_into()?;
let source_handle_lo = grouped_ciphertext_lo.handles.first().unwrap();
let destination_handle_lo = grouped_ciphertext_lo.handles.get(1).unwrap();
let auditor_handle_lo = grouped_ciphertext_lo.handles.get(2).unwrap();
let source_handle_hi = grouped_ciphertext_hi.handles.first().unwrap();
let destination_handle_hi = grouped_ciphertext_hi.handles.get(1).unwrap();
let auditor_handle_hi = grouped_ciphertext_hi.handles.get(2).unwrap();
let proof: BatchedGroupedCiphertext3HandlesValidityProof = self.proof.try_into()?;
⋮----
.verify(
⋮----
.map_err(|e| e.into())
⋮----
impl BatchedGroupedCiphertext3HandlesValidityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"source-pubkey", &self.source_pubkey);
transcript.append_pubkey(b"destination-pubkey", &self.destination_pubkey);
transcript.append_pubkey(b"auditor-pubkey", &self.auditor_pubkey);
transcript.append_grouped_ciphertext_3_handles(
⋮----
mod test {
⋮----
fn test_ciphertext_validity_proof_instruction_correctness() {
⋮----
let source_pubkey = source_keypair.pubkey();
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/batched_grouped_ciphertext_validity/mod.rs
================
mod handles_2;
mod handles_3;

================
File: zk-token-sdk/src/instruction/batched_range_proof/batched_range_proof_u128.rs
================
pub struct BatchedRangeProofU128Data {
⋮----
impl BatchedRangeProofU128Data {
pub fn new(
⋮----
.iter()
.try_fold(0_usize, |acc, &x| acc.checked_add(x))
.ok_or(ProofGenerationError::IllegalAmountBitLength)?;
let expected_bit_length = usize::try_from(u128::BITS).unwrap();
⋮----
return Err(ProofGenerationError::IllegalAmountBitLength);
⋮----
let mut transcript = context.new_transcript();
⋮----
.try_into()
.map_err(|_| ProofGenerationError::ProofLength)?;
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &BatchedRangeProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let (commitments, bit_lengths) = self.context.try_into()?;
let num_commitments = commitments.len();
if num_commitments > MAX_COMMITMENTS || num_commitments != bit_lengths.len() {
return Err(ProofVerificationError::IllegalCommitmentLength);
⋮----
let mut transcript = self.context_data().new_transcript();
let proof: RangeProof = self.proof.try_into()?;
⋮----
.verify(commitments.iter().collect(), bit_lengths, &mut transcript)
.map_err(|e| e.into())
⋮----
mod test {
⋮----
fn test_batched_range_proof_u128_instruction_correctness() {
⋮----
vec![
⋮----
vec![16, 16, 16, 16, 16, 16, 16, 16],
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());
⋮----
assert_eq!(

================
File: zk-token-sdk/src/instruction/batched_range_proof/batched_range_proof_u256.rs
================
pub struct BatchedRangeProofU256Data {
⋮----
impl BatchedRangeProofU256Data {
pub fn new(
⋮----
.iter()
.any(|length| *length > MAX_SINGLE_BIT_LENGTH)
⋮----
return Err(ProofGenerationError::IllegalCommitmentLength);
⋮----
.try_fold(0_usize, |acc, &x| acc.checked_add(x))
.ok_or(ProofGenerationError::IllegalAmountBitLength)?;
⋮----
return Err(ProofGenerationError::IllegalAmountBitLength);
⋮----
let mut transcript = context.new_transcript();
⋮----
.try_into()
.map_err(|_| ProofGenerationError::ProofLength)?;
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &BatchedRangeProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let (commitments, bit_lengths) = self.context.try_into()?;
let num_commitments = commitments.len();
⋮----
return Err(ProofVerificationError::IllegalCommitmentLength);
⋮----
if num_commitments > MAX_COMMITMENTS || num_commitments != bit_lengths.len() {
⋮----
let mut transcript = self.context_data().new_transcript();
let proof: RangeProof = self.proof.try_into()?;
⋮----
.verify(commitments.iter().collect(), bit_lengths, &mut transcript)
.map_err(|e| e.into())
⋮----
mod test {
⋮----
fn test_batched_range_proof_256_instruction_correctness() {
⋮----
vec![
⋮----
vec![32, 32, 32, 32, 32, 32, 32, 32],
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());
⋮----
assert_eq!(

================
File: zk-token-sdk/src/instruction/batched_range_proof/batched_range_proof_u64.rs
================
pub struct BatchedRangeProofU64Data {
⋮----
impl BatchedRangeProofU64Data {
pub fn new(
⋮----
.iter()
.try_fold(0_usize, |acc, &x| acc.checked_add(x))
.ok_or(ProofGenerationError::IllegalAmountBitLength)?;
let expected_bit_length = usize::try_from(u64::BITS).unwrap();
⋮----
return Err(ProofGenerationError::IllegalAmountBitLength);
⋮----
let mut transcript = context.new_transcript();
⋮----
.try_into()
.map_err(|_| ProofGenerationError::ProofLength)?;
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &BatchedRangeProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let (commitments, bit_lengths) = self.context.try_into()?;
let num_commitments = commitments.len();
if num_commitments > MAX_COMMITMENTS || num_commitments != bit_lengths.len() {
return Err(ProofVerificationError::IllegalCommitmentLength);
⋮----
let mut transcript = self.context_data().new_transcript();
let proof: RangeProof = self.proof.try_into()?;
⋮----
.verify(commitments.iter().collect(), bit_lengths, &mut transcript)
.map_err(|e| e.into())
⋮----
mod test {
⋮----
fn test_batched_range_proof_u64_instruction_correctness() {
⋮----
vec![
⋮----
vec![8, 8, 8, 8, 8, 8, 8, 8],
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());
⋮----
assert_eq!(

================
File: zk-token-sdk/src/instruction/batched_range_proof/mod.rs
================
pub mod batched_range_proof_u128;
pub mod batched_range_proof_u256;
pub mod batched_range_proof_u64;
use crate::zk_token_elgamal::pod;
⋮----
pub struct BatchedRangeProofContext {
⋮----
impl BatchedRangeProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_message(b"commitments", bytes_of(&self.commitments));
transcript.append_message(b"bit-lengths", bytes_of(&self.bit_lengths));
⋮----
fn new(
⋮----
let num_commitments = commitments.len();
⋮----
|| num_commitments != amounts.len()
|| num_commitments != bit_lengths.len()
|| num_commitments != openings.len()
⋮----
return Err(ProofGenerationError::IllegalCommitmentLength);
⋮----
for (i, commitment) in commitments.iter().enumerate() {
if commitment.get_point().is_identity() {
return Err(ProofGenerationError::InvalidCommitment);
⋮----
pod_commitments[i] = pod::PedersenCommitment(commitment.to_bytes());
⋮----
for (i, bit_length) in bit_lengths.iter().enumerate() {
⋮----
.try_into()
.map_err(|_| ProofGenerationError::IllegalAmountBitLength)?;
⋮----
Ok(BatchedRangeProofContext {
⋮----
type Error = ProofVerificationError;
fn try_into(self) -> Result<(Vec<PedersenCommitment>, Vec<usize>), Self::Error> {
⋮----
.into_iter()
.take_while(|commitment| *commitment != pod::PedersenCommitment::zeroed())
.map(|commitment| commitment.try_into())
⋮----
.map_err(|_| ProofVerificationError::ProofContext)?;
⋮----
.take(commitments.len())
.map(|bit_length| bit_length as usize)
.collect();
Ok((commitments, bit_lengths))

================
File: zk-token-sdk/src/instruction/grouped_ciphertext_validity/handles_2.rs
================
pub struct GroupedCiphertext2HandlesValidityProofData {
⋮----
pub struct GroupedCiphertext2HandlesValidityProofContext {
⋮----
impl GroupedCiphertext2HandlesValidityProofData {
pub fn new(
⋮----
let pod_destination_pubkey = pod::ElGamalPubkey(destination_pubkey.into());
let pod_auditor_pubkey = pod::ElGamalPubkey(auditor_pubkey.into());
let pod_grouped_ciphertext = (*grouped_ciphertext).into();
⋮----
let mut transcript = context.new_transcript();
⋮----
.into();
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &GroupedCiphertext2HandlesValidityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let destination_pubkey = self.context.destination_pubkey.try_into()?;
let auditor_pubkey = self.context.auditor_pubkey.try_into()?;
⋮----
self.context.grouped_ciphertext.try_into()?;
let destination_handle = grouped_ciphertext.handles.first().unwrap();
let auditor_handle = grouped_ciphertext.handles.get(1).unwrap();
let proof: GroupedCiphertext2HandlesValidityProof = self.proof.try_into()?;
⋮----
.verify(
⋮----
.map_err(|e| e.into())
⋮----
impl GroupedCiphertext2HandlesValidityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"destination-pubkey", &self.destination_pubkey);
transcript.append_pubkey(b"auditor-pubkey", &self.auditor_pubkey);
⋮----
.append_grouped_ciphertext_2_handles(b"grouped-ciphertext", &self.grouped_ciphertext);
⋮----
mod test {
⋮----
fn test_ciphertext_validity_proof_instruction_correctness() {
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/grouped_ciphertext_validity/handles_3.rs
================
pub struct GroupedCiphertext3HandlesValidityProofData {
⋮----
pub struct GroupedCiphertext3HandlesValidityProofContext {
⋮----
impl GroupedCiphertext3HandlesValidityProofData {
pub fn new(
⋮----
let pod_source_pubkey = pod::ElGamalPubkey(source_pubkey.into());
let pod_destination_pubkey = pod::ElGamalPubkey(destination_pubkey.into());
let pod_auditor_pubkey = pod::ElGamalPubkey(auditor_pubkey.into());
let pod_grouped_ciphertext = (*grouped_ciphertext).into();
⋮----
let mut transcript = context.new_transcript();
⋮----
.into();
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &GroupedCiphertext3HandlesValidityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let source_pubkey = self.context.source_pubkey.try_into()?;
let destination_pubkey = self.context.destination_pubkey.try_into()?;
let auditor_pubkey = self.context.auditor_pubkey.try_into()?;
⋮----
self.context.grouped_ciphertext.try_into()?;
let source_handle = grouped_ciphertext.handles.first().unwrap();
let destination_handle = grouped_ciphertext.handles.get(1).unwrap();
let auditor_handle = grouped_ciphertext.handles.get(2).unwrap();
let proof: GroupedCiphertext3HandlesValidityProof = self.proof.try_into()?;
⋮----
.verify(
⋮----
.map_err(|e| e.into())
⋮----
impl GroupedCiphertext3HandlesValidityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"source-pubkey", &self.source_pubkey);
transcript.append_pubkey(b"destination-pubkey", &self.destination_pubkey);
transcript.append_pubkey(b"auditor-pubkey", &self.auditor_pubkey);
⋮----
.append_grouped_ciphertext_3_handles(b"grouped-ciphertext", &self.grouped_ciphertext);
⋮----
mod test {
⋮----
fn test_ciphertext_validity_proof_instruction_correctness() {
⋮----
let source_pubkey = source_keypair.pubkey();
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/grouped_ciphertext_validity/mod.rs
================
mod handles_2;
mod handles_3;

================
File: zk-token-sdk/src/instruction/transfer/encryption.rs
================
pub struct TransferAmountCiphertext(pub(crate) GroupedElGamalCiphertext<3>);
⋮----
impl TransferAmountCiphertext {
pub fn new(
⋮----
(Self(grouped_ciphertext), opening)
⋮----
pub fn get_commitment(&self) -> &PedersenCommitment {
⋮----
pub fn get_source_handle(&self) -> &DecryptHandle {
self.0.handles.first().unwrap()
⋮----
pub fn get_destination_handle(&self) -> &DecryptHandle {
self.0.handles.get(1).unwrap()
⋮----
pub fn get_auditor_handle(&self) -> &DecryptHandle {
self.0.handles.get(2).unwrap()
⋮----
pub struct FeeEncryption(pub(crate) GroupedElGamalCiphertext<2>);
⋮----
impl FeeEncryption {
⋮----
pub fn get_withdraw_withheld_authority_handle(&self) -> &DecryptHandle {

================
File: zk-token-sdk/src/instruction/transfer/mod.rs
================
pub mod encryption;
pub mod with_fee;
pub mod without_fee;
⋮----
pub enum Role {
⋮----
pub fn split_u64(amount: u64, bit_length: usize) -> (u64, u64) {
⋮----
pub fn try_split_u64(amount: u64, bit_length: usize) -> Result<(u64, u64), InstructionError> {
⋮----
0 => Ok((0, amount)),
⋮----
let bit_length_complement = u64::BITS.checked_sub(bit_length as u32).unwrap();
⋮----
.checked_shl(bit_length_complement)
.and_then(|amount| amount.checked_shr(bit_length_complement))
.unwrap();
let hi = amount.checked_shr(bit_length as u32).unwrap();
Ok((lo, hi))
⋮----
64 => Ok((amount, 0)),
_ => Err(InstructionError::IllegalAmountBitLength),
⋮----
pub fn combine_lo_hi_u64(amount_lo: u64, amount_hi: u64, bit_length: usize) -> u64 {
⋮----
pub fn try_combine_lo_hi_u64(
⋮----
0 => Ok(amount_hi),
⋮----
let amount_hi = amount_hi.checked_shl(bit_length as u32).unwrap();
⋮----
.checked_add(amount_hi)
.ok_or(InstructionError::IllegalAmountBitLength)?;
Ok(combined)
⋮----
64 => Ok(amount_lo),
⋮----
fn try_combine_lo_hi_ciphertexts(
⋮----
1_u64.checked_shl(bit_length as u32).unwrap()
⋮----
return Err(InstructionError::IllegalAmountBitLength);
⋮----
Ok(ciphertext_lo + &(ciphertext_hi * &Scalar::from(two_power)))
⋮----
pub fn combine_lo_hi_commitments(
⋮----
pub fn try_combine_lo_hi_commitments(
⋮----
Ok(comm_lo + comm_hi * &Scalar::from(two_power))
⋮----
pub fn combine_lo_hi_openings(
⋮----
pub fn try_combine_lo_hi_openings(
⋮----
Ok(opening_lo + opening_hi * &Scalar::from(two_power))
⋮----
pub struct FeeParameters {
⋮----
mod test {
⋮----
fn test_split_u64() {
assert_eq!((0, 0), try_split_u64(0, 0).unwrap());
assert_eq!((0, 0), try_split_u64(0, 1).unwrap());
assert_eq!((0, 0), try_split_u64(0, 5).unwrap());
assert_eq!((0, 0), try_split_u64(0, 63).unwrap());
assert_eq!((0, 0), try_split_u64(0, 64).unwrap());
assert_eq!(
⋮----
assert_eq!((0, 1), try_split_u64(1, 0).unwrap());
assert_eq!((1, 0), try_split_u64(1, 1).unwrap());
assert_eq!((1, 0), try_split_u64(1, 5).unwrap());
assert_eq!((1, 0), try_split_u64(1, 63).unwrap());
assert_eq!((1, 0), try_split_u64(1, 64).unwrap());
⋮----
assert_eq!((0, 33), try_split_u64(33, 0).unwrap());
assert_eq!((1, 16), try_split_u64(33, 1).unwrap());
assert_eq!((1, 1), try_split_u64(33, 5).unwrap());
assert_eq!((33, 0), try_split_u64(33, 63).unwrap());
assert_eq!((33, 0), try_split_u64(33, 64).unwrap());
⋮----
assert_eq!((0, amount), try_split_u64(amount, 0).unwrap());
assert_eq!((1, (1 << 63) - 1), try_split_u64(amount, 1).unwrap());
assert_eq!((31, (1 << 59) - 1), try_split_u64(amount, 5).unwrap());
assert_eq!(((1 << 63) - 1, 1), try_split_u64(amount, 63).unwrap());
assert_eq!((amount, 0), try_split_u64(amount, 64).unwrap());
⋮----
fn test_split_and_combine(amount: u64, bit_length: usize) {
let (amount_lo, amount_hi) = try_split_u64(amount, bit_length).unwrap();
⋮----
fn test_combine_lo_hi_u64() {
test_split_and_combine(0, 0);
test_split_and_combine(0, 1);
test_split_and_combine(0, 5);
test_split_and_combine(0, 63);
test_split_and_combine(0, 64);
test_split_and_combine(1, 0);
test_split_and_combine(1, 1);
test_split_and_combine(1, 5);
test_split_and_combine(1, 63);
test_split_and_combine(1, 64);
test_split_and_combine(33, 0);
test_split_and_combine(33, 1);
test_split_and_combine(33, 5);
test_split_and_combine(33, 63);
test_split_and_combine(33, 64);
test_split_and_combine(u64::MAX, 0);
test_split_and_combine(u64::MAX, 1);
test_split_and_combine(u64::MAX, 5);
test_split_and_combine(u64::MAX, 63);
test_split_and_combine(u64::MAX, 64);
let err = try_combine_lo_hi_u64(0, 0, 65).unwrap_err();
assert_eq!(err, InstructionError::IllegalAmountBitLength);
⋮----
let err = try_combine_lo_hi_u64(amount_lo, amount_hi, 1).unwrap_err();

================
File: zk-token-sdk/src/instruction/transfer/with_fee.rs
================
pub struct TransferWithFeeData {
⋮----
pub struct TransferWithFeeProofContext {
⋮----
pub struct TransferWithFeePubkeys {
⋮----
impl TransferWithFeeData {
pub fn new(
⋮----
let (amount_lo, amount_hi) = try_split_u64(transfer_amount, TRANSFER_AMOUNT_LO_BITS)
.map_err(|_| ProofGenerationError::IllegalAmountBitLength)?;
⋮----
source_keypair.pubkey(),
⋮----
.checked_sub(transfer_amount)
.ok_or(ProofGenerationError::NotEnoughFunds)?;
⋮----
commitment: *ciphertext_lo.get_commitment(),
handle: *ciphertext_lo.get_source_handle(),
⋮----
commitment: *ciphertext_hi.get_commitment(),
handle: *ciphertext_hi.get_source_handle(),
⋮----
- try_combine_lo_hi_ciphertexts(
⋮----
calculate_fee(transfer_amount, fee_parameters.fee_rate_basis_points)
.ok_or(ProofGenerationError::FeeCalculation)?;
⋮----
try_split_u64(fee_to_encrypt, FEE_AMOUNT_LO_BITS)
⋮----
source: (*source_keypair.pubkey()).into(),
destination: (*destination_pubkey).into(),
auditor: (*auditor_pubkey).into(),
withdraw_withheld_authority: (*withdraw_withheld_authority_pubkey).into(),
⋮----
let pod_ciphertext_lo: pod::TransferAmountCiphertext = ciphertext_lo.into();
let pod_ciphertext_hi: pod::TransferAmountCiphertext = ciphertext_hi.into();
let pod_new_source_ciphertext: pod::ElGamalCiphertext = new_source_ciphertext.into();
let pod_fee_ciphertext_lo: pod::FeeEncryption = fee_ciphertext_lo.into();
let pod_fee_ciphertext_hi: pod::FeeEncryption = fee_ciphertext_hi.into();
⋮----
fee_parameters: fee_parameters.into(),
⋮----
let mut transcript = context.new_transcript();
⋮----
Ok(Self { context, proof })
⋮----
fn ciphertext_lo(&self, role: Role) -> Result<ElGamalCiphertext, InstructionError> {
⋮----
.try_into()
.map_err(|_| InstructionError::Decryption)?;
⋮----
Role::Source => Some(ciphertext_lo.get_source_handle()),
Role::Destination => Some(ciphertext_lo.get_destination_handle()),
Role::Auditor => Some(ciphertext_lo.get_auditor_handle()),
⋮----
Ok(ElGamalCiphertext {
⋮----
Err(InstructionError::MissingCiphertext)
⋮----
fn ciphertext_hi(&self, role: Role) -> Result<ElGamalCiphertext, InstructionError> {
⋮----
Role::Source => Some(ciphertext_hi.get_source_handle()),
Role::Destination => Some(ciphertext_hi.get_destination_handle()),
Role::Auditor => Some(ciphertext_hi.get_auditor_handle()),
⋮----
fn fee_ciphertext_lo(&self, role: Role) -> Result<ElGamalCiphertext, InstructionError> {
⋮----
Role::Destination => Some(fee_ciphertext_lo.get_destination_handle()),
⋮----
Some(fee_ciphertext_lo.get_withdraw_withheld_authority_handle())
⋮----
commitment: *fee_ciphertext_lo.get_commitment(),
⋮----
fn fee_ciphertext_hi(&self, role: Role) -> Result<ElGamalCiphertext, InstructionError> {
⋮----
Role::Destination => Some(fee_ciphertext_hi.get_destination_handle()),
⋮----
Some(fee_ciphertext_hi.get_withdraw_withheld_authority_handle())
⋮----
commitment: *fee_ciphertext_hi.get_commitment(),
⋮----
pub fn decrypt_amount(
⋮----
let ciphertext_lo = self.ciphertext_lo(role)?;
let ciphertext_hi = self.ciphertext_hi(role)?;
let amount_lo = ciphertext_lo.decrypt_u32(sk);
let amount_hi = ciphertext_hi.decrypt_u32(sk);
⋮----
Ok(amount_lo + shifted_amount_hi)
⋮----
Err(InstructionError::Decryption)
⋮----
pub fn decrypt_fee_amount(
⋮----
let ciphertext_lo = self.fee_ciphertext_lo(role)?;
let ciphertext_hi = self.fee_ciphertext_hi(role)?;
let fee_amount_lo = ciphertext_lo.decrypt_u32(sk);
let fee_amount_hi = ciphertext_hi.decrypt_u32(sk);
⋮----
Ok(fee_amount_lo + shifted_fee_amount_hi)
⋮----
fn context_data(&self) -> &TransferWithFeeProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let source_pubkey = self.context.transfer_with_fee_pubkeys.source.try_into()?;
⋮----
.try_into()?;
let auditor_pubkey = self.context.transfer_with_fee_pubkeys.auditor.try_into()?;
⋮----
let ciphertext_lo = self.context.ciphertext_lo.try_into()?;
let ciphertext_hi = self.context.ciphertext_hi.try_into()?;
let new_source_ciphertext = self.context.new_source_ciphertext.try_into()?;
let fee_ciphertext_lo = self.context.fee_ciphertext_lo.try_into()?;
let fee_ciphertext_hi = self.context.fee_ciphertext_hi.try_into()?;
let fee_parameters = self.context.fee_parameters.into();
self.proof.verify(
⋮----
impl TransferWithFeeProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_message(b"ciphertext-lo", bytes_of(&self.ciphertext_lo));
transcript.append_message(b"ciphertext-hi", bytes_of(&self.ciphertext_hi));
transcript.append_message(
⋮----
bytes_of(&self.transfer_with_fee_pubkeys),
⋮----
bytes_of(&self.new_source_ciphertext),
⋮----
transcript.append_message(b"fee-ciphertext-lo", bytes_of(&self.fee_ciphertext_lo));
transcript.append_message(b"fee-ciphertext-hi", bytes_of(&self.fee_ciphertext_hi));
transcript.append_message(b"fee-parameters", bytes_of(&self.fee_parameters));
⋮----
pub struct TransferWithFeeProof {
⋮----
impl TransferWithFeeProof {
⋮----
let pod_new_source_commitment: pod::PedersenCommitment = new_source_commitment.into();
transcript.append_commitment(b"commitment-new-source", &pod_new_source_commitment);
⋮----
let pod_claimed_commitment: pod::PedersenCommitment = claimed_commitment.into();
transcript.append_commitment(b"commitment-claimed", &pod_claimed_commitment);
let combined_commitment = try_combine_lo_hi_commitments(
ciphertext_lo.get_commitment(),
ciphertext_hi.get_commitment(),
⋮----
try_combine_lo_hi_openings(opening_lo, opening_hi, TRANSFER_AMOUNT_LO_BITS)
⋮----
try_combine_lo_hi_u64(fee_amount_lo, fee_amount_hi, TRANSFER_AMOUNT_LO_BITS)
⋮----
let combined_fee_commitment = try_combine_lo_hi_commitments(
fee_ciphertext_lo.get_commitment(),
fee_ciphertext_hi.get_commitment(),
⋮----
try_combine_lo_hi_openings(opening_fee_lo, opening_fee_hi, TRANSFER_AMOUNT_LO_BITS)
⋮----
let (delta_commitment, opening_delta) = compute_delta_commitment_and_opening(
⋮----
let pod_delta_commitment: pod::PedersenCommitment = delta_commitment.into();
transcript.append_commitment(b"commitment-delta", &pod_delta_commitment);
⋮----
let combined_amount = try_combine_lo_hi_u64(
⋮----
.checked_sub(combined_fee_amount)
⋮----
.checked_sub(delta_fee)
⋮----
vec![
⋮----
Ok(Self {
⋮----
equality_proof: equality_proof.into(),
ciphertext_amount_validity_proof: ciphertext_amount_validity_proof.into(),
fee_sigma_proof: fee_sigma_proof.into(),
fee_ciphertext_validity_proof: fee_ciphertext_validity_proof.into(),
⋮----
.map_err(|_| ProofGenerationError::ProofLength)?,
⋮----
pub fn verify(
⋮----
transcript.append_commitment(b"commitment-new-source", &self.new_source_commitment);
let new_source_commitment: PedersenCommitment = self.new_source_commitment.try_into()?;
let claimed_commitment: PedersenCommitment = self.claimed_commitment.try_into()?;
let equality_proof: CiphertextCommitmentEqualityProof = self.equality_proof.try_into()?;
⋮----
self.ciphertext_amount_validity_proof.try_into()?;
let fee_sigma_proof: FeeSigmaProof = self.fee_sigma_proof.try_into()?;
⋮----
self.fee_ciphertext_validity_proof.try_into()?;
let range_proof: RangeProof = self.range_proof.try_into()?;
equality_proof.verify(
⋮----
ciphertext_amount_validity_proof.verify(
⋮----
ciphertext_lo.get_destination_handle(),
ciphertext_hi.get_destination_handle(),
⋮----
ciphertext_lo.get_auditor_handle(),
ciphertext_hi.get_auditor_handle(),
⋮----
transcript.append_commitment(b"commitment-claimed", &self.claimed_commitment);
⋮----
.map_err(|_| ProofVerificationError::IllegalAmountBitLength)?;
⋮----
let delta_commitment = compute_delta_commitment(
⋮----
fee_sigma_proof.verify(
⋮----
fee_ciphertext_validity_proof.verify(
⋮----
fee_ciphertext_lo.get_destination_handle(),
fee_ciphertext_hi.get_destination_handle(),
⋮----
fee_ciphertext_lo.get_withdraw_withheld_authority_handle(),
fee_ciphertext_hi.get_withdraw_withheld_authority_handle(),
⋮----
let new_source_commitment = self.new_source_commitment.try_into()?;
⋮----
range_proof.verify(
⋮----
Ok(())
⋮----
fn calculate_fee(transfer_amount: u64, fee_rate_basis_points: u16) -> Option<(u64, u64)> {
let numerator = (transfer_amount as u128).checked_mul(fee_rate_basis_points as u128)?;
⋮----
.checked_add(ONE_IN_BASIS_POINTS)?
.checked_sub(1)?
.checked_div(ONE_IN_BASIS_POINTS)?;
⋮----
.checked_mul(ONE_IN_BASIS_POINTS)?
.checked_sub(numerator)?;
Some((fee as u64, delta_fee as u64))
⋮----
fn compute_delta_commitment_and_opening(
⋮----
fn compute_delta_commitment(
⋮----
mod test {
⋮----
fn test_fee_correctness() {
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
let withdraw_withheld_authority_pubkey = withdraw_withheld_authority_keypair.pubkey();
⋮----
let spendable_ciphertext = source_keypair.pubkey().encrypt(spendable_balance);
⋮----
.unwrap();
assert!(fee_data.verify_proof().is_ok());
⋮----
let destination_pubkey: ElGamalPubkey = pod::ElGamalPubkey::zeroed().try_into().unwrap();
⋮----
assert!(fee_data.verify_proof().is_err());

================
File: zk-token-sdk/src/instruction/transfer/without_fee.rs
================
pub struct TransferData {
⋮----
pub struct TransferProofContext {
⋮----
pub struct TransferPubkeys {
⋮----
impl TransferData {
⋮----
pub fn new(
⋮----
let (amount_lo, amount_hi) = try_split_u64(transfer_amount, TRANSFER_AMOUNT_LO_BITS)
.map_err(|_| ProofGenerationError::IllegalAmountBitLength)?;
⋮----
source_keypair.pubkey(),
⋮----
.checked_sub(transfer_amount)
.ok_or(ProofGenerationError::NotEnoughFunds)?;
⋮----
commitment: *ciphertext_lo.get_commitment(),
handle: *ciphertext_lo.get_source_handle(),
⋮----
commitment: *ciphertext_hi.get_commitment(),
handle: *ciphertext_hi.get_source_handle(),
⋮----
- try_combine_lo_hi_ciphertexts(
⋮----
source: (*source_keypair.pubkey()).into(),
destination: (*destination_pubkey).into(),
auditor: (*auditor_pubkey).into(),
⋮----
let pod_ciphertext_lo: pod::TransferAmountCiphertext = ciphertext_lo.into();
let pod_ciphertext_hi: pod::TransferAmountCiphertext = ciphertext_hi.into();
let pod_new_source_ciphertext: pod::ElGamalCiphertext = new_source_ciphertext.into();
⋮----
let mut transcript = context.new_transcript();
⋮----
Ok(Self { context, proof })
⋮----
fn ciphertext_lo(&self, role: Role) -> Result<ElGamalCiphertext, InstructionError> {
⋮----
.try_into()
.map_err(|_| InstructionError::Decryption)?;
⋮----
Role::Source => Some(ciphertext_lo.get_source_handle()),
Role::Destination => Some(ciphertext_lo.get_destination_handle()),
Role::Auditor => Some(ciphertext_lo.get_auditor_handle()),
⋮----
Ok(ElGamalCiphertext {
⋮----
Err(InstructionError::MissingCiphertext)
⋮----
fn ciphertext_hi(&self, role: Role) -> Result<ElGamalCiphertext, InstructionError> {
⋮----
Role::Source => Some(ciphertext_hi.get_source_handle()),
Role::Destination => Some(ciphertext_hi.get_destination_handle()),
Role::Auditor => Some(ciphertext_hi.get_auditor_handle()),
⋮----
pub fn decrypt_amount(
⋮----
let ciphertext_lo = self.ciphertext_lo(role)?;
let ciphertext_hi = self.ciphertext_hi(role)?;
let amount_lo = ciphertext_lo.decrypt_u32(sk);
let amount_hi = ciphertext_hi.decrypt_u32(sk);
⋮----
Ok(amount_lo + two_power * amount_hi)
⋮----
Err(InstructionError::Decryption)
⋮----
fn context_data(&self) -> &TransferProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let source_pubkey = self.context.transfer_pubkeys.source.try_into()?;
let destination_pubkey = self.context.transfer_pubkeys.destination.try_into()?;
let auditor_pubkey = self.context.transfer_pubkeys.auditor.try_into()?;
let ciphertext_lo = self.context.ciphertext_lo.try_into()?;
let ciphertext_hi = self.context.ciphertext_hi.try_into()?;
let new_spendable_ciphertext = self.context.new_source_ciphertext.try_into()?;
self.proof.verify(
⋮----
impl TransferProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_message(b"ciphertext-lo", bytes_of(&self.ciphertext_lo));
transcript.append_message(b"ciphertext-hi", bytes_of(&self.ciphertext_hi));
transcript.append_message(b"transfer-pubkeys", bytes_of(&self.transfer_pubkeys));
transcript.append_message(
⋮----
bytes_of(&self.new_source_ciphertext),
⋮----
pub struct TransferProof {
⋮----
impl TransferProof {
⋮----
let pod_new_source_commitment: pod::PedersenCommitment = new_source_commitment.into();
transcript.append_commitment(b"commitment-new-source", &pod_new_source_commitment);
⋮----
vec![source_new_balance, transfer_amount_lo, transfer_amount_hi],
vec![
⋮----
vec![&source_opening, opening_lo, opening_hi],
⋮----
vec![&source_opening, opening_lo, &opening_lo_negated, opening_hi],
⋮----
Ok(Self {
⋮----
equality_proof: equality_proof.into(),
validity_proof: validity_proof.into(),
⋮----
.map_err(|_| ProofGenerationError::ProofLength)?,
⋮----
pub fn verify(
⋮----
transcript.append_commitment(b"commitment-new-source", &self.new_source_commitment);
let commitment: PedersenCommitment = self.new_source_commitment.try_into()?;
let equality_proof: CiphertextCommitmentEqualityProof = self.equality_proof.try_into()?;
⋮----
self.validity_proof.try_into()?;
let range_proof: RangeProof = self.range_proof.try_into()?;
equality_proof.verify(
⋮----
aggregated_validity_proof.verify(
⋮----
ciphertext_lo.get_commitment(),
ciphertext_hi.get_commitment(),
⋮----
ciphertext_lo.get_destination_handle(),
ciphertext_hi.get_destination_handle(),
⋮----
ciphertext_lo.get_auditor_handle(),
ciphertext_hi.get_auditor_handle(),
⋮----
let new_source_commitment = self.new_source_commitment.try_into()?;
⋮----
range_proof.verify(
⋮----
let commitment_lo_negated = &(*COMMITMENT_MAX) - ciphertext_lo.get_commitment();
⋮----
Ok(())
⋮----
mod test {
⋮----
fn test_transfer_correctness() {
⋮----
let dest_pk = dest_keypair.pubkey();
⋮----
let auditor_pk = auditor_keypair.pubkey();
⋮----
let spendable_ciphertext = source_keypair.pubkey().encrypt(spendable_balance);
⋮----
.unwrap();
assert!(transfer_data.verify_proof().is_ok());
⋮----
let dest_pk = pod::ElGamalPubkey::zeroed().try_into().unwrap();
⋮----
assert!(transfer_data.verify_proof().is_err());
⋮----
fn test_source_dest_ciphertext() {
⋮----
let dest_pk = source_keypair.pubkey();
let dest_sk = source_keypair.secret();
⋮----
let auditor_sk = auditor_keypair.secret();
⋮----
assert_eq!(

================
File: zk-token-sdk/src/instruction/ciphertext_ciphertext_equality.rs
================
pub struct CiphertextCiphertextEqualityProofData {
⋮----
pub struct CiphertextCiphertextEqualityProofContext {
⋮----
impl CiphertextCiphertextEqualityProofData {
pub fn new(
⋮----
let pod_source_pubkey = pod::ElGamalPubkey(source_keypair.pubkey().into());
let pod_destination_pubkey = pod::ElGamalPubkey(destination_pubkey.into());
let pod_source_ciphertext = pod::ElGamalCiphertext(source_ciphertext.to_bytes());
let pod_destination_ciphertext = pod::ElGamalCiphertext(destination_ciphertext.to_bytes());
⋮----
let mut transcript = context.new_transcript();
⋮----
.into();
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &CiphertextCiphertextEqualityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let source_pubkey = self.context.source_pubkey.try_into()?;
let destination_pubkey = self.context.destination_pubkey.try_into()?;
let source_ciphertext = self.context.source_ciphertext.try_into()?;
let destination_ciphertext = self.context.destination_ciphertext.try_into()?;
let proof: CiphertextCiphertextEqualityProof = self.proof.try_into()?;
⋮----
.verify(
⋮----
.map_err(|e| e.into())
⋮----
impl CiphertextCiphertextEqualityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"source-pubkey", &self.source_pubkey);
transcript.append_pubkey(b"destination-pubkey", &self.destination_pubkey);
transcript.append_ciphertext(b"source-ciphertext", &self.source_ciphertext);
transcript.append_ciphertext(b"destination-ciphertext", &self.destination_ciphertext);
⋮----
mod test {
⋮----
fn test_ciphertext_ciphertext_instruction_correctness() {
⋮----
let source_ciphertext = source_keypair.pubkey().encrypt(amount);
⋮----
.pubkey()
.encrypt_with(amount, &destination_opening);
⋮----
destination_keypair.pubkey(),
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/ciphertext_commitment_equality.rs
================
pub struct CiphertextCommitmentEqualityProofData {
⋮----
pub struct CiphertextCommitmentEqualityProofContext {
⋮----
impl CiphertextCommitmentEqualityProofData {
pub fn new(
⋮----
pubkey: pod::ElGamalPubkey(keypair.pubkey().into()),
ciphertext: pod::ElGamalCiphertext(ciphertext.to_bytes()),
commitment: pod::PedersenCommitment(commitment.to_bytes()),
⋮----
let mut transcript = context.new_transcript();
⋮----
Ok(CiphertextCommitmentEqualityProofData {
⋮----
proof: proof.into(),
⋮----
fn context_data(&self) -> &CiphertextCommitmentEqualityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let pubkey = self.context.pubkey.try_into()?;
let ciphertext = self.context.ciphertext.try_into()?;
let commitment = self.context.commitment.try_into()?;
let proof: CiphertextCommitmentEqualityProof = self.proof.try_into()?;
⋮----
.verify(&pubkey, &ciphertext, &commitment, &mut transcript)
.map_err(|e| e.into())
⋮----
impl CiphertextCommitmentEqualityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"pubkey", &self.pubkey);
transcript.append_ciphertext(b"ciphertext", &self.ciphertext);
transcript.append_commitment(b"commitment", &self.commitment);
⋮----
mod test {
⋮----
fn test_ctxt_comm_equality_proof_correctness() {
⋮----
let ciphertext = keypair.pubkey().encrypt(amount);
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/errors.rs
================
use thiserror::Error;
⋮----
pub enum InstructionError {

================
File: zk-token-sdk/src/instruction/fee_sigma.rs
================
pub struct FeeSigmaProofData {
⋮----
pub struct FeeSigmaProofContext {
⋮----
impl FeeSigmaProofData {
pub fn new(
⋮----
let pod_fee_commitment = pod::PedersenCommitment(fee_commitment.to_bytes());
let pod_delta_commitment = pod::PedersenCommitment(delta_commitment.to_bytes());
let pod_claimed_commitment = pod::PedersenCommitment(claimed_commitment.to_bytes());
let pod_max_fee = max_fee.into();
⋮----
let mut transcript = context.new_transcript();
⋮----
.into();
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &FeeSigmaProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let fee_commitment = self.context.fee_commitment.try_into()?;
let delta_commitment = self.context.delta_commitment.try_into()?;
let claimed_commitment = self.context.claimed_commitment.try_into()?;
let max_fee = self.context.max_fee.into();
let proof: FeeSigmaProof = self.proof.try_into()?;
⋮----
.verify(
⋮----
.map_err(|e| e.into())
⋮----
impl FeeSigmaProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_commitment(b"fee-commitment", &self.fee_commitment);
transcript.append_commitment(b"delta-commitment", &self.fee_commitment);
transcript.append_commitment(b"claimed-commitment", &self.fee_commitment);
transcript.append_u64(b"max-fee", self.max_fee.into());
⋮----
mod test {
⋮----
fn test_fee_sigma_instruction_correctness() {
⋮----
.unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/mod.rs
================
pub mod batched_grouped_ciphertext_validity;
pub mod batched_range_proof;
pub mod ciphertext_ciphertext_equality;
pub mod ciphertext_commitment_equality;
pub mod errors;
pub mod fee_sigma;
pub mod grouped_ciphertext_validity;
pub mod pubkey_validity;
pub mod range_proof;
pub mod transfer;
pub mod withdraw;
pub mod zero_balance;
⋮----
use crate::errors::ProofVerificationError;
⋮----
pub enum ProofType {
⋮----
pub trait ZkProofData<T: Pod> {

================
File: zk-token-sdk/src/instruction/pubkey_validity.rs
================
pub struct PubkeyValidityData {
⋮----
pub struct PubkeyValidityProofContext {
⋮----
impl PubkeyValidityData {
pub fn new(keypair: &ElGamalKeypair) -> Result<Self, ProofGenerationError> {
let pod_pubkey = pod::ElGamalPubkey(keypair.pubkey().into());
⋮----
let mut transcript = context.new_transcript();
let proof = PubkeyValidityProof::new(keypair, &mut transcript).into();
Ok(PubkeyValidityData { context, proof })
⋮----
fn context_data(&self) -> &PubkeyValidityProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let pubkey = self.context.pubkey.try_into()?;
let proof: PubkeyValidityProof = self.proof.try_into()?;
proof.verify(&pubkey, &mut transcript).map_err(|e| e.into())
⋮----
impl PubkeyValidityProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"pubkey", &self.pubkey);
⋮----
mod test {
⋮----
fn test_pubkey_validity_instruction_correctness() {
⋮----
let pubkey_validity_data = PubkeyValidityData::new(&keypair).unwrap();
assert!(pubkey_validity_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/range_proof.rs
================
pub struct RangeProofContext {
⋮----
pub struct RangeProofU64Data {
⋮----
impl RangeProofU64Data {
pub fn new(
⋮----
let pod_commitment = pod::PedersenCommitment(commitment.to_bytes());
⋮----
let mut transcript = context.new_transcript();
let bit_size = usize::try_from(u64::BITS).unwrap();
let proof = RangeProof::new(vec![amount], vec![bit_size], vec![opening], &mut transcript)?
.try_into()
.map_err(|_| ProofGenerationError::ProofLength)?;
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &RangeProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context_data().new_transcript();
let commitment = self.context.commitment.try_into()?;
let proof: RangeProof = self.proof.try_into()?;
⋮----
.verify(vec![&commitment], vec![bit_size], &mut transcript)
.map_err(|e| e.into())
⋮----
impl RangeProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_commitment(b"commitment", &self.commitment);
⋮----
mod test {
⋮----
fn test_range_proof_64_instruction_correctness() {
⋮----
let proof_data = RangeProofU64Data::new(&commitment, amount, &opening).unwrap();
assert!(proof_data.verify_proof().is_ok());

================
File: zk-token-sdk/src/instruction/withdraw.rs
================
pub struct WithdrawData {
⋮----
pub struct WithdrawProofContext {
⋮----
impl WithdrawData {
pub fn new(
⋮----
.checked_sub(amount)
.ok_or(ProofGenerationError::NotEnoughFunds)?;
⋮----
let pod_pubkey = pod::ElGamalPubkey(keypair.pubkey().into());
let pod_final_ciphertext: pod::ElGamalCiphertext = final_ciphertext.into();
⋮----
let mut transcript = context.new_transcript();
⋮----
Ok(Self { context, proof })
⋮----
fn context_data(&self) -> &WithdrawProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let elgamal_pubkey = self.context.pubkey.try_into()?;
let final_balance_ciphertext = self.context.final_ciphertext.try_into()?;
⋮----
.verify(&elgamal_pubkey, &final_balance_ciphertext, &mut transcript)
⋮----
impl WithdrawProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"pubkey", &self.pubkey);
transcript.append_ciphertext(b"ciphertext", &self.final_ciphertext);
⋮----
pub struct WithdrawProof {
⋮----
impl WithdrawProof {
⋮----
let pod_commitment: pod::PedersenCommitment = commitment.into();
transcript.append_commitment(b"commitment", &pod_commitment);
⋮----
RangeProof::new(vec![final_balance], vec![64], vec![&opening], transcript)?;
Ok(Self {
⋮----
equality_proof: equality_proof.into(),
⋮----
.try_into()
.map_err(|_| ProofGenerationError::ProofLength)?,
⋮----
pub fn verify(
⋮----
transcript.append_commitment(b"commitment", &self.commitment);
let commitment: PedersenCommitment = self.commitment.try_into()?;
let equality_proof: CiphertextCommitmentEqualityProof = self.equality_proof.try_into()?;
let range_proof: RangeProof = self.range_proof.try_into()?;
equality_proof.verify(pubkey, final_ciphertext, &commitment, transcript)?;
range_proof.verify(
vec![&commitment],
vec![WITHDRAW_AMOUNT_BIT_LENGTH],
⋮----
Ok(())
⋮----
mod test {
⋮----
fn test_withdraw_correctness() {
⋮----
let current_ciphertext = keypair.pubkey().encrypt(current_balance);
⋮----
.unwrap();
assert!(data.verify_proof().is_ok());
⋮----
assert!(data.verify_proof().is_err());

================
File: zk-token-sdk/src/instruction/zero_balance.rs
================
pub struct ZeroBalanceProofData {
⋮----
pub struct ZeroBalanceProofContext {
⋮----
impl ZeroBalanceProofData {
pub fn new(
⋮----
let pod_pubkey = pod::ElGamalPubkey(keypair.pubkey().into());
let pod_ciphertext = pod::ElGamalCiphertext(ciphertext.to_bytes());
⋮----
let mut transcript = context.new_transcript();
let proof = ZeroBalanceProof::new(keypair, ciphertext, &mut transcript).into();
Ok(ZeroBalanceProofData { context, proof })
⋮----
fn context_data(&self) -> &ZeroBalanceProofContext {
⋮----
fn verify_proof(&self) -> Result<(), ProofVerificationError> {
let mut transcript = self.context.new_transcript();
let pubkey = self.context.pubkey.try_into()?;
let ciphertext = self.context.ciphertext.try_into()?;
let proof: ZeroBalanceProof = self.proof.try_into()?;
⋮----
.verify(&pubkey, &ciphertext, &mut transcript)
.map_err(|e| e.into())
⋮----
impl ZeroBalanceProofContext {
fn new_transcript(&self) -> Transcript {
⋮----
transcript.append_pubkey(b"pubkey", &self.pubkey);
transcript.append_ciphertext(b"ciphertext", &self.ciphertext);
⋮----
mod test {
⋮----
fn test_zero_balance_proof_instruction_correctness() {
⋮----
let ciphertext = keypair.pubkey().encrypt(0_u64);
let zero_balance_proof_data = ZeroBalanceProofData::new(&keypair, &ciphertext).unwrap();
assert!(zero_balance_proof_data.verify_proof().is_ok());
let ciphertext = keypair.pubkey().encrypt(1_u64);
⋮----
assert!(zero_balance_proof_data.verify_proof().is_err());

================
File: zk-token-sdk/src/range_proof/errors.rs
================
pub enum RangeProofGenerationError {
⋮----
pub enum RangeProofVerificationError {
⋮----
pub enum RangeProofGeneratorError {

================
File: zk-token-sdk/src/range_proof/generators.rs
================
struct GeneratorsChain {
⋮----
impl GeneratorsChain {
fn new(label: &[u8]) -> Self {
⋮----
shake.update(b"GeneratorsChain");
shake.update(label);
⋮----
reader: shake.finalize_xof(),
⋮----
fn fast_forward(mut self, n: usize) -> Self {
⋮----
self.reader.read(&mut buf);
⋮----
impl Default for GeneratorsChain {
fn default() -> Self {
⋮----
impl Iterator for GeneratorsChain {
type Item = RistrettoPoint;
fn next(&mut self) -> Option<Self::Item> {
⋮----
self.reader.read(&mut uniform_bytes);
Some(RistrettoPoint::from_uniform_bytes(&uniform_bytes))
⋮----
fn size_hint(&self) -> (usize, Option<usize>) {
⋮----
pub struct BulletproofGens {
⋮----
impl BulletproofGens {
pub fn new(gens_capacity: usize) -> Result<Self, RangeProofGeneratorError> {
⋮----
gens.increase_capacity(gens_capacity)?;
Ok(gens)
⋮----
pub fn increase_capacity(
⋮----
return Ok(());
⋮----
return Err(RangeProofGeneratorError::MaximumGeneratorLengthExceeded);
⋮----
self.G_vec.extend(
⋮----
.fast_forward(self.gens_capacity)
.take(new_capacity - self.gens_capacity),
⋮----
self.H_vec.extend(
⋮----
Ok(())
⋮----
pub(crate) fn G(&self, n: usize) -> impl Iterator<Item = &RistrettoPoint> {
⋮----
pub(crate) fn H(&self, n: usize) -> impl Iterator<Item = &RistrettoPoint> {
⋮----
struct GensIter<'a> {
⋮----
impl<'a> Iterator for GensIter<'a> {
type Item = &'a RistrettoPoint;
⋮----
Some(&self.array[cur_gen])
⋮----
(size, Some(size))

================
File: zk-token-sdk/src/range_proof/inner_product.rs
================
pub struct InnerProductProof {
⋮----
impl InnerProductProof {
⋮----
pub fn new(
⋮----
let mut n = G.len();
if G.len() != n
|| H.len() != n
|| a.len() != n
|| b.len() != n
|| G_factors.len() != n
|| H_factors.len() != n
⋮----
return Err(RangeProofGenerationError::GeneratorLengthMismatch);
⋮----
if !n.is_power_of_two() {
return Err(RangeProofGenerationError::InvalidBitSize);
⋮----
transcript.innerproduct_domain_separator(n as u64);
let lg_n = n.next_power_of_two().trailing_zeros() as usize;
⋮----
n = n.checked_div(2).unwrap();
let (a_L, a_R) = a.split_at_mut(n);
let (b_L, b_R) = b.split_at_mut(n);
let (G_L, G_R) = G.split_at_mut(n);
let (H_L, H_R) = H.split_at_mut(n);
⋮----
.ok_or(RangeProofGenerationError::InnerProductLengthMismatch)?;
⋮----
a_L.iter()
.zip(G_factors[n..n.checked_mul(2).unwrap()].iter())
.map(|(a_L_i, g)| a_L_i * g)
.chain(
b_R.iter()
.zip(H_factors[0..n].iter())
.map(|(b_R_i, h)| b_R_i * h),
⋮----
.chain(iter::once(c_L)),
G_R.iter().chain(H_L.iter()).chain(iter::once(Q)),
⋮----
.compress();
⋮----
a_R.iter()
.zip(G_factors[0..n].iter())
.map(|(a_R_i, g)| a_R_i * g)
⋮----
b_L.iter()
.zip(H_factors[n..n.checked_mul(2).unwrap()].iter())
.map(|(b_L_i, h)| b_L_i * h),
⋮----
.chain(iter::once(c_R)),
G_L.iter().chain(H_R.iter()).chain(iter::once(Q)),
⋮----
L_vec.push(L);
R_vec.push(R);
transcript.append_point(b"L", &L);
transcript.append_point(b"R", &R);
let u = transcript.challenge_scalar(b"u");
let u_inv = u.invert();
⋮----
u * G_factors[n.checked_add(i).unwrap()],
⋮----
u_inv * H_factors[n.checked_add(i).unwrap()],
⋮----
a_L.iter().chain(b_R.iter()).chain(iter::once(&c_L)),
⋮----
a_R.iter().chain(b_L.iter()).chain(iter::once(&c_R)),
⋮----
Ok(InnerProductProof {
⋮----
pub(crate) fn verification_scalars(
⋮----
let lg_n = self.L_vec.len();
⋮----
return Err(RangeProofVerificationError::InvalidBitSize);
⋮----
if n != (1_usize.checked_shl(lg_n as u32).unwrap()) {
⋮----
for (L, R) in self.L_vec.iter().zip(self.R_vec.iter()) {
transcript.validate_and_append_point(b"L", L)?;
transcript.validate_and_append_point(b"R", R)?;
challenges.push(transcript.challenge_scalar(b"u"));
⋮----
let mut challenges_inv = challenges.clone();
⋮----
s.push(allinv);
⋮----
let lg_i = 31_u32.checked_sub((i as u32).leading_zeros()).unwrap() as usize;
let k = 1_usize.checked_shl(lg_i as u32).unwrap();
⋮----
.checked_sub(1)
.and_then(|x| x.checked_sub(lg_i))
.unwrap()];
s.push(s[i - k] * u_lg_i_sq);
⋮----
Ok((challenges_sq, challenges_inv_sq, s))
⋮----
pub fn verify<IG, IH>(
⋮----
let (u_sq, u_inv_sq, s) = self.verification_scalars(n, transcript)?;
⋮----
.into_iter()
.zip(s.iter())
.map(|(g_i, s_i)| (self.a * s_i) * g_i.borrow())
.take(G.len());
let inv_s = s.iter().rev();
⋮----
.zip(inv_s)
.map(|(h_i, s_i_inv)| (self.b * s_i_inv) * h_i.borrow());
let neg_u_sq = u_sq.iter().map(|ui| -ui);
let neg_u_inv_sq = u_inv_sq.iter().map(|ui| -ui);
⋮----
.iter()
.map(|p| {
p.decompress()
.ok_or(RangeProofVerificationError::Deserialization)
⋮----
.chain(g_times_a_times_s)
.chain(h_times_b_div_s)
.chain(neg_u_sq)
.chain(neg_u_inv_sq),
⋮----
.chain(G.iter())
.chain(H.iter())
.chain(Ls.iter())
.chain(Rs.iter()),
⋮----
Ok(())
⋮----
Err(RangeProofVerificationError::AlgebraicRelation)
⋮----
pub fn serialized_size(&self) -> usize {
(self.L_vec.len() * 2 + 2) * 32
⋮----
pub fn to_bytes(&self) -> Vec<u8> {
let mut buf = Vec::with_capacity(self.serialized_size());
for (l, r) in self.L_vec.iter().zip(self.R_vec.iter()) {
buf.extend_from_slice(l.as_bytes());
buf.extend_from_slice(r.as_bytes());
⋮----
buf.extend_from_slice(self.a.as_bytes());
buf.extend_from_slice(self.b.as_bytes());
⋮----
pub fn from_bytes(slice: &[u8]) -> Result<InnerProductProof, RangeProofVerificationError> {
let b = slice.len();
if !b.is_multiple_of(32) {
return Err(RangeProofVerificationError::Deserialization);
⋮----
if !(num_elements - 2).is_multiple_of(2) {
⋮----
L_vec.push(CompressedRistretto(util::read32(&slice[pos..])));
R_vec.push(CompressedRistretto(util::read32(&slice[pos + 32..])));
⋮----
.into_option()
.ok_or(RangeProofVerificationError::Deserialization)?;
⋮----
Ok(InnerProductProof { L_vec, R_vec, a, b })
⋮----
mod tests {
⋮----
fn test_basic_correctness() {
⋮----
let bp_gens = BulletproofGens::new(n).unwrap();
let G: Vec<RistrettoPoint> = bp_gens.G(n).cloned().collect();
let H: Vec<RistrettoPoint> = bp_gens.H(n).cloned().collect();
⋮----
let a: Vec<_> = (0..n).map(|_| Scalar::random(&mut OsRng)).collect();
let b: Vec<_> = (0..n).map(|_| Scalar::random(&mut OsRng)).collect();
let c = util::inner_product(&a, &b).unwrap();
let G_factors: Vec<Scalar> = iter::repeat_n(Scalar::ONE, n).collect();
⋮----
let H_factors: Vec<Scalar> = util::exp_iter(y_inv).take(n).collect();
let b_prime = b.iter().zip(util::exp_iter(y_inv)).map(|(bi, yi)| bi * yi);
let a_prime = a.iter().cloned();
⋮----
a_prime.chain(b_prime).chain(iter::once(c)),
G.iter().chain(H.iter()).chain(iter::once(&Q)),
⋮----
G.clone(),
H.clone(),
a.clone(),
b.clone(),
⋮----
.unwrap();
assert!(proof
⋮----
let proof = InnerProductProof::from_bytes(proof.to_bytes().as_slice()).unwrap();

================
File: zk-token-sdk/src/range_proof/mod.rs
================
pub mod errors;
⋮----
pub mod generators;
⋮----
pub mod inner_product;
⋮----
pub mod util;
⋮----
pub struct RangeProof {
⋮----
impl RangeProof {
⋮----
pub fn new(
⋮----
let m = amounts.len();
if bit_lengths.len() != m || openings.len() != m {
return Err(RangeProofGenerationError::VectorLengthMismatch);
⋮----
.iter()
.any(|bit_length| *bit_length == 0 || *bit_length > u64::BITS as usize)
⋮----
return Err(RangeProofGenerationError::InvalidBitSize);
⋮----
let nm: usize = bit_lengths.iter().sum();
if !nm.is_power_of_two() {
⋮----
.map_err(|_| RangeProofGenerationError::MaximumGeneratorLengthExceeded)?;
⋮----
let mut gens_iter = bp_gens.G(nm).zip(bp_gens.H(nm));
for (amount_i, n_i) in amounts.iter().zip(bit_lengths.iter()) {
⋮----
let (G_ij, H_ij) = gens_iter.next().unwrap();
let v_ij = Choice::from((amount_i.checked_shr(j as u32).unwrap() & 1) as u8);
⋮----
point.conditional_assign(G_ij, v_ij);
⋮----
let A = A.compress();
let s_L: Vec<Scalar> = (0..nm).map(|_| Scalar::random(&mut OsRng)).collect();
let s_R: Vec<Scalar> = (0..nm).map(|_| Scalar::random(&mut OsRng)).collect();
⋮----
iter::once(&s_blinding).chain(s_L.iter()).chain(s_R.iter()),
iter::once(&(*H)).chain(bp_gens.G(nm)).chain(bp_gens.H(nm)),
⋮----
.compress();
transcript.append_point(b"A", &A);
transcript.append_point(b"S", &S);
let y = transcript.challenge_scalar(b"y");
let z = transcript.challenge_scalar(b"z");
⋮----
let a_L_j = Scalar::from(amount_i.checked_shr(j as u32).unwrap() & 1);
⋮----
i = i.checked_add(1).unwrap();
⋮----
.inner_product(&r_poly)
.ok_or(RangeProofGenerationError::InnerProductLengthMismatch)?;
⋮----
let T_1 = T_1.get_point().compress();
let T_2 = T_2.get_point().compress();
transcript.append_point(b"T_1", &T_1);
transcript.append_point(b"T_2", &T_2);
let x = transcript.challenge_scalar(b"x");
⋮----
agg_opening += exp_z * opening.get_scalar();
⋮----
*t_1_blinding.get_scalar(),
*t_2_blinding.get_scalar(),
⋮----
let t_x = t_poly.eval(x);
let t_x_blinding = t_blinding_poly.eval(x);
transcript.append_scalar(b"t_x", &t_x);
transcript.append_scalar(b"t_x_blinding", &t_x_blinding);
⋮----
let l_vec = l_poly.eval(x);
let r_vec = r_poly.eval(x);
transcript.append_scalar(b"e_blinding", &e_blinding);
let w = transcript.challenge_scalar(b"w");
⋮----
let G_factors: Vec<Scalar> = iter::repeat_n(Scalar::ONE, nm).collect();
let H_factors: Vec<Scalar> = util::exp_iter(y.invert()).take(nm).collect();
transcript.challenge_scalar(b"c");
⋮----
bp_gens.G(nm).cloned().collect(),
bp_gens.H(nm).cloned().collect(),
⋮----
Ok(RangeProof {
⋮----
pub fn verify(
⋮----
if comms.len() != bit_lengths.len() {
return Err(RangeProofVerificationError::VectorLengthMismatch);
⋮----
let m = bit_lengths.len();
⋮----
.map_err(|_| RangeProofVerificationError::MaximumGeneratorLengthExceeded)?;
⋮----
return Err(RangeProofVerificationError::InvalidBitSize);
⋮----
transcript.validate_and_append_point(b"A", &self.A)?;
transcript.validate_and_append_point(b"S", &self.S)?;
⋮----
transcript.validate_and_append_point(b"T_1", &self.T_1)?;
transcript.validate_and_append_point(b"T_2", &self.T_2)?;
⋮----
transcript.append_scalar(b"t_x", &self.t_x);
transcript.append_scalar(b"t_x_blinding", &self.t_x_blinding);
transcript.append_scalar(b"e_blinding", &self.e_blinding);
⋮----
let c = transcript.challenge_scalar(b"c");
let (x_sq, x_inv_sq, s) = self.ipp_proof.verification_scalars(nm, transcript)?;
let s_inv = s.iter().rev();
⋮----
.zip(bit_lengths.iter())
.flat_map(|(exp_z, n_i)| {
⋮----
.take(*n_i)
.map(move |exp_2| exp_2 * exp_z)
⋮----
.collect();
let gs = s.iter().map(|s_i| minus_z - a * s_i);
⋮----
.zip(util::exp_iter(y.invert()))
.zip(concat_z_and_2.iter())
.map(|((s_i_inv, exp_y_inv), z_and_2)| z + exp_y_inv * (zz * z_and_2 - b * s_i_inv));
⋮----
w * (self.t_x - a * b) + c * (delta(&bit_lengths, &y, &z) - self.t_x);
let value_commitment_scalars = util::exp_iter(z).take(m).map(|z_exp| c * zz * z_exp);
⋮----
.chain(iter::once(x))
.chain(iter::once(c * x))
.chain(iter::once(c * x * x))
.chain(iter::once(-self.e_blinding - c * self.t_x_blinding))
.chain(iter::once(basepoint_scalar))
.chain(x_sq.iter().cloned())
.chain(x_inv_sq.iter().cloned())
.chain(gs)
.chain(hs)
.chain(value_commitment_scalars),
iter::once(self.A.decompress())
.chain(iter::once(self.S.decompress()))
.chain(iter::once(self.T_1.decompress()))
.chain(iter::once(self.T_2.decompress()))
.chain(iter::once(Some(*H)))
.chain(iter::once(Some(G)))
.chain(self.ipp_proof.L_vec.iter().map(|L| L.decompress()))
.chain(self.ipp_proof.R_vec.iter().map(|R| R.decompress()))
.chain(bp_gens.G(nm).map(|&x| Some(x)))
.chain(bp_gens.H(nm).map(|&x| Some(x)))
.chain(comms.iter().map(|V| Some(*V.get_point()))),
⋮----
.ok_or(RangeProofVerificationError::MultiscalarMul)?;
if mega_check.is_identity() {
Ok(())
⋮----
Err(RangeProofVerificationError::AlgebraicRelation)
⋮----
pub fn to_bytes(&self) -> Vec<u8> {
let mut buf = Vec::with_capacity(7 * 32 + self.ipp_proof.serialized_size());
buf.extend_from_slice(self.A.as_bytes());
buf.extend_from_slice(self.S.as_bytes());
buf.extend_from_slice(self.T_1.as_bytes());
buf.extend_from_slice(self.T_2.as_bytes());
buf.extend_from_slice(self.t_x.as_bytes());
buf.extend_from_slice(self.t_x_blinding.as_bytes());
buf.extend_from_slice(self.e_blinding.as_bytes());
buf.extend_from_slice(&self.ipp_proof.to_bytes());
⋮----
pub fn from_bytes(slice: &[u8]) -> Result<RangeProof, RangeProofVerificationError> {
if !slice.len().is_multiple_of(32) {
return Err(RangeProofVerificationError::Deserialization);
⋮----
if slice.len() < 7 * 32 {
⋮----
let A = CompressedRistretto(util::read32(&slice[0..]));
let S = CompressedRistretto(util::read32(&slice[32..]));
let T_1 = CompressedRistretto(util::read32(&slice[2 * 32..]));
let T_2 = CompressedRistretto(util::read32(&slice[3 * 32..]));
⋮----
.into_option()
.ok_or(RangeProofVerificationError::Deserialization)?;
⋮----
fn delta(bit_lengths: &[usize], y: &Scalar, z: &Scalar) -> Scalar {
⋮----
for n_i in bit_lengths.iter() {
⋮----
mod tests {
⋮----
fn test_single_rangeproof() {
⋮----
RangeProof::new(vec![55], vec![32], vec![&open], &mut transcript_create).unwrap();
assert!(proof
⋮----
fn test_aggregated_rangeproof() {
⋮----
vec![55, 77, 99],
vec![64, 32, 32],
vec![&open_1, &open_2, &open_3],
⋮----
.unwrap();

================
File: zk-token-sdk/src/range_proof/util.rs
================
use curve25519_dalek::scalar::Scalar;
pub struct VecPoly1(pub Vec<Scalar>, pub Vec<Scalar>);
impl VecPoly1 {
pub fn zero(n: usize) -> Self {
VecPoly1(vec![Scalar::ZERO; n], vec![Scalar::ZERO; n])
⋮----
pub fn inner_product(&self, rhs: &VecPoly1) -> Option<Poly2> {
⋮----
let t0 = inner_product(&l.0, &r.0)?;
let t2 = inner_product(&l.1, &r.1)?;
let l0_plus_l1 = add_vec(&l.0, &l.1);
let r0_plus_r1 = add_vec(&r.0, &r.1);
let t1 = inner_product(&l0_plus_l1, &r0_plus_r1)? - t0 - t2;
Some(Poly2(t0, t1, t2))
⋮----
pub fn eval(&self, x: Scalar) -> Vec<Scalar> {
let n = self.0.len();
let mut out = vec![Scalar::ZERO; n];
⋮----
pub struct Poly2(pub Scalar, pub Scalar, pub Scalar);
impl Poly2 {
pub fn eval(&self, x: Scalar) -> Scalar {
⋮----
pub struct ScalarExp {
⋮----
impl Iterator for ScalarExp {
type Item = Scalar;
fn next(&mut self) -> Option<Scalar> {
⋮----
Some(exp_x)
⋮----
fn size_hint(&self) -> (usize, Option<usize>) {
⋮----
pub fn exp_iter(x: Scalar) -> ScalarExp {
⋮----
pub fn add_vec(a: &[Scalar], b: &[Scalar]) -> Vec<Scalar> {
if a.len() != b.len() {
⋮----
let mut out = vec![Scalar::ZERO; b.len()];
for i in 0..a.len() {
⋮----
pub fn read32(data: &[u8]) -> [u8; 32] {
⋮----
buf32[..].copy_from_slice(&data[..32]);
⋮----
pub fn inner_product(a: &[Scalar], b: &[Scalar]) -> Option<Scalar> {
⋮----
Some(out)
⋮----
pub fn sum_of_powers(x: &Scalar, n: usize) -> Scalar {
if !n.is_power_of_two() {
return sum_of_powers_slow(x, n);
⋮----
fn sum_of_powers_slow(x: &Scalar, n: usize) -> Scalar {
exp_iter(*x).take(n).sum()

================
File: zk-token-sdk/src/sigma_proofs/batched_grouped_ciphertext_validity_proof/handles_2.rs
================
pub struct BatchedGroupedCiphertext2HandlesValidityProof(GroupedCiphertext2HandlesValidityProof);
⋮----
impl BatchedGroupedCiphertext2HandlesValidityProof {
pub fn new<T: Into<Scalar>>(
⋮----
transcript.batched_grouped_ciphertext_validity_proof_domain_separator();
let t = transcript.challenge_scalar(b"t");
let batched_message = amount_lo.into() + amount_hi.into() * t;
⋮----
BatchedGroupedCiphertext2HandlesValidityProof(GroupedCiphertext2HandlesValidityProof::new(
⋮----
pub fn verify(
⋮----
validity_proof.verify(
⋮----
pub fn to_bytes(&self) -> [u8; 160] {
self.0.to_bytes()
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, ValidityProofVerificationError> {
GroupedCiphertext2HandlesValidityProof::from_bytes(bytes).map(Self)
⋮----
mod test {
⋮----
fn test_batched_grouped_ciphertext_validity_proof() {
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
let destination_handle_lo = destination_pubkey.decrypt_handle(&open_lo);
let destination_handle_hi = destination_pubkey.decrypt_handle(&open_hi);
let auditor_handle_lo = auditor_pubkey.decrypt_handle(&open_lo);
let auditor_handle_hi = auditor_pubkey.decrypt_handle(&open_hi);
⋮----
assert!(proof

================
File: zk-token-sdk/src/sigma_proofs/batched_grouped_ciphertext_validity_proof/handles_3.rs
================
pub struct BatchedGroupedCiphertext3HandlesValidityProof(GroupedCiphertext3HandlesValidityProof);
⋮----
impl BatchedGroupedCiphertext3HandlesValidityProof {
pub fn new<T: Into<Scalar>>(
⋮----
transcript.batched_grouped_ciphertext_validity_proof_domain_separator();
let t = transcript.challenge_scalar(b"t");
let batched_message = amount_lo.into() + amount_hi.into() * t;
⋮----
BatchedGroupedCiphertext3HandlesValidityProof(GroupedCiphertext3HandlesValidityProof::new(
⋮----
pub fn verify(
⋮----
validity_proof.verify(
⋮----
pub fn to_bytes(&self) -> [u8; BATCHED_GROUPED_CIPHERTEXT_3_HANDLES_VALIDITY_PROOF_LEN] {
self.0.to_bytes()
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, ValidityProofVerificationError> {
GroupedCiphertext3HandlesValidityProof::from_bytes(bytes).map(Self)
⋮----
mod test {
⋮----
fn test_batched_grouped_ciphertext_validity_proof() {
⋮----
let source_pubkey = source_keypair.pubkey();
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
let source_handle_lo = source_pubkey.decrypt_handle(&open_lo);
let source_handle_hi = source_pubkey.decrypt_handle(&open_hi);
let destination_handle_lo = destination_pubkey.decrypt_handle(&open_lo);
let destination_handle_hi = destination_pubkey.decrypt_handle(&open_hi);
let auditor_handle_lo = auditor_pubkey.decrypt_handle(&open_lo);
let auditor_handle_hi = auditor_pubkey.decrypt_handle(&open_hi);
⋮----
assert!(proof

================
File: zk-token-sdk/src/sigma_proofs/batched_grouped_ciphertext_validity_proof/mod.rs
================
mod handles_2;
mod handles_3;

================
File: zk-token-sdk/src/sigma_proofs/grouped_ciphertext_validity_proof/handles_2.rs
================
pub struct GroupedCiphertext2HandlesValidityProof {
⋮----
impl GroupedCiphertext2HandlesValidityProof {
pub fn new<T: Into<Scalar>>(
⋮----
transcript.grouped_ciphertext_validity_proof_domain_separator();
let P_dest = destination_pubkey.get_point();
let P_auditor = auditor_pubkey.get_point();
let x = amount.into();
let r = opening.get_scalar();
⋮----
let Y_0 = RistrettoPoint::multiscalar_mul(vec![&y_r, &y_x], vec![&(*H), &G]).compress();
let Y_1 = (&y_r * P_dest).compress();
let Y_2 = (&y_r * P_auditor).compress();
transcript.append_point(b"Y_0", &Y_0);
transcript.append_point(b"Y_1", &Y_1);
transcript.append_point(b"Y_2", &Y_2);
let c = transcript.challenge_scalar(b"c");
transcript.challenge_scalar(b"w");
⋮----
y_r.zeroize();
y_x.zeroize();
⋮----
pub fn verify(
⋮----
transcript.validate_and_append_point(b"Y_0", &self.Y_0)?;
transcript.validate_and_append_point(b"Y_1", &self.Y_1)?;
transcript.append_point(b"Y_2", &self.Y_2);
⋮----
let w = transcript.challenge_scalar(b"w");
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
let C = commitment.get_point();
let D_dest = destination_handle.get_point();
let D_auditor = auditor_handle.get_point();
⋮----
vec![
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; GROUPED_CIPHERTEXT_2_HANDLES_VALIDITY_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(self.Y_0.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_1.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_2.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_r.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_x.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, ValidityProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y_0 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_1 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_2 = ristretto_point_from_optional_slice(chunks.next())?;
let z_r = canonical_scalar_from_optional_slice(chunks.next())?;
let z_x = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(GroupedCiphertext2HandlesValidityProof {
⋮----
mod test {
⋮----
fn test_grouped_ciphertext_validity_proof_correctness() {
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
let destination_handle = destination_pubkey.decrypt_handle(&opening);
let auditor_handle = auditor_pubkey.decrypt_handle(&opening);
⋮----
assert!(proof
⋮----
fn test_grouped_ciphertext_validity_proof_edge_cases() {
let destination_pubkey = ElGamalPubkey::try_from([0u8; 32].as_slice()).unwrap();
⋮----
let commitment = PedersenCommitment::from_bytes(&[0u8; 32]).unwrap();
let opening = PedersenOpening::from_bytes(&[0u8; 32]).unwrap();

================
File: zk-token-sdk/src/sigma_proofs/grouped_ciphertext_validity_proof/handles_3.rs
================
pub struct GroupedCiphertext3HandlesValidityProof {
⋮----
impl GroupedCiphertext3HandlesValidityProof {
pub fn new<T: Into<Scalar>>(
⋮----
transcript.grouped_ciphertext_validity_proof_domain_separator();
let P_source = source_pubkey.get_point();
let P_destination = destination_pubkey.get_point();
let P_auditor = auditor_pubkey.get_point();
let x = amount.into();
let r = opening.get_scalar();
⋮----
let Y_0 = RistrettoPoint::multiscalar_mul(vec![&y_r, &y_x], vec![&(*H), &G]).compress();
let Y_1 = (&y_r * P_source).compress();
let Y_2 = (&y_r * P_destination).compress();
let Y_3 = (&y_r * P_auditor).compress();
transcript.append_point(b"Y_0", &Y_0);
transcript.append_point(b"Y_1", &Y_1);
transcript.append_point(b"Y_2", &Y_2);
transcript.append_point(b"Y_3", &Y_3);
let c = transcript.challenge_scalar(b"c");
transcript.challenge_scalar(b"w");
⋮----
y_r.zeroize();
y_x.zeroize();
⋮----
pub fn verify(
⋮----
transcript.validate_and_append_point(b"Y_0", &self.Y_0)?;
transcript.validate_and_append_point(b"Y_1", &self.Y_1)?;
transcript.validate_and_append_point(b"Y_2", &self.Y_2)?;
transcript.append_point(b"Y_3", &self.Y_3);
⋮----
let w = transcript.challenge_scalar(b"w");
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
let C = commitment.get_point();
let D_source = source_handle.get_point();
let D_destination = destination_handle.get_point();
let D_auditor = auditor_handle.get_point();
⋮----
vec![
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; GROUPED_CIPHERTEXT_3_HANDLES_VALIDITY_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(self.Y_0.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_1.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_2.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_3.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_r.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_x.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, ValidityProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y_0 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_1 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_2 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_3 = ristretto_point_from_optional_slice(chunks.next())?;
let z_r = canonical_scalar_from_optional_slice(chunks.next())?;
let z_x = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(GroupedCiphertext3HandlesValidityProof {
⋮----
mod test {
⋮----
fn test_grouped_ciphertext_3_handles_validity_proof_correctness() {
⋮----
let source_pubkey = source_keypair.pubkey();
⋮----
let destination_pubkey = destination_keypair.pubkey();
⋮----
let auditor_pubkey = auditor_keypair.pubkey();
⋮----
let source_handle = source_pubkey.decrypt_handle(&opening);
let destination_handle = destination_pubkey.decrypt_handle(&opening);
let auditor_handle = auditor_pubkey.decrypt_handle(&opening);
⋮----
assert!(proof
⋮----
fn test_grouped_ciphertext_3_handles_validity_proof_edge_cases() {
let source_pubkey = ElGamalPubkey::try_from([0u8; 32].as_slice()).unwrap();
let destination_pubkey = ElGamalPubkey::try_from([0u8; 32].as_slice()).unwrap();
⋮----
let source_handle = destination_pubkey.decrypt_handle(&opening);
⋮----
let commitment = PedersenCommitment::from_bytes(&[0u8; 32]).unwrap();
let opening = PedersenOpening::from_bytes(&[0u8; 32]).unwrap();
⋮----
let source_handle = source_pubkey.decrypt_handle(&zeroed_opening);
let destination_handle = destination_pubkey.decrypt_handle(&zeroed_opening);
let auditor_handle = auditor_pubkey.decrypt_handle(&zeroed_opening);

================
File: zk-token-sdk/src/sigma_proofs/grouped_ciphertext_validity_proof/mod.rs
================
mod handles_2;
mod handles_3;

================
File: zk-token-sdk/src/sigma_proofs/ciphertext_ciphertext_equality_proof.rs
================
pub struct CiphertextCiphertextEqualityProof {
⋮----
impl CiphertextCiphertextEqualityProof {
pub fn new(
⋮----
transcript.equality_proof_domain_separator();
let P_source = source_keypair.pubkey().get_point();
let D_source = source_ciphertext.handle.get_point();
let P_destination = destination_pubkey.get_point();
let s = source_keypair.secret().get_scalar();
⋮----
let r = destination_opening.get_scalar();
⋮----
let Y_0 = (&y_s * P_source).compress();
let Y_1 = RistrettoPoint::multiscalar_mul(vec![&y_x, &y_s], vec![&G, D_source]).compress();
let Y_2 = RistrettoPoint::multiscalar_mul(vec![&y_x, &y_r], vec![&G, &(*H)]).compress();
let Y_3 = (&y_r * P_destination).compress();
transcript.append_point(b"Y_0", &Y_0);
transcript.append_point(b"Y_1", &Y_1);
transcript.append_point(b"Y_2", &Y_2);
transcript.append_point(b"Y_3", &Y_3);
let c = transcript.challenge_scalar(b"c");
transcript.challenge_scalar(b"w");
⋮----
y_s.zeroize();
y_x.zeroize();
y_r.zeroize();
⋮----
pub fn verify(
⋮----
let P_source = source_pubkey.get_point();
let C_source = source_ciphertext.commitment.get_point();
⋮----
let C_destination = destination_ciphertext.commitment.get_point();
let D_destination = destination_ciphertext.handle.get_point();
transcript.validate_and_append_point(b"Y_0", &self.Y_0)?;
transcript.validate_and_append_point(b"Y_1", &self.Y_1)?;
transcript.validate_and_append_point(b"Y_2", &self.Y_2)?;
transcript.validate_and_append_point(b"Y_3", &self.Y_3)?;
⋮----
let w = transcript.challenge_scalar(b"w");
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
vec![
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; CIPHERTEXT_CIPHERTEXT_EQUALITY_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(self.Y_0.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_1.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_2.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_3.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_s.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_x.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_r.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, EqualityProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y_0 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_1 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_2 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_3 = ristretto_point_from_optional_slice(chunks.next())?;
let z_s = canonical_scalar_from_optional_slice(chunks.next())?;
let z_x = canonical_scalar_from_optional_slice(chunks.next())?;
let z_r = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(CiphertextCiphertextEqualityProof {
⋮----
mod test {
⋮----
fn test_ciphertext_ciphertext_equality_proof_correctness() {
⋮----
let source_ciphertext = source_keypair.pubkey().encrypt(message);
⋮----
.pubkey()
.encrypt_with(message, &destination_opening);
⋮----
destination_keypair.pubkey(),
⋮----
assert!(proof
⋮----
let source_ciphertext = source_keypair.pubkey().encrypt(source_message);
⋮----
.encrypt_with(destination_message, &destination_opening);

================
File: zk-token-sdk/src/sigma_proofs/ciphertext_commitment_equality_proof.rs
================
pub struct CiphertextCommitmentEqualityProof {
⋮----
impl CiphertextCommitmentEqualityProof {
pub fn new(
⋮----
transcript.equality_proof_domain_separator();
let P_source = source_keypair.pubkey().get_point();
let D_source = source_ciphertext.handle.get_point();
let s = source_keypair.secret().get_scalar();
⋮----
let r = opening.get_scalar();
⋮----
let Y_0 = (&y_s * P_source).compress();
let Y_1 = RistrettoPoint::multiscalar_mul(vec![&y_x, &y_s], vec![&G, D_source]).compress();
let Y_2 = RistrettoPoint::multiscalar_mul(vec![&y_x, &y_r], vec![&G, &(*H)]).compress();
transcript.append_point(b"Y_0", &Y_0);
transcript.append_point(b"Y_1", &Y_1);
transcript.append_point(b"Y_2", &Y_2);
let c = transcript.challenge_scalar(b"c");
transcript.challenge_scalar(b"w");
⋮----
y_s.zeroize();
y_x.zeroize();
y_r.zeroize();
⋮----
pub fn verify(
⋮----
let P_source = source_pubkey.get_point();
let C_source = source_ciphertext.commitment.get_point();
⋮----
let C_destination = destination_commitment.get_point();
transcript.validate_and_append_point(b"Y_0", &self.Y_0)?;
transcript.validate_and_append_point(b"Y_1", &self.Y_1)?;
transcript.validate_and_append_point(b"Y_2", &self.Y_2)?;
⋮----
let w = transcript.challenge_scalar(b"w");
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
vec![
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; CIPHERTEXT_COMMITMENT_EQUALITY_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(self.Y_0.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_1.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_2.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_s.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_x.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z_r.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, EqualityProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y_0 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_1 = ristretto_point_from_optional_slice(chunks.next())?;
let Y_2 = ristretto_point_from_optional_slice(chunks.next())?;
let z_s = canonical_scalar_from_optional_slice(chunks.next())?;
let z_x = canonical_scalar_from_optional_slice(chunks.next())?;
let z_r = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(CiphertextCommitmentEqualityProof {
⋮----
mod test {
⋮----
fn test_ciphertext_commitment_equality_proof_correctness() {
⋮----
let source_ciphertext = source_keypair.pubkey().encrypt(message);
⋮----
assert!(proof
⋮----
let source_ciphertext = source_keypair.pubkey().encrypt(encrypted_message);
⋮----
fn test_ciphertext_commitment_equality_proof_edge_cases() {
let public = ElGamalPubkey::try_from([0u8; 32].as_slice()).unwrap();
⋮----
let ciphertext = elgamal_keypair.pubkey().encrypt(message);
⋮----
let ciphertext = ElGamalCiphertext::from_bytes(&[0u8; 64]).unwrap();
let commitment = PedersenCommitment::from_bytes(&[0u8; 32]).unwrap();
let opening = PedersenOpening::from_bytes(&[0u8; 32]).unwrap();

================
File: zk-token-sdk/src/sigma_proofs/errors.rs
================
pub enum SigmaProofVerificationError {
⋮----
macro_rules! impl_from_transcript_error {
⋮----
pub struct EqualityProofVerificationError(#[from] pub(crate) SigmaProofVerificationError);
impl_from_transcript_error!(EqualityProofVerificationError);
⋮----
pub struct ValidityProofVerificationError(#[from] pub(crate) SigmaProofVerificationError);
impl_from_transcript_error!(ValidityProofVerificationError);
⋮----
pub struct ZeroBalanceProofVerificationError(#[from] pub(crate) SigmaProofVerificationError);
impl_from_transcript_error!(ZeroBalanceProofVerificationError);
⋮----
pub struct FeeSigmaProofVerificationError(#[from] pub(crate) SigmaProofVerificationError);
impl_from_transcript_error!(FeeSigmaProofVerificationError);
⋮----
pub struct PubkeyValidityProofVerificationError(#[from] pub(crate) SigmaProofVerificationError);
impl_from_transcript_error!(PubkeyValidityProofVerificationError);

================
File: zk-token-sdk/src/sigma_proofs/fee_proof.rs
================
pub struct FeeSigmaProof {
⋮----
impl FeeSigmaProof {
pub fn new(
⋮----
let mut transcript_fee_above_max = transcript.clone();
let mut transcript_fee_below_max = transcript.clone();
⋮----
transcript.append_point(b"Y_max_proof", &fee_max_proof.Y_max_proof);
transcript.append_point(b"Y_delta", &fee_equality_proof.Y_delta);
transcript.append_point(b"Y_claimed", &fee_equality_proof.Y_claimed);
transcript.challenge_scalar(b"c");
transcript.challenge_scalar(b"w");
⋮----
fn create_proof_fee_above_max(
⋮----
let C_delta = delta_commitment.get_point();
let C_claimed = claimed_commitment.get_point();
⋮----
vec![z_x, z_delta, -c_equality],
vec![&G, &(*H), C_delta],
⋮----
.compress();
⋮----
vec![z_x, z_claimed, -c_equality],
vec![&G, &(*H), C_claimed],
⋮----
let r_fee = fee_opening.get_scalar();
⋮----
let Y_max_proof = (y_max_proof * &(*H)).compress();
transcript.append_point(b"Y_max_proof", &Y_max_proof);
transcript.append_point(b"Y_delta", &Y_delta);
transcript.append_point(b"Y_claimed", &Y_claimed);
let c = transcript.challenge_scalar(b"c");
⋮----
fn create_proof_fee_below_max(
⋮----
let C_fee = fee_commitment.get_point();
⋮----
vec![z_max_proof, -c_max_proof, c_max_proof * m],
vec![&(*H), C_fee, &G],
⋮----
let r_delta = delta_opening.get_scalar();
let r_claimed = claimed_opening.get_scalar();
⋮----
RistrettoPoint::multiscalar_mul(vec![y_x, y_delta], vec![&G, &(*H)]).compress();
⋮----
RistrettoPoint::multiscalar_mul(vec![y_x, y_claimed], vec![&G, &(*H)]).compress();
⋮----
pub fn verify(
⋮----
let C_max = fee_commitment.get_point();
⋮----
transcript.validate_and_append_point(b"Y_max_proof", &self.fee_max_proof.Y_max_proof)?;
transcript.validate_and_append_point(b"Y_delta", &self.fee_equality_proof.Y_delta)?;
transcript.validate_and_append_point(b"Y_claimed", &self.fee_equality_proof.Y_claimed)?;
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
let w = transcript.challenge_scalar(b"w");
⋮----
vec![
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; FEE_SIGMA_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
⋮----
.next()
.unwrap()
.copy_from_slice(self.fee_max_proof.Y_max_proof.as_bytes());
⋮----
.copy_from_slice(self.fee_max_proof.z_max_proof.as_bytes());
⋮----
.copy_from_slice(self.fee_max_proof.c_max_proof.as_bytes());
⋮----
.copy_from_slice(self.fee_equality_proof.Y_delta.as_bytes());
⋮----
.copy_from_slice(self.fee_equality_proof.Y_claimed.as_bytes());
⋮----
.copy_from_slice(self.fee_equality_proof.z_x.as_bytes());
⋮----
.copy_from_slice(self.fee_equality_proof.z_delta.as_bytes());
⋮----
.copy_from_slice(self.fee_equality_proof.z_claimed.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, FeeSigmaProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y_max_proof = ristretto_point_from_optional_slice(chunks.next())?;
let z_max_proof = canonical_scalar_from_optional_slice(chunks.next())?;
let c_max_proof = canonical_scalar_from_optional_slice(chunks.next())?;
let Y_delta = ristretto_point_from_optional_slice(chunks.next())?;
let Y_claimed = ristretto_point_from_optional_slice(chunks.next())?;
let z_x = canonical_scalar_from_optional_slice(chunks.next())?;
let z_delta = canonical_scalar_from_optional_slice(chunks.next())?;
let z_claimed = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(Self {
⋮----
pub struct FeeMaxProof {
⋮----
impl ConditionallySelectable for FeeMaxProof {
fn conditional_select(a: &Self, b: &Self, choice: Choice) -> Self {
⋮----
Y_max_proof: conditional_select_ristretto(&a.Y_max_proof, &b.Y_max_proof, choice),
⋮----
pub struct FeeEqualityProof {
⋮----
impl ConditionallySelectable for FeeEqualityProof {
⋮----
Y_delta: conditional_select_ristretto(&a.Y_delta, &b.Y_delta, choice),
Y_claimed: conditional_select_ristretto(&a.Y_claimed, &b.Y_claimed, choice),
⋮----
fn conditional_select_ristretto(
⋮----
bytes[i] = u8::conditional_select(&a.as_bytes()[i], &b.as_bytes()[i], choice);
⋮----
CompressedRistretto(bytes)
⋮----
mod test {
⋮----
fn test_fee_above_max_proof() {
⋮----
assert!(proof
⋮----
fn test_fee_below_max_proof() {
⋮----
assert_eq!(
⋮----
fn test_fee_delta_is_zero() {

================
File: zk-token-sdk/src/sigma_proofs/mod.rs
================
pub mod errors;
⋮----
pub mod batched_grouped_ciphertext_validity_proof;
⋮----
pub mod ciphertext_ciphertext_equality_proof;
⋮----
pub mod ciphertext_commitment_equality_proof;
⋮----
pub mod fee_proof;
⋮----
pub mod grouped_ciphertext_validity_proof;
⋮----
pub mod pubkey_proof;
⋮----
pub mod zero_balance_proof;
⋮----
fn ristretto_point_from_optional_slice(
⋮----
return Err(SigmaProofVerificationError::Deserialization);
⋮----
if slice.len() != RISTRETTO_POINT_LEN {
⋮----
CompressedRistretto::from_slice(slice).map_err(|_| SigmaProofVerificationError::Deserialization)
⋮----
fn canonical_scalar_from_optional_slice(
⋮----
.and_then(|slice| (slice.len() == SCALAR_LEN).then_some(slice))
.and_then(|slice| slice.try_into().ok())
.and_then(|bytes| Scalar::from_canonical_bytes(bytes).into())
.ok_or(SigmaProofVerificationError::Deserialization)

================
File: zk-token-sdk/src/sigma_proofs/pubkey_proof.rs
================
pub struct PubkeyValidityProof {
⋮----
impl PubkeyValidityProof {
pub fn new(elgamal_keypair: &ElGamalKeypair, transcript: &mut Transcript) -> Self {
transcript.pubkey_proof_domain_separator();
let s = elgamal_keypair.secret().get_scalar();
assert!(s != &Scalar::ZERO);
let s_inv = s.invert();
⋮----
let Y = (&y * &(*H)).compress();
transcript.append_point(b"Y", &Y);
let c = transcript.challenge_scalar(b"c");
⋮----
y.zeroize();
⋮----
pub fn verify(
⋮----
let P = elgamal_pubkey.get_point();
transcript.validate_and_append_point(b"Y", &self.Y)?;
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
vec![&self.z, &(-&c), &(-&Scalar::ONE)],
vec![&(*H), P, &Y],
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; PUBKEY_VALIDITY_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(self.Y.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, PubkeyValidityProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y = ristretto_point_from_optional_slice(chunks.next())?;
let z = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(PubkeyValidityProof { Y, z })
⋮----
mod test {
⋮----
fn test_pubkey_proof_correctness() {
⋮----
assert!(proof
⋮----
ElGamalKeypair::new_from_signer(&Keypair::new(), Pubkey::default().as_ref()).unwrap();

================
File: zk-token-sdk/src/sigma_proofs/zero_balance_proof.rs
================
pub struct ZeroBalanceProof {
⋮----
impl ZeroBalanceProof {
pub fn new(
⋮----
transcript.zero_balance_proof_domain_separator();
let P = elgamal_keypair.pubkey().get_point();
let s = elgamal_keypair.secret().get_scalar();
let D = ciphertext.handle.get_point();
⋮----
let Y_P = (&y * P).compress();
let Y_D = (&y * D).compress();
transcript.append_point(b"Y_P", &Y_P);
transcript.append_point(b"Y_D", &Y_D);
let c = transcript.challenge_scalar(b"c");
transcript.challenge_scalar(b"w");
⋮----
y.zeroize();
⋮----
pub fn verify(
⋮----
let P = elgamal_pubkey.get_point();
let C = ciphertext.commitment.get_point();
⋮----
transcript.validate_and_append_point(b"Y_P", &self.Y_P)?;
transcript.append_point(b"Y_D", &self.Y_D);
⋮----
let w = transcript.challenge_scalar(b"w");
⋮----
.decompress()
.ok_or(SigmaProofVerificationError::Deserialization)?;
⋮----
vec![
⋮----
if check.is_identity() {
Ok(())
⋮----
Err(SigmaProofVerificationError::AlgebraicRelation.into())
⋮----
pub fn to_bytes(&self) -> [u8; ZERO_BALANCE_PROOF_LEN] {
⋮----
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(self.Y_P.as_bytes());
chunks.next().unwrap().copy_from_slice(self.Y_D.as_bytes());
chunks.next().unwrap().copy_from_slice(self.z.as_bytes());
⋮----
pub fn from_bytes(bytes: &[u8]) -> Result<Self, ZeroBalanceProofVerificationError> {
let mut chunks = bytes.chunks(UNIT_LEN);
let Y_P = ristretto_point_from_optional_slice(chunks.next())?;
let Y_D = ristretto_point_from_optional_slice(chunks.next())?;
let z = canonical_scalar_from_optional_slice(chunks.next())?;
Ok(ZeroBalanceProof { Y_P, Y_D, z })
⋮----
mod test {
⋮----
fn test_zero_balance_proof_correctness() {
⋮----
let elgamal_ciphertext = source_keypair.pubkey().encrypt(0_u64);
⋮----
assert!(proof
⋮----
let elgamal_ciphertext = source_keypair.pubkey().encrypt(1_u64);
⋮----
fn test_zero_balance_proof_edge_cases() {
⋮----
let ciphertext = ElGamalCiphertext::from_bytes(&[0u8; 64]).unwrap();
⋮----
let zeroed_commitment = PedersenCommitment::from_bytes(&[0u8; 32]).unwrap();
⋮----
.pubkey()
.decrypt_handle(&PedersenOpening::new_rand());
⋮----
handle: DecryptHandle::from_bytes(&[0u8; 32]).unwrap(),
⋮----
let public = ElGamalPubkey::try_from([0u8; 32].as_slice()).unwrap();
let ciphertext = public.encrypt(0_u64);

================
File: zk-token-sdk/src/zk_token_elgamal/pod/auth_encryption.rs
================
pub struct AeCiphertext(pub [u8; AE_CIPHERTEXT_LEN]);
unsafe impl Zeroable for AeCiphertext {}
unsafe impl Pod for AeCiphertext {}
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
write!(f, "{:?}", self.0)
⋮----
write!(f, "{}", BASE64_STANDARD.encode(self.0))
⋮----
impl_from_str!(
⋮----
impl Default for AeCiphertext {
fn default() -> Self {
⋮----
fn from(decoded_ciphertext: decoded::AeCiphertext) -> Self {
Self(decoded_ciphertext.to_bytes())
⋮----
type Error = AuthenticatedEncryptionError;
fn try_from(pod_ciphertext: AeCiphertext) -> Result<Self, Self::Error> {
Self::from_bytes(&pod_ciphertext.0).ok_or(AuthenticatedEncryptionError::Deserialization)
⋮----
mod tests {
⋮----
fn ae_ciphertext_fromstr() {
⋮----
let expected_ae_ciphertext: AeCiphertext = ae_key.encrypt(0_u64).into();
let ae_ciphertext_base64_str = format!("{expected_ae_ciphertext}");
let computed_ae_ciphertext = AeCiphertext::from_str(&ae_ciphertext_base64_str).unwrap();
assert_eq!(expected_ae_ciphertext, computed_ae_ciphertext);

================
File: zk-token-sdk/src/zk_token_elgamal/pod/elgamal.rs
================
pub struct ElGamalCiphertext(pub [u8; ELGAMAL_CIPHERTEXT_LEN]);
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
write!(f, "{:?}", self.0)
⋮----
write!(f, "{}", BASE64_STANDARD.encode(self.0))
⋮----
impl Default for ElGamalCiphertext {
fn default() -> Self {
⋮----
impl_from_str!(
⋮----
fn from(decoded_ciphertext: decoded::ElGamalCiphertext) -> Self {
Self(decoded_ciphertext.to_bytes())
⋮----
type Error = ElGamalError;
fn try_from(pod_ciphertext: ElGamalCiphertext) -> Result<Self, Self::Error> {
Self::from_bytes(&pod_ciphertext.0).ok_or(ElGamalError::CiphertextDeserialization)
⋮----
pub struct ElGamalPubkey(pub [u8; ELGAMAL_PUBKEY_LEN]);
⋮----
fn from(decoded_pubkey: decoded::ElGamalPubkey) -> Self {
Self(decoded_pubkey.into())
⋮----
fn try_from(pod_pubkey: ElGamalPubkey) -> Result<Self, Self::Error> {
Self::try_from(pod_pubkey.0.as_slice())
⋮----
pub struct DecryptHandle(pub [u8; DECRYPT_HANDLE_LEN]);
⋮----
fn from(decoded_handle: decoded::DecryptHandle) -> Self {
Self(decoded_handle.to_bytes())
⋮----
fn from(pod_handle: DecryptHandle) -> Self {
Self(pod_handle.0)
⋮----
fn try_from(pod_handle: DecryptHandle) -> Result<Self, Self::Error> {
Self::from_bytes(&pod_handle.0).ok_or(ElGamalError::CiphertextDeserialization)
⋮----
mod tests {
⋮----
fn elgamal_pubkey_fromstr() {
⋮----
let expected_elgamal_pubkey: ElGamalPubkey = (*elgamal_keypair.pubkey()).into();
let elgamal_pubkey_base64_str = format!("{expected_elgamal_pubkey}");
let computed_elgamal_pubkey = ElGamalPubkey::from_str(&elgamal_pubkey_base64_str).unwrap();
assert_eq!(expected_elgamal_pubkey, computed_elgamal_pubkey);
⋮----
fn elgamal_ciphertext_fromstr() {
⋮----
elgamal_keypair.pubkey().encrypt(0_u64).into();
let elgamal_ciphertext_base64_str = format!("{expected_elgamal_ciphertext}");
⋮----
ElGamalCiphertext::from_str(&elgamal_ciphertext_base64_str).unwrap();
assert_eq!(expected_elgamal_ciphertext, computed_elgamal_ciphertext);

================
File: zk-token-sdk/src/zk_token_elgamal/pod/grouped_elgamal.rs
================
use crate::encryption::grouped_elgamal::GroupedElGamalCiphertext;
⋮----
macro_rules! impl_extract {
⋮----
pub struct GroupedElGamalCiphertext2Handles(pub [u8; GROUPED_ELGAMAL_CIPHERTEXT_2_HANDLES]);
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
write!(f, "{:?}", self.0)
⋮----
impl Default for GroupedElGamalCiphertext2Handles {
fn default() -> Self {
⋮----
fn from(decoded_ciphertext: GroupedElGamalCiphertext<2>) -> Self {
Self(decoded_ciphertext.to_bytes().try_into().unwrap())
⋮----
type Error = ElGamalError;
fn try_from(pod_ciphertext: GroupedElGamalCiphertext2Handles) -> Result<Self, Self::Error> {
Self::from_bytes(&pod_ciphertext.0).ok_or(ElGamalError::CiphertextDeserialization)
⋮----
impl_extract!(TYPE = GroupedElGamalCiphertext2Handles);
⋮----
pub struct GroupedElGamalCiphertext3Handles(pub [u8; GROUPED_ELGAMAL_CIPHERTEXT_3_HANDLES]);
⋮----
impl Default for GroupedElGamalCiphertext3Handles {
⋮----
fn from(decoded_ciphertext: GroupedElGamalCiphertext<3>) -> Self {
⋮----
fn try_from(pod_ciphertext: GroupedElGamalCiphertext3Handles) -> Result<Self, Self::Error> {
⋮----
impl_extract!(TYPE = GroupedElGamalCiphertext3Handles);
⋮----
mod tests {
⋮----
fn test_2_handles_ciphertext_extraction() {
⋮----
[elgamal_keypair_0.pubkey(), elgamal_keypair_1.pubkey()],
⋮----
let pod_grouped_ciphertext: GroupedElGamalCiphertext2Handles = grouped_ciphertext.into();
let expected_pod_commitment: PedersenCommitment = commitment.into();
let actual_pod_commitment = pod_grouped_ciphertext.extract_commitment();
assert_eq!(expected_pod_commitment, actual_pod_commitment);
let expected_ciphertext_0 = elgamal_keypair_0.pubkey().encrypt_with(amount, &opening);
let expected_pod_ciphertext_0: ElGamalCiphertext = expected_ciphertext_0.into();
let actual_pod_ciphertext_0 = pod_grouped_ciphertext.try_extract_ciphertext(0).unwrap();
assert_eq!(expected_pod_ciphertext_0, actual_pod_ciphertext_0);
let expected_ciphertext_1 = elgamal_keypair_1.pubkey().encrypt_with(amount, &opening);
let expected_pod_ciphertext_1: ElGamalCiphertext = expected_ciphertext_1.into();
let actual_pod_ciphertext_1 = pod_grouped_ciphertext.try_extract_ciphertext(1).unwrap();
assert_eq!(expected_pod_ciphertext_1, actual_pod_ciphertext_1);
⋮----
.try_extract_ciphertext(2)
.unwrap_err();
assert_eq!(err, ElGamalError::CiphertextDeserialization);
⋮----
fn test_3_handles_ciphertext_extraction() {
⋮----
elgamal_keypair_0.pubkey(),
elgamal_keypair_1.pubkey(),
elgamal_keypair_2.pubkey(),
⋮----
let pod_grouped_ciphertext: GroupedElGamalCiphertext3Handles = grouped_ciphertext.into();
⋮----
let expected_ciphertext_2 = elgamal_keypair_2.pubkey().encrypt_with(amount, &opening);
let expected_pod_ciphertext_2: ElGamalCiphertext = expected_ciphertext_2.into();
let actual_pod_ciphertext_2 = pod_grouped_ciphertext.try_extract_ciphertext(2).unwrap();
assert_eq!(expected_pod_ciphertext_2, actual_pod_ciphertext_2);
⋮----
.try_extract_ciphertext(3)

================
File: zk-token-sdk/src/zk_token_elgamal/pod/instruction.rs
================
pub struct TransferAmountCiphertext(pub GroupedElGamalCiphertext3Handles);
⋮----
fn from(decoded_ciphertext: decoded::TransferAmountCiphertext) -> Self {
Self(decoded_ciphertext.0.into())
⋮----
type Error = ElGamalError;
fn try_from(pod_ciphertext: TransferAmountCiphertext) -> Result<Self, Self::Error> {
Ok(Self(pod_ciphertext.0.try_into()?))
⋮----
pub struct FeeEncryption(pub GroupedElGamalCiphertext2Handles);
⋮----
fn from(decoded_ciphertext: decoded::FeeEncryption) -> Self {
⋮----
fn try_from(pod_ciphertext: FeeEncryption) -> Result<Self, Self::Error> {
⋮----
pub struct FeeParameters {
⋮----
fn from(decoded_fee_parameters: decoded::FeeParameters) -> Self {
⋮----
fee_rate_basis_points: decoded_fee_parameters.fee_rate_basis_points.into(),
maximum_fee: decoded_fee_parameters.maximum_fee.into(),
⋮----
fn from(pod_fee_parameters: FeeParameters) -> Self {
⋮----
fee_rate_basis_points: pod_fee_parameters.fee_rate_basis_points.into(),
maximum_fee: pod_fee_parameters.maximum_fee.into(),

================
File: zk-token-sdk/src/zk_token_elgamal/pod/mod.rs
================
mod auth_encryption;
mod elgamal;
mod grouped_elgamal;
mod instruction;
mod pedersen;
mod range_proof;
mod sigma_proofs;
⋮----
pub enum ParseError {
⋮----
pub struct PodU16([u8; 2]);
⋮----
fn from(n: u16) -> Self {
Self(n.to_le_bytes())
⋮----
fn from(pod: PodU16) -> Self {
⋮----
pub struct PodU64([u8; 8]);
⋮----
fn from(n: u64) -> Self {
⋮----
fn from(pod: PodU64) -> Self {
⋮----
pub struct PodProofType(u8);
⋮----
fn from(proof_type: ProofType) -> Self {
Self(ToPrimitive::to_u8(&proof_type).unwrap())
⋮----
type Error = InstructionError;
fn try_from(pod: PodProofType) -> Result<Self, Self::Error> {
FromPrimitive::from_u8(pod.0).ok_or(Self::Error::InvalidAccountData)
⋮----
pub struct CompressedRistretto(pub [u8; 32]);
macro_rules! impl_from_str {
⋮----
pub(crate) use impl_from_str;

================
File: zk-token-sdk/src/zk_token_elgamal/pod/pedersen.rs
================
pub struct PedersenCommitment(pub [u8; PEDERSEN_COMMITMENT_LEN]);
⋮----
fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
write!(f, "{:?}", self.0)
⋮----
fn from(decoded_commitment: decoded::PedersenCommitment) -> Self {
Self(decoded_commitment.to_bytes())
⋮----
fn from(pod_commitment: PedersenCommitment) -> Self {
Self(pod_commitment.0)
⋮----
type Error = ElGamalError;
fn try_from(pod_commitment: PedersenCommitment) -> Result<Self, Self::Error> {
Self::from_bytes(&pod_commitment.0).ok_or(ElGamalError::CiphertextDeserialization)

================
File: zk-token-sdk/src/zk_token_elgamal/pod/range_proof.rs
================
pub struct RangeProofU64(pub [u8; RANGE_PROOF_U64_LEN]);
⋮----
type Error = RangeProofVerificationError;
fn try_from(decoded_proof: decoded::RangeProof) -> Result<Self, Self::Error> {
if decoded_proof.ipp_proof.serialized_size() != INNER_PRODUCT_PROOF_U64_LEN {
return Err(RangeProofVerificationError::Deserialization);
⋮----
copy_range_proof_modulo_inner_product_proof(&decoded_proof, &mut buf);
⋮----
.copy_from_slice(&decoded_proof.ipp_proof.to_bytes());
Ok(RangeProofU64(buf))
⋮----
fn try_from(pod_proof: RangeProofU64) -> Result<Self, Self::Error> {
⋮----
pub struct RangeProofU128(pub [u8; RANGE_PROOF_U128_LEN]);
⋮----
if decoded_proof.ipp_proof.serialized_size() != INNER_PRODUCT_PROOF_U128_LEN {
⋮----
Ok(RangeProofU128(buf))
⋮----
fn try_from(pod_proof: RangeProofU128) -> Result<Self, Self::Error> {
⋮----
pub struct RangeProofU256(pub [u8; RANGE_PROOF_U256_LEN]);
⋮----
if decoded_proof.ipp_proof.serialized_size() != INNER_PRODUCT_PROOF_U256_LEN {
⋮----
Ok(RangeProofU256(buf))
⋮----
fn try_from(pod_proof: RangeProofU256) -> Result<Self, Self::Error> {
⋮----
fn copy_range_proof_modulo_inner_product_proof(proof: &decoded::RangeProof, buf: &mut [u8]) {
let mut chunks = buf.chunks_mut(UNIT_LEN);
chunks.next().unwrap().copy_from_slice(proof.A.as_bytes());
chunks.next().unwrap().copy_from_slice(proof.S.as_bytes());
chunks.next().unwrap().copy_from_slice(proof.T_1.as_bytes());
chunks.next().unwrap().copy_from_slice(proof.T_2.as_bytes());
chunks.next().unwrap().copy_from_slice(proof.t_x.as_bytes());
⋮----
.next()
.unwrap()
.copy_from_slice(proof.t_x_blinding.as_bytes());
⋮----
.copy_from_slice(proof.e_blinding.as_bytes());
⋮----
unsafe impl Zeroable for RangeProofU64 {}
unsafe impl Pod for RangeProofU64 {}
unsafe impl Zeroable for RangeProofU128 {}
unsafe impl Pod for RangeProofU128 {}
unsafe impl Zeroable for RangeProofU256 {}
unsafe impl Pod for RangeProofU256 {}

================
File: zk-token-sdk/src/zk_token_elgamal/pod/sigma_proofs.rs
================
pub struct CiphertextCommitmentEqualityProof(pub [u8; CIPHERTEXT_COMMITMENT_EQUALITY_PROOF_LEN]);
⋮----
fn from(decoded_proof: DecodedCiphertextCommitmentEqualityProof) -> Self {
Self(decoded_proof.to_bytes())
⋮----
type Error = EqualityProofVerificationError;
fn try_from(pod_proof: CiphertextCommitmentEqualityProof) -> Result<Self, Self::Error> {
⋮----
pub struct CiphertextCiphertextEqualityProof(pub [u8; CIPHERTEXT_CIPHERTEXT_EQUALITY_PROOF_LEN]);
⋮----
fn from(decoded_proof: DecodedCiphertextCiphertextEqualityProof) -> Self {
⋮----
fn try_from(pod_proof: CiphertextCiphertextEqualityProof) -> Result<Self, Self::Error> {
⋮----
pub struct GroupedCiphertext2HandlesValidityProof(
⋮----
fn from(decoded_proof: DecodedGroupedCiphertext2HandlesValidityProof) -> Self {
⋮----
type Error = ValidityProofVerificationError;
fn try_from(pod_proof: GroupedCiphertext2HandlesValidityProof) -> Result<Self, Self::Error> {
⋮----
pub struct GroupedCiphertext3HandlesValidityProof(
⋮----
fn from(decoded_proof: DecodedGroupedCiphertext3HandlesValidityProof) -> Self {
⋮----
fn try_from(pod_proof: GroupedCiphertext3HandlesValidityProof) -> Result<Self, Self::Error> {
⋮----
pub struct BatchedGroupedCiphertext2HandlesValidityProof(
⋮----
fn from(decoded_proof: DecodedBatchedGroupedCiphertext2HandlesValidityProof) -> Self {
⋮----
fn try_from(
⋮----
pub struct BatchedGroupedCiphertext3HandlesValidityProof(
⋮----
fn from(decoded_proof: DecodedBatchedGroupedCiphertext3HandlesValidityProof) -> Self {
⋮----
pub struct ZeroBalanceProof(pub [u8; ZERO_BALANCE_PROOF_LEN]);
⋮----
fn from(decoded_proof: DecodedZeroBalanceProof) -> Self {
⋮----
type Error = ZeroBalanceProofVerificationError;
fn try_from(pod_proof: ZeroBalanceProof) -> Result<Self, Self::Error> {
⋮----
pub struct FeeSigmaProof(pub [u8; FEE_SIGMA_PROOF_LEN]);
⋮----
fn from(decoded_proof: DecodedFeeSigmaProof) -> Self {
⋮----
type Error = FeeSigmaProofVerificationError;
fn try_from(pod_proof: FeeSigmaProof) -> Result<Self, Self::Error> {
⋮----
pub struct PubkeyValidityProof(pub [u8; PUBKEY_VALIDITY_PROOF_LEN]);
⋮----
fn from(decoded_proof: DecodedPubkeyValidityProof) -> Self {
⋮----
type Error = PubkeyValidityProofVerificationError;
fn try_from(pod_proof: PubkeyValidityProof) -> Result<Self, Self::Error> {
⋮----
unsafe impl Zeroable for CiphertextCommitmentEqualityProof {}
unsafe impl Pod for CiphertextCommitmentEqualityProof {}
unsafe impl Zeroable for CiphertextCiphertextEqualityProof {}
unsafe impl Pod for CiphertextCiphertextEqualityProof {}
unsafe impl Zeroable for GroupedCiphertext2HandlesValidityProof {}
unsafe impl Pod for GroupedCiphertext2HandlesValidityProof {}
unsafe impl Zeroable for GroupedCiphertext3HandlesValidityProof {}
unsafe impl Pod for GroupedCiphertext3HandlesValidityProof {}
unsafe impl Zeroable for BatchedGroupedCiphertext2HandlesValidityProof {}
unsafe impl Pod for BatchedGroupedCiphertext2HandlesValidityProof {}
unsafe impl Zeroable for BatchedGroupedCiphertext3HandlesValidityProof {}
unsafe impl Pod for BatchedGroupedCiphertext3HandlesValidityProof {}
unsafe impl Zeroable for ZeroBalanceProof {}
unsafe impl Pod for ZeroBalanceProof {}

================
File: zk-token-sdk/src/zk_token_elgamal/convert.rs
================
fn from((commitment, handle): (pod::PedersenCommitment, pod::DecryptHandle)) -> Self {
⋮----
buf[..32].copy_from_slice(&commitment.0);
buf[32..].copy_from_slice(&handle.0);
⋮----
fn from(ciphertext: pod::ElGamalCiphertext) -> Self {
let commitment: [u8; 32] = ciphertext.0[..32].try_into().unwrap();
let handle: [u8; 32] = ciphertext.0[32..].try_into().unwrap();
⋮----
fn from(commitment: pod::PedersenCommitment) -> Self {
PodRistrettoPoint(commitment.0)
⋮----
fn from(point: PodRistrettoPoint) -> Self {
⋮----
fn from(handle: pod::DecryptHandle) -> Self {
PodRistrettoPoint(handle.0)
⋮----
mod target_arch {
⋮----
fn from(cr: CompressedRistretto) -> Self {
Self(cr.to_bytes())
⋮----
fn from(pod: pod::CompressedRistretto) -> Self {
Self(pod.0)
⋮----
mod target_arch {}
⋮----
mod tests {
⋮----
fn test_pod_range_proof_64() {
⋮----
RangeProof::new(vec![55], vec![64], vec![&open], &mut transcript_create).unwrap();
let proof_serialized: pod::RangeProofU64 = proof.try_into().unwrap();
let proof_deserialized: RangeProof = proof_serialized.try_into().unwrap();
assert!(proof_deserialized
⋮----
assert!(TryInto::<pod::RangeProofU128>::try_into(proof).is_err());
⋮----
fn test_pod_range_proof_128() {
⋮----
vec![55, 77, 99],
vec![64, 32, 32],
vec![&open_1, &open_2, &open_3],
⋮----
.unwrap();
let proof_serialized: pod::RangeProofU128 = proof.try_into().unwrap();
⋮----
assert!(TryInto::<pod::RangeProofU64>::try_into(proof).is_err());

================
File: zk-token-sdk/src/zk_token_elgamal/decryption.rs
================
pub fn decrypt(self, secret_key: &ElGamalSecretKey) -> Option<u64> {
let deserialized_ciphertext: Option<ElGamalCiphertext> = self.try_into().ok();
⋮----
ciphertext.decrypt_u32(secret_key)
⋮----
mod tests {
⋮----
fn test_pod_decryption() {
⋮----
assert_eq!(pod_ciphertext.decrypt(keypair.secret()).unwrap(), 0);
⋮----
let ciphertext = keypair.pubkey().encrypt(amount);
let pod_ciphertext: pod::ElGamalCiphertext = ciphertext.into();
assert_eq!(pod_ciphertext.decrypt(keypair.secret()).unwrap(), 55);

================
File: zk-token-sdk/src/zk_token_elgamal/mod.rs
================
pub mod convert;
pub mod decryption;
pub mod ops;
pub mod pod;

================
File: zk-token-sdk/src/zk_token_elgamal/ops.rs
================
const G: PodRistrettoPoint = PodRistrettoPoint([
⋮----
pub fn add(
⋮----
(*left_ciphertext).into();
⋮----
(*right_ciphertext).into();
⋮----
add_ristretto(&left_commitment.into(), &right_commitment.into())?.into();
⋮----
add_ristretto(&left_handle.into(), &right_handle.into())?.into();
Some((result_commitment, result_handle).into())
⋮----
pub fn multiply(
⋮----
let (commitment, handle): (pod::PedersenCommitment, pod::DecryptHandle) = (*ciphertext).into();
let commitment_point: PodRistrettoPoint = commitment.into();
let handle_point: PodRistrettoPoint = handle.into();
⋮----
multiply_ristretto(scalar, &commitment_point)?.into();
let result_handle: pod::DecryptHandle = multiply_ristretto(scalar, &handle_point)?.into();
⋮----
pub fn add_with_lo_hi(
⋮----
let shift_scalar = to_scalar(1_u64 << SHIFT_BITS);
let shifted_right_ciphertext_hi = multiply(&shift_scalar, right_ciphertext_hi)?;
let combined_right_ciphertext = add(right_ciphertext_lo, &shifted_right_ciphertext_hi)?;
add(left_ciphertext, &combined_right_ciphertext)
⋮----
pub fn subtract(
⋮----
subtract_ristretto(&left_commitment.into(), &right_commitment.into())?.into();
⋮----
subtract_ristretto(&left_handle.into(), &right_handle.into())?.into();
⋮----
pub fn subtract_with_lo_hi(
⋮----
subtract(left_ciphertext, &combined_right_ciphertext)
⋮----
pub fn add_to(ciphertext: &pod::ElGamalCiphertext, amount: u64) -> Option<pod::ElGamalCiphertext> {
let amount_scalar = to_scalar(amount);
let amount_point = multiply_ristretto(&amount_scalar, &G)?;
⋮----
add_ristretto(&commitment_point, &amount_point)?.into();
Some((result_commitment, handle).into())
⋮----
pub fn subtract_from(
⋮----
subtract_ristretto(&commitment_point, &amount_point)?.into();
⋮----
fn to_scalar(amount: u64) -> PodScalar {
⋮----
bytes[..8].copy_from_slice(&amount.to_le_bytes());
PodScalar(bytes)
⋮----
mod tests {
⋮----
fn test_zero_ct() {
⋮----
let spendable_ct: ElGamalCiphertext = spendable_balance.try_into().unwrap();
⋮----
let public = keypair.pubkey();
⋮----
assert_eq!(
⋮----
let transfer_amount_ct = public.encrypt_with(55_u64, &open);
let transfer_amount_pod: pod::ElGamalCiphertext = transfer_amount_ct.into();
let sum = ops::add(&spendable_balance, &transfer_amount_pod).unwrap();
let expected: pod::ElGamalCiphertext = public.encrypt_with(55_u64, &open).into();
assert_eq!(expected, sum);
⋮----
fn test_add_to() {
⋮----
let added_ct = ops::add_to(&spendable_balance, 55).unwrap();
⋮----
.encrypt_with(55_u64, &PedersenOpening::default())
.into();
assert_eq!(expected, added_ct);
⋮----
fn test_subtract_from() {
⋮----
let encrypted_amount: pod::ElGamalCiphertext = public.encrypt_with(amount, &open).into();
let subtracted_ct = ops::subtract_from(&encrypted_amount, 55).unwrap();
let expected: pod::ElGamalCiphertext = public.encrypt_with(22_u64, &open).into();
assert_eq!(expected, subtracted_ct);
⋮----
fn test_transfer_arithmetic() {
⋮----
let (amount_lo, amount_hi) = try_split_u64(transfer_amount, 16).unwrap();
⋮----
let source_pk = source_keypair.pubkey();
⋮----
let dest_pk = dest_keypair.pubkey();
⋮----
let auditor_pk = auditor_keypair.pubkey();
⋮----
let comm_lo: pod::PedersenCommitment = comm_lo.into();
let comm_hi: pod::PedersenCommitment = comm_hi.into();
let handle_source_lo: pod::DecryptHandle = source_pk.decrypt_handle(&open_lo).into();
let handle_dest_lo: pod::DecryptHandle = dest_pk.decrypt_handle(&open_lo).into();
let _handle_auditor_lo: pod::DecryptHandle = auditor_pk.decrypt_handle(&open_lo).into();
let handle_source_hi: pod::DecryptHandle = source_pk.decrypt_handle(&open_hi).into();
let handle_dest_hi: pod::DecryptHandle = dest_pk.decrypt_handle(&open_hi).into();
let _handle_auditor_hi: pod::DecryptHandle = auditor_pk.decrypt_handle(&open_hi).into();
⋮----
source_pk.encrypt_with(77_u64, &source_open).into();
⋮----
dest_pk.encrypt_with(77_u64, &dest_open).into();
let source_lo_ct: pod::ElGamalCiphertext = (comm_lo, handle_source_lo).into();
let source_hi_ct: pod::ElGamalCiphertext = (comm_hi, handle_source_hi).into();
⋮----
ops::subtract_with_lo_hi(&source_spendable_ct, &source_lo_ct, &source_hi_ct).unwrap();
⋮----
source_open - (open_lo.clone() + open_hi.clone() * Scalar::from(TWO_16));
⋮----
source_pk.encrypt_with(22_u64, &final_source_open).into();
assert_eq!(expected_source, final_source_spendable);
let dest_lo_ct: pod::ElGamalCiphertext = (comm_lo, handle_dest_lo).into();
let dest_hi_ct: pod::ElGamalCiphertext = (comm_hi, handle_dest_hi).into();
⋮----
ops::add_with_lo_hi(&dest_pending_ct, &dest_lo_ct, &dest_hi_ct).unwrap();
⋮----
dest_pk.encrypt_with(132_u64, &final_dest_open).into();
assert_eq!(expected_dest_ct, final_dest_pending);

================
File: zk-token-sdk/src/errors.rs
================
use crate::range_proof::errors::RangeProofGenerationError;
⋮----
pub enum ElGamalError {
⋮----
pub enum AuthenticatedEncryptionError {
⋮----
pub enum ProofGenerationError {
⋮----
pub enum ProofVerificationError {
⋮----
pub enum SigmaProofType {
⋮----
pub enum TranscriptError {
⋮----
fn from(err: EqualityProofVerificationError) -> Self {
⋮----
fn from(err: FeeSigmaProofVerificationError) -> Self {
⋮----
fn from(err: ZeroBalanceProofVerificationError) -> Self {
⋮----
fn from(err: ValidityProofVerificationError) -> Self {
⋮----
fn from(err: PubkeyValidityProofVerificationError) -> Self {

================
File: zk-token-sdk/src/lib.rs
================
pub(crate) mod macros;
⋮----
pub mod encryption;
mod range_proof;
mod sigma_proofs;
⋮----
mod transcript;
pub mod errors;
pub mod instruction;
pub mod zk_token_elgamal;
pub mod zk_token_proof_instruction;
pub mod zk_token_proof_program;
pub mod zk_token_proof_state;
⋮----
pub use curve25519_dalek;

================
File: zk-token-sdk/src/macros.rs
================
macro_rules! define_add_variants {
⋮----
macro_rules! define_sub_variants {
⋮----
macro_rules! define_mul_variants {

================
File: zk-token-sdk/src/transcript.rs
================
pub trait TranscriptProtocol {
⋮----
/// Append a `point` with the given `label`.
    fn append_point(&mut self, label: &'static [u8], point: &CompressedRistretto);
⋮----
/// Append an ElGamal ciphertext with the given `label`.
    fn append_ciphertext(&mut self, label: &'static [u8], point: &pod::ElGamalCiphertext);
⋮----
/// Append a grouped ElGamal ciphertext with 3 handles with the given `label`.
    fn append_grouped_ciphertext_3_handles(
⋮----
/// Append an ElGamal decryption handle with the given `label`.
    fn append_handle(&mut self, label: &'static [u8], point: &pod::DecryptHandle);
⋮----
/// Compute a `label`ed challenge variable.
    fn challenge_scalar(&mut self, label: &'static [u8]) -> Scalar;
⋮----
impl TranscriptProtocol for Transcript {
fn rangeproof_from_key_domain_separator(&mut self, n: u64) {
self.append_message(b"dom-sep", b"rangeproof from opening v1");
self.append_u64(b"n", n);
⋮----
fn rangeproof_from_opening_domain_separator(&mut self, n: u64) {
⋮----
fn innerproduct_domain_separator(&mut self, n: u64) {
self.append_message(b"dom-sep", b"ipp v1");
⋮----
fn close_account_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"CloseAccountProof");
⋮----
fn withdraw_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"WithdrawProof");
⋮----
fn transfer_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"TransferProof");
⋮----
fn append_scalar(&mut self, label: &'static [u8], scalar: &Scalar) {
self.append_message(label, scalar.as_bytes());
⋮----
fn append_point(&mut self, label: &'static [u8], point: &CompressedRistretto) {
self.append_message(label, point.as_bytes());
⋮----
fn validate_and_append_point(
⋮----
if point.is_identity() {
Err(TranscriptError::ValidationError)
⋮----
Ok(())
⋮----
fn challenge_scalar(&mut self, label: &'static [u8]) -> Scalar {
⋮----
self.challenge_bytes(label, &mut buf);
⋮----
fn append_pubkey(&mut self, label: &'static [u8], pubkey: &pod::ElGamalPubkey) {
self.append_message(label, &pubkey.0);
⋮----
fn append_ciphertext(&mut self, label: &'static [u8], ciphertext: &pod::ElGamalCiphertext) {
self.append_message(label, &ciphertext.0);
⋮----
fn append_grouped_ciphertext_2_handles(
⋮----
self.append_message(label, &grouped_ciphertext.0);
⋮----
fn append_grouped_ciphertext_3_handles(
⋮----
fn append_commitment(&mut self, label: &'static [u8], commitment: &pod::PedersenCommitment) {
self.append_message(label, &commitment.0);
⋮----
fn append_handle(&mut self, label: &'static [u8], handle: &pod::DecryptHandle) {
self.append_message(label, &handle.0);
⋮----
fn equality_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"equality-proof")
⋮----
fn zero_balance_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"zero-balance-proof")
⋮----
fn grouped_ciphertext_validity_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"validity-proof")
⋮----
fn batched_grouped_ciphertext_validity_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"batched-validity-proof")
⋮----
fn fee_sigma_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"fee-sigma-proof")
⋮----
fn pubkey_proof_domain_separator(&mut self) {
self.append_message(b"dom-sep", b"pubkey-proof")

================
File: zk-token-sdk/src/zk_token_proof_instruction.rs
================
pub enum ProofInstruction {
⋮----
pub struct ContextStateInfo<'a> {
⋮----
pub fn close_context_state(
⋮----
let accounts = vec![
⋮----
let data = vec![ToPrimitive::to_u8(&ProofInstruction::CloseContextState).unwrap()];
⋮----
pub fn verify_zero_balance(
⋮----
ProofInstruction::VerifyZeroBalance.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_withdraw(
⋮----
ProofInstruction::VerifyWithdraw.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_ciphertext_ciphertext_equality(
⋮----
.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_transfer(
⋮----
ProofInstruction::VerifyTransfer.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_transfer_with_fee(
⋮----
ProofInstruction::VerifyTransferWithFee.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_pubkey_validity(
⋮----
ProofInstruction::VerifyPubkeyValidity.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_range_proof_u64(
⋮----
ProofInstruction::VerifyRangeProofU64.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_batched_verify_range_proof_u64(
⋮----
ProofInstruction::VerifyBatchedRangeProofU64.encode_verify_proof(context_state_info, proof_data)
⋮----
pub fn verify_batched_verify_range_proof_u128(
⋮----
pub fn verify_batched_verify_range_proof_u256(
⋮----
pub fn verify_ciphertext_commitment_equality(
⋮----
pub fn verify_grouped_ciphertext_3_handles_validity(
⋮----
pub fn verify_batched_grouped_ciphertext_3_handles_validity(
⋮----
impl ProofInstruction {
pub fn encode_verify_proof<T, U>(
⋮----
vec![
⋮----
vec![]
⋮----
let mut data = vec![ToPrimitive::to_u8(self).unwrap()];
data.extend_from_slice(bytes_of(proof_data));
⋮----
pub fn encode_verify_proof_from_account(
⋮----
vec![AccountMeta::new(*proof_account, false)]
⋮----
data.extend_from_slice(&offset.to_le_bytes());
⋮----
pub fn instruction_type(input: &[u8]) -> Option<Self> {
⋮----
.first()
.and_then(|instruction| FromPrimitive::from_u8(*instruction))
⋮----
pub fn proof_data<T, U>(input: &[u8]) -> Option<&T>
⋮----
.get(1..)
.and_then(|data| bytemuck::try_from_bytes(data).ok())

================
File: zk-token-sdk/src/zk_token_proof_program.rs
================


================
File: zk-token-sdk/src/zk_token_proof_state.rs
================
pub struct ProofContextState<T: Pod> {
⋮----
unsafe impl<T: Pod> Zeroable for ProofContextState<T> {}
unsafe impl<T: Pod> Pod for ProofContextState<T> {}
⋮----
pub fn encode(
⋮----
buf.extend_from_slice(context_state_authority.as_ref());
buf.push(ToPrimitive::to_u8(&proof_type).unwrap());
buf.extend_from_slice(bytes_of(proof_context));
⋮----
pub fn try_from_bytes(input: &[u8]) -> Result<&Self, InstructionError> {
bytemuck::try_from_bytes(input).map_err(|_| InvalidAccountData)
⋮----
pub struct ProofContextStateMeta {
⋮----
impl ProofContextStateMeta {
⋮----
.get(..size_of::<ProofContextStateMeta>())
.and_then(|data| bytemuck::try_from_bytes(data).ok())
.ok_or(InvalidAccountData)

================
File: zk-token-sdk/.gitignore
================
/farf/

================
File: zk-token-sdk/Cargo.toml
================
[package]
name = "solana-zk-token-sdk"
description = "Solana Zk Token SDK"
documentation = "https://docs.rs/solana-zk-token-sdk"
version = { workspace = true }
authors = { workspace = true }
repository = { workspace = true }
homepage = { workspace = true }
license = { workspace = true }
edition = { workspace = true }

[lib]
crate-type = ["cdylib", "rlib"]

[features]
agave-unstable-api = []

[dependencies]
base64 = { workspace = true }
bytemuck = { workspace = true }
bytemuck_derive = { workspace = true }
num-derive = { workspace = true }
num-traits = { workspace = true }
solana-curve25519 = { workspace = true }
solana-instruction = { workspace = true, features = ["std"] }
solana-pubkey = { workspace = true, features = ["bytemuck"] }
solana-sdk-ids = { workspace = true }
thiserror = { workspace = true }

[target.'cfg(not(target_os = "solana"))'.dependencies]
aes-gcm-siv = { workspace = true }
bincode = { workspace = true }
curve25519-dalek = { workspace = true, features = ["serde"] }
itertools = { workspace = true }
merlin = { workspace = true }
rand = "0.8.5"
serde = { workspace = true }
serde_json = { workspace = true }
sha3 = { workspace = true }
solana-derivation-path = { workspace = true }
solana-seed-derivable = { workspace = true }
solana-seed-phrase = { workspace = true }
solana-signature = { workspace = true }
solana-signer = { workspace = true }
subtle = { workspace = true }
zeroize = { workspace = true, features = ["zeroize_derive"] }

[dev-dependencies]
solana-keypair = { workspace = true }
tiny-bip39 = { workspace = true }

[lints]
workspace = true

================
File: zk-token-sdk/README.md
================
# zk-token-sdk (DEPRECATED)

**This crate is deprecated and no longer maintained.**

This crate has been replaced by the [zk-sdk](https://github.com/solana-program/zk-elgamal-proof) crate.

For the latest updates and features, please use the new crate.





================================================================
End of Codebase
================================================================
